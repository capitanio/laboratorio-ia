{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Elaborazione del Linguaggio Naturale {#sec-nlp}\n",
        "\n",
        "## Laboratorio di Python\n",
        "\n",
        "### Esperimento 1: Introduzione ai Word Embeddings\n",
        "\n",
        "In questo esperimento vogliamo implementare i word embedding in maniera semplificata e intuitiva per cercare di capire le notevoli proprietà che riescono a esprimere.\n",
        "I *word embeddings* sono vettori numerici. Qui li rappresentiamo in 3D con assi per *regalità*, *genere* ed *età* per parole come \"re\", \"regina\", ecc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "# Word embeddings semplificati\n",
        "word_embeddings = {\n",
        "    \"re\": [5.0, 5.0, 5.0],\n",
        "    \"regina\": [5.0, -5.0, 5.0],\n",
        "    \"principe\": [3.0, 5.0, 2.0],\n",
        "    \"principessa\": [3.0, -5.0, 2.0],\n",
        "    \"uomo\": [1.0, 5.0, 5.0],\n",
        "    \"donna\": [1.0, -5.0, 5.0]\n",
        "}\n",
        "\n",
        "words = list(word_embeddings.keys())\n",
        "embeddings = list(word_embeddings.values())\n",
        "\n",
        "# Grafico 3D\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "x = [emb[0] for emb in embeddings]\n",
        "y = [emb[1] for emb in embeddings]\n",
        "z = [emb[2] for emb in embeddings]\n",
        "ax.scatter(x, y, z, s=100)\n",
        "for i, word in enumerate(words):\n",
        "    ax.text(embeddings[i][0], embeddings[i][1], embeddings[i][2], word)\n",
        "ax.set_xlabel('Regalità')\n",
        "ax.set_ylabel('Genere')\n",
        "ax.set_zlabel('Età')\n",
        "ax.set_title('Visualizzazione 3D dei Word Embeddings')\n",
        "ax.view_init(elev=20, azim=7)\n",
        "plt.show()\n",
        "\n",
        "# Distanza coseno\n",
        "def distanza_coseno(vec1, vec2):\n",
        "    prodotto_scalare = np.dot(vec1, vec2)\n",
        "    norma_vec1 = np.linalg.norm(vec1)\n",
        "    norma_vec2 = np.linalg.norm(vec2)\n",
        "    return 1 - (prodotto_scalare / (norma_vec1 * norma_vec2))\n",
        "\n",
        "# Matrice delle distanze\n",
        "n_words = len(words)\n",
        "matrice_distanze = [[0.0] * n_words for _ in range(n_words)]\n",
        "for i in range(n_words):\n",
        "    for j in range(n_words):\n",
        "        matrice_distanze[i][j] = distanza_coseno(embeddings[i], embeddings[j])\n",
        "\n",
        "# Visualizzazione\n",
        "print(\"Matrice delle distanze coseno:\")\n",
        "print(\"          \", end=\"\")\n",
        "for word in words:\n",
        "    print(f\"{word:>10}\", end=\"\")\n",
        "print()\n",
        "for i, word1 in enumerate(words):\n",
        "    print(f\"{word1:10}\", end=\"\")\n",
        "    for j in range(n_words):\n",
        "        print(f\"{matrice_distanze[i][j]:10.3f}\", end=\"\")\n",
        "    print()\n",
        "\n",
        "# Calcolo di \"regina\"\n",
        "def sottrai_vec(vec1, vec2):\n",
        "    return np.array(vec1) - np.array(vec2)\n",
        "def somma_vec(vec1, vec2):\n",
        "    return np.array(vec1) + np.array(vec2)\n",
        "\n",
        "print(\"Word embedding di regina:\")\n",
        "print(word_embeddings[\"regina\"])\n",
        "print(\"Word embedding calcolato: regina = re - uomo + donna\")\n",
        "print(somma_vec(sottrai_vec(word_embeddings[\"re\"], word_embeddings[\"uomo\"]), word_embeddings[\"donna\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I risulrari numerici dell'esperimento ci mostrano che anche se in una versione molto semplificata, i word embedding sono in grado di esprimere proprietà come la regalità, il genere e l'età.\n",
        "Infatti si noti come sottraendo a **re** **uomo** si ottiene la regalità che può essere sommata a **donna** per ottenere **regina**.\n",
        "\n",
        "### Esperimento 2: Analisi del Sentiment\n",
        "\n",
        "In questo esperimento vogliamo stimare il sentiment (molto negativo, negativo, neutrale, positivo, molto positivo) di un frammento di testo. \n",
        "A questo scopo usiamo un modello addestrato su più lingue per stimare il sentiment in frammenti di testo in Italiano e Giapponese.Il modello prescelto è tabularisai/multilingual-sentiment-analysis di Hugging Face.\n",
        "\n",
        "::: {.callout-caution}\n",
        "Nota: Richiede pip install transformers e una connessione per scaricare il modello.\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Pipeline con modello multilingue\n",
        "pipe = pipeline(\"text-classification\", model=\"tabularisai/multilingual-sentiment-analysis\")\n",
        "\n",
        "# Testo in Italiano\n",
        "frase = \"Questo prodotto non è fatto bene.\"\n",
        "risultato = pipe(frase)\n",
        "print(frase)\n",
        "print(risultato)\n",
        "\n",
        "# Testo tradotto in Giapponese \n",
        "frase = \"この製品はよく作られていません。\"\n",
        "risultato = pipe(frase)\n",
        "print(frase)\n",
        "print(risultato)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'output dell'esperimento ci dice che entrambre le frasi sono considerate negative.\n",
        "Si noti come la frase in Giapponese sia la traduzione della frase in Italiano fatta da un traduttore basato su LLM e non mostrato in questo esempio.\n",
        "\n",
        "### Esperimento 3: Sistema di Domanda-Risposta su un Testo Giuridico\n",
        "\n",
        "In questo esperimento vogliamo implementare un semplicissimo sistema che ci consenta di di dialogare con un breve testo giuridico. Facendo domande e ottenendo risposte sui contenuti del testo.Il modello adottato è \"deepset/roberta-base-squad2\" sempre da Hugging Faceper rispondere a domande su un testo giuridico.\n",
        "\n",
        "::: {.callout-caution}\n",
        "Nota: Richiede pip install transformers e una connessione per scaricare il modello.\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Pipeline per question answering\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Contesto giuridico\n",
        "contesto = \"\"\"\n",
        "L'articolo 3 della Costituzione italiana stabilisce che tutti i cittadini hanno pari dignità sociale e sono eguali davanti alla legge,\n",
        "senza distinzione di sesso, razza, lingua, religione, opinioni politiche, condizioni personali e sociali.\n",
        "È compito della Repubblica rimuovere gli ostacoli di ordine economico e sociale che,\n",
        "limitando di fatto la libertà e l'eguaglianza dei cittadini, impediscono il pieno sviluppo della persona umana.\n",
        "\"\"\"\n",
        "\n",
        "# Domande\n",
        "domanda1 = \"Qual è il compito della Repubblica?\"\n",
        "risultato1 = qa_pipeline(question=domanda1, context=contesto)\n",
        "print(f\"Domanda: {domanda1}\")\n",
        "print(f\"Risposta: {risultato1['answer']}\\n\")\n",
        "\n",
        "domanda2 = \"Chi ha pari dignità sociale?\"\n",
        "risultato2 = qa_pipeline(question=domanda2, context=contesto)\n",
        "print(f\"Domanda: {domanda2}\")\n",
        "print(f\"Risposta: {risultato2['answer']}\\n\")\n",
        "\n",
        "domanda3 = \"Quale articolo della Costituzione stabilisce che tutti i cittadini hanno pari dignità sociale?\"\n",
        "risultato3 = qa_pipeline(question=domanda3, context=contesto)\n",
        "print(f\"Domanda: {domanda3}\")\n",
        "print(f\"Risposta: {risultato3['answer']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dall'output dell'esperimento possiamo vedere che il sistema è in grado di rispondere a domande sul testo giuridico. Ovviamente il sistema non è in grado di rispondere a domande il cui oggetto non è specificato nel testo. Inoltre, la brevità del testo usata non consente di rispondere a domande che richiedono un'analisi più approfondita."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "C:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
