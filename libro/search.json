[
  {
    "objectID": "2-algoritmi.html",
    "href": "2-algoritmi.html",
    "title": "Algoritmi",
    "section": "",
    "text": "Inferenza Logica\nL‚Äôinferenza logica √® un processo fondamentale nel campo della logica, della matematica e della filosofia, utilizzato per derivare conclusioni a partire da premesse o informazioni date. Questo processo pu√≤ essere visto come un mezzo per scoprire nuove verit√† o per confermare la validit√† di affermazioni esistenti. L‚Äôinferenza logica si suddivide principalmente in due categorie: deduttiva e induttiva.\nL‚Äôinferenza deduttiva √® quella in cui la conclusione deriva necessariamente dalle premesse; se le premesse sono vere, la conclusione non pu√≤ che essere vera. Un classico esempio di inferenza deduttiva √® il sillogismo: ‚ÄúTutti gli uomini sono mortali; Socrate √® un uomo; quindi, Socrate √® mortale.‚Äù In questo caso, la verit√† delle premesse garantisce la verit√† della conclusione.\nL‚Äôinferenza induttiva, invece, opera diversamente: partendo da osservazioni specifiche o da una serie di dati, arriva a conclusioni pi√π generali, che non sono necessariamente certe ma probabili. Ad esempio, se si osserva che il sole √® sorto ogni giorno, si potrebbe inferire che il sole sorger√† anche domani. Questa forma di inferenza √® molto utilizzata nella scienza, dove gli scienziati formulano ipotesi basate su dati osservati e sperimentali.\nUn altro tipo di inferenza logica √® l‚Äôabduzione, che implica la formazione della migliore spiegazione possibile data un insieme di osservazioni. Questo tipo di inferenza √® spesso utilizzato nella diagnosi medica, nella ricerca scientifica e nelle indagini criminali, dove si cerca di spiegare i dati osservati nel modo pi√π coerente possibile.\nL‚Äôinferenza logica √® strettamente legata al concetto di validit√† e di correttezza degli argomenti. Un‚Äôargomentazione √® valida se la sua struttura logica √® tale che, qualora le premesse siano vere, anche la conclusione deve essere vera. Tuttavia, un‚Äôargomentazione pu√≤ essere valida senza essere corretta; per essere corretta, deve avere anche premesse vere. Ad esempio, l‚Äôargomentazione ‚ÄúTutti gli unicorni sono verdi; io possiedo un unicorno; quindi, il mio unicorno √® verde‚Äù √® valida dal punto di vista logico, ma non √® corretta perch√© le premesse non sono vere.\nL‚Äôinferenza logica √® alla base di molti sistemi di intelligenza artificiale e di calcolo automatico, dove gli algoritmi vengono progettati per inferire nuove informazioni a partire da dati iniziali. Nei sistemi esperti, per esempio, vengono utilizzate regole di inferenza per simulare il processo decisionale umano. In conclusione, l‚Äôinferenza logica √® uno strumento potente e versatile che permea molte aree del pensiero umano e della tecnologia, consentendo di avanzare nella conoscenza e nella comprensione del mondo che ci circonda. L‚Äôinferenza logica √® una tecnica fondamentale dell‚Äôintelligenza artificiale che utilizza le regole logiche per derivare nuove informazioni da quelle esistenti. Nella giurisprudenza, l‚Äôinferenza logica pu√≤ essere utilizzata per analizzare le leggi e determinare le conseguenze logiche delle azioni legali.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algoritmi</span>"
    ]
  },
  {
    "objectID": "2-algoritmi.html#inferenza-logica",
    "href": "2-algoritmi.html#inferenza-logica",
    "title": "Algoritmi",
    "section": "",
    "text": "definizione Treccani: inferenza logica sinonimo di ¬´argomentazione logica¬ª utilizzato per designare il processo di deduzione di una formula A, detta conclusione, a partire da una o pi√π formule, dette premesse. Secondo A. De Morgan, una inferenza √® la ¬´produzione di una proposizione come conseguenza necessaria di una o pi√π proposizioni¬ª.\n\n\n\n\n\n\n\n\nI sistemi esperti - Negli anni ‚Äô80, l‚Äôinferenza logica √® stata fondamentale nello sviluppo dei sistemi esperti, strumenti avanzati di intelligenza artificiale progettati per risolvere problemi complessi emulando il ragionamento umano. Due noti prodotti commerciali di quel periodo sono stati MYCIN, un sistema esperto per la diagnosi di infezioni del sangue, e XCON, utilizzato per configurare sistemi di computer VAX di Digital Equipment Corporation. MYCIN e XCON sfruttavano regole di inferenza per elaborare informazioni e fornire raccomandazioni o soluzioni, dimostrando l‚Äôefficacia dell‚Äôinferenza logica in applicazioni pratiche e commerciali &gt; - ‚ÄúRule-based Expert Systems : The MYCIN Experiments of the Stanford Heuristic Programming Project‚Äù, edited by Bruce G. Buchanan, Edward H. Shortliffe (AddisonWesley, 1984) - ‚ÄúRI: an Expert in the Computer Systems Domain‚Äù\n\n\nProposizioni Logiche\nLe proposizioni logiche sono dichiarazioni atomiche che possono essere valutate come vere o false. Le proposizioni possono essere combinate utilizzando operatori logici come AND, OR, NOT, IMPLIES, che permettono di costruire regole complesse rappresentate da formule logiche.\nEcco alcuni esempi di proposizioni logiche:\np: ‚ÄúIl sole √® luminoso‚Äù (Vero) q: ‚ÄúLa Luna √® fatta di formaggio‚Äù (Falso) r: ‚ÄúSe piove, allora la strada sar√† bagnata‚Äù (Condizionale)\n\n\nCalcolo delle Proposizioni Logiche\nLe proposizioni logiche possono essere manipolate utilizzando vari operatori logici che eseguono operazioni specifiche:\nCongiunzione (AND - ‚àß): L‚Äôoperatore AND restituisce vero solo quando entrambe le proposizioni coinvolte sono vere. Ad esempio, se abbiamo due proposizioni p e q, p ‚àß q √® vero solo se entrambe p e q sono vere. La cosidetta tabella di verit√† riportata qui sotto consente di vedere come funziona l‚Äôoperatore AD.\n\nTavola della verit√† per la congiunzione\n\n\np\nq\np ‚àß q\n\n\n\n\nFalse\nFalse\nFalse\n\n\nFalse\nTrue\nFalse\n\n\nTrue\nFalse\nFalse\n\n\nTrue\nTrue\nTrue\n\n\n\nDisgiunzione (OR - ‚à®): L‚Äôoperatore OR restituisce vero se almeno una delle due proposizioni coinvolte √® vera. Ad esempio, p ‚à® q √® vero se p √® vero oppure se q √® vero oppure se entrambi sono veri. La tabella di verit√† riportata qui sotto consente di vedere come funziona l‚Äôoperatore OR.\n\nTavola della verit√† per la disgiunzione\n\n\np\nq\np ‚à® q\n\n\n\n\nFalse\nFalse\nFalse\n\n\nFalse\nTrue\nTrue\n\n\nTrue\nFalse\nTrue\n\n\nTrue\nTrue\nTrue\n\n\n\nNegazione (NOT - ¬¨): L‚Äôoperatore NOT cambia il valore di verit√† di una proposizione. Ad esempio, ¬¨p √® vero se p √® falso e viceversa.\n\nTavola della verit√† per la negazione\n\n\np\n¬¨p\n\n\n\n\nFalse\nTrue\n\n\nTrue\nFalse\n\n\n\nImplicazione (‚Üí): L‚Äôimplicazione √® un‚Äôoperazione logica che collega due proposizioni e stabilisce una relazione di condizionalit√†. Si rappresenta con il simbolo ‚Äú‚Üí‚Äù e si legge come ‚Äúse‚Ä¶ allora‚Äù. In un‚Äôimplicazione del tipo ‚Äúp ‚Üí q‚Äù, la proposizione p √® chiamata l‚Äôantecedente e la proposizione q √® il conseguente. L‚Äôimplicazione √® falsa solo nel caso in cui l‚Äôantecedente √® vero e il conseguente √® falso. In tutti gli altri casi, l‚Äôimplicazione √® considerata vera. Poich√© questa operazione √® alla base di molti algoritmi di inferenza, √® importante capire come funziona. La tabella di verit√† riportata qui sotto consente di vedere come funziona l‚Äôoperatore implicazione.\n\nTavola della verit√† per l‚Äôimplicazione\n\n\np\nq\np ‚Üí q\n\n\n\n\nFalse\nFalse\nTrue\n\n\nFalse\nTrue\nTrue\n\n\nTrue\nFalse\nFalse\n\n\nTrue\nTrue\nTrue\n\n\n\nEsempio di Implicazione: supponiamo di avere le seguenti proposizioni: - p: Il sole splende. - q: Faccio una passeggiata.\nL‚Äôimplicazione che possiamo formulare √®: ‚ÄúSe il sole splende, allora faccio una passeggiata‚Äù, che si scrive come ‚Äúp ‚Üí q‚Äù. Dalla tabella della verit√†, possiamo vedere che in tre dei quattro casi l‚Äôimplicazione ‚Äúp ‚Üí q‚Äù √® vera. L‚Äôunico caso in cui l‚Äôimplicazione √® falsa √® quando il sole splende (p √® vero) ma non faccio una passeggiata (q √® falso).\nQuindi, in base alla logica dell‚Äôimplicazione, se il sole splende, sto effettivamente facendo una passeggiata o potrei anche non farla (ad eccezione del caso in cui il sole splenda e io non faccia una passeggiata, in cui l‚Äôimplicazione √® falsa).\nImplicazione Bilaterale (‚ÜîÔ∏é): L‚Äôimplicazione bilaterale √® un‚Äôoperazione logica che stabilisce che due proposizioni sono equivalenti, cio√® che entrambe le proposizioni hanno lo stesso valore di verit√†. Si rappresenta con il simbolo ‚Äú‚ÜîÔ∏é‚Äù e si legge come ‚Äúse e solo se‚Äù. L‚Äôimplicazione bilaterale √® vera solo quando le proposizioni hanno lo stesso valore di verit√†, sia entrambe vere che entrambe false.\n\nTavola della verit√† per l‚Äôimplicazione bilaterale\n\n\np\nq\np ‚ÜîÔ∏é q\n\n\n\n\nFalse\nFalse\nTrue\n\n\nFalse\nTrue\nFalse\n\n\nTrue\nFalse\nFalse\n\n\nTrue\nTrue\nTrue\n\n\n\nL‚Äôimplicazione bilaterale, anche conosciuta come ‚Äúse e solo se‚Äù, √® un importante concetto logico che stabilisce che due proposizioni sono logicamente equivalenti, cio√® entrambe sono vere o entrambe sono false contemporaneamente.\nEsempio di Implicazione Bilaterale: supponiamo di avere le seguenti proposizioni:\n\np: Oggi √® venerd√¨.\nq: Domani √® sabato.\n\nL‚Äôimplicazione bilaterale tra p e q pu√≤ essere scritta come p ‚ÜîÔ∏é q, che si legge come ‚ÄúOggi √® venerd√¨ se e solo se domani √® sabato‚Äù.\nDalla tabella di verit√†, possiamo notare che l‚Äôimplicazione bilaterale ‚ÄúOggi √® venerd√¨ se e solo se domani √® sabato‚Äù √® vera solo nei casi in cui entrambe le proposizioni sono vere (primo e ultimo caso) o entrambe sono false. Se c‚Äô√® una discrepanza nelle verit√† delle proposizioni, l‚Äôimplicazione bilaterale diventa falsa (secondo e terzo caso).\nQuindi, nel nostro esempio, l‚Äôaffermazione ‚ÄúOggi √® venerd√¨ se e solo se domani √® sabato‚Äù √® vera solo quando entrambe le proposizioni sono vere o entrambe sono false, evidenziando l‚Äôequivalenza logica tra le due proposizioni nel contesto dell‚Äôimplicazione bilaterale.\n\n\nBasi della Conoscenza\nLa base della conoscenza in un agente a inferenza logica √® costituita da proposizioni logiche, che sono affermazioni dichiarative che possono essere vere o false. Le proposizioni possono essere atomiche o composte e sono spesso rappresentate utilizzando variabili proposizionali. Queste variabili assumono valori di verit√† (vero o falso) e vengono combinate tramite operatori logici per formare regole logiche complesse. La base della conoscenza in un sistema logico definisce le relazioni tra le proposizioni e fornisce le fondamenta per il ragionamento e l‚Äôinferenza. Un agente a inferenza logica usa la Base della Conoscenza per giungere a conclusioni circa il mondo che la circonda; Per fare ci√≤ ha bisogno di regole di implicazione logica (‚ä®): Se Œ± ‚ä® Œ≤, ovvero se Œ± implica logicamente Œ≤, in ogni mondo dove Œ± √® vera allora Œ≤ √® vera. √à diversa dall‚Äôimplicazione perch√© non √® un connettivo logico ma una relazione che dice che se Œ± √® vera allora Œ≤ √® vera e basta!\n\n\nSistemi basati sulla conoscenza\nI sistemi basati sulla conoscenza sono strumenti informatici progettati per emulare il processo decisionale umano attraverso l‚Äôutilizzo di una base di conoscenza strutturata. Questi sistemi raccolgono, organizzano e utilizzano informazioni specifiche di un dominio per risolvere problemi complessi che richiedono competenza specialistica. Una componente fondamentale √® la base di conoscenza, che contiene fatti, regole ed euristiche rappresentative del sapere umano in un determinato campo. Il motore di inferenza √® l‚Äôaltro elemento chiave: applica regole logiche ai dati presenti nella base di conoscenza per dedurre nuove informazioni o prendere decisioni informate.\n\n\n\nProcesso di creazione e gestione di un sistema basato sulla conoscenza\n\n\nIl processo di creazione di un sistema esperto basato sull‚Äôinferenza logica inizia con l‚Äôacquisizione della conoscenza, dove gli esperti del dominio collaborano per estrarre informazioni e regole rilevanti. Queste conoscenze vengono poi formalizzate nella rappresentazione della conoscenza, utilizzando strutture come regole if-then, ontologie o reti semantiche, che alimentano la base di conoscenza. Il motore di inferenza viene sviluppato per applicare queste regole logiche ai dati forniti, deducendo nuove informazioni o prendendo decisioni informate. La gestione del sistema include l‚Äôaggiornamento continuo della base di conoscenza per riflettere nuove scoperte o cambiamenti nel dominio, nonch√© la verifica e la validazione del sistema per garantirne l‚Äôaccuratezza e l‚Äôaffidabilit√†. Gli utenti interagiscono con il sistema attraverso un‚Äôinterfaccia che facilita l‚Äôinserimento dei dati e la visualizzazione dei risultati, permettendo anche il feedback per miglioramenti futuri.\nQuesti sistemi trovano applicazione in vari settori, come la medicina, l‚Äôingegneria, la finanza e l‚Äôassistenza clienti. Ad esempio, in ambito medico, un sistema basato sulla conoscenza pu√≤ aiutare nella diagnosi di malattie analizzando sintomi e storie cliniche dei pazienti. L‚Äôefficacia di tali sistemi dipende dalla qualit√† e dall‚Äôaggiornamento costante della base di conoscenza, nonch√© dalla capacit√† del motore di inferenza di elaborare correttamente le informazioni.\nUn vantaggio significativo dei sistemi basati sulla conoscenza √® la possibilit√† di conservare e diffondere l‚Äôesperienza di esperti, rendendola accessibile a un pubblico pi√π ampio e contribuendo alla standardizzazione delle pratiche. Tuttavia, la creazione e la manutenzione di una base di conoscenza richiedono notevoli risorse e competenze. Con l‚Äôavanzamento dell‚Äôintelligenza artificiale e dell‚Äôapprendimento automatico, questi sistemi continuano a evolversi, integrando nuove tecniche per migliorare l‚Äôefficienza, l‚Äôaccuratezza e la capacit√† di apprendimento autonomo nelle loro applicazioni.\n\n\nSemplice Sistema Esperto in ambito penale\nIn questo paragrafo, useremo la libreria SymPy in Python per creare un semplice sistema esperto basato sull‚Äôinferenza logica nell‚Äôambito del diritto penale. Questo sistema aiuter√† a determinare se determinati comportamenti costituiscono un reato, in base ai fatti noti e alle norme applicabili. Si noti che la libreria SymPy √® stata sviluppata per consentire il calcolo simbolico in Python. In questo caso useremo le funzionalit√† di calcolo simbolico per la rappresentazione della conoscenza, usando le funzionalit√† di calcolo logico, e per l‚Äôinferenza logica.\n \n(click-ando su questo pulsante aprirete il quaderno all‚Äôinterno di COLAB di Google dove potrete eseguire il quaderno online senza bisogno di avere un ambiente Python sulla vostra macchina.)\n\nIntroduzione\nIl diritto penale si basa su norme che definiscono quali comportamenti sono considerati reati e quali elementi devono essere presenti affinch√© un‚Äôazione sia punibile. Un sistema esperto in questo contesto pu√≤ aiutare a:\n\nValutare se un‚Äôazione specifica costituisce un reato.\nIdentificare gli elementi costitutivi del reato.\nFornire una base logica per decisioni legali.\n\nUtilizzeremo SymPy per modellare proposizioni logiche, regole legali e per effettuare inferenze.\n\n\n\nInstallazione di SymPy\nAssicurati di avere SymPy installato:\npip install sympy\nSe stai utilizzando questo notebook in un ambiente in cui SymPy non √® installato, esegui la seguente cella:\n\n!pip install sympy\n\n\n\nConcetti di Base nel Diritto Penale\nPrima di iniziare, definiamo alcuni concetti chiave:\n\nFatti: Eventi o azioni specifiche accadute.\nReati: Comportamenti definiti come illeciti dalla legge penale.\nElementi Costitutivi del Reato: Condizioni che devono essere soddisfatte perch√© un comportamento sia considerato un reato (ad esempio, azione, intenzione, nesso causale).\nRegole Legali: Norme che stabiliscono le condizioni in cui un comportamento √® punibile.\n\n\n\n\nModellazione con SymPy\nPasso 1: Importare i Moduli Necessari\nImportiamo i moduli necessari da SymPy per lavorare con la logica proposizionale.\n\nfrom sympy import symbols\nfrom sympy.logic.boolalg import And, Or, Not, Implies, Equivalent\nfrom sympy.logic.inference import satisfiable\n\nPasso 2: Definire le Proposizioni Logiche\nDefiniamo le variabili che rappresentano i fatti e gli elementi costitutivi del reato.\n\n# Fatti\nAzione, Intenzione, NessoCausale = symbols('Azione Intenzione NessoCausale')\n\n# Reato\nOmicidio = symbols('Omicidio')\n\nPasso 3: Definire le Regole che discendono dal Codice Penale\nAd esempio, secondo il codice penale, l‚Äôomicidio richiede:\n\nAzione: Causare la morte di una persona.\nIntenzione: Volont√† di causare la morte (dolo).\nNesso Causale: La morte √® conseguenza dell‚Äôazione.\n\nDefiniamo la regola:\n\n# Regola: Se c'√® Azione, Intenzione e Nesso Causale, allora si configura l'Omicidio\nregola_omicidio = Implies(And(Azione, Intenzione, NessoCausale), Omicidio)\n\nPasso 4: Definire i Fatti Noti\nSupponiamo di avere i seguenti fatti:\n\nUna persona ha compiuto un‚Äôazione che ha causato la morte di un‚Äôaltra.\nAveva l‚Äôintenzione di causare la morte.\nEsiste un nesso causale tra l‚Äôazione e la morte.\n\n\n# Fatti noti\nfatto1 = Azione  # L'azione di causare la morte\nfatto2 = Intenzione  # Intenzione di causare la morte\nfatto3 = NessoCausale  # La morte √® conseguenza dell'azione\n\nPasso 5: Creare la Base di Conoscenza\nCombiniamo fatti e regole:\n\n# Base di conoscenza\nbase_conoscenza = And(fatto1, fatto2, fatto3, regola_omicidio)\n\nPasso 6: Inferenza Logica\nVerifichiamo se, sulla base dei fatti e delle regole, possiamo concludere che si tratta di omicidio.\n\n# Verifichiamo se Omicidio √® deducibile\nipotesi = And(base_conoscenza, Not(Omicidio))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura il reato di omicidio.\")\nelse:\n    print(\"Non possiamo concludere che si tratti di omicidio.\")\n\nSi configura il reato di omicidio.\n\n\nOutput atteso:\nSi configura il reato di omicidio.\n\n\nEspansione del Sistema\nCaso con Mancanza di Intenzione\nSupponiamo che l‚Äôintenzione non sia presente (ad esempio, si tratta di omicidio colposo).\n\n# Fatti noti senza Intenzione\nfatto1 = Azione\nfatto2 = Not(Intenzione)  # Mancanza di intenzione\nfatto3 = NessoCausale\n\n# Base di conoscenza aggiornata\nbase_conoscenza = And(fatto1, fatto2, fatto3, regola_omicidio)\n\nInferenza per Omicidio\n\n# Inferenza\nipotesi = And(base_conoscenza, Not(Omicidio))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura il reato di omicidio.\")\nelse:\n    print(\"Non possiamo concludere che si tratti di omicidio.\")\n\nNon possiamo concludere che si tratti di omicidio.\n\n\nOutput atteso:\nNon possiamo concludere che si tratti di omicidio.\n\nAggiunta di Altre Regole\nAggiungiamo la regola per l‚Äôomicidio colposo:\n\n# Definizione del reato di Omicidio Colposo\nOmicidioColposo = symbols('OmicidioColposo')\n\n# Regola per Omicidio Colposo: Azione e Nesso Causale senza Intenzione\nregola_omicidio_colposo = Implies(And(Azione, Not(Intenzione), NessoCausale), OmicidioColposo)\n\n# Aggiorniamo la base di conoscenza\nbase_conoscenza = And(fatto1, fatto2, fatto3, regola_omicidio, regola_omicidio_colposo)\n\nInferenza per Omicidio Colposo\n\n# Verifichiamo se si configura l'Omicidio Colposo\nipotesi = And(base_conoscenza, Not(OmicidioColposo))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura il reato di omicidio colposo.\")\nelse:\n    print(\"Non possiamo concludere che si tratti di omicidio colposo.\")\n\nSi configura il reato di omicidio colposo.\n\n\nOutput atteso:\nSi configura il reato di omicidio colposo.\n\n\n\nConclusione\nAbbiamo visto come utilizzare SymPy per modellare un semplice sistema esperto nel campo del diritto penale. Questo esempio illustra come le regole legali e i fatti possono essere formalizzati utilizzando la logica proposizionale, permettendo al sistema di effettuare inferenze logiche.\nRicorda che questo √® un modello semplificato e che il diritto penale √® complesso e richiede una comprensione approfondita per essere modellato accuratamente. Questo sistema pu√≤ essere un punto di partenza per sviluppi pi√π avanzati e per esplorare l‚Äôintersezione tra intelligenza artificiale e diritto.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algoritmi</span>"
    ]
  },
  {
    "objectID": "2-algoritmi.html#inferenza-probabilistica",
    "href": "2-algoritmi.html#inferenza-probabilistica",
    "title": "Algoritmi",
    "section": "Inferenza Probabilistica",
    "text": "Inferenza Probabilistica\nL‚Äôinferenza probabilistica utilizza la teoria delle probabilit√† per fare previsioni o inferenze basate su dati incompleti o incerti. Questo tipo di inferenza √® particolarmente utile in tutti i contesti dove le informazioni possono essere incomplete o incerte.\nL‚Äôagente artificiale in situazioni di incertezza affronta la sfida di prendere decisioni razionali quando non si dispone di informazioni complete o quando le informazioni disponibili sono soggette a variabilit√†. In tali contesti, l‚Äôagente deve essere in grado di gestire e interpretare l‚Äôincertezza in modo efficace per agire in modo intelligente e adattivo.\nL‚Äôincertezza pu√≤ derivare da diversi fattori, come la natura incompleta delle informazioni, la presenza di rumore nei dati, l‚Äôaleatoriet√† degli eventi o la complessit√† dei problemi da affrontare. Gli agenti artificiali, dotati di capacit√† di ragionamento probabilistico e di inferenza, sono in grado di valutare le conseguenze di diverse azioni in base alle probabilit√† associate agli eventi futuri e agli esiti attesi.\nL‚Äôinferenza probabilistica √® una tecnica utilizzata nell‚Äôambito dell‚ÄôIntelligenza Artificiale per prendere decisioni o formulare previsioni basate su informazioni incerte o parziali. In pratica, ci√≤ significa che invece di avere risposte binarie (vero o falso), lavoriamo con probabilit√†, cio√® con il grado di certezza o incertezza riguardo a una determinata affermazione o evento.\nEsempio in un contesto legale\nImmagina un caso giuridico in cui una persona √® accusata di un crimine. Nel sistema giuridico, la giuria deve prendere una decisione sulla colpevolezza o innocenza dell‚Äôimputato. Tuttavia, spesso non abbiamo prove definitive o testimonianze che garantiscono una certezza assoluta. In questo contesto, l‚Äôinferenza probabilistica pu√≤ essere applicata. Invece di dire semplicemente ‚Äúcolpevole‚Äù o ‚Äúinnocente,‚Äù i giurati possono assegnare una probabilit√† alla colpevolezza dell‚Äôimputato. Ad esempio, potrebbero dire che ci sono il 70% di probabilit√† che l‚Äôimputato sia colpevole e il 30% di probabilit√† che sia innocente. Infine, una soglia sulla probabilit√† di colpevolezza potrebbe dare origine alla sentenza.\nEsempio in un generico contesto di diagnosi\nNel caso di una diagnosi ( in qualunque settore) √® necessario prendere una decisione con conoscenza incerta. Si √® in una situazione di incertezza in quanto la lista di situazioni e cause da descrivere non pu√≤ essere esaustiva (praticamente infinita per la mancanza di conoscenza universale). Non si pu√≤ usare la logica del primo ordine per gestire la diagnosi perch√©: - √® impossibile elencare l‚Äôinsieme praticamente infinito di antecedenti e conseguenti per evitare eccezioni - √® impossibile avere una conoscenza metodologica completa - √® impossibile avere una conoscenza applicativa completa - L‚Äôagente non potr√† mai agire con una piena consapevolezza di verit√† e correttezza, avr√† solo un grado di credenza sulla bont√† delle azioni da intraprendere e dei risultati.\n\nInferenza probabilistica e La teoria delle probabilit√†\nL‚Äôinferenza probabilistica √® un processo di ragionamento che utilizza il calcolo delle probabilit√† per prendere decisioni o formulare previsioni in situazioni in cui le informazioni sono incomplete o incerte. L‚Äôinferenza probabilistica √® fondamentale in vari campi, come la statistica, l‚Äôapprendimento automatico, la medicina, la finanza e molti altri.\nIl calcolo delle probabilit√† √® una branca della matematica che si occupa di misurare e analizzare la probabilit√† di eventi casuali. La probabilit√† √® una misura numerica che descrive la possibilit√† che un evento specifico accada.\n\n‚ÄúIl concetto di probabilit√† √® il pi√π importante della scienza moderna, soprattutto perch√© nessuno ha la pi√π pallida idea del suo significato.‚Äù (Bertrand Russel)\n\nLa teoria della probabilit√† assume la stessa assunzione ontologica della logica: - i fatti del mondo sono: veri o falsi (con una certa probabilit√†) - Ogni possibile situazione in cui si trova il nostro agente √® un mondo ¬µ; Esempio: nel caso del gioco del Lotto, per la singola estrazione ci possono essere 90 mondi, uno per ogni numero che pu√≤ essere estratto. - Ogni mondo ¬µ √® un insieme di fatti: - fatti veri (V) - fatti falsi (F) - fatti incerti (I)\nTale teoria pu√≤ essere formulata in diversi modi a seconda del tipo di assunzioni iniziali che si utilizzano. In questo testo si utilizza la teoria della probabilit√† basata sui cosiddetti assiomi di Kolmogorov e per questo detta Teoria Assiomatica della Probabilit√†.\nGli assiomi di Kolmogorov costituiscono la base matematica della teoria delle probabilit√†, formulata dal matematico russo Andrey Kolmogorov nel suo lavoro ‚ÄúGrundbegriffe der Wahrscheinlichkeitsrechnung‚Äù nel 1933.\nEcco una descrizione dei tre assiomi di Kolmogorov:\n\nPrimo Assioma (Non-negativit√†): La probabilit√† di un evento √® sempre un numero reale non negativo: P(A)‚â•0 per ogni evento A. Per rappresentare la probabilit√† di un certo mondo si usa il simbolo P(¬µ), 0 &lt;= P(¬µ) &lt;= 1\n\nP(¬µ) = 0 significa che il mondo ¬µ non ha nessuna possibilit√† di verificarsi. Ad esempio la probabilit√† che al lotto venga estratto il numero 0 (zero)\nP(¬µ) = 1 significa che il mondo ¬µ √® certo. Ad esempio la probabilit√† che il risultato di una estrazione sia minore o uguale a 90 √® 1 Pi√π √® ¬´grande¬ª P(¬µ) √® pi√π √® verosimile che si verifichi il mondo ¬µ.\n\nSecondo Assioma (Normalizzazione) : La somma delle probabilit√† di tutti gli eventi possibili nello spazio campione √® uguale a 1: P(S) = 1, dove S rappresenta lo spazio campione. Ad esempio, la somma delle probabilit√† di estrazione di tutti i numeri del lotto √® pari a 1\nTerzo Assioma (Additivit√†) : Se A1, A2, A3, ‚Ä¶ sono eventi mutuamente esclusivi (cio√® non possono accadere simultaneamente), allora la probabilit√† dell‚Äôunione di questi eventi √® uguale alla somma delle loro probabilit√† individuarie: P(A1 ‚à™ A2 ‚à™ A3 ‚à™ ‚Ä¶) = P(A1) + P(A2) + P(A3) + ‚Ä¶ Ad esempio, la probabilit√† di estrarre un numero pari al lotto √® pari alla somma delle probabilit√† di estrarre i numeri pari da 2 a 90. ‚Äã\n\nGli assiomi di Kolmogorov forniscono un fondamento rigoroso per definire le probabilit√† e garantiscono che le probabilit√† siano consistenti e soddisfino le propriet√† chiave della teoria delle probabilit√†. Questi assiomi sono essenziali per lo studio formale della probabilit√† e vengono utilizzati per sviluppare e applicare concetti probabilistici in varie discipline, inclusi statistica, teoria dei giochi, intelligenza artificiale e molti altri campi scientifici.\n\n\nCacolo della probabilit√† incondizionata o a priori\ncalcolo della probabilit√† di estrazione di un numero x al lotto Usando i tre assiomi di Kolmogorov :\nsi pu√≤ calcolare la probabilit√† di estrazione di un numero x al lotto. - Dal primo assionmato si ha che P(x) &gt;= 0. - Dal secondo assioma si ha che la somma di tutti i P(x), con x che va da 1 a 90, √® pari a 1. - Dal terzo si evince che essendo le probabilit√† di estrazione di un numero x uguale a quella di estrarre un numero y, con x diverso da y, si ha che la probabilit√† di estrarre un numero x √® pari a 1/90.\ncalcolo della probabilit√† del risultato x nel lancio di un dado Nel lancio di un dado a 6 facce:\nla probabilit√† P(n) di ottenere il numero n √® P(n) = 1/6 perch√© all‚Äôesito del lancio tutte le facce del dado hanno uguale probabilit√†.\ncalcolo della probabilit√† del risultato nel lancio di due dadi : Nell‚Äôesito del lancio di due dadi, dobbiamo considerare che i mondi possibili ed equiprobabili sono 6x6=36 e quindi la probabilit√† di uno di questi mondi √® 1/36.\ncalcolo della probabilit√† del risultato x come somma dei valori nel lancio di due dadi : Nell‚Äôesito del lancio di due dadi, se vogliamo calcolare la probabilit√† che esca un certo valore x come somma dei valori dei due dadi dobbaimo considerare che i valori possibili di x [2,12] non sono equiprobabili. Infatti, per esempio, la probabilit√† di ottenere 2 √® 1/36, mentre la probabilit√† di ottenere 7 √® 6/36. Per calcolare la probabilit√† del valore x √® sufficiente contare quanti sono i mondi in cui il valore x si ottiene come somma dei valori dei due dadi e poi dividere per il numero totale di mondi possibili. I possibili risultati del lancio di due dadi sono 36 :\n\nLancio di due dadi\n\n\n\n\n\n\n\n\n\n\n\n+\n1\n2\n3\n4\n5\n6\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n2\n3\n4\n5\n6\n7\n8\n\n\n3\n4\n5\n6\n7\n8\n9\n\n\n4\n5\n6\n7\n8\n9\n10\n\n\n5\n6\n7\n8\n9\n10\n11\n\n\n6\n7\n8\n9\n10\n11\n12\n\n\n\nLa probabilit√† di ottenere 2 √® data dal numero di esiti favorevoli al risultato 2, in questo caso √® solo uno, diviso il numero totale di esiti possibili, in questo caso 36. La possibilit√† di ottenere 3 √® data dal numero di esiti favorevoli al risultato 3, in questo caso sono 2, diviso il numero totale di esiti possibili, in questo caso 36. ‚Ä¶\nP(2)=1/36, P(3)=2/36, P(4)=3/36, P(5)=4/36, P(6)=5/36, P(7)=6/36, P(8)=5/36, P(9)=4/36, P(10)=3/36, P(11)=2/36, P(12)=1/36\n\n\nVariabili aleatorie\nUna variabile aleatoria nel calcolo delle probabilit√† √® una variabile che pu√≤ assumere uno dei possibili valori in un certo dominio: - La variabile lancio nel lancio di un dado pu√≤ assumere uno dei valori nel dominio {1,2,3,4,5,6} - La variabile sentenza nel processo penale pu√≤ assumere uno dei valori nel dominio {¬´Non luogo a procedere¬ª, ¬´Proscioglimento¬ª, ¬´Condanna¬ª} - La variabile diagnosi in campo medico pu√≤ assumere uno dei valori nel dominio {¬´Malattia¬ª, ¬´Non malattia¬ª}.\nNell‚Äôinferenza probsbilistica si √® interessati alla probabilit√† che una certa variabile aleatoria assuma un certo valore. Ad esempio, in un determinato processo penale si potrebbe avere:\n\nP(sentenza = ¬´Non luogo a procedere¬ª) = 0,1\nP(sentenza = ¬´Proscioglimento¬ª) = 0,1\nP(sentenza = ¬´Condanna¬ª) = 0,8\n\nPer codificare la variabile aleatoria ‚Äúsentenza‚Äù in Python, si pu√≤ utilizzare ad esempio la struttura dati dizionario che mappa i possibili esiti (‚ÄúNon luogo a procedere‚Äù, ‚ÄúProscioglimento‚Äù, ‚ÄúCondanna‚Äù) ai rispettivi valori numerici di probabilit√†. Ecco un esempio di come si potrebbe codificare la variabile aleatoria ‚Äúsentenza‚Äù in Python utilizzando un dizionario:\n\n# Definizione della variabile aleatoria sentenza con i suoi possibili valori\nsentenza = {\n    \"Non luogo a procedere\": 0.128, # probabilit√† del 12.8% di non luogo a procedere\n    \"Proscioglimento\": 0.548,       # probabilit√† del 54.8% di proscioglimento\n    \"Condanna\": 0.324               # probabilit√† del 32.4% di condanna\n}\nsomma = 0\nfor esito, probabilita in sentenza.items():\n    print(f\"La probabilit√† di '{esito}' √®: {probabilita}\")\n    somma = somma + probabilita\nprint(\" la somma delle probabilit√† √® pari a \", somma)\n\nLa probabilit√† di 'Non luogo a procedere' √®: 0.128\nLa probabilit√† di 'Proscioglimento' √®: 0.548\nLa probabilit√† di 'Condanna' √®: 0.324\n la somma delle probabilit√† √® pari a  1.0\n\n\n\n\nDistribuzioni di probabilit√†\nle distribuzioni di probabilit√† sono funzioni che descrivono la probabilit√† di ogni possibile valore di una variabile aleatoria. Ad esempio, la distribuzione di probabilit√† della variabile aleatoria ‚Äúsentenza‚Äù nel processo penale pu√≤ essere rappresentata come segue: P(sentenza) = {0.1, 0.1, 0.8}. Nel seguito vedremo alcune distribuzioni di probabilit√† notevoli.\n\n\nProbabilit√† congiunta\nLa probabilit√† congiunta √® la probabilit√† che due eventi si verifichino contemporaneamente. Ad esempio, la probabilit√† che un processo penale porti a una condanna e che il condannato sia colpevole √® data dalla probabilit√† congiunta di questi due eventi. Oppure, in ambito medico, la probabilit√† che un paziente abbia una certa patologia e che il test diagnostico sia positivo √® data dalla probabilit√† congiunta di questi due eventi. Oppure, in ambito metereologico, la probabilit√† che sia nuvolo e che piova √® la probabilit√† congiunta di questi due eventi:\nprobabilit√† che sia nuvoloso:\n\n\n\n\nnuvoloso\n¬¨nuvoloso\n\n\n\n\nP(n)\n0,7\n0,3\n\n\n\nprobabilit√† che piova:\n\n\n\n\npiove\n¬¨piove\n\n\n\n\nP(p)\n0,2\n0,8\n\n\n\nprobabilit√† che sia nuvoloso e piova:\n\n\n\nP(p,n)\nnuvoloso\n¬¨nuvoloso\n\n\n\n\npiove\n0,55\n0,05\n\n\n¬¨piove\n0,15\n0,25\n\n\n\n\n\nIndipendenza delle variabili aleatorie\nL‚Äôindipendenza di due eventi indica che il verificarsi di uno non influenza il verificarsi dell‚Äôaltro. Ad esempio: Lancio di due dadi. Il lancio del primo non influenza il secondo; Il contrario, la dipendenza, indica che il verificarsi di uno influenza il verificarsi dell‚Äôaltro. Nel caso in cui due variabili aleatorie siano indipendenti si ha la seguente propriet√†:\nP(a ‚àß b)=P(a)*P(b)\n\n\nNegazione\nLa negazione di un evento √® l‚Äôevento che si verifica quando l‚Äôevento originale non si verifica. Ad esempio, la negazione dell‚Äôevento ‚Äúpiove‚Äù √® ‚Äúnon piove‚Äù.\nSe la probabilit√† che un evento √® Œ±, la probabilit√† che l‚Äôevento non si verifichi √® 1 - Œ±.\nP(A) = Œ±, allora P(¬¨A) = 1 - Œ±\n\n\nInclusione\nP(a ‚à® b) = P(a) + P(b) - P(a ‚àß b).\nLa probabilit√† che si verifichi l‚Äôevento a o l‚Äôevento b √® uguale alla somma delle probabilit√† dei due eventi meno la probabilit√† congiunta. Si noti che se gli eventi sono incompatibili la probabilit√† congiunta √® nulla! image-2.png\n\n\nMarginalizzazione\nLa marginalizzazione √® una tecnica utilizzata per calcolare la probabilit√† di un evento dato un insieme di eventi. Ad esempio, la probabilit√† che un processo penale porti a una condanna dato che il condannato √® colpevole √® data dalla marginalizzazione della probabilit√† congiunta di questi due eventi.\nP(a) = P(a, b) + P(a, ¬¨b).\nLa probabilit√† che si verifichi b √® disgiunta dalla probabilit√† che si verifichi ¬¨b. Quindi, quando si verifica a si ha b oppure ¬¨b ma non entrambi quindi se sommo le probabilit√† P(a, b) + P(a, ¬¨b) ottengo P(a)\n\n\nprobabilit√† condizionata\nLa probabilit√† condizionata √® la probabilit√† che un evento si verifichi dato che un altro evento si √® verificato. Ad esempio, la probabilit√† che un processo penale porti a una condanna dato che il sottoposto a giudizio √® colpevole √® data dalla probabilit√† condizionata di questi due eventi.\nE‚Äô possibile fare inferenze a proposito della probabilit√† di una proposizione ignota A, data la prova B, calcolando P(A/B) (probabilit√† di A dato che tutto ci√≤ che sappiamo √® B) (inferenza probabilistica)\nUn‚Äôinterrogazione ad un sistema di ragionamento probabilistico chieder√† di calcolare il valore di una particolare probabilit√† condizionata.\nFin qui abbiamo visto casi in cui il singolo evento non era condizionato da altro evento:\n\nPrima estrazione del lotto;\nLancio di uno o due dadi\n\nCosa succede alla probabilit√† quando l‚Äôavverarsi di una proposizione √® condizionata all‚Äôavverarsi di un‚Äôaltra proposizione?\nP(a|b) = probabilit√† dell‚Äôevento a dato che noi sappiamo che l‚Äôevento b si √® verificato. Oppure, ‚Äú la probabilit√† di a dato b‚Äù Possiamo chiederci:\n\nQual‚Äô√® la probabilit√† che vinca la ‚Äú Roma‚Äù se ha vinto la ‚Äú Lazio‚Äù?, P(Roma/Lazio).\nQual‚Äô√® la probabilit√† che arrivi il ‚Äú38‚Äù se √® arrivato il ‚Äú52‚Äù?‚Äù, P(‚Äú38‚Äù/‚Äù52‚Äù).\n\nLa formula per calcolare la probabilit√† condizionata di a dato b √® la seguente: \\[\nP(a/b) =(ùëÉ(ùëé‚àßùëè))/(ùëÉ(ùëè));\n\\] ‚Äúsiamo interessati agli eventi dove a e b sono vere, ma solo nei mondi dove b √® vera!‚Äù \\[\nP(a‚àßb)=P(b)P(a/b)\n\\] \\[\nP(a‚àßb)=P(b)P(a/b)\n\\]\n\ncalcolo della probabilit√† condizionata: lancio di due dadi\nQual √® la probabilit√† che si ottenga una somma pari 9 lanciando due dadi se il primo dado √® 6, P(9/6)? La risposta si ottiene direttamente dalla formula della probabilit√† condizionata e da quella della probabilit√† congiunta: p(9/6) = P(9 ‚àß 6) / P(6) = 1/36 / 1/6 = 1/6\nLa proposizione a = ¬´somma=9¬ª si verifica con i seguenti lanci:\na = {(6,3),(5,4),(4,5),(3,6)} -&gt; P(a) = 4/36\nLa proposizione b = ¬´primo dado=6¬ª si verifica con i seguenti lanci:\nb = {(6,1),(6,2),(6,3),(6,4),(6,5),(6,6)} -&gt; P(b) = 6/36\na ‚Äú‚àß‚Äù b = {(6,3)} ÔÉ® P(a ‚Äú‚àß‚Äù b) = 1/36\nP(a/b) =(ùëÉ(ùëé ‚Äú‚àß‚Äù ùëè) )/(ùëÉ(ùëè))= (1/36)/(6/36)=1/6\n\nLancio di due dadi\n\n\n\n\n\n\n\n\n\n\n\n+\n1\n2\n3\n4\n5\n6\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n2\n3\n4\n5\n6\n7\n8\n\n\n3\n4\n5\n6\n7\n8\n9\n\n\n4\n5\n6\n7\n8\n9\n10\n\n\n5\n6\n7\n8\n9\n10\n11\n\n\n6\n7\n8\n9\n10\n11\n12\n\n\n\nOvvero, per risolvere l‚Äôesercizio dobbiamo osservare l‚Äô ultima riga della tabella realtiva al lancio del primo dado con risultato 6. i casi favorevoli sono solo 1, mentre i casi possibili sono 6. Quindi la probabilit√† √® 1/6.\n\n\ncalcolo della probabilit√† condizionata: caso penale\nSupponiamo di avere un dataset di 1.000 casi penali. Per ogni caso, raccogliamo le seguenti informazioni:\n\nAlibi del sospettato (S√¨/No)\nTestimone oculare presente (S√¨/No)\nCondanna del sospettato (S√¨/No)\n\n\n\n\nAlibi\nTestimone Oculare\nCondanna\nNumero di Casi\n\n\n\n\nS√¨\nS√¨\nS√¨\n50\n\n\nS√¨\nS√¨\nNo\n20\n\n\nS√¨\nNo\nS√¨\n30\n\n\nS√¨\nNo\nNo\n100\n\n\nNo\nS√¨\nS√¨\n200\n\n\nNo\nS√¨\nNo\n50\n\n\nNo\nNo\nS√¨\n150\n\n\nNo\nNo\nNo\n400\n\n\ntotale\n-\n-\n1.000\n\n\n\nQuesto dataset pu√≤ essere utilizzato per calcolare varie probabilit√† condizionate.\nEsercizio 2.1: Probabilit√† di condanna dato che il sospettato non ha un alibi e c‚Äô√® un testimone oculare.\n\nFormula: \\(P(\\text{Condanna} = \\text{S√¨} \\mid \\text{Alibi} = \\text{No}, \\text{Testimone} = \\text{S√¨})\\)\nCalcolo:\n\nNumero di casi con Alibi = No, Testimone = S√¨, Condanna = S√¨: 200\nNumero totale di casi con Alibi = No, Testimone = S√¨: 200 + 50 = 250\n\\(P = \\frac{200}{250} = 0{,}8  (80\\%)\\)\n\n\nEsercizio 2.2: Probabilit√† che ci sia un testimone oculare dato che il sospettato √® stato condannato.\n\nFormula: \\(P(\\text{Testimone} = \\text{S√¨} \\mid \\text{Condanna} = \\text{S√¨})\\)\nCalcolo:\n\nNumero di casi con Testimone = S√¨, Condanna = S√¨: \\(50 + 200 = 250\\)\nNumero totale di casi con Condanna = S√¨: \\(50 + 30 + 200 + 150 = 430\\)\n\\(P = \\frac{250}{430} \\approx 0{,}581  (58,1\\%)\\)\n\n\nEsercizio 2.3: Probabilit√† che un sospettato non abbia un alibi dato che non √® stato condannato.\n\nFormula: $P( = = ) $\nCalcolo:\n\nNumero di casi con Alibi = No, Condanna = No: 50 + 400 = 450\nNumero totale di casi con Condanna = No: 20 + 100 + 50 + 400 = 570\n\\(P = \\frac{450}{570} \\approx 0{,}789  (78,9\\%)\\)\n\n\nQuesto dataset consente di esplorare come diverse variabili influenzino le probabilit√† di determinati esiti nel contesto del diritto penale. Pu√≤ essere utilizzato per analisi statistiche, studi accademici o simulazioni di casi giudiziari.\n\n\n\nCondizionamento\n\\[\nP(a) = P(a/b)P(b) + P(a/¬¨b)P(¬¨b).\n\\] Il condizionamento discende immediatamente dalla marginalizzazione. La probabilit√† che si verifichi a √® data dalla marginalizzazione della probabilit√† congiunta di questi due eventi. La probabilit√† che si verifichi b √® disgiunta dalla probabilit√† che si verifichi ¬¨b. Quindi, quando si verifica a si ha b oppure ¬¨b ma non entrambi quindi se sommo le probabilit√† P(a, b) + P(a, ¬¨b) ottengo P(a).\nVediamo due esempi di applicazioni della formula di condizionamento in Python, uno nel campo medico e uno nel campo giuridico penale:\nCampo medico Supponiamo di avere le seguenti informazioni:\nLa probabilit√† che una persona sviluppi un certo effetto collaterale a seguito di un farmaco √® \\(P(Effetto collaterale) = 0.2\\).\nSi sa che se una persona sviluppa l‚Äôeffetto collaterale, la probabilit√† che abbia assunto il farmaco √® \\(P(Farmaco|Effetto collaterale) = 0.9\\). D‚Äôaltra parte, se una persona non mostra l‚Äôeffetto collaterale, la probabilit√† che abbia comunque assunto il farmaco √® \\(P(Farmaco|¬¨Effetto collaterale) = 0.1\\). In questo caso, il condizionamento riguarda la probabilit√† di assunzione del farmaco date le informazioni sull‚Äôeffetto collaterale senza coinvolgere il teorema di Bayes.\nQuindi, la probabilit√† di assunzione del farmaco √® \\[\n\\begin{split}\nP(\\text{Farmaco}) = P(\\text{Farmaco|Effetto collaterale})P(\\text{Effetto collaterale}) + \\\\\nP(\\text{Farmaco}|\\text{¬¨Effetto collaterale})P(\\text{¬¨Effetto collaterale}).\n\\end{split}\n\\]\nla codifica in Python √® la seguente:\n\n#definizioni delle probaibilit√†\nP_effetto_collaterale = 0.2\nP_farmaco_effetto_collaterale = 0.9\nP_farmaco_non_effetto_collaterale = 0.1\nP_farmaco = P_farmaco_effetto_collaterale * P_effetto_collaterale +\\\n            P_farmaco_non_effetto_collaterale * (1 - P_effetto_collaterale)\nprint(f\"La probabilit√† che una pesona abbia assunto il farmaco √® : {P_farmaco}\")\n\nOutput atteso :\nLa probabilit√† che una pesona abbia assunto il farmaco √® : 0.26\nCampo Giuridico Penale :\nImmaginiamo di avere le seguenti informazioni in un contesto giuridico penale: $P(Condanna con prove schiaccianti) = 0.95 $\n\\(P(Condanna senza prove schiaccianti) = 0.2\\)\n\\(P(Prove schiaccianti) = 0.3\\)\nUtilizziamo la formula di condizionamento per calcolare la probabilit√† di condanna:\n\\[\n\\begin{split}\nP(\\text{Condanna})= P(\\text{Condanna con prove schiaccianti})P(\\text{Prove schiaccianti}) + \\\\\nP(\\text{Condanna senza prove schiaccianti})(1-P(\\text{Prove schiaccianti}))\n\\end{split}\n\\]\nLa codifica in Python √® la seguente:\n\nprob_condanna_prove_schiaccianti = 0.95\nprob_condanna_no_prove_schiaccianti = 0.2\nprob_prove_schiaccianti = 0.3\nprob_condanna = prob_condanna_prove_schiaccianti * prob_prove_schiaccianti +\\\n                prob_condanna_no_prove_schiaccianti * (1 - prob_prove_schiaccianti)\nprint(f\"La probabilit√† che un imputato sia colpevole dato che ci sono prove schiaccianti √®: {prob_condanna}\")\n\nOutput atteso :\nLa probabilit√† che un imputato sia colpevole \ndato che ci sono prove schiaccianti √®: 0.42499999999999993\nQuesti due esempi illustrano come la formula di condizionamento possa essere applicata in contesti medici e giuridici penali per calcolare probabilit√† condizionate basate su informazioni specifiche relative agli eventi considerati.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algoritmi</span>"
    ]
  },
  {
    "objectID": "2-algoritmi.html#inferenza-bayesiana",
    "href": "2-algoritmi.html#inferenza-bayesiana",
    "title": "Algoritmi",
    "section": "Inferenza Bayesiana",
    "text": "Inferenza Bayesiana\n\n‚ÄúMr.¬†Bayes ‚Ä¶ design ‚Ä¶ was to find out a method by which we might judge concerning the probability that an event has to happen, in given circumstances, upon supposition that we know nothing concerning it but that, under the same circumstances, it has happened a certain number of times, and failed a certain other number of times.‚Äù - (Richard Price, presentando lo scritto dell‚Äôamico Thomas Bayes alla Royal Society of London)\n\nIl Teorema di Bayes, formalizzato dal reverendo Thomas Bayes nel XVIII secolo, √® uno strumento fondamentale nell‚Äôambito della statistica e dell‚Äôintelligenza artificiale che permette di aggiornare le nostre credenze riguardo ad un‚Äôipotesi sulla base di nuove evidenze. Le tecniche di inferenza basate su questo teorema sono ampiamente utilizzate in diversi campi, dall‚Äôanalisi dei dati alla diagnostica medica, dalla finanza alla progettazione di algoritmi di machine learning.\n\nIl Teorema di Bayes\nIl Teorema di Bayes fornisce un modo per calcolare la probabilit√† condizionata di un‚Äôipotesi data l‚Äôevidenza osservata. Formalmente, il teorema pu√≤ essere espresso come:\n\\[\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\]\nDove: - P(A|B) √® la probabilit√† dell‚Äôipotesi A dato l‚Äôevidenza B. - P(B|A) √® la probabilit√† dell‚Äôevidenza B dato l‚Äôipotesi A. - P(A) √® la probabilit√† a priori dell‚Äôipotesi A. - P(B) √® la probabilit√† dell‚Äôevidenza B.\n\n\nApplicazioni Pratiche\nDiagnostica Medica\nNel campo della diagnostica medica, il Teorema di Bayes √® utilizzato per valutare la probabilit√† che un paziente abbia una certa malattia sulla base dei sintomi presentati e dei risultati dei test di laboratorio. Ad esempio, se la probabilit√† di un test positivo dato che il paziente ha la malattia e la probabilit√† che il paziente abbia effettivamente la malattia sono note, il teorema di Bayes pu√≤ essere impiegato per calcolare la probabilit√† che il paziente abbia la malattia date le informazioni disponibili.\nFinanza\nNel settore finanziario, il Teorema di Bayes viene adoperato per valutare il rischio e formulare previsioni basate su dati storici e informazioni di mercato. Ad esempio, il teorema pu√≤ essere utilizzato per stimare la probabilit√† di un evento futuro, come un aumento dei tassi di interesse, sulla base di indicatori economici attuali.\nMachine Learning\nNei modelli di machine learning, come le reti bayesiane, il Teorema di Bayes svolge un ruolo chiave nell‚Äôaggiornare le probabilit√† delle variabili all‚Äôinterno del modello in risposta ai nuovi dati. Questo processo di apprendimento bayesiano consente ai modelli di essere pi√π flessibili ed adattabili all‚Äôevoluzione dei dati nel tempo.\ndiritto penale\nDalle statistiche (false perch√© inventate da me :) di un certo tribunale o dal Ministero della Giustizia abbiamo che - 80% degli imputati condannati hanno precedenti penali P(precedenti/condanna) = 0,8; - 10% degli imputati sono condannati P(condanna) = 0,1 - 20% degli imputati hanno precedenti penali P(precedenti) = 0,2\nApplicando il teorema di Bayes abbiamo che la probabilit√† che un imputato con precedenti sia condannato √® \\[\nP(condanna/precedenti) = P(condanna) \\cdot \\frac{P(precedenti/condanna)}{P(precedenti)} = 0,1 \\cdot \\frac{0,8}{0,2}= 0,4\n\\]\nSi osservi che la probabilit√† di essere condannati era del 10%. Applicando il teorema di Bayes abbiamo scoperto che la probabilit√† di essere condannato √® del 40% se sappiamo che la persona sottoposta a giudizio ha dei precedenti penali. Ovvero, la probabilit√† iniziale di essere condannati senza sapere se sono presenti o meno precedenti penali viene moltiplicata per 4 (il cosidetto fattore di Bayes).\nLe tecniche di inferenza basate sul Teorema di Bayes forniscono un approccio potente per il ragionamento probabilistico e l‚Äôaggiornamento delle credenze in base alle evidenze disponibili. Utilizzate in una vasta gamma di settori, queste tecniche consentono di prendere decisioni informate e di sfruttare al meglio le informazioni a disposizione. La comprensione e l‚Äôapplicazione corretta del Teorema di Bayes sono cruciali per ottenere risultati accurati e significativi nelle analisi statistiche e nel machine learning.\n\nApplicazione del Teorema di Bayes: caso penale\nApplicazione del teorema di Bayes al data set del caso pratico calcolo della probabilit√† condizionata: caso penale il Teorema di Bayes per calcolare la probabilit√† che un sospettato venga condannato dato che non ha un alibi, cio√® \\(P(\\text{Condanna} = \\text{S√¨} \\mid \\text{Alibi} = \\text{No})\\). Questo ci permette di comprendere meglio l‚Äôimpatto dell‚Äôassenza di un alibi sulla probabilit√† di condanna.\nObiettivo: Calcolare \\(P(\\text{Condanna} = \\text{S√¨} \\mid \\text{Alibi} = \\text{No})\\).\nTeorema di Bayes:\n\\[\nP(\\text{Condanna} = \\text{S√¨} \\mid \\text{Alibi} = \\text{No}) = \\frac{P(\\text{Alibi} = \\text{No} \\mid \\text{Condanna} = \\text{S√¨}) \\times P(\\text{Condanna} = \\text{S√¨})}{P(\\text{Alibi} = \\text{No})}\n\\]\nPasso 1: Calcolare \\(P(\\text{Alibi} = \\text{No} \\mid \\text{Condanna} = \\text{S√¨})\\)\n\nNumero totale di casi con Condanna = S√¨:\n\\(50 + 30 + 200 + 150 = 430\\) casi.\nNumero di casi con Alibi = No e Condanna = S√¨:\n\\(200 + 150 = 350\\) casi.\nCalcolo:\n\\[\nP(\\text{Alibi} = \\text{No} \\mid \\text{Condanna} = \\text{S√¨}) = \\frac{350}{430} \\approx 0{,}8139 \\ (81{,}39\\%)\n\\]\n\nPasso 2: Calcolare $ P( = )$\n\nNumero totale di casi con Condanna = S√¨: $ 430 $ (come sopra).\nNumero totale di casi: \\(1.000\\).\nCalcolo:\n\\[\nP(\\text{Condanna} = \\text{S√¨}) = \\frac{430}{1.000} = 0{,}43 \\ (43\\%)\n\\]\n\nPasso 3: Calcolare \\(P(\\text{Alibi} = \\text{No})\\)\n\nNumero totale di casi con Alibi = No:\n\\(200 + 50 + 150 + 400 = 800\\) casi.\nNumero totale di casi: \\(1.000\\).\nCalcolo:\n\\[\nP(\\text{Alibi} = \\text{No}) = \\frac{800}{1.000} = 0{,}8 \\ (80\\%)\n\\]\n\nPasso 4: Applicare il Teorema di Bayes\n\\[\nP(\\text{Condanna} = \\text{S√¨} \\mid \\text{Alibi} = \\text{No}) = \\frac{0{,}8139 \\times 0{,}43}{0{,}8} = \\frac{0{,}349977}{0{,}8} = 0{,}4375 \\ (43{,}75\\%)\n\\]\nRisultato:\nLa probabilit√† che un sospettato venga condannato dato che non ha un alibi √® circa 43,75%.\n\nVerifica Diretta dai Dati del Dataset\nPer confermare il risultato, possiamo calcolare direttamente \\(P(\\text{Condanna} = \\text{S√¨} \\mid \\text{Alibi} = \\text{No})\\):\n\nNumero di casi con Alibi = No: \\(800\\) (come calcolato sopra).\nNumero di casi con Alibi = No e Condanna = S√¨: \\(200 + 150 = 350\\).\nCalcolo diretto:\n\\[\nP(\\text{Condanna} = \\text{S√¨} \\mid \\text{Alibi} = \\text{No}) = \\frac{350}{800} = 0{,}4375 \\ (43{,}75\\%)\n\\]\n\nIl risultato conferma il calcolo effettuato tramite il Teorema di Bayes. Questo risultato indica che, secondo i dati del dataset:\n\nSe un sospettato non ha un alibi, ha una probabilit√† del 43,75% di essere condannato.\nL‚Äôassenza di un alibi non aumenta significativamente la probabilit√† di condanna rispetto alla probabilit√† generale di condanna nel dataset, che √® del 43%.\nImportanza dell‚ÄôAlibi: In questo dadaset, l‚Äôalibi non sembra essere un fattore importante nel determinare l‚Äôesito di un caso. Avere un alibi pu√≤ ridurre la probabilit√† di condanna.\nUtilizzo del Teorema di Bayes: Questo esempio illustra come il Teorema di Bayes possa essere utilizzato per aggiornare le probabilit√† in base a informazioni nuove o specifiche, nel contesto del diritto penale.\n\n\n\n\nreti di Bayes\nUna¬†rete bayesiana¬†(BN,¬†Bayesian network) √® un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l‚Äôuso di un¬†grafo aciclico diretto¬†(DAG) . Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu√≤ essere usata per calcolare la probabilit√† della presenza di diverse malattie. Le reti Bayesiane sono Grafi diretti. Ogni nodo rappresenta una variabile aleatoria e ogni freccia da X a Y indica che X √® un genitore di Y. Ovvero, indica che la distribuzione probabilistica di Y dipende da X. Ogni nodo ha la distribuzione probabilistica P(X | Genitori(X)). Vediamo un esempio sui mezzi di trasporto (:\n\n\n\nRete di Bayes puntualit√† treno\n\n\n2 Rete Bayesiana treno.ipynb \n(click-ando su questo pulsante aprirete il quaderno all‚Äôinterno di COLAB di Google dove potrete eseguire il quaderno online senza bisogno di avere un ambiente Python sulla vostra macchina.)\nUna rete bayesiana (di credenza) richiede che ogni nodo del grafo sia condizionatamente indipendente da qualsiasi sottoinsieme di nodi che non siano discendenti dei predecessori diretti del nodo stesso. Ci si affida ad un esperto di dominio per la definizione della topologia della rete di credenze (quali nodi e quali relazioni condizionali di dipendenza), poi si calcolano le influenze dirette e le conseguenti probabilit√†. Ci√≤ equivale a definire la conoscenza del mondo in cui pu√≤ avvenire un evento. Ovvero, la rete rappresenta le assunzioni che si possono fare su quel dominio. Le probabilit√† condizionate tra i nodi riassumono un insieme potenzialmente infinito di circostanze a noi ignote e che potrebbero influenzare l‚Äôevento. La topologia della rete √® la base di conoscenza generale ed astratta dell‚Äôambiente in cui si possono verificare gli eventi e rappresenta la struttura generale del processo causale nel dominio, piuttosto che fornire dettagli su un particolare elemento. Nelle reti bayesiane gli archi che connettono i nodi esprimono le relazioni causali dirette (causa -&gt; effetto). Una volta definita la topologia bisogna specificare la tabella delle probabilit√† condizionate associata ad ogni nodo. Ogni riga della tabella esprime la probabilit√† del valore di ogni nodo per un caso condizionante (combinazione di valori dei nodi genitori produttoria delle prob. condiz.) Un nodo con nessun genitore √® rappresentato dalla probabilit√† a priori.\n\nEsempio di rete bayesiana: indagine criminale\n2 Rete Bayesiana indagine criminale.ipynb \n(click-ando su questo pulsante aprirete il quaderno all‚Äôinterno di COLAB di Google dove potrete eseguire il quaderno online senza bisogno di avere un ambiente Python sulla vostra macchina.)\nScriviamo il codice Python necessario per creare un modello di Rete Bayesiana per analizzare la probabilit√† di colpevolezza di un sospetto in un‚Äôindagine criminale. Il modello considera tre elementi di prova: la presenza di un‚Äôarma (Arma), un movente (Movente) e un alibi (Alibi), e come questi influenzano la probabilit√† di colpevolezza (Colpevolezza).\nIl codice non richieder√† input diretti dall‚Äôutente. Invece, definisce la struttura della Rete Bayesiana e imposta le tabelle di probabilit√† per ciascun fattore basate su valori predefiniti che dovrebbero essere estrapolati da statistiche sulle indagini criminali.\nDescrizione del codice\nL‚Äôoutput di questo codice √®: - un modello di Rete Bayesiana verificato; - la stampa del modello; - la stampa delle Distribuzioni di Probabilit√† Condizionata (CPD) per ogni variabile nella rete; - il grafo della rete Bayesiana.\nInizialmente, definiamo la struttura della Rete Bayesiana, mostrando come i fattori di prova (Arma, Movente, Alibi) influenzano la colpevolezza (Colpevolezza). Quindi, definiamo le tabelle di probabilit√† per ciascun fattore. Ad esempio, la probabilit√† che un‚Äôarma sia presente sia presente sul luogo del delitto la poniamo pari al 70% (0.7) e la sua assenza al 30% (0.3). Pi√π complessa √® la definizione della tabella di probabilit√† per la colpevolezza, che considera tutte le possibili combinazioni dei fattori di prova. Tutte queste tabelle sono aggiunte al modello di Rete Bayesiana. Infine, verifichiamo se il modello √® definito correttamente e stampiamo tutte le distribuzioni di probabilit√†.\nLa logica chiave in questo codice √® come esso rappresenta le relazioni tra diversi elementi di prova e la colpevolezza. Ad esempio, la presenza di un‚Äôarma, un movente e la mancanza di un alibi aumenterebbero la probabilit√† di colpevolezza, mentre la loro assenza la diminuirebbe. Questo √® riflesso nella tabella di probabilit√† per ‚ÄòColpevolezza‚Äô, che considera tutte le possibili combinazioni di prove:\n\n\n\nArma\nMotive\nAlibi\nP(Non Colpevole)\nP(Colpevole)\n\n\n\n\n0\n0\n0\n0.1\n0.9\n\n\n0\n0\n1\n0.2\n0.8\n\n\n0\n1\n0\n0.3\n0.7\n\n\n0\n1\n1\n0.4\n0.6\n\n\n1\n0\n0\n0.5\n0.5\n\n\n1\n0\n1\n0.6\n0.4\n\n\n1\n1\n0\n0.7\n0.3\n\n\n1\n1\n1\n0.8\n0.2\n\n\n\nIn questa tabella:\n0 rappresenta l‚Äôassenza (di arma, movente o alibi) 1 rappresenta la presenza Le ultime due colonne mostrano le probabilit√† di non colpevolezza e colpevolezza per ogni combinazione di evidenze\nQuesta Rete Bayesiana pu√≤ essere utilizzata per calcolare la probabilit√† di colpevolezza dato uno scenario di prove, aiutando gli investigatori a quantificare e ragionare sull‚Äôincertezza nei casi criminali.\n\nfrom pgmpy.models import BayesianNetwork\nfrom pgmpy.factors.discrete import TabularCPD\n\n# Definizione del modello\nmodel = BayesianNetwork([('Arma', 'Colpevolezza'),\n                       ('Movente', 'Colpevolezza'),\n                       ('Alibi', 'Colpevolezza')])\n\n# Definizione delle probabilit√† condizionate\ncpd_arma = TabularCPD(variable='Arma', variable_card=2,\n                      values=[[0.7], [0.3]])\ncpd_Movente = TabularCPD(variable='Movente', variable_card=2,\n                        values=[[0.6], [0.4]])\ncpd_alibi = TabularCPD(variable='Alibi', variable_card=2,\n                       values=[[0.5], [0.5]])\ncpd_colpevolezza = TabularCPD(variable='Colpevolezza', variable_card=2,\n                              values=[[0.9, 0.7, 0.6, 0.4, 0.6, 0.4, 0.3, 0.1],\n                                      [0.1, 0.3, 0.4, 0.6, 0.4, 0.6, 0.7, 0.9]],\n                              evidence=['Arma', 'Movente', 'Alibi'],\n                              evidence_card=[2, 2, 2])\n# cpd_colpevolezza = TabularCPD(variable='Colpevolezza', variable_card=2,\n#                               values=[[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n#                                       [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]],\n#                               evidence=['Arma', 'Movente', 'Alibi'],\n#                               evidence_card=[2, 2, 2])\n\n# Aggiunta delle probabilit√† condizionate al modello\nmodel.add_cpds(cpd_arma, cpd_Movente, cpd_alibi, cpd_colpevolezza)\n\n# Verifica del modello\nprint(\"Il modello √® corretto: \", model.check_model())\n\n# Stampa del modello\nfor cpd in model.get_cpds():\n    print(\"CPD di {variable}:\".format(variable=cpd.variable))\n    print(cpd)\n\nIl modello √® corretto:  True\nCPD di Arma:\n+---------+-----+\n| Arma(0) | 0.7 |\n+---------+-----+\n| Arma(1) | 0.3 |\n+---------+-----+\nCPD di Movente:\n+------------+-----+\n| Movente(0) | 0.6 |\n+------------+-----+\n| Movente(1) | 0.4 |\n+------------+-----+\nCPD di Alibi:\n+----------+-----+\n| Alibi(0) | 0.5 |\n+----------+-----+\n| Alibi(1) | 0.5 |\n+----------+-----+\nCPD di Colpevolezza:\n+-----------------+------------+-----+------------+------------+\n| Arma            | Arma(0)    | ... | Arma(1)    | Arma(1)    |\n+-----------------+------------+-----+------------+------------+\n| Movente         | Movente(0) | ... | Movente(1) | Movente(1) |\n+-----------------+------------+-----+------------+------------+\n| Alibi           | Alibi(0)   | ... | Alibi(0)   | Alibi(1)   |\n+-----------------+------------+-----+------------+------------+\n| Colpevolezza(0) | 0.9        | ... | 0.3        | 0.1        |\n+-----------------+------------+-----+------------+------------+\n| Colpevolezza(1) | 0.1        | ... | 0.7        | 0.9        |\n+-----------------+------------+-----+------------+------------+\n\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Assumendo che 'model' sia il tuo BayesianNetwork gi√† definito\nG = nx.DiGraph()\nG.add_edges_from(model.edges())\n\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='lightblue',\n        node_size=3000, arrowsize=20, font_size=12, font_weight='bold')\n\nplt.title(\"Rete di Bayes per l'Analisi della Colpevolezza\")\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nInfine, una volta costruita la rete di Bayes possiamo interrogarla per avere una stima della probabilit√† di un determinato evento. Qual √® la probabilt√† che un indagato senza alibi, senza movente e in assenza di arma del delitto sia colpevole?\n\nfrom pgmpy.inference import VariableElimination\n\n# Creiamo un oggetto per l'inferenza\ninference = VariableElimination(model)\n\n# Definiamo l'evidenza per la situazione descritta\nevidence = {\n    'Alibi': 0,  # 0 rappresenta l'assenza di alibi\n    'Movente': 0, # 0 rappresenta l'assenza di motivo\n    'Arma': 0    # 0 rappresenta che l'arma non √® stata trovata\n}\n\n# Calcoliamo la probabilit√† di colpevolezza dato l'evidenza\nresult = inference.query(['Colpevolezza'], evidence=evidence)\n\n# Stampiamo il risultato\nprint(\"Probabilit√† di colpevolezza:\")\nprint(result.values)\n\nProbabilit√† di colpevolezza:\n[0.9 0.1]\n\n\n\nfrom pgmpy.inference import VariableElimination\n\n# Creiamo un oggetto per l'inferenza\ninference = VariableElimination(model)\n\n# Definiamo l'evidenza per la situazione descritta\nevidence = {\n    'Alibi': 1,  # 0 rappresenta l'assenza di alibi\n    'Movente': 0, # 0 rappresenta l'assenza di motivo\n    'Arma': 0    # 0 rappresenta che l'arma non √® stata trovata\n}\n\n# Calcoliamo la probabilit√† di colpevolezza dato l'evidenza\nresult = inference.query(['Colpevolezza'], evidence=evidence)\n\n# Stampiamo il risultato\nprint(\"Probabilit√† di colpevolezza:\")\nprint(result.values)\n\nProbabilit√† di colpevolezza:\n[0.7 0.3]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algoritmi</span>"
    ]
  },
  {
    "objectID": "2-algoritmi.html#algoritmi-di-ricerca",
    "href": "2-algoritmi.html#algoritmi-di-ricerca",
    "title": "Algoritmi",
    "section": "Algoritmi di Ricerca",
    "text": "Algoritmi di Ricerca\nGli algoritmi di ricerca sono utilizzati per esplorare spazi di soluzione vasti e complessi. Nel contesto legale, possono essere utilizzati per trovare precedenti giuridici o per esplorare possibili risultati di un caso. In generale, i problemi di ricerca coinvolgono un agente a cui viene assegnato uno stato iniziale e uno stato obiettivo e restituisce una soluzione su come passare dal primo al secondo.\nGli algoritmi di ricerca sono usati in molte applicazioni della intelligenza artificiale, tra cui:\n\nProblemi di pianificazione: trovare una sequenza di azioni per raggiungere un obiettivo.\nRisoluzione di puzzle e giochi: come il cubo di Rubik, gli scacchi o il gioco del 15.\nNavigazione e percorsi: trovare il percorso migliore in mappe o reti stradali.\nOttimizzazione di processi: trovare la configurazione ottimale in problemi complessi.\nScheduling: organizzare attivit√† o risorse in modo efficiente.\nRiconoscimento di pattern: identificare strutture o sequenze in dati complessi.\nDiagnosi medica: identificare possibili malattie basandosi su sintomi.\nElaborazione del linguaggio naturale: analisi sintattica e semantica.\nVisione artificiale: riconoscimento di oggetti e scene in immagini.\nRobotica: pianificazione del movimento e navigazione autonoma.\n\nQuesti algoritmi sono versatili e possono essere adattati a molti altri domini, rendendo la ricerca un‚Äôarea fondamentale dell‚Äôintelligenza artificiale.\n\nGlossario della ricerca\n\nagente: Una entit√† che percepisce e agisce nel suo ambiente.\nstato: Una configurazione di un agente nel suo ambiente.\nstato iniziale: Lo stato iniziale di un agente.\nstato finale: Lo stato obiettivo di un agente.\nazioni: Le azioni che un agente pu√≤ eseguire da un determinato stato\nmodello di transizione di stato: Un modello che descrive come un agente pu√≤ cambiare lo stato in seguito a un‚Äôazione.\nspazio degli stati: L‚Äôinsieme di tutti gli stati raggiungibili da uno stato iniziale.\ncosto di un cammino o percorso: La somma dei costi delle azioni lungo un percorso.\nsoluzione: Un percorso che porta da uno stato iniziale a uno stato finale. Se ha un costo minimo, √® una soluzpoon ottima.\nalgoritmo di ricerca: Un algoritmo che cerca di trovare una soluzione.\n\n\n\nProblemi di ricerca\nI problemi che si possono affrontare con gli algoritmi di ricerca sono generalmente caratterizzati da una struttura specifica:\n\nStato iniziale: Questo rappresenta la condizione o la configurazione di partenza del problema.\nAzioni o operatori: Questi rappresentano le possibili mosse o le transizioni che possono essere effettuate a partire da uno stato.\nTest obiettivo (goal test): Questo √® un criterio che determina se uno stato specifico risolve il problema.\nFunzione costo: Questa associa un costo a ogni operatore o azione. Il costo pu√≤ rappresentare, ad esempio, il tempo, lo sforzo o le risorse necessarie per eseguire un‚Äôazione.\n\nA seconda della natura del problema, lo stato iniziale pu√≤ essere un singolo stato o un insieme di stati. Inoltre, i problemi possono essere classificati in base alla conoscenza che l‚Äôagente ha sullo stato in cui si trova e sulle azioni.\nUna volta definito il problema in questi termini, l‚Äôalgoritmo di ricerca pu√≤ essere utilizzato per esplorare lo spazio degli stati e trovare una soluzione, che √® una sequenza di azioni che porta dallo stato iniziale a uno stato che soddisfa il test obiettivo¬π.\nesempio di problema di ricerca\nUn esempio classico di problema che segue questa struttura: il problema del commesso viaggiatore (Travelling Salesman Problem, TSP).\nDato un insieme di citt√†, e note le distanze tra ciascuna coppia di esse, trovare il tragitto di minima percorrenza che un commesso viaggiatore deve seguire per visitare tutte le citt√† una ed una sola volta e ritornare alla citt√† di partenza\n\nStato iniziale: Il commesso viaggiatore si trova in una citt√† specifica (ad esempio, Roma) e deve visitare tutte le altre citt√† una sola volta e tornare alla citt√† di partenza.\nAzioni o operatori: Il commesso viaggiatore pu√≤ scegliere di viaggiare da una citt√† all‚Äôaltra. Ogni possibile percorso da una citt√† all‚Äôaltra rappresenta un‚Äôazione.\nTest obiettivo (goal test): Il test obiettivo verifica se tutte le citt√† sono state visitate una sola volta e se il commesso viaggiatore √® tornato alla citt√† di partenza.\nFunzione costo: Il costo di un percorso pu√≤ essere la distanza totale percorsa o il tempo totale impiegato per il viaggio.\n\nL‚Äôobiettivo del problema del commesso viaggiatore √® trovare il percorso pi√π breve (o il percorso che minimizza il tempo di viaggio) che visita tutte le citt√† una sola volta e ritorna alla citt√† di partenza. Gli algoritmi di ricerca possono essere utilizzati per esplorare lo spazio degli stati (cio√®, tutti i possibili percorsi) e trovare la soluzione ottimale.\n\n\nAlgoritmo ‚Äúgenerale‚Äù di ricerca\nIn ogni istante l‚Äôagente si trover√† davanti un insieme di stati possibili da esplorare. Questo insieme di stati √® noto come la ¬´frontiera¬ª (Come nel far west :). Abbiamo bisogno di una struttura dati in grado di contenere gli stati della frontiera che l‚Äôagente pu√≤ esplorare.Vedremo almeno due implementazioni. Lo pseudocodice dell‚Äôalgoritmo ‚Äúgenerale‚Äù di ricerca √® il seguente:\n1 Se la Frontiera √® vuota, Finito!.¬†Si tratta di un problema insolubile!.\n2 Rimuovi un nodo dalla frontiera e consideralo come candidato.\n3    Se il nodo contiene lo stato finale, Restituisci la soluzione. Finito!\n4    Altrimenti\n5        Cerca tutti i nodi raggiungibili dal nodo corrente e aggiungili alla frontiera.\n6        Aggiungi il nodo corrente all‚Äôinsieme dei nodi visitati.\n7 Torna al passo 1.\nL‚Äôalgoritmo di ricerca generale √® un approccio generale per risolvere problemi di ricerca. Nella descrizione di questo algoritmo √® stato omesso un passo fondamentale: come si fa a scegliere il nodo da rimuovere dalla frontiera? La scelta del nodo da rimuovere dalla frontiera √® un passo cruciale nell‚Äôalgoritmo di ricerca. Questa scelta √® basata su una strategia di ricerca, che determina l‚Äôordine in cui i nodi vengono esplorati. L‚Äôimplementazione della frontier√† √® quindi legata alla strategia di ricerca. Le struttre dati usate per la frontiera sono le seguenti:\n\nStack: L‚Äôultimo nodo inserito √® il primo estratto (LIFO = Last In First Out) ‚Äì&gt; Algoritmo Depth First search (DFS)\nQueue: Il primo nodo inserito √® il primo estratto (FIFO = First In First Out) ‚Äì&gt; Algoritmo Breadth First Search (BFS)\nPriority Queue: Il nodo con il valore di pririt√† pi√π alto √® il primo estratto ‚Äì&gt; Algoritmo Best First Search (BFS)\nSet: L‚Äôelemento con il valore di costo pi√π basso √® il primo estratto ‚Äì&gt; Algoritmo A* (A*)\n\ndef ricerca_generale(problema, strategia):\n    frontiera = Strategia(problema)\n    while not frontiera.vuota():\n        nodo = frontiera.rimuovi_nodo()\n        if problema.test_obiettivo(nodo.stato):\n            return nodo\n        frontiera.aggiungi_nodi(nodo.genera_successori())\n    return None\n\n\nStrategie di ricerca non informate\n\nNelle strategie di ricerca non informate l‚Äôagente non vede e non sente se non il proprio stato.\n\nLe strategie di ricerca non informate sono un tipo di algoritmo di ricerca che non utilizza alcuna conoscenza specifica o informazione aggiuntiva sul problema da risolvere. Questi algoritmi utilizzano solo la struttura del problema e la definizione di stato e azione per esplorare lo spazio degli stati. Esempi di strategie di ricerca non informate:\n\nRicerca in profondit√† (Depth-First Search, DFS): Questa strategia esplora lo spazio degli stati andando in profondit√† prima di esplorare i nodi adiacenti. √à una strategia ricorsiva che inizia dallo stato iniziale e procede fino a quando non raggiunge uno stato finale o non pu√≤ pi√π espandere ulteriormente.\nRicerca in ampiezza (Breadth-First Search, BFS): Questa strategia esplora lo spazio degli stati espandendo prima i nodi adiacenti allo stato iniziale, quindi i nodi adiacenti ai nodi adiacenti, e cos√¨ via. √à una strategia che esplora lo spazio degli stati in modo uniforme, garantendo che vengano esplorati prima i nodi pi√π vicini allo stato iniziale.\n‚Ä¶\n\n\nRicerca in profondit√† (Depth-First Search, DFS)\nLa ricerca in profondit√† (Depth-First Search, DFS) √® una strategia di ricerca che esplora lo spazio degli stati andando in profondit√† prima di esplorare i nodi adiacenti. √à una strategia ricorsiva che inizia dallo stato iniziale e procede fino a quando non raggiunge uno stato finale o non pu√≤ pi√π espandere ulteriormente. Questo algoritmo si basa sull‚Äôadozione di una struttura dati a coda per implementare la frontiera.\n\n\n\nDepth-First Search, DFS\n\n\n\n\nRicerca in ampiezza (Breadth-First Search, BFS)\nLa ricerca in ampiezza (Breadth-First Search, BFS) √® una strategia di ricerca che esplora lo spazio degli stati espandendo prima i nodi adiacenti allo stato iniziale, quindi i nodi adiacenti ai nodi adiacenti, e cos√¨ via. √à una strategia che esplora lo spazio degli stati in modo uniforme, garantendo che vengano esplorati prima i nodi pi√π vicini allo stato iniziale. Questo algoritmo si basa sull‚Äôadozione di una struttura dati a pila per implementare la frontiera.\n\n\n\nBreadth-First Search, BFS\n\n\n\n\nDFS e BFS in Python\nUsando l‚Äôalgoritmo generico di ricerca che abbiamo visto fin qui si possono risolvere diversi problemi. Ad esempio, con l‚Äôagente AI fin qui sviluppata possiamo risolvere il problema di trovare il percorso in un labirinto. Per fare questo dobbiamo solo codificare lo spazio degli stati di questo problema e applicare la nostra AI a qualche caso reale.\nstruttura dati per i nodi\nLa struttura dati per memorizzare il generico nodo del grafo dei possibili stati √®\n\nclass Nodo():\n    def __init__(self, stato, genitore, azione):\n        self.stato = stato\n        self.genitore = genitore\n        self.azione = azione\n\nStruttura dati per la frontiera\nL‚Äôaltra struttura dati di cui abbiamo bisogno √® una struttura dati per la Frontiera. Come abbiamo visto ci sono due tipo di struttura dati che possiamo usare per la frontiera.\n\nStruttura dati ‚Äúpila‚Äù per la frontiera Depth First Search (DFS). La pila √® una struttura dati che adotta una logica Last In First Out (l‚Äôultimo a entrare √® il primo ad uscire come accade per una pila, appunto, di piatti :)\nStruttura dati ‚Äúcoda‚Äù per la frontiera Breadth First Search (BFS). La coda √® una struttura dati che adotta una logica First In First Out (l‚Äôelemento che entra per primo √® l‚Äôelemento che esce per primo come accade nella coda ad uno sportello :)\n\n\nclass FrontieraPila():\n    def __init__(self):\n        self.frontiera = []\n\n    def aggiungiStato(self, nodo):\n        self.frontiera.append(nodo)\n\n    def contieneStato(self, stato):\n        return any(nodo.stato == stato for nodo in self.frontiera)\n\n    def eVuota(self):\n        return len(self.frontiera) == 0\n\n    def rimuoviStato(self):\n        if self.eVuota():\n            raise Exception(\"Frontiera vuota\")\n        else:\n            nodo = self.frontiera[-1]\n            self.frontiera = self.frontiera[:-1]\n            return nodo\n\nclass FrontieraCoda(FrontieraPila):\n    def rimuoviStato(self):\n        if self.eVuota():\n            raise Exception(\"Frontiera vuota\")\n        else:\n            nodo = self.frontiera[0]\n            self.frontiera = self.frontiera[1:]\n            return nodo\n\nPossiamo valutare il funzionamento delle due strutture dati introdptte con una semplice simulazione. Memorizziamo 3 stati A,B e C nelle due strutture dati e osserviamo quale stato √® estratto dal metodo rimuoviStato:\n\npila = FrontieraPila()\npila.aggiungiStato(\"A\") # pila = [\"A\"]\npila.aggiungiStato(\"B\") # pila = [\"A\", \"B\"]\npila.aggiungiStato(\"C\") # pila = [\"A\", \"B\", \"C\"]\npila.rimuoviStato()     # pila = [\"A\", \"B\"]\n\n'C'\n\n\n\ncoda = FrontieraCoda()\ncoda.aggiungiStato(\"A\") # coda = [\"A\"]\ncoda.aggiungiStato(\"B\") # coda = [\"A\", \"B\"]\ncoda.aggiungiStato(\"C\") # coda = [\"A\", \"B\", \"C\"]\ncoda.rimuoviStato() # coda = [\"B\", \"C\"]\n\n'A'\n\n\nPer descrivere un labirinto useremo un semplice formato testuale come il seguente:\n#####B#\n##### #\nA     #\n#### ##\n     ##\n#######\nDove il simbolo # rappresenta una parete, il simbolo A un punto di partenza, il simbolo B un punto di arrivo e lo spazio una cella libera. Il labirinto sar√† memorizzato in un file testuale (.txt) e sar√† ‚Äúpassato‚Äù al risolutore di labirinti. La classe Python che si definir√† qui di seguito si occupa del caricamento del labirinto da file di tipo testuale, della sua rappresentazione grafica e della sua risoluzione.\n\nclass Labirinto():\n\n    def __init__(self, nomeFile):\n\n        # legge il file del labirinto e imposta altezza e larghezza del labirinto\n        with open(nomeFile) as f:\n            contenuti = f.read()\n\n        # Verifica che il file contenga almeno uno stato iniziale (= un ingresso) e uno finale (= una uscita)\n        if contenuti.count(\"A\") != 1:\n            raise Exception(\"Un labirinto deve avere esattamente un punto di partenza\")\n        if contenuti.count(\"B\") != 1:\n            raise Exception(\"Un labirinto deve avere esattamente un obiettivo\")\n\n        # Calcola l'altezza e la larghezza del labirinto\n        contenuti = contenuti.splitlines()\n        self.altezza = len(contenuti)\n        self.larghezza = max(len(line) for line in contenuti)\n\n        # tiene traccia dei muri del labirinto\n        self.muri = []\n        for i in range(self.altezza):\n            riga = []\n            for j in range(self.larghezza):\n                try:\n                    if contenuti[i][j] == \"A\":\n                        self.start = (i, j)\n                        riga.append(False)\n                    elif contenuti[i][j] == \"B\":\n                        self.goal = (i, j)\n                        riga.append(False)\n                    elif contenuti[i][j] == \" \":\n                        riga.append(False)\n                    else:\n                        riga.append(True)\n                except IndexError:\n                    riga.append(False)\n            self.muri.append(riga)\n\n        self.soluzione = None\n\n\n\n    def nodiVicini(self, stato):\n        riga, col = stato\n        candidati = [\n            (\"su\", (riga - 1, col)),\n            (\"giu\", (riga + 1, col)),\n            (\"sin\", (riga, col - 1)),\n            (\"des\", (riga, col + 1))\n        ]\n\n        risultato = []\n        for azione, (r, c) in candidati:\n            if 0 &lt;= r &lt; self.altezza and 0 &lt;= c &lt; self.larghezza and not self.muri[r][c]:\n                risultato.append((azione, (r, c)))\n        return risultato\n\n\n    def risolvi(self,frontiera):\n        \"\"\"Trova una soluzione al labirinto, se ne esiste una!\"\"\"\n\n        # contiene il conteggio degli stati esplorati\n        self.numeroStatiEsplorati = 0\n\n        # Inizializziamo la frontiera con lo stato iniziale\n        start = Nodo(stato=self.start, genitore=None, azione=None)\n        frontiera.aggiungiStato(start)\n\n        # Inizializzazione di un set di stati esplorati al momento vuoto\n        self.statiEsplorati = set()\n\n        # Continua a eseguire in ciclo finch√© non si trova una soluzione \n        # o il problema non √® risolvibile\n        while True:\n\n            # Se non c'√® nulla nella frontiera vuol dire che il problema \n            # non √® risolvibile. Ovvero, non c'√® un cammino tra start e goal!\n            if frontiera.eVuota():\n                raise Exception(\"Non esiste una soluzione\")\n\n            # Sceglie un nodo dalla froniera\n            nodo = frontiera.rimuoviStato()\n            self.numeroStatiEsplorati += 1\n\n            # Se il nodo estratto √® il nodo goal allora abbiamo trovato il nodo di arrivo \n            # e risolto il problema\n            if nodo.stato == self.goal:\n                azioni = []\n                celle = []\n                # ripercorre il cammino al contrario dal goal verso lo stato start \n                # per creare il cammino che porta dallo start al goal. Ovvero, la soluzione.\n                while nodo.genitore is not None:\n                    azioni.append(nodo.azione)\n                    celle.append(nodo.stato)\n                    nodo = nodo.genitore\n                # Siccome ha costruito il cammino soluzione in direzione inversa, ovvero \n                # da goal a start per avere il cammino orientato in modo corretto deve \n                # invertire sia la lista degli stati che quella delle azioni\n                azioni.reverse()\n                celle.reverse()\n                # Quindi memorizza la lista degli stati e la lista delle azioni da \n                # intraprendere nell'attributo soluzione della classe Labirinto\n                self.soluzione = (azioni, celle)\n                return\n\n            # Altrimenti marchiamo il nodo estratto come esplorato\n            self.statiEsplorati.add(nodo.stato)\n\n            # E aggiungiamo i nodi vicini alla frontiera\n            for azione, stato in self.nodiVicini(nodo.stato):\n                if not frontiera.contieneStato(stato) and stato not in self.statiEsplorati:\n                    child = Nodo(stato=stato, genitore=nodo, azione=azione)\n                    frontiera.aggiungiStato(child)\n\n\n    def stampaLabirinto(self, mostraSoluzione=True, mostraStatiEsplorati=False):\n        soluzione = self.soluzione[1] if self.soluzione is not None else None\n        print()\n        for i, riga in enumerate(self.muri):\n            for j, col in enumerate(riga):\n                if col:\n                    print(\"‚ñà\", end=\"\")\n                elif (i, j) == self.start:\n                    print(\"A\", end=\"\")\n                elif (i, j) == self.goal:\n                    print(\"B\", end=\"\")\n                elif soluzione is not None and mostraSoluzione and \\\n                                               (i, j) in soluzione:\n                    print(\"*\", end=\"\")\n                # Stati esplorati\n                elif soluzione is not None and mostraStatiEsplorati and \\\n                                            (i, j) in self.statiEsplorati:\n                    print(\"o\", end=\"\")\n                else:\n                    print(\" \", end=\"\")\n            print()\n        print()\n\nPossiamo caricare un labirinto e vedere la sua stampa a video:\n\nl = Labirinto(\"labirinto2.txt\")\nprint(\"Labirinto:\")\nl.stampaLabirinto(False,False)\n\nLabirinto:\n\n‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà ‚ñà\n‚ñà ‚ñà‚ñà‚ñà‚ñà                ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà                     ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà   ‚ñà‚ñà                ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà ‚ñà ‚ñà‚ñà ‚ñà‚ñà‚ñà ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà ‚ñà    ‚ñà   ‚ñà‚ñàB‚ñà         ‚ñà ‚ñà ‚ñà\n‚ñà ‚ñà ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà ‚ñà‚ñà             ‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà             ‚ñà‚ñà    ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà             ‚ñà   ‚ñà\nA      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n\n\n\nAdesso, usando il metodo risolvi della classe labirinto appena definita possiamo risolvere il labirinto. La prima soluzione la cerchiamo con l‚Äôalgoritmo DFS passando al risolutore una frontiera a pila\n\nimport time\nfrom datetime import timedelta\n\nprint(\"Sto cercando una soluzione con una frontiera pila (DFS)...\")\ntempoIniziale = time.time_ns()\nl.risolvi(FrontieraPila())\nprint(\"Numero di stati esplorati : \", l.numeroStatiEsplorati)\ntempoImpiegato = time.time_ns() - tempoIniziale\nmsg = \"L'esecuzione del codice ha richiesto : %s microsecondi (Wall clock time)\" \\\n       % timedelta(microseconds=round(tempoImpiegato/1000))\nprint(msg)\nprint(\"Soluzione trovata : \")\nl.stampaLabirinto(mostraStatiEsplorati=True,mostraSoluzione=True)\n\nSto cercando una soluzione con una frontiera pila (DFS)...\nNumero di stati esplorati :  194\nL'esecuzione del codice ha richiesto : 0:00:00.000809 microsecondi (Wall clock time)\nSoluzione trovata : \n\n‚ñà‚ñà‚ñàooooooooooooooooo‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n‚ñàooo‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñàooo‚ñào‚ñà\n‚ñào‚ñà‚ñà‚ñà‚ñàoooooooooooooooo‚ñào‚ñào‚ñào‚ñà\n‚ñào‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñào‚ñào‚ñào‚ñà\n‚ñàooooooooooooooooooooo‚ñào‚ñào‚ñào‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñào‚ñào‚ñào‚ñà\n‚ñà   ‚ñà‚ñà********oooooooo‚ñào‚ñào‚ñào‚ñà\n‚ñà ‚ñà ‚ñà‚ñà*‚ñà‚ñà‚ñà ‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñào‚ñào‚ñà\n‚ñà ‚ñà****‚ñà   ‚ñà‚ñàB‚ñàooooooooo‚ñào‚ñào‚ñà\n‚ñà ‚ñà*‚ñà‚ñào‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñào‚ñào‚ñà\n‚ñà‚ñà‚ñà*‚ñà‚ñàooooooooooooo‚ñà‚ñà‚ñà‚ñào‚ñào‚ñào‚ñà\n‚ñà‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñà‚ñào‚ñào‚ñào‚ñào‚ñà\n‚ñà‚ñà‚ñà****ooooooooo‚ñà‚ñàoooo‚ñào‚ñào‚ñào‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñào‚ñào‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñàooooooooooooo‚ñàooo‚ñà\nA******‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n\n\n\nQuindi, cerchiamo con l‚Äôalgoritmo BFS passando al risolutore una frontiera a coda\n\nprint(\"Sto cercando una soluzione con una frontiera a coda (BFS)...\")\ntempoIniziale = time.time_ns()\nl.risolvi(FrontieraCoda())\nprint(\"Numero di stati esplorati : \", l.numeroStatiEsplorati)\ntempoImpiegato = time.time_ns() - tempoIniziale\nmsg = \"L'esecuzione del codice ha richiesto : %s microsecondi (Wall clock time)\" \\\n      % timedelta(microseconds=round(tempoImpiegato/1000))\nprint(msg)\nprint(\"Soluzione trovata : \")\nl.stampaLabirinto(mostraStatiEsplorati=True,mostraSoluzione=True)\n\nSto cercando una soluzione con una frontiera a coda (BFS)...\nNumero di stati esplorati :  77\nL'esecuzione del codice ha richiesto : 0:00:00 microsecondi (Wall clock time)\nSoluzione trovata : \n\n‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà ‚ñà\n‚ñà ‚ñà‚ñà‚ñà‚ñà                ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà                     ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñàooo‚ñà‚ñà********o       ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñào‚ñào‚ñà‚ñà*‚ñà‚ñà‚ñào‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà\n‚ñào‚ñà****‚ñàooo‚ñà‚ñàB‚ñà         ‚ñà ‚ñà ‚ñà\n‚ñào‚ñà*‚ñà‚ñào‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà*‚ñà‚ñàooooooooo    ‚ñà‚ñà‚ñà‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà****ooooooooo‚ñà‚ñà    ‚ñà ‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñào‚ñà ‚ñà ‚ñà\n‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà*‚ñà‚ñà‚ñà‚ñàooooooooooooo‚ñà   ‚ñà\nA******‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n\n\n\nOsserviamo dai risultati ottenuti che per questo labirinto l‚Äôalgoritmo di ricerca pi√π veloce √® il BFS perch√© ha trovato la soluzione visitando 77 nodi mentre l‚Äôalgoritmo DFS ha visitato 194 nodi per arrivare alla stessa soluzione.\n\n\n\nAlgoritmi di ricerca informati\nGli algoritmi di ricerca informati sono una classe di algoritmi di ricerca che utilizzano una funzione euristica per guidare la ricerca verso la soluzione in modo pi√π efficiente rispetto agli algoritmi di ricerca non informati come BFS e DFS. Questi algoritmi sfruttano informazioni aggiuntive sul problema, come la distanza stimata dalla soluzione, per esplorare in modo intelligente lo spazio di ricerca.\nUno degli algoritmi di ricerca informati pi√π noti √® l‚Äôalgoritmo A* (pronunciato ‚ÄúA star‚Äù). Esso combina in modo bilanciato le informazioni sulla distanza gi√† percorsa e una stima della distanza rimanente dalla soluzione, utilizzando una funzione euristica. L‚Äôalgoritmo A* √® completo, ovvero garantisce di trovare una soluzione se esiste, ed √® anche ottimale, cio√® trova il percorso pi√π breve verso la soluzione se la funzione euristica √® ammissibile.\nAltri algoritmi di ricerca informati includono la ricerca di best-first, che espande sempre il nodo pi√π promettente in base alla funzione euristica, e la ricerca greedy, che si basa esclusivamente sulla stima euristica senza considerare il costo del percorso gi√† fatto. Questi algoritmi possono essere pi√π veloci dell‚ÄôA* in alcuni casi, ma non garantiscono necessariamente di trovare la soluzione ottimale.\nGli algoritmi di ricerca informati trovano applicazione in numerosi campi, come l‚Äôintelligenza artificiale, la robotica, la pianificazione di percorsi e la risoluzione di problemi di ottimizzazione. La scelta dell‚Äôalgoritmo pi√π appropriato dipende dalle caratteristiche del problema, come la complessit√† dello spazio di ricerca, la disponibilit√† di informazioni euristiche accurate e i requisiti di ottimalit√† della soluzione.\n\nFunzioni euristiche\nLe funzioni euristiche svolgono un ruolo cruciale negli algoritmi di ricerca informati, fornendo una stima della distanza o del costo rimanente per raggiungere la soluzione. Queste funzioni sono progettate per guidare la ricerca in modo intelligente, evitando di esplorare percorsi poco promettenti e concentrandosi sulle regioni dello spazio di ricerca pi√π vicine alla soluzione.\nUna buona funzione euristica dovrebbe essere ammissibile, ovvero non sovrastimare mai il costo effettivo per raggiungere la soluzione. Ci√≤ garantisce che l‚Äôalgoritmo di ricerca, come A*, trovi una soluzione ottimale se esiste. Inoltre, una funzione euristica accurata e informativa pu√≤ accelerare notevolmente la ricerca, riducendo il numero di nodi esplorati prima di trovare la soluzione.\nNella risoluzione di labirinti, una funzione euristica comune √® la distanza di Manhattan o la distanza euclidea tra la posizione corrente e l‚Äôuscita del labirinto. Queste funzioni forniscono una stima della distanza minima rimanente, ignorando gli ostacoli presenti nel labirinto. Tuttavia, funzioni euristiche pi√π sofisticate possono tenere conto di ulteriori informazioni, come la disposizione degli ostacoli o la topologia del labirinto, per ottenere stime pi√π accurate.\nLa progettazione di funzioni euristiche efficaci √® spesso una sfida cruciale nell‚Äôapplicazione degli algoritmi di ricerca informati a problemi complessi del mondo reale.\n\n\n\nDistanze euclidee e di Manhattan\n\n\nDistanza euclidea La distanza euclidea, anche nota come distanza in linea retta, √® una misura della distanza tra due punti in uno spazio euclideo, come il piano cartesiano o lo spazio tridimensionale. Essa rappresenta la lunghezza del segmento di retta che congiunge i due punti.\nLa formula per calcolare la distanza euclidea tra due punti \\(A=(x_A, y_A)\\) e \\(B=(x_B, y_B)\\) in un piano cartesiano bidimensionale √®:\n\\[d_{euclide}=\\sqrt{(x_B-x_A)^2+(y_B-Y_A)^2}\\]\nLa distanza euclidea √® ampiamente utilizzata come funzione euristica negli algoritmi di ricerca informati, come l‚Äôalgoritmo A*, per stimare la distanza rimanente dalla soluzione. Essa fornisce una stima ammissibile (non sovrastima) della distanza effettiva, soddisfacendo cos√¨ i requisiti per garantire l‚Äôottimalit√† dell‚Äôalgoritmo di ricerca.\nTuttavia, la distanza euclidea pu√≤ essere una stima poco accurata in alcuni contesti, come nei labirinti o in presenza di ostacoli, poich√© non tiene conto degli impedimenti lungo il percorso. In questi casi, possono essere utilizzate funzioni euristiche pi√π sofisticate per ottenere stime pi√π precise.\nDistanza di Manhattan La distanza di Manhattan, anche nota come distanza city-block o distanza tassista, √® una metrica utilizzata per calcolare la distanza tra due punti in uno spazio a coordinate cartesiane. Essa prende il nome dalla griglia di strade di Manhattan, dove i percorsi possibili sono limitati a spostamenti orizzontali e verticali.\nLa formula per calcolare la distanza di Manhattan tra due punti \\(A=(x_A, y_A)\\) e \\(B=(x_B, y_B)\\) in un piano cartesiano bidimensionale √®:\n\\[d_{Manhattan}=(x_B-x_A)+(y_B-Y_A)\\]\nEssenzialmente, la distanza di Manhattan √® la somma delle differenze assolute delle coordinate x e y dei due punti.\nLa distanza di Manhattan √® spesso utilizzata come funzione euristica negli algoritmi di ricerca informati, come l‚Äôalgoritmo A*, per risolvere problemi di ricerca su griglie o labirinti. Essa fornisce una stima ammissibile della distanza effettiva, garantendo cos√¨ l‚Äôottimalit√† dell‚Äôalgoritmo di ricerca.\nRispetto alla distanza euclidea, la distanza di Manhattan pu√≤ essere una stima pi√π accurata in contesti come i labirinti, poich√© tiene conto delle restrizioni di movimento lungo le direzioni orizzontali e verticali. Tuttavia, pu√≤ sottostimare la distanza effettiva in situazioni in cui sono possibili percorsi diagonali.\nLa scelta tra la distanza euclidea e la distanza di Manhattan come funzione euristica dipende dalle caratteristiche specifiche del problema di ricerca e dalle propriet√† dello spazio di ricerca.\n\n\nAlgoritmo di ricerca informato Greedy Best-First Search\n\n\n\nricerca informata\n\n\nQuando l‚Äôalgoritmo si trova nella cella colorata di azzurro deve scegliere se proseguire nella cella a distanza 9 o in quella a distanza 11 dal goal. Quale scegliere? GBF sceglie la cella con distanza 9 dall‚Äôobiettivo. √à una buona scelta? Direi di no! Il cammino scelto √® il pi√π lungo. Forse, si pu√≤ fare di meglio? Se esaminiamo le cella a e b notiamo l‚Äôeuristica che ci ha portato in b con GBS √® minore dell‚Äô euristica in a. Ma, che cosa succede se oltre a considerare la distanza dall‚Äôobbiettivo aggiungo il cammino fatto all‚Äôeuristica h? Ovvero: \\[H = distanza da percorrere + distanza percorsa\\] Entra l‚Äôalgoritmo informato A*\n\n\nAlgoritmo di ricerca informato A*\n\n\n\nRicerca informata A*\n\n\nL‚Äôalgoritmo A* √® un algoritmo di ricerca informato che utilizza una funzione di valutazione per guidare la ricerca verso la soluzione ottimale. La funzione di valutazione, nota come funzione di costo \\(h(n)\\), √® composta da due componenti: 1. Costo del cammino: \\(g(n)\\), che rappresenta il costo del cammino per raggiungere il nodo \\(n\\) dalla radice. 2. Stima del costo rimanente: \\(f(n)\\), che rappresenta una stima del costo rimanente per raggiungere la soluzione ottimale partendo dal nodo \\(n\\). La funzione di valutazione \\(h(n)\\) √® definita come: \\[h(n) = g(n) + f(n)\\] L‚Äôalgoritmo A* utilizza una coda di priorit√† per mantenere i nodi da esplorare in base al valore della funzione di valutazione \\(f(n)\\). I nodi con il valore pi√π basso di \\(h(n)\\) vengono estratti dalla coda e esplorati prima. Nel caso in figura, con questa nuova euristica vediamo che a √® una scelta migliore di b perch√© ha una euristica minore.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algoritmi</span>"
    ]
  },
  {
    "objectID": "2-algoritmi.html#algoritmi-equitativi",
    "href": "2-algoritmi.html#algoritmi-equitativi",
    "title": "Algoritmi",
    "section": "Algoritmi Equitativi",
    "text": "Algoritmi Equitativi\nL‚Äôavvento dell‚ÄôIntelligenza Artificiale e il progresso nella capacit√† computazionale delle moderne macchine hanno rivoluzionato molteplici aspetti della nostra vita quotidiana. Tra le numerose applicazioni dell‚ÄôIA, gli algoritmi predittivi e gli algoritmi di ripartizione equitativa si distinguono per il loro potenziale straordinario e per le sfide etiche che presentano.\nGli algoritmi predittivi, capaci di effettuare previsioni estremamente accurate in svariati scenari, sono diventati strumenti essenziali in settori cruciali come quello giudiziario, creditizio, assicurativo e sanitario. Questi algoritmi analizzano enormi quantit√† di dati per prendere decisioni che possono avere un impatto significativo sulla vita delle persone. Tuttavia, il loro crescente impiego ha sollevato una preoccupazione fondamentale: l‚Äôequit√†.\nL‚Äôequit√† negli algoritmi si riferisce alla loro capacit√† di trattare in modo imparziale tutti i gruppi di persone, indipendentemente da attributi sensibili come etnia, genere, et√† o stato socioeconomico. Senza adeguate misure di equit√†, gli algoritmi rischiano di perpetuare o addirittura amplificare disuguaglianze sociali ed economiche esistenti, poich√© i dati utilizzati per il loro addestramento possono contenere pregiudizi storici e sistemici.\nParallelamente, gli algoritmi di ripartizione equitativa giocano un ruolo cruciale nella distribuzione giusta e bilanciata di risorse o beni tra pi√π parti. Questi algoritmi trovano applicazione in scenari diversi, dalla divisione dei beni durante un divorzio alla distribuzione di fondi di emergenza in situazioni di crisi.\nPer affrontare le sfide legate all‚Äôequit√†, sono stati sviluppati vari approcci e metodologie. Tra questi, la pre-elaborazione dei dati mira a correggere i bias presenti nei dati prima dell‚Äôaddestramento degli algoritmi. Durante lo sviluppo, si possono includere vincoli di equit√† nei processi di ottimizzazione per evitare che l‚Äôalgoritmo favorisca ingiustamente un gruppo rispetto a un altro. Il post-processamento dei risultati permette di aggiustare le previsioni per eliminare disparit√† tra gruppi diversi.\nLa trasparenza e la spiegabilit√† degli algoritmi sono essenziali per affrontare le questioni etiche correlate. Spesso, gli algoritmi pi√π avanzati sono percepiti come ‚Äúscatole nere‚Äù, rendendo difficile comprendere i processi decisionali e attribuire responsabilit√† in caso di errori. Questo solleva importanti questioni di responsabilit√† e trasparenza.\nL‚Äôimplementazione di algoritmi equitativi pu√≤ avere impatti significativi in vari settori. Nel sistema giudiziario, strumenti equi possono promuovere la fiducia nel sistema legale. Nei processi di assunzione, possono garantire valutazioni basate sulle competenze piuttosto che su caratteristiche personali. Nel campo sanitario, possono migliorare l‚Äôaccesso e la qualit√† delle cure per tutte le popolazioni.\nIn conclusione, l‚Äôequit√† nell‚ÄôIA √® un aspetto cruciale che richiede attenzione e considerazione. Mentre gli algoritmi predittivi e gli algoritmi di ripartizione equitativa rivestono un ruolo fondamentale nella nostra vita quotidiana, √® essenziale garantire che siano sviluppati e utilizzati in modo equo e trasparente. Solo cos√¨ possiamo trarre il massimo beneficio dalla potenza dell‚ÄôIA senza incorrere in potenziali disuguaglianze e pregiudizi. In questo paragrafo, esploreremo gli algoritmi di ripartizione equitativa, che sono essenziali per garantire che le risorse o i beni siano distribuiti in modo equo tra le parti interessate. Questi algoritmi trovano applicazione in scenari diversi, dalla divisione dei beni durante un divorzio alla distribuzione di fondi di emergenza in situazioni di crisi.\n\nagenti partecipanti\nIn generale, si ha a che fare con un insieme N di agenti o partecipanti o giocatori. Questi agenti hanno la necessit√† di mettersi d‚Äôaccordo sulla divisione di un certo numero M di beni, risorse, oggetti, ecc.\n\n\nbeni\nGli algoritmi di suddivisione equa possono essere applicati a diversi tipi di beni, ciascuno con caratteristiche specifiche che influenzano il modo in cui la suddivisione deve essere effettuata. Questi beni possono essere classificati in diverse categorie:\nBeni Divisibili I beni divisibili sono quelli che possono essere suddivisi in parti pi√π piccole senza perdere il loro valore intrinseco. Esempi includono:\n\nCibo: come una torta o una pizza, che possono essere tagliati in fette.\nTerreni: una propriet√† terriera pu√≤ essere suddivisa in appezzamenti pi√π piccoli.\nDenaro: che pu√≤ essere facilmente diviso in unit√† pi√π piccole.\n\nBeni Indivisibili I beni indivisibili non possono essere suddivisi senza perdere il loro valore o funzionalit√†. Esempi includono:\n\nOggetti fisici unici: come una macchina, un‚Äôopera d‚Äôarte o un elettrodomestico.\nRuoli o incarichi: come una posizione lavorativa o un incarico specifico in un progetto.\n\nBeni Combinati Alcuni beni possono essere considerati una combinazione di elementi divisibili e indivisibili. Ad esempio:\n\nPacchetti di beni: come un set di mobili dove ogni pezzo √® indivisibile, ma il set complessivo pu√≤ essere suddiviso.\nProgetti con compiti specifici: dove i singoli compiti possono essere indivisibili, ma l‚Äôintero progetto pu√≤ essere suddiviso tra diversi partecipanti.\n\nBeni con Valore Soggettivo Alcuni beni hanno un valore che varia a seconda delle preferenze individuali dei partecipanti. Esempi includono:\n\nOggetti con valore sentimentale: come regali o ricordi di famiglia.\nElementi artistici o culturali: come quadri o libri, il cui valore pu√≤ dipendere dal gusto personale.\n\nBeni Temporanei Questi sono beni che possono essere utilizzati per un certo periodo di tempo e poi riassegnati. Esempi includono:\n\nUso di risorse comuni: come una sala conferenze, un campo sportivo o un‚Äôattrezzatura condivisa.\nServizi o turni di lavoro: dove il tempo di servizio o il turno pu√≤ essere diviso tra pi√π persone.\n\nBeni Digitali I beni digitali possono essere suddivisi e duplicati senza perdere valore. Esempi includono:\n\nSoftware: che pu√≤ essere concesso in licenza a pi√π utenti.\nContenuti digitali: come e-book, musica o video, che possono essere condivisi tra pi√π persone. Per affrontare questi problemi, gli algoritmi di suddivisione equa utilizzano criteri diversi, come la proporzionalit√†, l‚Äôefficienza, l‚Äôequita, l‚Äôinvidia-zero (nessun partecipante dovrebbe invidiare la parte degli altri) e altre nozioni di giustizia.\n\nEsempi di criteri di equit√†\n\nProporzionalit√†: Ogni partecipante riceve una quota proporzionale alle proprie pretese o contributi.\nInvidia-zero: Nessun partecipante deve preferire la parte assegnata a un altro partecipante alla propria parte.\nEfficienza Pareto: Non √® possibile riassegnare le risorse in modo che qualcuno sia in una situazione migliore senza che qualcun altro sia in una situazione peggiore.\nEquit√† equitativa: Ogni partecipante percepisce di aver ricevuto una parte equa in base a criteri specifici.\n\nGli algoritmi di suddivisione equa cercano di trovare soluzioni che bilancino questi criteri, a seconda delle specifiche esigenze del contesto in cui vengono applicati.\n\n\nRegole e assunzioni\nRegole Affinch√© la divisione di un bene S sia equa: - i giocatori devono essere partecipanti volontari e accettare le regole del gioco come vincolanti.\n\nI giocatori devono agire razionalmente secondo il loro sistema di credenze.\nLe regole della matematica si applicano quando si assegnano valori agli oggetti in S.\nSolo i giocatori sono coinvolti nel gioco, non ci sono agenti esterni come avvocati o altri intermediari.\n\nSe i giocatori seguono le regole, il gioco terminer√† dopo un numero finito di mosse dei giocatori e risulter√† in una divisione di S.\nAssunzioni\nGli algoritmi si basano sulle seguenti assunzionimere quanto segue:\n\nTutti i giocatori giocano in modo corretto.\nNon hanno informazioni precedenti sui gusti o le avversioni degli altri giocatori.\nNon assegnano valori in modo da manipolare il gioco.\nTutti i giocatori hanno uguali diritti nella condivisione dell‚Äôinsieme S. In altre parole, se ci sono tre giocatori, ogni giocatore ha diritto ad almeno 1/3 di S.\n\nSe queste assunzioni non sono soddisfatte, la divisione potrebbe non essere completamente equa.\n\n\nMatematica elementare per algoritmi di ripartizione equa\n\nPercentuale: Una percentuale √® una frazione con un denominatore di 100. Ad esempio, il 50% √® la met√†, il 25% √® un quarto e il 100% √® l‚Äôintero.\nPercentuale di un numero: Per trovare la percentuale di un numero, moltiplica il numero per la percentuale come decimale. Ad esempio, il 25% di 80 √® 0,25 x 80 = 20.\nPercentuale di un numero n1 rispetto a un numero n2: Per calcolare la percentuale di un numero n1 rispetto a un numero n2, dividi n1 per n2 e moltiplica per 100. Ad esempio, se 20 √® una parte di 80, si ha che 20 √® il (20/80) x 100 di 80 o il 25% di 80.\n\nesempio: 1. Alice e Bob hanno un sacchetto di 100 monete. Alice ha 60 monete, mentre Bob ha 40 monete. Qual √® la percentuale di monete di Alice rispetto a Bob? Soluzione: - La percentuale di monete di Alice rispetto a Bob: (60/40) x 100 = 150%. - Quindi, Alice ha il 150% delle monete di Bob.\n\nAlice, Bob, Claudia e Daniele hanno una torta. Alice ha 2 fette, Bob ha 3 fette, Claudia ha 4 fette e Daniele ha 1 fetta. Qual √® la percentuale di fette di Alice rispetto a Bob? Soluzione:\n\n\nLa percentuale di fette di Alice rispetto a Bob: (2/3) x 100 = 66,67%. Qual √® la percentuale di torta che ha Alice? Soluuzione:\nLa percentuale di torta che ha Alice: (2/10) x 100 = 20%.\n\n\n\nAlgoritmi di Ripartizione Equitativa\nUn problema tipico di ripartizione equa pu√≤ essere formulato come segue: Alice, Bruno, Carla e Davide hanno una torta. La torta √® divisa in 4 parti non necessariamente uguali e non con la stessa farcitura e/o copertura. Ognuno dei 4 partecipanti ha una sua preferenza per ognuna delle quattro parti. Le preferenze sono riassunte nella seguente tabella:\n\n\n\n\n\n\n\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nLa domanda che ci si pone √®: Quale porzione di torta considererebbe equa ogni giocatore? √à importante ricordare che un algoritmo di ripartizione equa si basa sulle assunzioni del paragrafo 3.5.3. Pertanto, ogni giocatore ha espresso la propria preferenza senza conoscere le preferenze degli altri partecipanti. La soluzione, in questo caso, √® illustrata nella tabella seguente, dove √® evidenziata la porzione assegnata a ciascun giocatore, rispettando le preferenze manifestate.\n\n\n\n\n\n\n\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nL‚Äôimplementazione dell‚Äôalgorimo usato per ottenere la soluzione √® riportata nella prossima sezione\n\ndef divisione_equa(preferenze):\n    # 1. **Inizializzazione** : Converti il dizionario delle preferenze in una lista \n    # di tuple per una gestione pi√π semplice\n    partecipanti = list(preferenze.keys())\n    valori_preferenze = list(preferenze.values())\n\n    # Numero di partecipanti e porzioni\n    num_partecipanti = len(partecipanti)\n    num_porzioni = len(valori_preferenze[0])\n\n    # Inizializza la lista di allocazione\n    allocazione = [-1] * num_partecipanti\n    porzioni_usate = [False] * num_porzioni\n\n    # 2. **Funzione `trova_preferenza_massima`** : Funzione per trovare il partecipante \n    # con la preferenza pi√π alta per una data porzione\n    def trova_preferenza_massima(porzione):\n        preferenza_massima = -1\n        indice_partecipante = -1\n        for i in range(num_partecipanti):\n            if valori_preferenze[i][porzione] &gt; preferenza_massima and allocazione[i] == -1:\n                preferenza_massima = valori_preferenze[i][porzione]\n                indice_partecipante = i\n        return indice_partecipante\n\n    # 3. **Assegnazione delle Porzioni** : Assegna le porzioni ai partecipanti\n    for porzione in range(num_porzioni):\n        indice_partecipante = trova_preferenza_massima(porzione)\n        allocazione[indice_partecipante] = porzione\n        porzioni_usate[porzione] = True\n\n    # 4. **Creazione del Risultato** : Crea un dizionario di risultato per mappare \n    # i partecipanti alle loro porzioni allocate\n    risultato = {partecipanti[i]: f\"porzione {allocazione[i] + 1}\" \\\n                 for i in range(num_partecipanti)}\n\n    return risultato\n\n# 5. **Esecuzione del Codice**: Esegui il codice con le preferenze fornite\n\n# Preferenze dei partecipanti\npreferenze = {\n    'Alice': [10, 50, 30, 10],  # Preferenze per le porzioni 1, 2, 3, e 4\n    'Bruno': [30, 30, 10, 30],\n    'Carla': [40, 20, 20, 20],\n    'Davide': [25, 25, 25, 25]\n}\n\n# Trova la divisione equa delle porzioni\nallocazione = divisione_equa(preferenze)\n\n# Stampa il risultato\nprint(\"Una divisione equa delle porzioni √® la seguente:\")\nfor partecipante, porzione in allocazione.items():\n    print(f\"{partecipante} riceve {porzione}\")\n\nUna divisione equa delle porzioni √® la seguente:\nAlice riceve porzione 2\nBruno riceve porzione 4\nCarla riceve porzione 1\nDavide riceve porzione 3\n\n\nIl semplice codice Python proposto implementa un algoritmpo di divisione equa nel seguente modo:\n\nInizializzazione:\n\nConvertiamo il dizionario delle preferenze in una lista di tuple per una gestione pi√π semplice.\nOtteniamo i nomi dei partecipanti e le loro preferenze.\nInizializziamo le liste allocazione e porzioni_usate per tenere traccia delle porzioni assegnate e delle porzioni gi√† utilizzate.\n\nFunzione trova_preferenza_massima:\n\nQuesta funzione trova il partecipante con la preferenza pi√π alta per una data porzione che non ha ancora ricevuto una porzione.\nScorre tutti i partecipanti e confronta le loro preferenze per la porzione corrente, restituendo l‚Äôindice del partecipante con la preferenza massima.\n\nAssegnazione delle Porzioni:\n\nPer ogni porzione, troviamo il partecipante con la preferenza pi√π alta utilizzando la funzione trova_preferenza_massima.\nAssegniamo la porzione a quel partecipante e segniamo la porzione come utilizzata.\n\nCreazione del Risultato:\n\nCreiamo un dizionario risultato che mappa i partecipanti alle loro porzioni assegnate.\nRestituiamo il dizionario risultato.\n\nEsecuzione del Codice:\n\nDefiniamo le preferenze dei partecipanti.\nChiamiamo la funzione divisione_equa per ottenere la divisione delle porzioni.\nStampiamo il risultato.\n\n\nEvidentemente, l‚Äôalgoritmo proposto non √® l‚Äôunica soluzione possibile e pu√≤ dare origine a situazioni di iniquit√† o di conflitti. Ad esempio se le preferenze dei partecipanti sono:\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n20%\n40%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nSi noti il conflitto tra Alice e Carla per la porzione 2. La soluzione a cui arriva l‚Äôalgoritmo visto √®:\n\npreferenze = {\n    'Alice': [10, 50, 30, 10],  # Preferenze per le porzioni 1, 2, 3, e 4\n    'Bruno': [30, 30, 10, 30],\n    'Carla': [20, 40, 20, 20],\n    'Davide': [25, 25, 25, 25]\n}\n\n# Trova la divisione equa delle porzioni\nallocazione = divisione_equa(preferenze)\n\n# Stampa il risultato\nprint(\"Una divisione equa delle porzioni √® la seguente:\")\nfor partecipante, porzione in allocazione.items():\n    print(f\"{partecipante} riceve {porzione}\")\n\nUna divisione equa delle porzioni √® la seguente:\nAlice riceve porzione 2\nBruno riceve porzione 1\nCarla riceve porzione 4\nDavide riceve porzione 3\n\n\nIn questo caso, Carla riceve una porzione per la quale ha espresso un interesse minore e potrebbe invidiare Alice, che ha ottenuto proprio la porzione che lei avrebbe preferito. Tuttavia, non ci si pu√≤ fare niente. La soluzione proposta √® la migliore possibile date le preferenze espresse e i beni indivisibili disponibili.\nValore soggettivo di un bene\nPrima di trattare l‚Äôargomento dell‚Äôinvidia, c‚Äô√® un altro aspetto interessante da approfondire: il valore soggettivo del bene. Ad esempio, nella suddivisione esaminata, se la torta costa 18 ‚Ç¨, quale sarebbe il valore economico di ogni porzione di torta per ciascun partecipante?\nTememdo conto che le preferenze sono le seguenti:\n\n\n\n\n\n\n\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nAlice ha il 50% di prefernenze per la porzione 2 quindi per lei la porzione 2 vale il 50% di 18‚Ç¨ = 9‚Ç¨ e cos√¨ via. La tabella dei valori delle singole perzioni per ogni partecipante √® la seguente:\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n1,80‚Ç¨\n9,00‚Ç¨\n5,40‚Ç¨\n1,80‚Ç¨\n\n\nBruno\n5,40‚Ç¨\n5,40‚Ç¨\n1,80‚Ç¨\n5,40‚Ç¨\n\n\nCarla\n7,20‚Ç¨\n3,60‚Ç¨\n3,60‚Ç¨\n3,60‚Ç¨\n\n\nDavide\n4,50‚Ç¨\n4,50‚Ç¨\n4,50‚Ç¨\n4,50‚Ç¨\n\n\n\nVediamo un altro esempio di calcolo del valore soggettivo di un bene. Alice vede una torta che costa 18‚Ç¨ di cui una met√† al cioccolato e l‚Äôaltra al pistacchio. Alice ama il cioccolato e non ama il pistacchio. Alice valuta la porzione al cioccolato al 90% e la porzione al pistacchio al 10%. Quindi Alice valuta la met√† al cioccolato al 90% di 18‚Ç¨ = 16,20‚Ç¨ e la met√† al pistacchio al 10% di 18‚Ç¨ = 1,80‚Ç¨.\nIn generale, il valore soggettivo di un bene pu√≤ essere influenzato da una variet√† di fattori, che riflettono le percezioni individuali e le circostanze specifiche. Ecco alcuni degli aspetti principali che possono influenzare il valore soggettivo:\n\nScarsit√†: Un bene raro o difficile da reperire tende ad avere un valore soggettivo pi√π elevato1. Domanda: La popolarit√† o la desiderabilit√† di un bene possono aumentarne il valore percepito1.\nPreferenze personali: Gli interessi, i gusti e le preferenze individuali giocano un ruolo significativo nel determinare il valore di un bene per una persona1.\nSignificato culturale: Il valore di un bene pu√≤ essere influenzato dal suo significato o dalla sua importanza in una determinata cultura.\nCircostanze situazionali: Eventi specifici o situazioni particolari possono alterare il valore di un bene. Ad esempio, l‚Äôacqua potrebbe avere un valore molto pi√π alto in un deserto rispetto a una citt√†2.\nAffinit√† personale: Il legame emotivo o la storia personale con un bene possono aumentarne il valore per un individuo2.\nIncertezza e mancanza di conoscenza: A volte le persone possono valutare l‚Äôimportanza di un bene in modo non conforme alla sua reale importanza a causa dell‚Äôincertezza o della mancanza di informazioni.\n\nQuesti fattori dimostrano che il valore di un bene non √® fisso o intrinseco, ma √® piuttosto determinato dalle percezioni e dalle circostanze individuali. La teoria del valore soggettivo sostiene che il valore di un bene dipende dall‚Äôambiente e dalle persone che lo percepiscono, piuttosto che dai costi di produzione o dal lavoro necessario per crearlo1.\nMitigazione dell‚Äôinvidia\nCome anticipato, √® necessario approfondire il problema della divisione equa senza invidia. Immaginiamo due amici, Alice e Bruno, che devono dividersi una serie di oggetti di valore in modo che nessuno dei due si senta invidioso dell‚Äôaltro. Ad esempio, supponiamo che Alice e Bruno debbano dividersi i seguenti beni con le rispettive valutazioni:\n\n\n\nOggetto\nAlice\nBruno\n\n\n\n\norologio\n4\n2\n\n\nlibro\n2\n3\n\n\npenna\n2\n3\n\n\nquadro\n2\n2\n\n\n\nNwl seguito si propone una implementazione dell‚Äôalgoritmo envy free in Python:\n\ndef allocazione_senza_invidia(beni, valutazioni): # 1. **Definizione della Funzione**\n    \"\"\"\n    Algoritmo di Envy-Free per la divisione di beni indivisibili tra due persone.\n\n    beni: lista di beni da dividere\n    valutazioni: dizionario con le valutazioni dei beni per ciascun partecipante\n    \"\"\"\n    # 2. **Inizializzazione delle Assegnazioni**:\n    assegnazione = {'Alice': [], 'Bob': []}\n    valori_totali = {'Alice': 0, 'Bob': 0}\n\n    # 3. **Ordinamento dei Beni**: Ordina gli oggetti in base alla somma delle valutazioni\n    beni_ordinati = sorted(beni, key=lambda x: valutazioni['Alice'][x] + \\\n                            valutazioni['Bob'][x], reverse=True)\n\n    # 4. **Assegnazione dei Beni**: Assegna gli oggetti in modo da bilanciare i valori totali\n    for bene in beni_ordinati:\n        if valori_totali['Alice'] &lt;= valori_totali['Bob']:\n            assegnazione['Alice'].append(bene)\n            valori_totali['Alice'] += valutazioni['Alice'][bene]\n        else:\n            assegnazione['Bob'].append(bene)\n            valori_totali['Bob'] += valutazioni['Bob'][bene]\n\n    # 5. **Verifica e Correzione delle Invidie**: Verifica e corregge eventuali invidie\n    for bene in beni_ordinati:\n        if valutazioni['Alice'][bene] &gt; valutazioni['Bob'][bene] and  \\\n                                         bene in assegnazione['Bob']:\n            if valori_totali['Alice'] &lt; valori_totali['Bob']:\n                assegnazione['Bob'].remove(bene)\n                assegnazione['Alice'].append(bene)\n                valori_totali['Alice'] += valutazioni['Alice'][bene]\n                valori_totali['Bob'] -= valutazioni['Bob'][bene]\n        elif valutazioni['Bob'][bene] &gt; valutazioni['Alice'][bene] and \\\n                                         bene in assegnazione['Alice']:\n            if valori_totali['Bob'] &lt; valori_totali['Alice']:\n                assegnazione['Alice'].remove(bene)\n                assegnazione['Bob'].append(bene)\n                valori_totali['Bob'] += valutazioni['Bob'][bene]\n                valori_totali['Alice'] -= valutazioni['Alice'][bene]\n\n    return assegnazione # 6. **Ritorno delle Assegnazioni**:\n\nIl funzionamento del codice √® il seguente:\n\nDefinizione della Funzione:\ndef allocazione_senza_invidia(beni, valutazioni):\n\nDefinisce una funzione chiamata allocazione_senza_invidia che prende due parametri: beni (lista di beni da dividere) e valutazioni (dizionario con le valutazioni dei beni per ciascun partecipante).\n\nInizializzazione delle Assegnazioni:\nassegnazione = {'Alice': [], 'Bob': []}\nvalori_totali = {'Alice': 0, 'Bob': 0}\n\nInizializza due dizionari: assegnazione per tenere traccia dei beni assegnati a ciascun partecipante e valori_totali per tenere traccia del valore totale dei beni assegnati a ciascun partecipante.\n\nOrdinamento dei Beni:\nbeni_ordinati = sorted(beni, key=lambda x: valutazioni['Alice'][x] + \\\n                       valutazioni['Bob'][x], reverse=True)\n\nOrdina i beni in base alla somma delle valutazioni di Alice e Bob, in ordine decrescente.\n\nAssegnazione dei Beni:\nfor bene in beni_ordinati:\n    if valori_totali['Alice'] &lt;= valori_totali['Bob']:\n        assegnazione['Alice'].append(bene)\n        valori_totali['Alice'] += valutazioni['Alice'][bene]\n    else:\n        assegnazione['Bob'].append(bene)\n        valori_totali['Bob'] += valutazioni['Bob'][bene]\n\nAssegna i beni in modo da bilanciare i valori totali tra Alice e Bob. Se il valore totale di Alice √® minore o uguale a quello di Bob, il bene viene assegnato ad Alice, altrimenti a Bob.\n\nVerifica e Correzione delle Invidie:\nfor bene in beni_ordinati:\n    if valutazioni['Alice'][bene] &gt; valutazioni['Bob'][bene] and \\ \n                                    bene in assegnazione['Bob']:\n        if valori_totali['Alice'] &lt; valori_totali['Bob']:\n            assegnazione['Bob'].remove(bene)\n            assegnazione['Alice'].append(bene)\n            valori_totali['Alice'] += valutazioni['Alice'][bene]\n            valori_totali['Bob'] -= valutazioni['Bob'][bene]\n    elif valutazioni['Bob'][bene] &gt; valutazioni['Alice'][bene] and \\\n                                    bene in assegnazione['Alice']:\n        if valori_totali['Bob'] &lt; valori_totali['Alice']:\n            assegnazione['Alice'].remove(bene)\n            assegnazione['Bob'].append(bene)\n            valori_totali['Bob'] += valutazioni['Bob'][bene]\n            valori_totali['Alice'] -= valutazioni['Alice'][bene]\n\nVerifica se ci sono invidie e corregge le assegnazioni di conseguenza. Se Alice valuta un bene pi√π di Bob e il bene √® assegnato a Bob, viene riassegnato ad Alice se il valore totale di Alice √® inferiore a quello di Bob, e viceversa.\n\nRitorno delle Assegnazioni:\nreturn assegnazione\n\nRestituisce il dizionario delle assegnazioni finali.\n\n\nCaso d‚ÄôUso Reale\nDivisione di una serie di oggetti di valore tra Alice e Bruno, in modo che nessuno dei due si senta invidioso dell‚Äôaltro. Ad esempio, supponiamo che Alice e Bruno debbano dividersi i seguenti beni con le rispettive valutazioni personali:\n\n\nbeni = ['orologio', 'libro', 'penna']\nvalutazioni = {\n    'Alice': {'orologio': 10, 'libro': 5, 'penna': 1},\n    'Bob': {'orologio': 8, 'libro': 7, 'penna': 2}\n}\n\nUtilizzando la funzione allocazione_senza_invidia, possiamo ottenere una divisione equa:\n\nassegnazione = allocazione_senza_invidia(beni, valutazioni)\nprint(assegnazione)\n\n{'Alice': ['orologio'], 'Bob': ['libro', 'penna']}\n\n\nIn questo caso, Alice riceve l‚Äôorologio, mentre Bob riceve il libro e la penna, garantendo che nessuno dei due si senta invidioso dell‚Äôaltro.\n\n\nGli algoritmi di divisione equa in letteratura\nGli algoritmi di ripartizione equa sono un insieme di metodi utilizzati per distribuire risorse limitate tra pi√π utenti o gruppi in modo equo e imparziale. Questi algoritmi mirano a garantire che ogni utente o gruppo riceva una quota equa delle risorse, tenendo conto di fattori come le esigenze individuali, le priorit√† e le limitazioni. Esistono diversi tipi di algoritmi di ripartizione equa, tra questi si citano:\n1. Metodi per la Divisione Equa tra Due Partecipanti - Adjusted Winner (AW): Algoritmo per la divisione equa di oggetti tra due partecipanti. - Citazione: Brams, S. J., & Taylor, A. D. (1996). Fair Division: From Cake-Cutting to Dispute Resolution. Cambridge University Press.\n\nDivide and Choose: Metodo classico per la divisione equa tra due partecipanti.\n\nCitazione: Steinhaus, H. (1948). The problem of fair division. Econometrica, 16(1), 101-104.\n\nLast Diminisher: Estensione del metodo Divide and Choose per pi√π partecipanti.\n\nCitazione: Steinhaus, H. (1948). The problem of fair division. Econometrica, 16(1), 101-104.\n\n\nMetodi per la Divisione Equa tra Tre O Pi√π Partecipanti - Algoritmo di Selfridge-Conway: Metodo per la divisione equa di una torta tra tre partecipanti. - Citazione: Robertson, J., & Webb, W. (1998). Cake-cutting algorithms: Be fair if you can. AK Peters/CRC Press.\n\nAlgoritmo di Dubins-Spanier: Metodo per la divisione equa di una risorsa continua tra n partecipanti.\n\nCitazione: Dubins, L. E., & Spanier, E. H. (1961). How to cut a cake fairly. The American Mathematical Monthly, 68(1), 1-17.\n\nAlgoritmo di Stromquist: Metodo per la divisione envy-free tra tre partecipanti usando un numero finito di tagli.\n\nCitazione: Stromquist, W. (1980). How to cut a cake fairly. The American Mathematical Monthly, 87(8), 640-644.\n\nAlgoritmo di Austin: Metodo per la divisione envy-free tra quattro o pi√π partecipanti.\n\nCitazione: Austin, A. K. (1982). Sharing a cake. The Mathematical Gazette, 66(437), 212-215.\n\nAlgoritmo di Brams-Taylor-Zwicker: Metodo per la divisione equa tra pi√π di tre partecipanti.\n\nCitazione: Brams, S. J., Taylor, A. D., & Zwicker, W. S. (1997). A moving-knife solution to the four-person envy-free cake-division problem. Proceedings of the American Mathematical Society, 125(2), 547-554.\n\nAlgoritmo di Brams-Taylor per n partecipanti: Metodo per la divisione envy-free tra n partecipanti.\n\nCitazione: Brams, S. J., & Taylor, A. D. (1995). An envy-free cake division protocol. The American Mathematical Monthly, 102(1), 9-18.\n\n\nMetodi di Allocazione Proporzionale - Proportional Allocation: Metodi per allocare risorse in modo proporzionale alle richieste o ai diritti delle parti. - Citazione: Young, H. P. (1994). Equity: In Theory and Practice. Princeton University Press.\n\nMaximin Share Allocation: Concetto di equit√† per l‚Äôallocazione di beni indivisibili.\n\nCitazione: Budish, E. (2011). The combinatorial assignment problem: Approximate competitive equilibrium from equal incomes. Journal of Political Economy, 119(6), 1061-1103.\n\nCompetitive Equilibrium from Equal Incomes (CEEI): Meccanismo per l‚Äôallocazione equa di risorse divisibili.\n\nCitazione: Varian, H. R. (1974). Equity, envy, and efficiency. Journal of Economic Theory, 9(1), 63-91.\n\n\nMetodi di Assegnazione Casuale - Random Priority (RP): Meccanismo di assegnazione casuale utilizzato in vari contesti, come l‚Äôassegnazione di dormitori universitari. - Citazione: Abdulkadiroƒülu, A., & S√∂nmez, T. (1998). Random serial dictatorship and the core from random endowments in house allocation problems. Econometrica, 66(3), 689-701.\n\nProbabilistic Serial (PS): Meccanismo di assegnazione con garanzie di efficienza ordinale.\n\nCitazione: Bogomolnaia, A., & Moulin, H. (2001). A new solution to the random assignment problem. Journal of Economic Theory, 100(2), 295-328.\n\n\nMetodi Vari - Undercut Procedure: Metodo per la divisione equa di beni indivisibili. - Citazione: Brams, S. J., & Taylor, A. D. (1999). The Win-Win Solution: Guaranteeing Fair Shares to Everybody. W. W. Norton & Company.\n\nPicking Sequence Protocols: Metodi di divisione basati su sequenze di scelte.\n\nCitazione: Bouveret, S., & Lang, J. (2011). A general elicitation-free protocol for allocating indivisible goods. In Twenty-Second International Joint Conference on Artificial Intelligence.\n\nAlgoritmo di Robertson-Webb: Framework per misurare la complessit√† degli algoritmi di cake-cutting.\n\nCitazione: Robertson, J., & Webb, W. (1998). Cake-cutting algorithms: Be fair if you can. AK Peters/CRC Press.\n\n\nPer chi vuole provare ad applicare gli algoritmi equitativi in casi reali su una piattaforma online si segnala l‚Äôinteressante sito: Spliddit Algorithms: Suite di algoritmi equitativi implementati sulla piattaforma web Spliddit (Goldman, J., & Procaccia, A. D. (2014). Spliddit: Unleashing fair division algorithms. ACM SIGecom Exchanges, 13(2), 41-46).\n\n\ndef adjusted_winner(items, alice_values, bob_values, max_iterations=1000):\n    n = len(items)\n    alice_items = []\n    bob_items = []\n\n    # Fase 1: Assegnazione iniziale\n    for i in range(n):\n        if alice_values[i] &gt;= bob_values[i]:\n            alice_items.append(items[i])\n        else:\n            bob_items.append(items[i])\n\n    # Fase 2: Calcolo dei punteggi\n    alice_score = sum(alice_values[items.index(item)] for item in alice_items)\n    bob_score = sum(bob_values[items.index(item)] for item in bob_items)\n\n    # Fase 3: Aggiustamento\n    iterations = 0\n    while abs(alice_score - bob_score) &gt; 0.001 and iterations &lt; max_iterations:\n        if alice_score &gt; bob_score:\n            item_to_transfer = max(alice_items, key=lambda x: bob_values[items.index(x)] / \\\n                                   alice_values[items.index(x)])\n            alice_items.remove(item_to_transfer)\n            bob_items.append(item_to_transfer)\n            alice_score -= alice_values[items.index(item_to_transfer)]\n            bob_score += bob_values[items.index(item_to_transfer)]\n        else:\n            item_to_transfer = max(bob_items, key=lambda x: alice_values[items.index(x)] / \\\n                                   bob_values[items.index(x)])\n            bob_items.remove(item_to_transfer)\n            alice_items.append(item_to_transfer)\n            bob_score -= bob_values[items.index(item_to_transfer)]\n            alice_score += alice_values[items.index(item_to_transfer)]\n        iterations += 1\n\n    return alice_items, bob_items, alice_score, bob_score, iterations\n\n\n# Esempio di utilizzo\nitems = ['A', 'B', 'C', 'D']\nalice_values = [30, 25, 35, 10]\nbob_values = [20, 30, 25, 25]\n\nalice_final, bob_final, alice_final_score, bob_final_score, iterations_final = \\\n                                adjusted_winner(items, alice_values, bob_values)\nprint(\"Iterazioni necessarie:\", iterations_final)\nprint(\"Alice riceve:\", alice_final)\nprint(\"Bob riceve:\", bob_final)\n\nIterazioni necessarie: 1000\nAlice riceve: ['A', 'C']\nBob riceve: ['B', 'D']",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algoritmi</span>"
    ]
  },
  {
    "objectID": "2-algoritmi.html#algoritmi-predittivi",
    "href": "2-algoritmi.html#algoritmi-predittivi",
    "title": "Algoritmi",
    "section": "Algoritmi Predittivi",
    "text": "Algoritmi Predittivi\nGli algoritmi di predizione sono usati per creare modelli basati sull‚Äô apprendedimento dei dati misurati o prodotti in un certo dominio applicativo al fine di fare previsioni su eventi futuri. Questi algoritmi possono essere classificati in diverse categorie in base al tipo di apprendimento, al tipo di output, e alle tecniche utilizzate:\nClassificazione Basata sul Tipo di Apprendimento: 1. Apprendimento Supervisionato: Gli algoritmi di apprendimento supervisionato richiedono un set di dati etichettato per l‚Äôaddestramento. Utilizzano queste etichette per apprendere una funzione che mappa gli input agli output desiderati. Esempi includono la regressione lineare, gli alberi decisionali e le reti neurali¬π. 2. Apprendimento Non Supervisionato: Questi algoritmi scoprono pattern nascosti o strutture nei dati non etichettati. Tecniche comuni sono la clusterizzazione e la riduzione della dimensionalit√†¬π. 3. Apprendimento Semi-supervisionato e Rinforzato: Combinano elementi dei primi due tipi, utilizzando un piccolo set di dati etichettati insieme a una grande quantit√† di dati non etichettati, o apprendendo attraverso il rinforzo da un ambiente¬π.\nClassificazione Basata sul Tipo di Output: 1. Classificazione: Quando l‚Äôoutput √® una categoria, come ‚Äúspam‚Äù o ‚Äúnon spam‚Äù in un filtro di posta elettronica, si parla di classificazione. Gli algoritmi di classificazione assegnano un‚Äôetichetta discreta a un‚Äôistanza di input¬π. 2. Regressione: Se l‚Äôoutput √® un valore continuo, come il prezzo di una casa, si utilizza la regressione. Gli algoritmi di regressione prevedono un valore numerico basato sugli input¬π. 3. Ranking: Alcuni algoritmi ordinano gli elementi in base alla probabilit√† di appartenenza a una certa categoria o valore¬π.\nClassificazione Basata sulle Tecniche Utilizzate: 1. Alberi Decisionali: Suddividono i dati in modo gerarchico basandosi su attributi specifici. Sono semplici da interpretare ma possono soffrire di overfitting¬≤. 2. Random Forest: Una collezione di alberi decisionali che riduce il rischio di overfitting e gestisce meglio le variabili non correlate¬≤. 3. Support Vector Machine (SVM): Trovano il miglior iperpiano che separa i dati in classi. Sono efficaci in spazi ad alta dimensionalit√†¬≤. 4. K-Nearest Neighbors (K-NN): Classificano i nuovi dati in base alla classe pi√π comune tra i vicini pi√π prossimi. Sono semplici da implementare ma computazionalmente costosi¬≤. 5. Reti Neurali: Sono modelli ispirati al funzionamento del cervello umano e possono catturare relazioni complesse nei dati¬π.\nOgni algoritmo ha i suoi vantaggi e svantaggi, e la scelta dipende da vari fattori come la dimensione e la natura del dataset, la velocit√† richiesta, la trasparenza del modello e la capacit√† di gestire dati non lineari o mancanti. Ad esempio, gli alberi decisionali sono facili da interpretare ma possono soffrire di overfitting, mentre le SVM sono efficaci con dataset di piccole dimensioni ma meno efficienti con dataset molto grandi¬≤.\nL‚Äôagente deve imparare a riconoscere alcune configurazioni del suo percepito sulla base di un esperienza fatta su casi detti di training e deve essere in grado di riconoscere un nuovo percepito mai visto prima.\nIl percepito dell‚Äôagente √® composto da dati, caratteristiche, che possono essere di tipo continuo (es. temperatura) o categoriali (es. colore rosso). I dati categoriali possono essere ordinabili (es. scarso, insufficiente, ‚Ä¶) o non ordinabili (es. sesso)\nAll‚Äôagente pu√≤ essere chiesto di predire un dato continuo, nel qual caso si tratta di predizione o regressione, oppure pu√≤ essere chiesto di predire un dato categoriale, nel qual caso si tratta di classificazione.\nIl processo di predizione segue il seguente flusso:\n\nDefinizione del Problema\n\nIdentificare il tipo di problema (classificazione, regressione, clustering)\n\nRaccolta dei Dati\n\nOttenere dati rilevanti e di qualit√†\n\nPre-elaborazione dei Dati\n\nPulizia dei dati\nGestione dei valori mancanti\nNormalizzazione\nRiduzione della dimensionalit√†\n\nDivisione dei Dati\n\nCreare set di addestramento e di test\n\nScelta dell‚ÄôAlgoritmo\n\nSelezionare l‚Äôalgoritmo adatto al problema\n\nAddestramento del Modello\n\nImparare dai dati di addestramento\n\nValutazione del Modello\n\nTestare il modello con il set di test\n\nOttimizzazione\n\nRegolare i parametri per migliorare le prestazioni\n\nDeployment\n\nImplementare il modello in produzione\n\nMonitoraggio e Manutenzione\n\nAggiornare e ottimizzare il modello nel tempo\n\n\nNei prossimi paragrafi si presenter√† una descrizione di ognuno di questi passi con un esempio concreto.\n\nDefinizione del Problema\nQuestp √® il primo passo nel processo di predizione nell‚Äôintelligenza artificiale. Questa fase richiede una comprensione chiara e precisa dell‚Äôobiettivo che si desidera raggiungere con l‚Äôalgoritmo di predizione. Che si tratti di prevedere il comportamento del consumatore, di diagnosticare malattie o di identificare frodi, √® fondamentale stabilire parametri chiari e misurabili. La definizione del problema guida tutte le fasi successive, dalla raccolta dei dati alla scelta dell‚Äôalgoritmo pi√π adatto, assicurando che l‚Äôintero processo sia allineato con l‚Äôobiettivo finale. Un‚Äôaccurata definizione del problema √® la base per un modello predittivo efficace e funzionale.\nesempio pratico:\nUn esempio pratico di definizione del problema nel contesto del processo di predizione potrebbe essere il seguente scenario nel settore della vendita al dettaglio:\nScenario: Un‚Äôazienda di e-commerce ha notato un aumento del tasso di abbandono del carrello da parte dei clienti durante il processo di checkout.\nDefinizione del Problema: - Obiettivo: Ridurre il tasso di abbandono del carrello e aumentare il tasso di conversione delle vendite. - Dati Necessari: Dati di navigazione del sito web, transazioni completate e abbandonate, feedback dei clienti, dati demografici e comportamentali degli utenti. - Ipotesi: Si ipotizza che l‚Äôabbandono del carrello possa essere dovuto a fattori quali costi di spedizione inaspettati, complessit√† del processo di checkout, mancanza di opzioni di pagamento, o problemi tecnici del sito. - Metodologia: Utilizzare algoritmi di machine learning per analizzare i pattern di abbandono e identificare i punti critici nel processo di checkout. - Soluzione Attesa: Implementare miglioramenti mirati nel processo di checkout basati sui risultati dell‚Äôanalisi predittiva, come la semplificazione delle procedure, l‚Äôaggiunta di pi√π opzioni di pagamento, o la trasparenza dei costi di spedizione.\nIn questo esempio, la definizione del problema √® ben strutturata e orientata all‚Äôobiettivo di migliorare l‚Äôesperienza dell‚Äôutente e ottimizzare il processo di vendita. L‚Äôanalisi predittiva aiuter√† l‚Äôazienda a comprendere le cause dell‚Äôabbandono del carrello e a formulare interventi efficaci per risolvere il problema.\n\n\nRaccolta dei Dati\nSi tratta di acquisire informazioni rilevanti per il problema da risolvere. Questo processo non si limita alla mera acquisizione di dati grezzi; √® una pratica strategica che trasforma questi dati in insights preziosi, capaci di guidare decisioni informate. I dati possono essere raccolti da fonti interne come database aziendali, o esterne come social media, sensori IoT (Internet of Things), o registri pubblici. La raccolta deve essere sistematica e organizzata, assicurando che i dati siano accurati, completi e aggiornati. √à fondamentale anche considerare la privacy e la sicurezza dei dati durante la raccolta e l‚Äôelaborazione.\nEsempio Pratico: Un ospedale vuole sviluppare un sistema di predizione per identificare i pazienti a rischio di riammissione entro 30 giorni dalla dimissione. La raccolta dei dati inizia con l‚Äôidentificazione delle informazioni necessarie, che includono dati demografici dei pazienti, diagnosi, trattamenti ricevuti, durata del soggiorno ospedaliero e dati storici sulle riammissioni. Questi dati vengono poi raccolti da cartelle cliniche elettroniche, registri ospedalieri e interviste con il personale sanitario. Una volta raccolti, i dati sono puliti e preparati per l‚Äôanalisi, rimuovendo eventuali errori o duplicazioni e assicurando che siano in un formato utilizzabile per l‚Äôaddestramento dell‚Äôalgoritmo di predizione. Questo processo permette all‚Äôospedale di costruire un modello predittivo che pu√≤ aiutare a migliorare la qualit√† delle cure e ridurre i costi associati alle riammissioni non necessarie.\n\n\nPre-elaborazione dei Dati\nSi prepara il dataset per garantire che l‚Äôalgoritmo di machine learning funzioni in modo ottimale. Questo passo include diverse attivit√† chiave:\n\nPulizia dei dati: correzione o rimozione di dati errati, corrotti, duplicati o non pertinenti. La pulizia assicura che il modello non apprenda da informazioni fuorvianti o irrilevanti.\nGestione dei valori mancanti: I dati incompleti sono comuni in molti dataset. La gestione dei valori mancanti pu√≤ includere tecniche come l‚Äôimputazione, dove i valori mancanti sono sostituiti con stime, o l‚Äôeliminazione delle righe o colonne con dati mancanti.\nNormalizzazione: scalatura dei dati in modo che attributi con ampi intervalli di valori non dominino quelli con intervalli pi√π stretti. La normalizzazione √® essenziale per algoritmi che sono sensibili alle scale dei dati, come la regressione lineare o le reti neurali.\nRiduzione della dimensionalit√†: Tecniche come l‚ÄôAnalisi delle Componenti Principali (PCA) sono utilizzate per ridurre il numero di variabili nel dataset, mantenendo solo quelle pi√π informative. Questo non solo semplifica il modello, ma pu√≤ anche migliorare le prestazioni riducendo il rischio di overfitting.\n\nEsempio Pratico: Immaginiamo di avere un dataset di immagini per un sistema di riconoscimento facciale. La pulizia dei dati potrebbe comportare la rimozione di immagini sfocate o non riconoscibili. Per gestire i valori mancanti, potremmo utilizzare tecniche di imputazione per completare le caratteristiche facciali parzialmente occluse. La normalizzazione potrebbe essere applicata per assicurare che le variazioni di luminosit√† siano tutte uguali in modo da non influenzino il riconoscimento. Infine, si procede a uniformare il formato file e le dimensioni. Ad esempio, formato file jpg e dimensioni 128x128 pizel.\n\n\nDivisione dei Dati\nSi separa il dataset in due o pi√π gruppi per diversi scopi: addestramento, validazione e test. Questa divisione serve per avere dati per valutare l‚Äôefficacia e la generalizzabilit√† del modello predittivo. Il set di addestramento √® utilizzato per insegnare all‚Äôalgoritmo a riconoscere i pattern nei dati. Il set di validazione, quando presente, aiuta a ottimizzare i parametri del modello e a prevenire l‚Äôoverfitting. Infine, il set di test serve a valutare le prestazioni del modello su dati non visti durante l‚Äôaddestramento, fornendo una stima dell‚Äôerrore di generalizzazione.\nLa proporzione della divisione pu√≤ variare, ma una suddivisione comune √® 70% per l‚Äôaddestramento, 15% per la validazione e 15% per il test. √à importante che la divisione dei dati sia rappresentativa dell‚Äôintero dataset, quindi tecniche come il campionamento stratificato possono essere utilizzate per mantenere la stessa distribuzione delle classi in ciascun set.\nEsempio Pratico: Un‚Äôazienda di telecomunicazioni vuole prevedere quali clienti potrebbero lasciare l‚Äôazienda (churn). Il dataset include variabili come l‚Äôuso dei servizi, la durata del contratto, e la soddisfazione del cliente. Dopo la pre-elaborazione, il dataset di 1000 clienti viene diviso in 700 per l‚Äôaddestramento, 150 per la validazione e 150 per il test. Questa divisione permette all‚Äôazienda di addestrare il modello sul set di addestramento, ottimizzarlo sul set di validazione e infine valutare la sua capacit√† di prevedere il churn sul set di test.\nIl training set, il validation set e il test set sono tre sottoinsiemi di dati utilizzati nel processo di machine learning per sviluppare e valutare modelli predittivi. Ecco a cosa servono:\n\nTraining Set: √à il sottoinsieme di dati utilizzato per addestrare il modello. Il modello apprende a riconoscere i pattern e le relazioni tra i dati in modo che possa fare previsioni o prendere decisioni. Tipicamente, √® il pi√π grande dei tre set e fornisce la base su cui il modello costruisce la sua comprensione del problema.\nValidation Set: Viene utilizzato per fornire una valutazione imparziale delle prestazioni del modello durante la fase di addestramento. Questo set √® cruciale per il tuning dei parametri del modello, come la scelta del numero di strati in una rete neurale o il valore di regolarizzazione in una regressione. Aiuta a prevenire l‚Äôoverfitting, che si verifica quando un modello √® troppo complesso e si adatta troppo bene ai dati di addestramento, perdendo la capacit√† di generalizzare su nuovi dati.\nTest Set: Dopo che il modello √® stato addestrato e validato, il test set viene utilizzato per valutare le prestazioni finali del modello. Questo set non √® mai stato visto dal modello durante l‚Äôaddestramento e simula dati del mondo reale su cui il modello dovr√† operare. Fornisce una misura oggettiva di quanto bene il modello possa aspettarsi di esibirsi in pratica.\n\nEsempio Pratico: Immaginiamo di voler studiare il problema della previsione dei prezzi delle case basato su caratteristiche come la posizione, la dimensione e l‚Äôanno di costruzione. Il training set potrebbe includere migliaia di esempi di case vendute negli ultimi anni. Il validation set potrebbe essere usato per regolare i parametri del modello, come la complessit√† del modello stesso. Infine, il test set, che consiste in dati recenti di vendite di case, verrebbe utilizzato per valutare quanto accuratamente il modello pu√≤ prevedere i prezzi delle case in condizioni attuali di mercato.\n\n\nScelta dell‚Äô algoritmo\nLa scelta dell‚Äôalgoritmo determina l‚Äôapproccio con cui il modello analizzer√† i dati e far√† previsioni. La selezione dell‚Äôalgoritmo dipende da vari fattori, tra cui il tipo di problema (classificazione, regressione, clustering), la natura dei dati, la dimensione del dataset e le risorse computazionali disponibili. Ad esempio, per problemi di classificazione, algoritmi come le reti neurali, le macchine a vettori di supporto (SVM) e gli alberi decisionali sono spesso utilizzati. Per la regressione, si possono considerare algoritmi come la regressione lineare, la regressione polinomiale o le reti neurali. √à importante anche considerare la complessit√† dell‚Äôalgoritmo: algoritmi pi√π complessi possono offrire maggiore accuratezza, ma richiedono pi√π tempo e risorse per l‚Äôaddestramento.\nEsempio Pratico: Nell‚Äô esempio della predizione del prezzo delle case introdotto nel precedente paragrafo, se si dispone di un dataset con caratteristiche come la dimensione della casa, il numero di stanze, la posizione, ecc., si potrebbe scegliere un algoritmo di regressione lineare per iniziare, poich√© √® semplice e offre una buona interpretabilit√†. Tuttavia, se i dati mostrano relazioni non lineari, si potrebbe passare a un algoritmo pi√π complesso come una rete neurale per migliorare la precisione delle previsioni.\n\n\nAddestramento del modello\nL‚Äôaddestramento di un modello di machine learning √® un processo iterativo che consiste nell‚Äôesporre un algoritmo a un ampio dataset di apprendimento, con l‚Äôobiettivo di insegnargli a riconoscere pattern e a fare predizioni accurate su nuovi dati. La qualit√† e l‚Äôefficacia di un modello dipendono fortemente dalla scelta dell‚Äôalgoritmo, dalla qualit√† dei dati e dalle tecniche di addestramento utilizzate.\nModalit√† di apprendimento Esistono diverse modalit√† di apprendimento:\n\nApprendimento supervisionato: Il modello viene addestrato su un dataset etichettato, dove ogni esempio √® associato a una risposta corretta. L‚Äôobiettivo √® insegnare al modello a mappare nuovi input alle loro rispettive etichette.\nApprendimento non supervisionato: Il modello lavora con dati non etichettati, cercando di scoprire strutture nascoste nei dati, come gruppi di dati simili (clustering).\nApprendimento semi-supervisionato: Combina elementi dei due approcci precedenti, utilizzando sia dati etichettati che non etichettati.\n\nHardware e software\nL‚Äôaddestramento di modelli complessi richiede risorse computazionali significative. Le GPU e le TPU sono hardware specializzati che accelerano i calcoli necessari per l‚Äôaddestramento di reti neurali profonde. Inoltre, sono necessari software specifici per definire le architetture delle reti neurali e gestire il processo di addestramento.\nOverfitting e underfitting Durante l‚Äôaddestramento, √® fondamentale evitare due problemi comuni: l‚Äôoverfitting e l‚Äôunderfitting.\nOverfitting: Si verifica quando il modello si adatta troppo ai dati di addestramento, perdendo la capacit√† di generalizzare a nuovi dati. In questo caso, il modello memorizza i dettagli specifici dei dati di addestramento invece di apprendere le caratteristiche generali. Underfitting: Si verifica quando il modello √® troppo semplice per catturare la complessit√† dei dati. In questo caso, il modello non √® in grado di apprendere le relazioni significative tra le variabili.\nImplicazioni etiche\nL‚Äôaddestramento di modelli di machine learning solleva importanti questioni etiche. √à fondamentale utilizzare dataset rappresentativi e bilanciati per evitare bias e discriminazioni. Inoltre, √® necessario considerare le potenziali conseguenze negative dell‚Äôutilizzo di modelli in contesti reali, come la privacy e la sicurezza dei dati.\n\n\nValutazione del modello\nLa valutazione del modello √® una fase cruciale nel processo di sviluppo di un modello di machine learning, poich√© consente di misurare la capacit√† del modello addestrato di generalizzare a nuovi dati, ovvero di fare predizioni accurate su esempi che non ha mai visto durante l‚Äôaddestramento.\nMetriche di valutazione\nLe metriche di valutazione variano a seconda del tipo di problema. Nei problemi di classificazione, ad esempio, si utilizzano metriche come:\n\nAccuratezza: misura la percentuale di casi classificati correttamente.\nPrecisione: misura la percentuale di veri positivi (cio√® quei casi che effettivamente appartengono alla classe positiva) tra i casi classificati come positivi.\nRichiamo: misura la percentuale di veri positivi tra tutti i casi positivi reali.\nF1-score: misura la media armonica tra precisione e richiamo.\nCurva ROC (Receiver Operating Characteristic) con l‚Äôarea sotto la curva (AUC): misura la capacit√† del modello di distinguere correttamente tra le classi.\n\nNei problemi di regressione, invece, si utilizzano metriche come:\n\nErrore quadratico medio (MSE): misura la differenza media quadratica tra i valori predetti dal modello e i valori reali.\nCoefficiente di determinazione (R¬≤): misura la percentuale di variazione dei valori predetti rispetto ai valori reali.\n\nSpero che queste correzioni siano utili! Hai altre domande o c‚Äô√® qualcos‚Äôaltro su cui posso aiutarti? üòä Analisi dei risultati\nL‚Äôanalisi dei risultati della valutazione permette di identificare eventuali problemi come l‚Äôoverfitting o l‚Äôunderfitting. L‚Äôoverfitting si verifica quando il modello si adatta troppo ai dati di addestramento, perdendo la capacit√† di generalizzare a nuovi dati. L‚Äôunderfitting si verifica quando il modello √® troppo semplice e non riesce a catturare la complessit√† dei dati.\nEsempio pratico: Consideriamo un modello di machine learning addestrato per predire la probabilit√† di ricidivit√† di un reo in base ai dati raccolti su di lui. Dopo l‚Äôaddestramento, il modello viene valutato su un dataset di test che contiene informazioni su nuovi reati. Utilizzando la Cross-validation, calcolando metriche come l‚Äôaccuratezza e il richiamo, possiamo valutare l‚Äôaffidabilit√† delle predizioni del modello. Un‚Äôalta accuratezza indica che il modello √® generalmente corretto nelle sue previsioni, mentre un alto richiamo indica che il modello √® bravo a identificare i reati che effettivamente si sono verificati.\n\n\nOttimizzazione degli iperparametri\nL‚Äôottimizzazione degli iperparametri √® un processo iterativo che consiste nel regolare i parametri esterni al modello che non vengono appresi durante l‚Äôaddestramento, ma che influenzano significativamente le sue prestazioni. Esempi di iperparametri includono il tasso di apprendimento, la profondit√† di un albero decisionale o il numero di neuroni in una rete neurale.\nL‚Äôobiettivo dell‚Äôottimizzazione √® individuare la combinazione di iperparametri che massimizza le prestazioni del modello su un dataset di valutazione indipendente. Per raggiungere questo obiettivo, si utilizzano diverse tecniche, tra cui:\n\nRicerca a griglia: Esplora sistematicamente tutte le possibili combinazioni di iperparametri all‚Äôinterno di un intervallo specificato.\nRicerca casuale: Seleziona casualmente combinazioni di iperparametri, potendo essere pi√π efficiente della ricerca a griglia in spazi di ricerca ampi.\nOttimizzazione bayesiana: Utilizza modelli probabilistici per guidare la ricerca verso le regioni dello spazio degli iperparametri pi√π promettenti.\n\nPer valutare l‚Äôefficacia delle diverse combinazioni di iperparametri, si ricorre alla validazione incrociata. Questa tecnica consiste nel suddividere il dataset in pi√π parti, addestrando il modello su una parte e valutandolo sulle altre. Ripetendo questo processo multiple volte, si ottiene una stima pi√π robusta delle prestazioni del modello.\nTecniche come l‚Äôearly stopping possono essere utilizzate per migliorare ulteriormente il processo di ottimizzazione. L‚Äôearly stopping consiste nell‚Äôinterrompere l‚Äôaddestramento quando le prestazioni del modello sul dataset di convalida iniziano a peggiorare, evitando cos√¨ l‚Äôoverfitting.\nEsempio pratico: Consideriamo un modello di rete neurale convoluzionale (CNN) addestrato per classificare immagini di cani e gatti. Per ottimizzare le prestazioni del modello, potremmo variare i seguenti iperparametri: il numero di strati convoluzionali, il numero di filtri per strato, il tasso di apprendimento e la funzione di attivazione. Utilizzando la ricerca a griglia e la validazione incrociata, possiamo identificare la combinazione di iperparametri che porta alle migliori prestazioni. Inoltre, possiamo utilizzare l‚Äôearly stopping per evitare di addestrare eccessivamente il modello.\n\n\nDeployment\nIl deployment √® la fase finale del processo di predizione, in cui il modello addestrato e ottimizzato viene messo in produzione per essere utilizzato in applicazioni reali. Questa fase implica la preparazione del modello per l‚Äôintegrazione con sistemi esistenti, garantendo che sia scalabile, affidabile e sicuro. Il deployment pu√≤ avvenire su diverse piattaforme, come server locali, cloud o dispositivi edge (dispositivi periferici che elaborano i dati vicino alla fonte, riducendo la latenza e il carico sui server centrali), a seconda delle esigenze dell‚Äôapplicazione. √à importante notare che l‚Äôhardware necessario per il deployment √® diverso da quello utilizzato per l‚Äôaddestramento. Durante l‚Äôaddestramento, sono necessarie risorse computazionali elevate, come GPU o TPU, per gestire i complessi calcoli e l‚Äôottimizzazione dei parametri del modello. Tuttavia, una volta che il modello √® addestrato, il deployment richiede meno potenza computazionale, poich√© il modello deve solo eseguire previsioni basate sui dati in ingresso. Questo permette di utilizzare hardware meno potente e pi√π economico per il deployment, riducendo i costi operativi.\nSfide del deployment: * Scalabilit√†: Il sistema di deployment deve essere in grado di gestire un aumento del carico di lavoro e di scalare in modo elastico per soddisfare le esigenze dell‚Äôapplicazione. * Affidabilit√†: Il modello deve essere disponibile e funzionante in modo continuo, minimizzando i tempi di fermo e garantendo la qualit√† delle previsioni. * Sicurezza: √à fondamentale proteggere il modello e i dati sensibili da accessi non autorizzati e attacchi informatici.\nesempio pratico: Un esempio pratico di deployment √® l‚Äôimplementazione di un modello di raccomandazione per un sito di e-commerce. Supponiamo di avere un modello che suggerisce prodotti agli utenti basato sul loro comportamento di navigazione e acquisto. Dopo aver addestrato e ottimizzato il modello utilizzando hardware potente come GPU, il passo successivo √® integrarlo con il sistema del sito web. Questo pu√≤ comportare la creazione di API (Application Programming Interfaces, interfacce che permettono a diverse applicazioni di comunicare tra loro) che permettono al sito di inviare dati al modello e ricevere raccomandazioni in tempo reale. Una volta implementato, il modello pu√≤ analizzare i dati degli utenti e fornire suggerimenti personalizzati, migliorando l‚Äôesperienza dell‚Äôutente e potenzialmente aumentando le vendite. Per garantire prestazioni elevate, il modello pu√≤ essere deployato su un server cloud scalabile, come AWS (Amazon Web Services) o GCP (Google Cloud Platform).Monitorando le prestazioni del modello, √® possibile fare aggiustamenti e aggiornamenti per mantenere alta la qualit√† delle raccomandazioni.\n\n\nMonitoraggio e manutenzione\nIl monitoraggio e la manutenzione sono attivit√† cruciali nel ciclo di vita di un modello di predizione, volte a garantire che il modello rimanga accurato e affidabile nel tempo. Dopo il deployment, √® essenziale monitorare continuamente le prestazioni del modello per rilevare eventuali degradi dovuti a cambiamenti nei dati o nel contesto operativo. Questo pu√≤ includere il monitoraggio di indicatori di degrado come:\n\nAumento dell‚Äôerrore di previsione: Se il modello inizia a fare pi√π errori nelle previsioni rispetto a prima, potrebbe essere un segnale di degrado. Questo pu√≤ essere misurato attraverso metriche come l‚Äôerrore quadratico medio (MSE) per i modelli di regressione o l‚Äôaccuratezza per i modelli di classificazione.\nDiminuzione dell‚Äôaccuratezza: Un calo nell‚Äôaccuratezza complessiva del modello indica che le previsioni non sono pi√π affidabili come in passato.\nAumento dei falsi positivi/negativi: Per i modelli di classificazione, un aumento dei falsi positivi (previsioni errate di eventi positivi) o dei falsi negativi (previsioni errate di eventi negativi) pu√≤ indicare che il modello non sta pi√π funzionando correttamente.\nCambiamenti nelle distribuzioni dei dati: Se i dati in ingresso cambiano significativamente rispetto ai dati su cui il modello √® stato addestrato, il modello potrebbe non essere pi√π in grado di generalizzare correttamente. Questo pu√≤ essere monitorato attraverso tecniche di drift detection.\nAumento del tempo di risposta: Se il modello impiega pi√π tempo per fare previsioni, potrebbe essere un segnale che qualcosa non va, come un sovraccarico computazionale o inefficienze nel codice.\n\nLa manutenzione del modello pu√≤ comportare aggiornamenti periodici, riaddestramento con nuovi dati e ottimizzazioni per adattarsi a nuove condizioni. Inoltre, √® importante implementare sistemi di allerta per notificare tempestivamente eventuali problemi. La manutenzione preventiva e correttiva aiuta a mantenere il modello efficiente e a evitare errori significativi che potrebbero influenzare le decisioni basate sulle sue previsioni.\nEsempio pratico: Un esempio pratico di monitoraggio e manutenzione √® l‚Äôuso di un modello di rilevamento delle frodi in una banca. Dopo il deployment, il modello analizza le transazioni in tempo reale per identificare attivit√† sospette. Il team di data science monitora costantemente le prestazioni del modello, verificando che mantenga un alto tasso di rilevamento delle frodi e un basso tasso di falsi positivi. Se il modello inizia a mostrare segni di degrado, come un aumento dei falsi positivi, il team pu√≤ riaddestrarlo utilizzando dati pi√π recenti o aggiustare i parametri per migliorare la sua accuratezza. Questo processo continuo garantisce che il modello rimanga efficace nel proteggere la banca dalle frodi.\nEsempio di algoritmo predittivo in Python:\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\n# Dati storici dei casi (caratteristiche e risultati)\nX = np.array([[25, 1], [45, 0], [35, 1], [50, 0]])  # Et√† e tipo di crimine\ny = np.array([1, 0, 1, 0])  # Risultato del caso (1 = colpevole, 0 = innocente)\n\n# Addestramento del modello predittivo\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\n# Previsione di un nuovo caso\nnew_case = np.array([[30, 1]])  # Nuovo caso: 30 anni, tipo di crimine 1\nprediction = model.predict(new_case)\nprint(f\"Previsione del nuovo caso: {'colpevole' if prediction[0] == 1 else 'innocente'}.\")\nIn questo capitolo, abbiamo esplorato vari algoritmi utilizzati nell‚Äôintelligenza artificiale, con esempi pratici applicati alla giurisprudenza. Questi algoritmi sono strumenti potenti che possono aiutare a migliorare l‚Äôefficienza e l‚Äôequit√† nel contesto legale.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algoritmi</span>"
    ]
  },
  {
    "objectID": "3-machine learning.html",
    "href": "3-machine learning.html",
    "title": "Machine learning",
    "section": "",
    "text": "Apprendimento Supervisionato",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "3-machine learning.html#apprendimento-supervisionato",
    "href": "3-machine learning.html#apprendimento-supervisionato",
    "title": "Machine learning",
    "section": "",
    "text": "Definizione e Principi di Base\nL‚Äôapprendimento supervisionato √® un sottoinsieme del machine learning che si occupa di costruire modelli predittivi utilizzando un dataset etichettato, dove ogni esempio di input √® associato a un output corrispondente (l‚Äôetichetta). Il processo di apprendimento supervisionato pu√≤ essere visto come una forma di mappatura funzionale (f: X Y), dove (X) rappresenta lo spazio degli input (caratteristiche o feature) e (Y) rappresenta lo spazio degli output (etichette). L‚Äôobiettivo principale √® imparare una funzione (f) che, dato un nuovo input, sia in grado di predire l‚Äôoutput corretto.\nIl processo di addestramento coinvolge due fasi principali: l‚Äôapprendimento e la generalizzazione. Durante la fase di apprendimento, il modello viene addestrato su un insieme di dati di addestramento, cercando di minimizzare la funzione di perdita, che misura la discrepanza tra le previsioni del modello e le etichette effettive. Successivamente, nella fase di generalizzazione, il modello viene testato su nuovi dati non visti per valutare la sua capacit√† di fare previsioni accurate al di fuori del set di addestramento.\nI principi fondamentali che guidano l‚Äôapprendimento supervisionato includono la funzione di perdita, che determina quanto una previsione √® lontana dal valore vero; l‚Äôottimizzazione, che √® il processo attraverso il quale il modello migliora le sue previsioni iterativamente; e il bias-variance tradeoff, che √® il bilanciamento tra un modello troppo semplice (alto bias) e uno troppo complesso (alta varianza).\n\n\nClassificazione\nLa classificazione √® una tecnica di apprendimento supervisionato in cui l‚Äôobiettivo √® assegnare una classe o etichetta specifica a un input, in base a un insieme di dati di addestramento. Esistono vari tipi di problemi di classificazione:\n\nClassificazione binaria: Qui, l‚Äôoutput √® limitato a due classi, come ‚Äús√¨‚Äù o ‚Äúno‚Äù, ‚Äúspam‚Äù o ‚Äúnon spam‚Äù. Questo tipo di problema √® comune in scenari come la diagnosi medica (es. malato o non malato) e nella sicurezza informatica (es. email sicura o phishing).\nClassificazione multiclasse: In questo caso, l‚Äôoutput pu√≤ appartenere a una di pi√π classi (es. classificare un documento come ‚Äúlegale‚Äù, ‚Äúfinanziario‚Äù o ‚Äúscientifico‚Äù). Le tecniche utilizzate possono includere approcci come la regressione logistica multinomiale, le reti neurali e le macchine a supporto di vettori (SVM).\nClassificazione multilabel: Qui, un singolo input pu√≤ essere associato a pi√π classi contemporaneamente (es. un articolo di giornale che potrebbe essere classificato sia come ‚Äúpolitico‚Äù che come ‚Äúeconomico‚Äù). Tecniche come l‚Äôapproccio One-vs-All e le reti neurali sono frequentemente utilizzate in questi contesti.\n\nUn punto di interesse particolare nella classificazione √® il concetto di boundary decisionale. Questo rappresenta il confine nello spazio delle caratteristiche che separa le diverse classi. Nei modelli lineari, questo confine √® una linea retta o un iperpiano, mentre nei modelli non lineari pu√≤ assumere forme molto pi√π complesse.\n\n\nRegressione\nLa regressione √® un tipo di problema di apprendimento supervisionato, focalizzato sulla previsione di un valore continuo piuttosto che su una classe discreta. A differenza della classificazione, dove l‚Äôoutput √® un‚Äôetichetta, nella regressione l‚Äôoutput √® un valore numerico che pu√≤ variare su un intervallo continuo.\n\nRegressione lineare: Il modello di regressione lineare √® uno dei pi√π semplici e intuitivi. Esso assume che esista una relazione lineare tra le caratteristiche dell‚Äôinput e l‚Äôoutput. La formula generale per la regressione lineare semplice √® \\[\ny = \\beta_0 + \\beta_1x\n,\\] dove \\(\\beta_0\\) √® l‚Äôintercetta con l‚Äôasse delle ordinate e \\(\\beta_1\\) √® la pendenza della retta.\nRegressione polinomiale: Quando la relazione tra le variabili non √® lineare, si pu√≤ ricorrere alla regressione polinomiale, che permette di modellare relazioni pi√π complesse includendo termini polinomiali delle variabili indipendenti.\nRegressione multivariata: Questo tipo di regressione viene utilizzato quando si desidera prevedere l‚Äôoutput in base a pi√π variabili indipendenti. √à un‚Äôestensione naturale della regressione lineare e polinomiale.\n\nLa regolarizzazione (es. Ridge e Lasso) √® una tecnica comune utilizzata nella regressione per prevenire l‚Äôoverfitting, imponendo una penalit√† alla complessit√† del modello, limitando cos√¨ i valori dei coefficienti di regressione.\n\n\nAlgoritmi Principali dell‚ÄôApprendimento Supervisionato\nL‚Äôapprendimento supervisionato si avvale di una vasta gamma di algoritmi che possono essere utilizzati per risolvere problemi sia di classificazione che di regressione. Ogni algoritmo ha caratteristiche specifiche che lo rendono pi√π o meno adatto a particolari tipi di dati e problemi. Di seguito, verranno presentati alcuni dei principali algoritmi utilizzati nell‚Äôapprendimento supervisionato.\n\nRegressione Lineare\nLa regressione lineare √® uno degli algoritmi pi√π semplici e ampiamente utilizzati per problemi di regressione. Assume una relazione lineare tra le variabili indipendenti e la variabile dipendente e cerca di trovare la retta (o l‚Äôiperpiano nel caso di pi√π variabili indipendenti) che meglio approssima i dati. La semplicit√† della regressione lineare la rende facile da interpretare, ma la sua capacit√† di modellare solo relazioni lineari pu√≤ limitare la sua applicabilit√† in scenari pi√π complessi.\n\n\nRegressione Logistica\nLa regressione logistica √® un algoritmo di classificazione che viene utilizzato quando l‚Äôoutput √® binario. A differenza della regressione lineare, la regressione logistica utilizza una funzione logistica (o sigmoide) per modellare la probabilit√† che un dato appartenga a una classe specifica. Questo approccio √® ampiamente utilizzato per problemi come la classificazione di e-mail come ‚Äúspam‚Äù o ‚Äúnon spam‚Äù o per la predizione di eventi binari (es. successo o fallimento di un‚Äôazione legale).\n\n\nAlberi di Decisione\nGli alberi di decisione sono modelli non parametrici che possono essere utilizzati sia per la classificazione che per la regressione. Essi segmentano il dataset in sottogruppi omogenei attraverso una serie di decisioni basate sui valori delle caratteristiche. Ogni nodo dell‚Äôalbero rappresenta una decisione basata su una caratteristica, e i rami rappresentano le possibili conseguenze di tale decisione. Gli alberi di decisione sono facili da interpretare e visualizzare, il che li rende particolarmente utili quando √® necessaria una comprensione trasparente del processo decisionale. Tuttavia, gli alberi di decisione possono essere inclini all‚Äôoverfitting, specialmente se non adeguatamente potati.\n\n\nRandom Forest\nIl Random Forest √® un metodo ensemble basato su alberi di decisione. Consiste in un insieme di alberi di decisione indipendenti addestrati su diverse porzioni del dataset (attraverso il bootstrapping) e utilizzando un sottoinsieme casuale di caratteristiche. Il risultato finale √® ottenuto aggregando le previsioni di tutti gli alberi (es. tramite voto di maggioranza per la classificazione o media per la regressione). Questa tecnica riduce significativamente il rischio di overfitting rispetto a un singolo albero di decisione e migliora la precisione e la robustezza del modello.\n\n\nSupport Vector Machines (SVM)\nLe Support Vector Machines (SVM) sono algoritmi molto potenti sia per la classificazione che per la regressione. Il loro obiettivo √® trovare un iperpiano ottimale che separi i dati di diverse classi con il massimo margine possibile. Le SVM sono particolarmente efficaci in spazi ad alta dimensionalit√† e possono essere estese per gestire separazioni non lineari utilizzando il kernel trick, che permette di mappare i dati in uno spazio di dimensione superiore dove la separazione diventa lineare.\n\n\nk-Nearest Neighbors (k-NN)\nIl k-Nearest Neighbors (k-NN) √® un algoritmo di classificazione e regressione basato su un‚Äôidea semplice ma efficace: per predire l‚Äôetichetta di un nuovo dato, si cercano i k punti pi√π vicini nel dataset di addestramento e si assegna al nuovo dato la classe maggioritaria (nel caso di classificazione) o la media dei valori (nel caso di regressione). Il k-NN √® molto intuitivo e non richiede una fase di addestramento, ma pu√≤ diventare inefficiente con dataset molto grandi o in presenza di rumore.\n\n\nReti Neurali\nLe reti neurali sono modelli ispirati al funzionamento del cervello umano e sono particolarmente potenti per la modellazione di relazioni non lineari complesse. Una rete neurale √® composta da strati di nodi (neuroni) interconnessi, dove ciascun nodo applica una funzione non lineare ai dati in ingresso e trasmette il risultato ai nodi dello strato successivo. Le reti neurali possono essere utilizzate sia per la classificazione che per la regressione e sono alla base di tecniche avanzate come il deep learning.\n\nPercettrone Multistrato (MLP): √à una delle architetture pi√π semplici di reti neurali, composto da uno o pi√π strati nascosti tra l‚Äôinput e l‚Äôoutput. Il MLP √® capace di apprendere rappresentazioni complesse dei dati, ma richiede un‚Äôattenta configurazione dei parametri e una grande quantit√† di dati per addestramento.\nReti Neurali Convoluzionali (CNN): Utilizzate principalmente per l‚Äôelaborazione di immagini, le CNN applicano convoluzioni ai dati in ingresso per estrarre automaticamente caratteristiche di alto livello. Sono particolarmente efficaci in problemi di riconoscimento di immagini e visione artificiale.\nReti Neurali Ricorrenti (RNN): Progettate per gestire dati sequenziali come testi o serie temporali, le RNN hanno connessioni che permettono l‚Äôuso di informazioni provenienti da precedenti stati dell‚Äôinput. Questo le rende ideali per problemi come la modellazione del linguaggio naturale o la previsione di sequenze.\n\n\n\nGradient Boosting Machines (GBM)\nIl Gradient Boosting √® una tecnica di ensemble che costruisce modelli in modo sequenziale, dove ogni nuovo modello cerca di correggere gli errori commessi dai modelli precedenti. I modelli individuali sono generalmente alberi di decisione semplici (stump), e il risultato finale √® una somma ponderata di questi alberi. Algoritmi popolari come XGBoost e LightGBM sono varianti ottimizzate del Gradient Boosting, note per la loro efficacia e velocit√†, specialmente in competizioni di machine learning.\n\n\nNaive Bayes\nIl Naive Bayes √® un algoritmo di classificazione basato sul teorema di Bayes, con l‚Äôassunzione ‚Äúnaive‚Äù che le caratteristiche siano indipendenti l‚Äôuna dall‚Äôaltra, una ipotesi raramente vera nel mondo reale. Nonostante questa assunzione, il Naive Bayes √® sorprendentemente efficace, specialmente per problemi di classificazione testuale come la categorizzazione di documenti o l‚Äôanalisi del sentiment.\n\n\nEnsemble Learning\nL‚Äôensemble learning combina le previsioni di pi√π modelli per ottenere un risultato finale pi√π robusto e accurato. Oltre al Random Forest e al Gradient Boosting, altre tecniche di ensemble includono il bagging e lo stacking. Il bagging riduce la varianza addestrando lo stesso modello su diverse porzioni del dataset, mentre lo stacking combina le previsioni di diversi modelli tramite un meta-modello, che apprende a pesare le diverse previsioni.\n\n\nConclusioni\nCiascuno degli algoritmi discussi ha punti di forza e di debolezza che lo rendono pi√π o meno adatto a particolari problemi di apprendimento supervisionato. La scelta dell‚Äôalgoritmo pi√π appropriato dipende dalla natura del problema, dalla quantit√† e qualit√† dei dati disponibili e dalle specifiche esigenze dell‚Äôapplicazione. In contesti giuridici, dove la trasparenza e l‚Äôinterpretabile sono spesso fondamentali, gli algoritmi semplici e interpretabili come gli alberi di decisione o la regressione logistica potrebbero essere preferibili, mentre in applicazioni pi√π complesse come l‚Äôanalisi di grandi volumi di dati testuali, algoritmi pi√π sofisticati come le reti neurali o le tecniche di ensemble possono offrire prestazioni superiori.\n\n\n\nApprendimento per Rinforzo\n\nConcetti Base\nL‚Äôapprendimento per rinforzo (Reinforcement Learning, RL) si distingue dagli altri tipi di apprendimento supervisionato in quanto l‚Äôagente apprende attraverso l‚Äôinterazione diretta con l‚Äôambiente, senza avere accesso diretto a una serie di etichette corrette per ogni azione. In RL, l‚Äôagente prende decisioni sequenziali e riceve ricompense (o punizioni) che riflettono l‚Äôefficacia delle sue azioni. Il compito dell‚Äôagente √® quindi quello di imparare una politica, o strategia, che massimizza la ricompensa totale nel tempo.\n\n\nAgenti, Ambiente e Politiche\nGli elementi chiave nell‚Äôapprendimento per rinforzo includono:\n\nAgente: L‚Äôentit√† che prende decisioni nell‚Äôambiente.\nAmbiente: Il contesto in cui l‚Äôagente opera e da cui riceve feedback sotto forma di ricompense.\nPolitica (Policy): La strategia che l‚Äôagente segue per determinare quali azioni intraprendere in ogni stato.\nFunzione di valore (Value Function): Una funzione che valuta l‚Äôutilit√† di essere in un certo stato, dato un insieme di azioni future possibili.\nFunzione di ricompensa (Reward Function): Una funzione che fornisce un feedback immediato sulle azioni dell‚Äôagente.\n\n\n\nAlgoritmi Principali (es. Q-Learning, Deep Q-Networks)\n\nQ-Learning: √à uno degli algoritmi di apprendimento per rinforzo pi√π semplici e pi√π conosciuti. Q-Learning si basa sull‚Äôapprendimento della funzione Q, che stima la qualit√† (o valore) di un‚Äôazione in un dato stato. L‚Äôagente utilizza questa funzione per decidere quali azioni intraprendere al fine di massimizzare la ricompensa cumulativa. Q-Learning √® un algoritmo off-policy, il che significa che l‚Äôagente pu√≤ apprendere la politica ottimale indipendentemente dalla politica attualmente seguita.\nDeep Q-Networks (DQN): Estende Q-Learning utilizzando reti neurali profonde per approssimare la funzione Q, consentendo cos√¨ di gestire ambienti con spazi di stato molto grandi o continui. Questo approccio √® stato utilizzato con successo in diversi contesti, tra cui il superamento delle prestazioni umane in giochi complessi come Atari.\n\n\n\nApplicazioni\nL‚Äôapprendimento per rinforzo √® utilizzato in un‚Äôampia variet√† di applicazioni, che vanno dai giochi (es. scacchi, Go, e videogiochi come quelli sviluppati da OpenAI e DeepMind) alla robotica (es. robot che imparano a camminare o manipolare oggetti), fino a scenari come la guida autonoma. Nell‚Äôambito giuridico, potrebbe essere applicato per ottimizzare flussi di lavoro complessi, simulare scenari di negoziazione o migliorare i processi decisionali attraverso simulazioni avanzate.\n\n\n\nOverfitting e Underfitting\nL‚Äôoverfitting e l‚Äôunderfitting sono due delle principali problematiche che emergono nell‚Äôapprendimento supervisionato e possono influenzare significativamente la capacit√† di un modello di generalizzare su nuovi dati.\n\nOverfitting: Si verifica quando un modello diventa troppo complesso, catturando non solo i pattern rilevanti nei dati di addestramento ma anche il rumore. Un modello overfit avr√† prestazioni eccellenti sui dati di addestramento ma scarse prestazioni su dati nuovi e non visti. Questo problema pu√≤ essere mitigato attraverso tecniche come la regolarizzazione (es. Lasso, Ridge), l‚Äôearly stopping (interrompere l‚Äôaddestramento prima che il modello inizi a memorizzare il rumore), e l‚Äôutilizzo di pi√π dati o di modelli pi√π semplici.\nUnderfitting: Si verifica quando un modello √® troppo semplice per rappresentare adeguatamente i dati. Un modello underfit avr√† scarse prestazioni sia sui dati di addestramento che sui dati di test, poich√© non riesce a catturare i pattern sottostanti. Per evitare l‚Äôunderfitting, √® necessario aumentare la complessit√† del modello o migliorare la qualit√† dei dati.\n\nL‚Äôobiettivo nella costruzione di un modello √® trovare il giusto equilibrio tra bias e varianza, in modo da ottenere un modello che sia abbastanza complesso da catturare i pattern rilevanti nei dati senza diventare cos√¨ complesso da catturare anche il rumore.\n\n\nValutazione dei Modelli\nLa valutazione dei modelli √® un passo critico per garantire che un modello di apprendimento supervisionato sia non solo accurato ma anche robusto e generalizzabile a dati non visti. La scelta delle metriche di valutazione dipende dal tipo di problema (classificazione o regressione) e dalle specifiche esigenze dell‚Äôapplicazione.\n\nValutazione nei problemi di classificazione:\n\nAccuratezza: √à la misura pi√π semplice e rappresenta la proporzione di previsioni corrette sul totale delle previsioni. Tuttavia, in presenza di classi sbilanciate, l‚Äôaccuratezza pu√≤ essere ingannevole, poich√© un modello che predice sempre la classe maggioritaria avr√† un‚Äôaccuratezza elevata anche se non √® utile.\nPrecisione e Recall: La precisione misura la proporzione di veri positivi rispetto al totale delle predizioni positive, mentre il recall misura la proporzione di veri positivi rispetto al totale dei veri positivi pi√π i falsi negativi. Queste metriche sono particolarmente importanti quando ci sono costi associati ai falsi positivi o ai falsi negativi.\nF1-Score: √à la media armonica tra precisione e recall e fornisce un singolo valore che rappresenta un buon compromesso tra queste due metriche. L‚ÄôF1-score √® utile in contesti dove √® necessario bilanciare precisione e recall.\nAUC-ROC: La curva ROC (Receiver Operating Characteristic) e l‚Äôarea sotto la curva ROC (AUC) sono strumenti grafici che rappresentano la capacit√† di un classificatore di distinguere tra le classi. AUC fornisce un valore che varia da 0 a 1, dove 1 rappresenta un classificatore perfetto e 0.5 rappresenta un classificatore casuale.\nMatrice di Confusione: Questa tabella riassume i veri positivi, falsi positivi, veri negativi e falsi negativi, offrendo una visione pi√π dettagliata delle prestazioni del modello. √à particolarmente utile per identificare se un modello ha bias specifici in determinate classi.\n\nValutazione nei problemi di regressione:\n\nErrore Quadratico Medio (MSE): Misura la media dei quadrati degli errori, penalizzando maggiormente gli errori grandi. √à una delle metriche pi√π utilizzate per problemi di regressione, ma √® sensibile ai valori anomali.\nErrore Assoluto Medio (MAE): Misura la media delle differenze assolute tra le previsioni e i valori reali. A differenza del MSE, il MAE √® meno sensibile agli outlier, rendendolo una buona scelta quando si desidera una valutazione robusta.\nR¬≤ (R-quadrato): Questa metrica rappresenta la proporzione della varianza nei dati di output che √® spiegata dal modello. Un valore vicino a 1 indica che il modello spiega bene la varianza dei dati, mentre un valore vicino a 0 indica il contrario.\n\nCross-Validation:\nLa cross-validation √® una tecnica statistica utilizzata per valutare la capacit√† di generalizzazione di un modello. Uno dei metodi pi√π comuni √® la k-fold cross-validation, dove il dataset viene diviso in k sottoinsiemi (folds), e il modello viene addestrato k volte, utilizzando ogni volta un diverso fold come set di test e gli altri k-1 come set di addestramento. La cross-validation aiuta a mitigare l‚Äôoverfitting, fornendo una stima pi√π affidabile delle prestazioni del modello.\nBias e Varianza:\nIl tradeoff tra bias e varianza √® cruciale nella valutazione dei modelli. Bias alto indica che il modello √® troppo rigido e non riesce a catturare la complessit√† dei dati (underfitting), mentre varianza alta indica che il modello √® troppo sensibile ai dati di addestramento e non riesce a generalizzare (overfitting). Le tecniche di regolarizzazione, il tuning dei parametri e la scelta appropriata degli algoritmi possono aiutare a bilanciare bias e varianza per ottenere un modello ottimale.\n\nValutazione nei Problemi di Classificazione: Un Esempio di Recidiva Penale\nConsideriamo un modello utilizzato per predire la recidiva penale, dove l‚Äôobiettivo √® determinare se un individuo sar√† recidivo (1) o non recidivo (0) entro un certo periodo di tempo. Supponiamo di avere un dataset di test composto da 100 individui, e il modello ha prodotto le seguenti previsioni:\n\nVeri Positivi (VP): 40 (il modello ha correttamente predetto che 40 individui sarebbero recidivi)\nFalsi Positivi (FP): 10 (il modello ha predetto che 10 individui sarebbero recidivi, ma in realt√† non lo sono)\nVeri Negativi (VN): 30 (il modello ha correttamente predetto che 30 individui non sarebbero recidivi)\nFalsi Negativi (FN): 20 (il modello ha predetto che 20 individui non sarebbero recidivi, ma in realt√† lo sono)\n\nUtilizziamo queste informazioni per calcolare alcune delle metriche di valutazione pi√π comuni:\n\nAccuratezza (Accuracy): La proporzione di tutte le previsioni corrette sul totale delle osservazioni. \\[\\text{Accuratezza} = \\frac{VP + VN}{VP + FP + VN + FN} = \\frac{40 + 30}{40 + 10 + 30 + 20} = \\frac{70}{100} = 0{,}7\\]\nL‚Äôaccuratezza del modello √® 0,7, cio√® il 70% delle previsioni sono corrette.\nPrecisione (Precision): La proporzione di veri positivi sul totale delle previsioni positive (veri positivi pi√π falsi positivi). \\[\\text{Precisione} = \\frac{VP}{VP + FP} = \\frac{40}{40 + 10} = \\frac{40}{50} = 0{,}8\\] La precisione del modello √® 0,8, ovvero l‚Äô80% delle predizioni di recidiva erano corrette.\nRecall (Sensibilit√†): La proporzione di veri positivi sul totale dei veri recidivi (veri positivi pi√π falsi negativi). \\[\\text{Recall} = \\frac{VP}{VP + FN} = \\frac{40}{40 + 20} = \\frac{40}{60} = 0{,}67\\] Il recall del modello √® 0,67, cio√® il 67% dei recidivi √® stato correttamente identificato.\nF1-Score: La media armonica di precisione e recall, che fornisce un compromesso tra le due metriche. \\[\\text{F1-Score} = 2 \\times \\frac{\\text{Precisione} \\times \\text{Recall}}{\\text{Precisione} + \\text{Recall}} = 2 \\times \\frac{0{,}8 \\times 0{,}67}{0{,}8 + 0{,}67} = 2 \\times \\frac{0{,}536}{1{,}47} \\approx 0{,}73\\] L‚ÄôF1-Score del modello √® 0,73, che indica un buon bilanciamento tra precisione e recall.\n\nValutazione dei Risultati: Questo modello presenta una precisione alta, il che √® positivo per evitare falsi allarmi, ma il recall √® relativamente basso, suggerendo che alcuni recidivi non vengono identificati. In un contesto di recidiva penale, potrebbe essere necessario considerare un compromesso tra riduzione dei falsi positivi e aumento del recall, magari esplorando altre strategie di modellazione o modificando la soglia decisionale del modello.\nValutazione nei Problemi di Regressione: Un Esempio di Previsione del valore di un Immobile\nConsideriamo ora un modello di regressione utilizzato per predire il valore di un immobile. Supponiamo di avere un dataset di test con i valori reali di 5 immobili e le previsioni del modello, come mostrato nella tabella seguente:\n\n\n\nImmobile\nValore Reale (‚Ç¨)\nValore Predetto (‚Ç¨)\n\n\n\n\n1\n300,000\n310,000\n\n\n2\n450,000\n430,000\n\n\n3\n500,000\n490,000\n\n\n4\n400,000\n420,000\n\n\n5\n350,000\n345,000\n\n\n\nUtilizziamo questi dati per calcolare alcune metriche di valutazione:\n\nErrore Assoluto Medio (MAE): La media delle differenze assolute tra i valori predetti e quelli reali. \\[\n\\begin{split}\n\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| = \\\\ \\frac{|300-310|+|450-430|+|500-490|+|400-420|+|350-345|}{5}\n\\end{split}\n\\] \\[\n\\text{MAE} = \\frac{10,000 + 20,000 + 10,000 + 20,000 + 5,000}{5} = \\frac{65,000}{5} = 13,000 \\text{ ‚Ç¨}\n\\] L‚Äôerrore assoluto medio √® 13,000 ‚Ç¨, indicando che, in media, le previsioni del modello differiscono dal valore reale di circa 13,000 ‚Ç¨.\nErrore Quadratico Medio (MSE): La media dei quadrati degli errori, che penalizza maggiormente gli errori pi√π grandi. \\[\n\\begin{split}\n\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\\\ \\frac{(300-310)^2+(450-430)^2+(500-490)^2+(400-420)^2+(350-345)^2}{5} \\\\\n= \\frac{(10,000)^2 + (-20,000)^2 + (-10,000)^2 + (-20,000)^2 + (5,000)^2}{5} \\\\\n= \\frac{100,000,000 + 400,000,000 + 100,000,000 + 400,000,000 + 25,000,000}{5} \\\\\n= \\frac{1,025,000,000}{5} = 205,000,000 \\text{ ‚Ç¨}^2\n\\end{split}\n\\] L‚Äôerrore quadratico medio √® 205,000,000 ‚Ç¨¬≤, che indica un‚Äôelevata sensibilit√† agli errori pi√π grandi.\nErrore Quadratico Medio Radice (RMSE): La radice quadrata dell‚ÄôMSE, che riporta l‚Äôerrore medio alla stessa scala delle variabili predette. \\[\n\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{205,000,000} \\approx 14,318 \\text{ ‚Ç¨}\n\\] Il valore dell‚ÄôRMSE √® 14,318 ‚Ç¨, fornendo un‚Äôindicazione dell‚Äôerrore medio sulle predizioni in termini di valore dell‚Äôimmobile.\nR¬≤ (R-quadrato): Misura la proporzione della varianza nei valori reali spiegata dal modello. \\[\nR^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n\\] Dove \\(\\bar{y}\\) √® il valore medio dei valori reali. Supponiamo che \\(\\bar{y} = 400,000\\) e che la somma dei quadrati delle differenze rispetto alla media sia 200,000,000,000 ‚Ç¨. Allora: \\[\nR^2 = 1 - \\frac{1,025,000,000}{200,000,000,000} \\approx 0{,}994\n\\]\nValutazione dei Risultati: Il modello di regressione mostra una forte capacit√† di spiegare la varianza nei dati (R¬≤ = 0,994), il che suggerisce che √® altamente predittivo per questo specifico dataset. Tuttavia, l‚ÄôRMSE di 14,318 ‚Ç¨ e il MAE di 13,000 ‚Ç¨ indicano che, sebbene il modello sia generalmente accurato, ci sono ancora errori significativi nelle predizioni, che potrebbero essere rilevanti in contesti dove la precisione √® cruciale, come nella determinazione del valore di un immobile per fini fiscali o di compravendita. La presenza di un MSE elevato suggerisce che il modello potrebbe essere sensibile agli outlier, e ulteriori indagini potrebbero essere necessarie per migliorare la robustezza del modello, magari esplorando tecniche di regolarizzazione o di gestione degli outlier.\n\nIn ambito giuridico, la valutazione dei modelli pu√≤ assumere un ruolo particolarmente delicato, poich√© la precisione delle previsioni pu√≤ influenzare decisioni importanti. Ad esempio, in un sistema predittivo per la recidiva criminale, √® cruciale minimizzare sia i falsi positivi (persone etichettate erroneamente come ad alto rischio) che i falsi negativi (persone etichettate erroneamente come a basso rischio), utilizzando metriche come l‚ÄôAUC-ROC e l‚ÄôF1-score per garantire un equilibrio tra precisione e recall. In contesti dove i falsi positivi possono avere conseguenze legali severe, come nel rilevamento di frodi, l‚Äôaccuratezza da sola potrebbe non essere sufficiente, rendendo necessaria una valutazione pi√π sfumata attraverso una combinazione di metriche.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "3-machine learning.html#apprendimento-non-supervisionato",
    "href": "3-machine learning.html#apprendimento-non-supervisionato",
    "title": "Machine learning",
    "section": "Apprendimento Non Supervisionato",
    "text": "Apprendimento Non Supervisionato\nL‚Äôapprendimento non supervisionato √® un ramo del machine learning in cui i modelli vengono addestrati su dati senza etichette, ossia senza output conosciuti. L‚Äôobiettivo √® scoprire strutture, pattern o relazioni nascoste all‚Äôinterno dei dati. A differenza dell‚Äôapprendimento supervisionato, che richiede un dataset etichettato, l‚Äôapprendimento non supervisionato si concentra su come raggruppare dati simili o ridurre la complessit√† dei dati mantenendo le informazioni essenziali. Di seguito esamineremo i principali approcci e tecniche utilizzati in questo campo.\n\nClustering\nIl clustering √® una tecnica di apprendimento non supervisionato che mira a raggruppare i dati in gruppi (cluster) in base alla somiglianza tra gli elementi. Gli elementi all‚Äôinterno di un cluster sono pi√π simili tra loro rispetto a quelli di cluster differenti. Questa tecnica √® ampiamente utilizzata per esplorare la struttura sottostante dei dati e per identificare segmenti naturali all‚Äôinterno di un dataset.\nEsistono vari metodi di clustering, tra cui:\n\nK-means: Uno degli algoritmi di clustering pi√π popolari, il k-means divide il dataset in k cluster, dove k √® un numero predefinito. L‚Äôalgoritmo funziona iterativamente, assegnando ogni punto dati al cluster il cui centroide √® il pi√π vicino e poi aggiornando i centroidi in base ai punti assegnati. Il processo continua fino a che i centroidi non cambiano pi√π o le assegnazioni dei punti si stabilizzano. K-means √® semplice ed efficace, ma pu√≤ essere sensibile alla scelta di k e ai valori iniziali dei centroidi.\nAgglomerative Hierarchical Clustering: Questo approccio costruisce una gerarchia di cluster attraverso un processo iterativo in cui ogni punto dati inizia come un cluster separato, e a ogni passo, i due cluster pi√π vicini vengono uniti. Questo processo continua fino a che tutti i punti dati non appartengono a un singolo cluster. Il risultato pu√≤ essere rappresentato come un dendrogramma, che visualizza la struttura gerarchica dei cluster. Questo metodo √® utile per esplorare la struttura dei dati a diversi livelli di granularit√†.\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise): DBSCAN √® un algoritmo di clustering basato sulla densit√† che identifica cluster di alta densit√† separati da aree di bassa densit√†. A differenza di k-means, DBSCAN non richiede di specificare il numero di cluster in anticipo e pu√≤ identificare cluster di forma arbitraria, oltre a gestire outlier in modo naturale.\n\n\n\nRiduzione della Dimensionalit√†\nLa riduzione della dimensionalit√† √® una tecnica che mira a ridurre il numero di variabili (o caratteristiche) nel dataset mantenendo la maggior parte dell‚Äôinformazione rilevante. Questo √® particolarmente utile quando si lavora con dati ad alta dimensionalit√†, dove un numero elevato di variabili pu√≤ complicare l‚Äôanalisi e aumentare il rischio di overfitting.\nAlcuni dei metodi principali per la riduzione della dimensionalit√† includono:\n\nPrincipal Component Analysis (PCA): PCA √® una tecnica matematica che trasforma i dati in un nuovo spazio di coordinate ridotto, dove le nuove variabili (componenti principali) sono combinazioni lineari delle variabili originali. Le componenti principali sono ordinate in modo tale che la prima componente catturi la massima varianza nei dati, la seconda componente catturi la seconda massima varianza, e cos√¨ via. Riducendo il numero di componenti principali, PCA pu√≤ ridurre la dimensionalit√† dei dati preservando gran parte dell‚Äôinformazione originale.\nt-SNE (t-Distributed Stochastic Neighbor Embedding): t-SNE √® una tecnica di riduzione della dimensionalit√† non lineare che √® particolarmente efficace per la visualizzazione di dati ad alta dimensionalit√†. Riduce i dati in uno spazio a 2 o 3 dimensioni, preservando le relazioni di vicinanza tra i punti dati, il che lo rende ideale per visualizzare cluster naturali nei dati.\nAutoencoder: Gli autoencoder sono reti neurali progettate per imparare una rappresentazione compressa dei dati. Sono composti da due parti: l‚Äôencoder, che riduce i dati in uno spazio a bassa dimensionalit√†, e il decoder, che ricostruisce i dati originali dalla rappresentazione compressa. Gli autoencoder sono particolarmente utili per la riduzione della dimensionalit√† in problemi complessi dove le relazioni tra le variabili non sono lineari.\n\n\n\nAlgoritmi Principali\nNel contesto dell‚Äôapprendimento non supervisionato, ci sono diversi algoritmi che giocano un ruolo fondamentale. Alcuni di questi sono:\n\nK-means: Come gi√† discusso, k-means √® un algoritmo di clustering ampiamente utilizzato grazie alla sua semplicit√† ed efficacia. Tuttavia, la scelta del numero di cluster (k) e la sensibilit√† ai valori iniziali possono influenzare significativamente i risultati.\nGaussian Mixture Models (GMM): GMM √® un metodo di clustering che assume che i dati siano generati da una combinazione di distribuzioni gaussiane. Ogni cluster √® modellato come una distribuzione gaussiana, e l‚Äôalgoritmo cerca di trovare i parametri delle gaussiane che meglio spiegano la distribuzione dei dati. GMM √® pi√π flessibile di k-means in quanto pu√≤ modellare cluster con forme ellittiche e non richiede che i cluster siano di forma sferica.\nHierarchical Clustering: Questo algoritmo costruisce una gerarchia di cluster che possono essere esplorati a diversi livelli di granularit√†. Pu√≤ essere agglomerativo o divisivo, offrendo una rappresentazione visiva della struttura dei cluster attraverso dendrogrammi.\nDBSCAN: Oltre al clustering basato sulla densit√†, DBSCAN √® noto per la sua capacit√† di identificare outlier, rendendolo particolarmente utile in dataset con rumore o in cui i cluster non sono facilmente distinguibili.\nPCA: Sebbene originariamente progettato per la riduzione della dimensionalit√†, PCA √® spesso utilizzato anche come metodo preliminare di analisi per comprendere la struttura dei dati e preparare i dati per ulteriori analisi di clustering.\nt-SNE: Questo algoritmo √® particolarmente apprezzato per la visualizzazione di dati ad alta dimensionalit√†, specialmente in contesti dove √® importante capire la struttura interna dei dati, come nel clustering o nell‚Äôidentificazione di pattern nascosti.\n\n\n\nApplicazioni\nL‚Äôapprendimento non supervisionato trova applicazione in una vasta gamma di settori e problemi, soprattutto in contesti in cui i dati non sono etichettati e l‚Äôobiettivo √® scoprire strutture nascoste o ridurre la complessit√† dei dati. Alcune delle principali applicazioni includono:\n\nSegmentazione del Mercato: Le tecniche di clustering come k-means e GMM sono utilizzate per segmentare i clienti in gruppi omogenei in base ai loro comportamenti o caratteristiche, permettendo strategie di marketing mirate e personalizzate.\nAnalisi delle Reti Sociali: L‚Äôapprendimento non supervisionato pu√≤ essere utilizzato per identificare comunit√† o gruppi di interesse all‚Äôinterno di reti sociali, analizzando le connessioni tra individui o entit√†.\nRilevamento delle Anomalie: Algoritmi come DBSCAN sono utilizzati per identificare outlier o anomalie nei dati, come transazioni fraudolente, guasti nei sistemi o attivit√† insolite.\nPreprocessing dei Dati per Modelli Supervisionati: La riduzione della dimensionalit√† attraverso PCA o autoencoder √® spesso utilizzata come fase di preprocessing per migliorare le prestazioni di modelli di apprendimento supervisionato, riducendo il rumore e la complessit√† dei dati.\nVisualizzazione dei Dati: Tecniche come t-SNE sono utilizzate per ridurre la dimensionalit√† dei dati ad alta complessit√†, facilitando la visualizzazione e l‚Äôinterpretazione delle strutture interne dei dati, come cluster o pattern nascosti.\n\nIn ambito giuridico, l‚Äôapprendimento non supervisionato pu√≤ essere utilizzato per l‚Äôanalisi di grandi volumi di documenti legali, la scoperta di pattern nei dati dei casi, o la segmentazione dei casi giudiziari per identificare tipologie ricorrenti e relazioni tra i casi. Queste tecniche forniscono strumenti potenti per esplorare e comprendere i dati in modo pi√π profondo, senza la necessit√† di etichette predefinite.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "3-machine learning.html#bias",
    "href": "3-machine learning.html#bias",
    "title": "Machine learning",
    "section": "Bias",
    "text": "Bias\nIl bias nei modelli di machine learning √® una questione critica, soprattutto in settori sensibili come il diritto, dove le decisioni automatizzate possono avere implicazioni significative su persone e gruppi. Il bias pu√≤ portare a previsioni errate e ingiuste, perpetuando disuguaglianze sociali e legali. In questa sezione, esploreremo in dettaglio le diverse tipologie di bias, le cause e gli impatti che esse possono avere, e le tecniche per mitigare questi bias, con esempi pratici che illustrano il problema.\n\nTipologie di Bias\nI modelli di machine learning possono essere affetti da vari tipi di bias, ciascuno con caratteristiche specifiche e potenziali impatti:\n\nBias di Selezione: Si verifica quando il dataset utilizzato per addestrare il modello non rappresenta adeguatamente la popolazione o il fenomeno che si intende modellare. Ad esempio, immaginate un modello di machine learning sviluppato per predire il successo di un‚Äôazione legale basato su dati storici. Se il dataset include solo casi di successo e non quelli falliti, il modello potrebbe sovrastimare le probabilit√† di successo. Supponiamo che su un campione di 1.000 casi, solo 100 siano stati inclusi nel dataset e questi siano stati scelti per la loro rilevanza legale; se 90 di questi 100 casi sono stati di successo, il modello potrebbe imparare che il successo √® estremamente probabile (90%), ignorando che nella realt√† solo 200 dei 1.000 casi totali erano di successo, riducendo la probabilit√† reale al 20%.\nBias di Conferma: Questo tipo di bias emerge quando i dati o le caratteristiche selezionate per il modello confermano preconcetti o ipotesi preesistenti. Ad esempio, se un modello per la concessione del credito utilizza dati storici di prestiti concessi prevalentemente a individui di una determinata etnia o genere, potrebbe perpetuare lo stesso comportamento discriminatorio. Se nel dataset storico il 70% dei prestiti √® stato concesso a uomini, il modello potrebbe imparare a favorire inconsciamente le richieste di prestito fatte da uomini, basando le sue decisioni su pattern storici piuttosto che su criteri obiettivi di solvibilit√†.\nBias di Sopravvivenza: Questo bias si verifica quando l‚Äôanalisi si basa solo sui dati relativi ai ‚Äúsopravvissuti‚Äù a un determinato processo, ignorando i casi che non ce l‚Äôhanno fatta. Ad esempio, se un‚Äôanalisi per determinare i fattori di successo per avviare uno studio legale si basa solo su studi legali che sono riusciti, si ignoreranno i casi di studi legali che hanno fallito, portando a una sovrastima delle caratteristiche di successo. Se su 1.000 studi legali, solo 100 sono rimasti attivi dopo 10 anni, ma l‚Äôanalisi considera solo questi 100, il modello non riuscir√† a catturare i motivi del fallimento degli altri 900.\nBias Sistemico: Il bias sistemico riflette le disuguaglianze o le discriminazioni gi√† presenti nei dati storici e nei sistemi sociali. Per esempio, un modello che predice la recidiva basato su dati storici che riflettono pratiche discriminatorie della polizia potrebbe perpetuare tali discriminazioni. Se i dati storici mostrano che un determinato gruppo etnico ha un tasso di arresto pi√π alto a causa di pratiche di profilazione razziale, il modello potrebbe etichettare automaticamente questo gruppo come pi√π a rischio di recidiva, senza considerare il bias nella raccolta dei dati.\nBias Algoritmico: Questo tipo di bias √® introdotto dall‚Äôalgoritmo stesso, spesso a causa di obiettivi di ottimizzazione che non rappresentano adeguatamente il problema. Ad esempio, se un algoritmo di scoring creditizio √® ottimizzato esclusivamente per ridurre i tassi di insolvenza, potrebbe penalizzare ingiustamente gruppi demografici che storicamente hanno avuto meno accesso al credito. Supponiamo che l‚Äôalgoritmo tenda a ridurre il credito alle persone con un background socio-economico pi√π basso per minimizzare il rischio; in questo caso, il bias si manifesta nel modo in cui l‚Äôalgoritmo interpreta e valuta le caratteristiche socio-economiche.\n\n\n\nCause e Impatti del Bias\nLe cause del bias nei modelli di machine learning sono molteplici e possono derivare da diverse fasi del ciclo di vita del modello:\n\nDataset Non Rappresentativi: Uno dei motivi principali del bias √® l‚Äôuso di dataset non rappresentativi della popolazione target. Se il modello √® addestrato su dati che non riflettono tutte le possibili variabili del problema, esso sar√† inevitabilmente biased. Ad esempio, se un modello di predizione della recidiva √® addestrato principalmente su dati relativi a reati minori, potrebbe non essere accurato quando applicato a reati pi√π gravi. Questo pu√≤ portare a una sovrastima del rischio per alcuni individui, con conseguenti decisioni ingiuste.\nScelte di Modellazione: Le decisioni prese durante la fase di modellazione, come la selezione delle caratteristiche o la scelta dell‚Äôalgoritmo, possono introdurre bias. Se le caratteristiche scelte riflettono pregiudizi culturali o storici, il modello potrebbe imparare e riprodurre questi pregiudizi. Ad esempio, se si decide di includere la variabile ‚Äúquartiere di residenza‚Äù in un modello per la concessione di prestiti, questo potrebbe introdurre bias se certi quartieri sono associati a gruppi etnici o socio-economici specifici.\nFeedback Loop: Un feedback loop si verifica quando le previsioni di un modello influenzano i dati futuri, rafforzando il bias. Ad esempio, un sistema di polizia predittiva che invia pi√π pattuglie in quartieri gi√† sorvegliati pi√π intensamente potrebbe generare pi√π arresti in quelle aree, portando a un ulteriore aumento della sorveglianza e a un rafforzamento del bias iniziale. Se un modello predice che una particolare zona ha un‚Äôalta probabilit√† di criminalit√† e quindi concentra l√¨ le risorse di polizia, si avr√† un numero maggiore di segnalazioni di crimini in quell‚Äôarea, creando un ciclo che perpetua il bias.\n\nGli impatti del bias possono essere devastanti, soprattutto in contesti dove le decisioni automatizzate influenzano direttamente le vite delle persone:\n\nDiscriminazione: Un modello biased pu√≤ perpetuare o amplificare disuguaglianze esistenti, portando a decisioni discriminatorie. Ad esempio, se un modello di scoring creditizio discrimina ingiustamente contro minoranze etniche, potrebbe negare l‚Äôaccesso al credito a persone altrimenti meritevoli. Supponiamo che in un dataset di 10.000 richieste di prestito, il modello respinga il 30% delle richieste da parte di una minoranza etnica specifica a causa di un bias nei dati storici; questo porterebbe a una discriminazione ingiustificata e potenzialmente illegale.\nPerdita di Fiducia: Se i sistemi di intelligenza artificiale sono percepiti come ingiusti o discriminatori, la fiducia del pubblico in questi sistemi pu√≤ essere gravemente compromessa, limitando la loro accettazione e utilit√†. Ad esempio, se un sistema di giustizia predittiva √® percepito come discriminatorio nei confronti di certi gruppi etnici, potrebbe sollevare preoccupazioni pubbliche e ridurre la legittimit√† delle decisioni automatizzate, portando a un rifiuto dell‚Äôuso di tali tecnologie.\nConseguenze Legali: L‚Äôuso di modelli biased in decisioni legali pu√≤ portare a contenziosi e danni reputazionali per le istituzioni che li utilizzano, oltre a violare normative e leggi sulla non discriminazione. Ad esempio, un‚Äôazienda che utilizza un modello di selezione del personale che favorisce inconsciamente candidati maschi rispetto a candidati femmine potrebbe essere esposta a cause legali per discriminazione di genere, con conseguenti danni economici e reputazionali.\n\n\n\nTecniche di Mitigazione del Bias\nEsistono diverse tecniche per mitigare il bias nei modelli di machine learning, che possono essere implementate in varie fasi del ciclo di vita del modello:\n\nRaccolta e Preparazione dei Dati: Una delle tecniche pi√π efficaci per mitigare il bias √® assicurarsi che il dataset sia il pi√π possibile rappresentativo della popolazione target. Ci√≤ pu√≤ richiedere la raccolta di dati aggiuntivi per garantire che tutti i gruppi siano equamente rappresentati. Ad esempio, se un dataset per la concessione di mutui mostra che solo il 10% dei richiedenti appartiene a una minoranza etnica, potrebbe essere utile raccogliere dati aggiuntivi per aumentare questa percentuale, riducendo cos√¨ il bias nel modello.\nPre-processing dei Dati: Prima dell‚Äôaddestramento del modello, si possono applicare tecniche di pre-processing per ridurre il bias. Un esempio √® l‚Äôeliminazione di caratteristiche correlate al bias (come genere o etnia) o la normalizzazione dei dati per garantire che nessun gruppo sia sovrarappresentato. Ad esempio, se si sta costruendo un modello di selezione del personale, si potrebbe rimuovere il campo ‚Äúgenere‚Äù per evitare che il modello impari a discriminare in base a esso.\nModellazione In-process: Durante l‚Äôaddestramento, possono essere applicate tecniche di regolarizzazione che penalizzano il modello se sfrutta caratteristiche correlate al bias. Ad esempio, si possono utilizzare obiettivi di equit√†, come la parit√† di trattamento tra diversi gruppi. Supponiamo di avere un modello di classificazione che tende a discriminare un gruppo specifico; applicando una regolarizzazione che penalizza il modello se questo gruppo ha un tasso di errore significativamente diverso dagli altri, √® possibile ridurre il bias.\nPost-processing: Dopo l‚Äôaddestramento, possono essere applicate tecniche di post-processing per correggere il bias nelle previsioni del modello. Un esempio √® la calibrazione delle probabilit√† predette per garantire che le previsioni siano uniformi tra i diversi gruppi. Se un modello di scoring creditizio assegna punteggi pi√π bassi a un determinato gruppo etnico, si pu√≤ applicare un aggiustamento che uniformi i punteggi tra i gruppi, riducendo cos√¨ il bias.\nMonitoraggio e Aggiornamento Continuo: Il bias pu√≤ evolversi nel tempo man mano che cambiano i dati e le condizioni. √à quindi essenziale monitorare continuamente i modelli e aggiornarli periodicamente per garantire che il bias non si reintroduca o peggiori. Ad esempio, un modello utilizzato per la concessione di prestiti potrebbe essere rivalutato ogni anno per verificare che non stia emergendo nuovo bias a causa di cambiamenti nei dati demografici o economici.\nAnalisi di Impatto e Auditing: Condurre un‚Äôanalisi di impatto e auditing regolare sui modelli di machine learning √® fondamentale per identificare e correggere eventuali bias. Questo processo dovrebbe coinvolgere non solo esperti tecnici, ma anche stakeholder etici e legali per garantire che i modelli siano equi e conformi alle normative. Ad esempio, un modello utilizzato per predire la recidiva potrebbe essere sottoposto a una revisione annuale da parte di un comitato etico, che esamini l‚Äôequit√† delle previsioni e proponga modifiche se necessario.\n\nConclusione: La gestione del bias nei modelli di machine learning √® essenziale per garantire che le applicazioni dell‚ÄôIA, soprattutto in ambiti sensibili come il diritto, siano eque e giuste. Attraverso l‚Äôadozione di tecniche appropriate di mitigazione del bias, √® possibile sviluppare modelli che non solo siano accurati, ma che rispettino anche i principi di equit√† e non discriminazione. Questi modelli possono quindi essere utilizzati in modo responsabile, minimizzando il rischio di perpetuare disuguaglianze e promuovendo decisioni pi√π giuste e trasparenti.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "3-machine learning.html#reti-neurali-1",
    "href": "3-machine learning.html#reti-neurali-1",
    "title": "Machine learning",
    "section": "Reti Neurali",
    "text": "Reti Neurali\nLe reti neurali rappresentano una delle aree pi√π affascinanti e potenti dell‚Äôintelligenza artificiale, capaci di modellare e risolvere problemi complessi che spaziano dalla classificazione di immagini alla generazione di testi. Originariamente ispirate al funzionamento del cervello umano, le reti neurali sono diventate un pilastro fondamentale nel campo del machine learning e del deep learning, offrendo soluzioni avanzate per una vasta gamma di applicazioni, compresi i sistemi giuridici. In questo paragrafo, esploreremo le basi delle reti neurali, partendo dai concetti fondamentali della regressione lineare e logistica, fino ad arrivare alle architetture pi√π avanzate utilizzate nei moderni modelli di deep learning.\nIl viaggio inizia con la Regressione Lineare e Logistica (Sezione 4.4.1), che, pur essendo modelli semplici, costituiscono le fondamenta su cui si costruiscono concetti pi√π complessi delle reti neurali. La regressione lineare √® utilizzata per problemi di previsione continua, mentre la regressione logistica √® cruciale per problemi di classificazione binaria. Questi modelli, pur essendo relativamente semplici, offrono intuizioni fondamentali sulla modellazione dei dati e sulla costruzione di funzioni di previsione.\nProseguendo, discuteremo il Percettrone (Sezione 4.4.2), che √® la forma pi√π semplice di rete neurale e rappresenta un singolo neurone artificiale. Il percettrone √® in grado di risolvere problemi di classificazione lineare ed √® il punto di partenza per la comprensione delle reti neurali pi√π complesse. Nonostante la sua semplicit√†, il percettrone ha un‚Äôimportanza storica significativa, poich√© ha introdotto il concetto di apprendimento supervisionato nelle reti neurali.\nSuccessivamente, ci addentreremo nelle Reti Neurali Multistrato (MLP) (Sezione 4.4.3), che sono estensioni del percettrone e costituiscono il cuore delle reti neurali moderne. Un MLP √® composto da pi√π strati di neuroni, che permettono di modellare relazioni non lineari tra le variabili. Questa capacit√† di apprendere rappresentazioni complesse rende le MLP strumenti estremamente potenti per una vasta gamma di applicazioni, dalla predizione di valori continui alla classificazione di immagini.\nIl capitolo esplorer√† poi il mondo del Deep Learning (Sezione 4.4.4), una sottocategoria delle reti neurali che ha rivoluzionato il campo dell‚Äôintelligenza artificiale. Approfondiremo diverse Architetture (Sezione 4.4.4.1), come le Reti Neurali Convoluzionali (CNN), utilizzate principalmente per l‚Äôelaborazione delle immagini, le Reti Neurali Ricorrenti (RNN), ideali per l‚Äôelaborazione di dati sequenziali come il testo, e le Generative Adversarial Networks (GAN), che hanno aperto nuove frontiere nella generazione di contenuti. Inoltre, esploreremo le Tecniche di Addestramento (Sezione 4.4.4.2) che consentono alle reti neurali di apprendere in modo efficiente e accurato da grandi quantit√† di dati.\nInfine, il capitolo si concentrer√† sulle Applicazioni ai Linguaggi Naturali (Sezione 4.4.5), un‚Äôarea in cui le reti neurali hanno fatto progressi straordinari. Discuteremo i Modelli di Linguaggio Preaddestrati (Sezione 4.4.5.1) e i Large Language Models (LLM) (Sezione 4.4.5.2), come GPT e BERT, che sono in grado di comprendere e generare testi in modo sorprendentemente umano. Esploreremo l‚ÄôArchitettura e le Caratteristiche (Sezione 4.4.5.2.1) di questi modelli, fornendo Esempi di LLM (Sezione 4.4.5.2.2) e analizzando le loro Applicazioni e Impatti (Sezione 4.4.5.2.3) nei campi del diritto, dell‚Äôeducazione e oltre.\nQuesto capitolo fornir√† agli studenti una comprensione profonda e completa delle reti neurali, evidenziando non solo i principi teorici, ma anche le applicazioni pratiche e le implicazioni etiche e sociali dell‚Äôuso di queste tecnologie avanzate.\n\nRegressione Lineare e Logistica\nLe tecniche di regressione lineare e logistica costituiscono le basi delle reti neurali e di molti altri algoritmi di machine learning. Questi modelli semplici ma potenti permettono di comprendere come le reti neurali apprendono dai dati e come vengono effettuate le previsioni.\n\nRegressione Lineare\nLa regressione lineare √® uno degli algoritmi pi√π semplici e intuitivi per predire un valore continuo. L‚Äôidea centrale della regressione lineare √® trovare una funzione lineare che meglio approssimi la relazione tra una o pi√π variabili indipendenti (o caratteristiche) e una variabile dipendente.\nMatematicamente, la regressione lineare pu√≤ essere espressa come:\n\\[\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\\]\nDove: - \\(\\hat{y}\\) √® il valore predetto della variabile dipendente. - \\(x_1, x_2, \\dots, x_n\\) sono le variabili indipendenti (le caratteristiche). - \\(\\beta_0\\) √® l‚Äôintercetta, che rappresenta il valore di \\(\\hat{y}\\) quando tutte le variabili indipendenti sono uguali a zero. - \\(\\beta_1, \\beta_2, \\dots, \\beta_n\\) sono i coefficienti di regressione che indicano l‚Äôinfluenza di ciascuna variabile indipendente su \\(\\hat{y}\\).\nL‚Äôobiettivo della regressione lineare √® trovare i valori dei coefficienti \\(\\beta_0, \\beta_1, \\dots, \\beta_n\\) che minimizzano la differenza tra i valori predetti \\(\\hat{y}\\) e i valori osservati \\(y\\) nei dati. Questa differenza √® spesso misurata utilizzando l‚Äôerrore quadratico medio (Mean Squared Error, MSE), definito come:\n\\[MSE = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2\\]\nDove: - \\(m\\) √® il numero di esempi nel dataset. - \\(\\hat{y}_i\\) √® il valore predetto per l‚Äôi-esimo esempio. - \\(y_i\\) √® il valore osservato per l‚Äôi-esimo esempio.\nLa regressione lineare trova i coefficienti \\(\\beta\\) che minimizzano l‚ÄôMSE, utilizzando tecniche di ottimizzazione come il metodo dei minimi quadrati.\nesempio di regressione lineare: si hanno a disposizione i valori di vari immobili di cui si conosce la superficie calpestabile. Si vuole prevedere/stimare il prezzo di un immobile di 150 m^2. Le ipotesi sono che tutti gli immobili sono nella stessa area urbana e sono di pari pregio e stato di conservazione. Inoltre, per comodit√† generemo i dati usando il generatore di numeri casuali della libreria numpy.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generare dati di esempio\nnp.random.seed(42)\n# Metri quadrati (variabile indipendente)\n# 50 immobili con una media di 100 m¬≤ e deviazione standard di 20 m¬≤\nX = np.random.normal(100, 20, 50).reshape(-1, 1)  \n# Prezzo in migliaia di euro (variabile dipendente) con una certa \n# correlazione e aggiunta di rumore\ny = 200 + 2 * X.flatten() + np.random.normal(0, 15, X.shape[0])\n\n\n\n# Creare il modello di regressione lineare\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predire i valori per la linea di regressione\ny_pred = model.predict(X)\n\n# Grafico dei dati e del risultato della regressione\nplt.figure(figsize=(10, 6))\nplt.scatter(X, y, color='blue', label='Dati reali')\nplt.plot(X, y_pred, color='red', label='Regressione lineare')\nplt.xlabel('Metri quadrati')\nplt.ylabel('Prezzo (migliaia di euro)')\nplt.title('Regressione Lineare: Predizione del Prezzo di un Immobile')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Applicare i coefficienti della regressione a un immobile di 150 metri quadrati\nsquare_meters = np.array([[150]])\npredicted_price = model.predict(square_meters)\n\nmodel.coef_, model.intercept_, predicted_price[0]\n\n\n\n\n\n\n\n\n(array([2.07730673]),\n np.float64(192.88465267224188),\n np.float64(504.48066278658195))\n\n\nIl modello di regressione lineare costruito ha prodotto i seguenti risultati:\n\nCoefficiente della regressione \\((\\beta_1\\)): 2.08 (approssimato), che rappresenta l‚Äôaumento medio del prezzo (in migliaia di euro) per ogni metro quadrato aggiuntivo.\nIntercetta \\((\\beta_0\\)): 192.88 (approssimato), che rappresenta il prezzo di base in migliaia di euro quando l‚Äôimmobile ha 0 metri quadrati.\n\nUtilizzando questi coefficienti per predire il prezzo di un immobile di 150 metri quadrati:\n\\[\\text{Prezzo predetto} = 192.88 + 2.08 \\times 150 \\approx 504.48 \\text{ migliaia di euro}\\]\nQuindi, il prezzo stimato per un immobile di 150 metri quadrati √® di circa 504.48 migliaia di euro, ossia 504,480 euro.\n\n\nRegressione Logistica\nMentre la regressione lineare √® utilizzata per la previsione di valori continui, la regressione logistica √® un modello di classificazione utilizzato quando l‚Äôobiettivo √® prevedere una variabile dipendente binaria (cio√®, che pu√≤ assumere solo due valori, come 0 o 1).\nLa regressione logistica trasforma la previsione lineare utilizzando una funzione logistica (o sigmoide), che mappa i valori reali in un intervallo compreso tra 0 e 1. Questo intervallo pu√≤ essere interpretato come una probabilit√†.\nLa funzione logistica √® definita come:\n\\[\\text{sigmoide}(z) = \\frac{1}{1 + e^{-z}}\\]\nDove: - \\(z\\) √® la combinazione lineare delle caratteristiche, simile a quella usata nella regressione lineare: \\[z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\\]\nIl valore predetto dalla regressione logistica, \\(\\hat{y}\\), rappresenta la probabilit√† che la variabile dipendente assuma il valore 1, dato un insieme di caratteristiche \\(x_1, x_2, \\dots, x_n\\). Formalmente:\n\\[\\hat{y} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n)}}\\]\nIl modello viene addestrato utilizzando una funzione di perdita specifica, nota come log-loss o cross-entropy loss, che misura la differenza tra la probabilit√† predetta e il valore osservato:\n\\[\\text{Log-Loss} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\\right]\\]\nL‚Äôobiettivo √® minimizzare la log-loss durante l‚Äôaddestramento, regolando i coefficienti \\(\\beta\\) per migliorare la capacit√† del modello di distinguere tra le due classi.\nesempio di regressione logistica: si immagini di conoscere i dati relativi ad un coefficiente di rischio e alla probabilit√† di colpevolezza di un imputato. Per comodit√† i dati saranno simulati usando il generatore di numeri casuali di numpy con una distribuzione gaussiana.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\n# Simuliamo un dataset per predire la probabilit√† che un imputato sia dichiarato colpevole\n# Basandoci su un punteggio di rischio (ipotetico) su scala da 0 a 100\n\n# Generare dati di esempio\nnp.random.seed(42)\n# Punteggio di rischio (variabile indipendente)\n# 100 imputati con un punteggio medio di 50 e deviazione standard di 15\nX = np.random.normal(50, 15, 100).reshape(-1, 1)  \n# Esito (colpevole = 1, non colpevole = 0), determinato da una funzione logistica con \n# un po' di rumore\ny = (1 / (1 + np.exp(-0.1 * (X.flatten() - 50)))) &gt; np.random.rand(100)\n\n# Dividere i dati in train e test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Creare il modello di regressione logistica\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predire i valori sul set di test\ny_pred_prob = model.predict_proba(X_test)[:, 1]\ny_pred = model.predict(X_test)\n\n# Grafico dei dati e della curva di decisione\nplt.figure(figsize=(10, 6))\nplt.scatter(X_test, y_test, color='blue', label='Dati reali')\nplt.scatter(X_test, y_pred_prob, color='red', label='Probabilit√† predetta')\nplt.plot(sorted(X_test.flatten()), sorted(y_pred_prob), color='green', \\\n         label='Curva di decisione')\nplt.xlabel('Punteggio di rischio')\nplt.ylabel('Probabilit√† di colpevolezza')\nplt.title('Regressione Logistica: Predizione della Colpevolezza')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Mostrare la matrice di confusione\nConfusionMatrixDisplay.from_estimator(model, X_test, y_test, display_labels=\\\n                                      [\"Non colpevole\", \"Colpevole\"], cmap=plt.cm.Blues)\nplt.title('Matrice di Confusione')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesto ultimo grafico mostra la distribuzione delle previsioni del modello rispetto ai valori reali, evidenziando il numero di imputati correttamente classificati come ‚ÄúColpevole‚Äù o ‚ÄúNon colpevole‚Äù e quelli classificati erroneamente. Questo strumento √® utile per valutare le prestazioni del modello e comprendere meglio i suoi errori in un contesto giuridico.\n\n\nConnessione con le Reti Neurali\nLe reti neurali, in particolare quelle pi√π semplici come il percettrone, possono essere viste come estensioni dei modelli di regressione lineare e logistica. Un neurone in una rete neurale esegue una combinazione lineare delle caratteristiche (come nella regressione lineare), seguita da una funzione di attivazione (come la funzione logistica nella regressione logistica). Questo permette alle reti neurali di apprendere rappresentazioni complesse e non lineari, rendendole strumenti estremamente potenti per la modellazione dei dati.\nIn sintesi, la comprensione della regressione lineare e logistica fornisce le basi per comprendere come funzionano le reti neurali, ponendo le fondamenta per concetti pi√π avanzati come il deep learning. Questi modelli non solo offrono un‚Äôintroduzione alla modellazione predittiva, ma forniscono anche intuizioni cruciali su come le reti neurali apprendono dai dati per fare previsioni.\n\n\n\nPercettrone\nIl percettrone √® uno dei modelli pi√π semplici e fondamentali delle reti neurali artificiali ed √® stato introdotto da Frank Rosenblatt nel 1958. √à considerato il progenitore delle reti neurali moderne e rappresenta un singolo neurone artificiale. Nonostante la sua semplicit√†, il percettrone ha avuto un impatto significativo nello sviluppo dell‚Äôintelligenza artificiale, dimostrando che le macchine potevano apprendere a classificare dati attraverso un processo di addestramento supervisionato.\n\nStruttura e Funzionamento\nIl percettrone √® un modello di classificazione lineare che mira a separare i dati in due classi distinte (ad esempio, ‚Äúpositivo‚Äù e ‚Äúnegativo‚Äù). √à composto da un insieme di ingressi, pesi associati a ciascun ingresso, un bias, una funzione di somma e una funzione di attivazione. Ogni ingresso rappresenta una caratteristica del dato da classificare.\nMatematicamente, il funzionamento del percettrone pu√≤ essere descritto come segue:\n\nCalcolo della somma ponderata: Ogni ingresso (x_i) viene moltiplicato per un peso \\(w_i\\) corrispondente, e viene aggiunto un bias \\(b\\): \\[\nz = \\sum_{i=1}^{n} w_i \\cdot x_i + b\n\\] Dove:\n\n\\(x_i\\) sono le caratteristiche in input.\n\\(w_i\\) sono i pesi associati agli input.\n\\(b\\) √® il bias, un termine che permette di traslare la funzione di attivazione.\n\nFunzione di attivazione: Il valore ottenuto dalla somma ponderata viene passato attraverso una funzione di attivazione. Nel percettrone classico, la funzione di attivazione √® una funzione a soglia (o funzione di Heaviside): \\[\n\\hat{y} = \\begin{cases}\n1 & \\text{se } z \\geq 0 \\\\\n0 & \\text{se } z &lt; 0\n\\end{cases}\n\\] Questa funzione determina l‚Äôoutput del percettrone: se la somma ponderata √® maggiore o uguale a zero, l‚Äôoutput sar√† 1 (classe positiva); altrimenti, sar√† 0 (classe negativa).\n\n\n\nAddestramento del Percettrone\nL‚Äôobiettivo dell‚Äôaddestramento del percettrone √® trovare i pesi \\(w_i\\) e il bias \\(b\\) che permettono al modello di classificare correttamente i dati. Questo processo avviene attraverso l‚Äôalgoritmo di aggiornamento del percettrone, che segue questi passi:\n\nInizializzazione: I pesi e il bias vengono inizializzati a valori casuali o a zero.\nPredizione: Per ogni esempio nel dataset di addestramento, il percettrone calcola l‚Äôoutput \\(\\hat{y}\\) utilizzando i pesi e il bias correnti.\nAggiornamento: Se l‚Äôoutput \\(\\hat{y}\\) non corrisponde al valore atteso \\(y\\) (cio√®, il modello ha commesso un errore), i pesi e il bias vengono aggiornati:\n$$ w_i w_i + w_i\nb b + b $$ Dove\n\\[\n\\Delta w_i = \\eta \\cdot (y - \\hat{y}) \\cdot x_i\n\\] e \\[\n\\Delta b = \\eta \\cdot (y - \\hat{y})\n\\] , con \\(\\eta\\) che rappresenta il tasso di apprendimento.\nIterazione: Questo processo continua iterativamente fino a quando il modello non commette pi√π errori o il numero massimo di iterazioni viene raggiunto.\n\n\n\nLimitazioni e Applicazioni\nUna delle limitazioni principali del percettrone √® che pu√≤ risolvere solo problemi di classificazione linearmente separabili. Questo significa che se le classi non possono essere separate da una linea retta (o un iperpiano in dimensioni superiori), il percettrone non sar√† in grado di classificare correttamente i dati. Tuttavia, l‚Äôintroduzione di reti neurali multistrato (MLP) ha superato questa limitazione, permettendo di risolvere problemi pi√π complessi.\nNonostante questa limitazione, il percettrone ha applicazioni pratiche in compiti di classificazione semplice e continua a essere un importante strumento educativo per comprendere i fondamenti delle reti neurali e del machine learning.\nesempio di Perceptrone: Esempio di applicazione del percettrone per predire l‚Äôesito di una causa legale, basandosi su due caratteristiche: la complessit√† del caso e l‚Äôesperienza dell‚Äôavvocato.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay, classification_report\nfrom sklearn.datasets import make_blobs\n\n# Creiamo un dataset simulato per un'applicazione giuridica\n# Ad esempio, predire se una causa sar√† vinta o persa basandosi su due caratteristiche \n# legali (ad es., complessit√† del caso e esperienza dell'avvocato)\n\n# Generare dati di esempio\nX, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0,\\\n                            n_clusters_per_class=1, random_state=42)\n# X, y = make_blobs(n_samples=100, centers=[[1,3], [3,1]], random_state=1)\n# Dividere i dati in train e test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Creare e addestrare il modello di Perceptrone\nperc_model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\nperc_model.fit(X_train, y_train)\n\n# Predire sul set di test\ny_pred = perc_model.predict(X_test)\n\n# Grafico dei risultati\nplt.figure(figsize=(10, 6))\n\n# Dati reali\nplt.scatter(X_test[y_test == 0][:, 0], X_test[y_test == 0][:, 1], color='blue',\\\n             marker='o', label='Perso (Reale)')\nplt.scatter(X_test[y_test == 1][:, 0], X_test[y_test == 1][:, 1], color='green',\\\n             marker='x', label='Vinto (Reale)')\n\n# Dati predetti\nplt.scatter(X_test[y_pred == 0][:, 0], X_test[y_pred == 0][:, 1], color='red',\\\n             marker='o', facecolors='none', label='Perso (Predetto)')\nplt.scatter(X_test[y_pred == 1][:, 0], X_test[y_pred == 1][:, 1], color='yellow',\\\n             marker='x', label='Vinto (Predetto)')\n\n# Linea di decisione del perceptrone\nx_values = np.linspace(X_test[:, 0].min(), X_test[:, 0].max(), 100)\ndecision_boundary = -(perc_model.coef_[0, 0] * x_values + perc_model.intercept_[0]) \\\n                     / perc_model.coef_[0, 1]\nplt.plot(x_values, decision_boundary, color='black', linestyle='--',\\\n          label='Confine Decisionale')\n\nplt.xlabel('Complessit√† del caso')\nplt.ylabel('Esperienza dell\\'avvocato')\nplt.title('Perceptrone: Predizione della Vittoria o Sconfitta in un procedimento legale')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Mostrare la matrice di confusione e il rapporto di classificazione\nConfusionMatrixDisplay.from_estimator(perc_model, X_test, y_test, display_labels=\\\n                                      [\"Perso\", \"Vinto\"], cmap=plt.cm.Blues)\nplt.title('Matrice di Confusione')\nplt.show()\n\nprint(classification_report(y_test, y_pred, target_names=[\"Perso\", \"Vinto\"]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n              precision    recall  f1-score   support\n\n       Perso       1.00      1.00      1.00        15\n       Vinto       1.00      1.00      1.00        15\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\n\n\nNel grafico sopra, i punti blu rappresentano i casi persi, mentre i punti verdi rappresentano i casi vinti, basati sui dati reali. I punti rossi e gialli rappresentano rispettivamente le predizioni del modello per i casi persi e vinti. La linea nera tratteggiata indica il confine decisionale del percettrone, che separa i casi predetti come vinti o persi.\nIl modello ha eseguito una classificazione quasi perfetta su questo dataset di test, come evidenziato dalla matrice di confusione e dal rapporto di classificazione. Tutti i casi sono stati correttamente classificati, con una precisione, recall e F1-score di 1.00 per entrambe le classi (‚ÄúPerso‚Äù e ‚ÄúVinto‚Äù).\nQuesto risultato, pur essendo ideale, √® tipico di dati sintetici e ben separabili linearmente, che spesso non riflettono la complessit√† dei casi reali. Tuttavia, dimostra come il percettrone possa essere utilizzato per costruire modelli di classificazione in ambiti giuridici, fornendo una base per decisioni automatizzate in scenari meno complessi. Questo esempio ci aiuta a comprendere l‚Äôimportanza di valutare le performance del modello in contesti realistici e di considerare l‚Äôuso di modelli pi√π complessi, come le reti neurali multistrato, quando le classi non sono facilmente separabili linearmente.\n\n\n\nDeep learning\nIl deep learning √® una sottocategoria avanzata del machine learning che sfrutta reti neurali profonde per affrontare problemi complessi, caratterizzati da grandi quantit√† di dati e dalla necessit√† di apprendere rappresentazioni astratte e stratificate delle informazioni. Il viaggio nel deep learning inizia spesso con le Reti Neurali Multistrato (MLP), che rappresentano il primo passo verso la comprensione delle reti neurali profonde.\n\nReti Neurali Multistrato (MLP)\nLe Reti Neurali Multistrato (MLP = Multi Layer Perceptron) sono una forma di rete neurale feedforward, composte da uno strato di input, uno o pi√π strati nascosti e uno strato di output. Le MLP sono in grado di apprendere rappresentazioni non lineari dei dati grazie all‚Äôuso di funzioni di attivazione non lineari nei neuroni dei loro strati nascosti. Sebbene siano efficaci per molti compiti, le MLP tradizionali hanno una capacit√† limitata di affrontare problemi particolarmente complessi, poich√© sono generalmente composte da pochi strati nascosti.\nL‚Äôaddestramento delle MLP avviene attraverso l‚Äôalgoritmo di backpropagation, che calcola e minimizza l‚Äôerrore del modello aggiornando i pesi dei collegamenti tra i neuroni. Questa tecnica √® fondamentale non solo per le MLP, ma anche per le reti neurali pi√π complesse utilizzate nel deep learning.\n\nArchitettura delle MLP\nUn MLP pu√≤ essere configurato in diverse architetture a seconda del problema da risolvere. La configurazione pi√π comune √® quella con un singolo strato di input, uno o pi√π strati nascosti e uno strato di output. Ogni neurone in uno strato √® collegato a tutti i neuroni dello strato successivo, rendendo la rete completamente connessa.\n\nReti con un solo strato nascosto: Questo √® il tipo pi√π semplice di MLP, in cui un singolo strato nascosto √® sufficiente per risolvere problemi relativamente semplici o linearmente separabili con una funzione di attivazione non lineare.\nReti con pi√π strati nascosti: Quando i dati presentano una complessit√† maggiore, un MLP con pi√π strati nascosti pu√≤ catturare pattern pi√π complessi. Ogni strato aggiuntivo consente alla rete di apprendere rappresentazioni intermedie che possono essere utilizzate per ottenere una predizione finale pi√π accurata.\nDeep MLP: Quando il numero di strati nascosti aumenta significativamente, la rete viene considerata ‚Äúprofonda‚Äù (deep). Questi modelli, sebbene potenti, richiedono una maggiore attenzione durante l‚Äôaddestramento per evitare problemi come l‚Äôoverfitting o la vanishing gradient problem.\n\n\n\nFunzioni di Attivazione\nLe funzioni di attivazione sono cruciali per introdurre la non linearit√† nelle reti neurali, permettendo al modello di apprendere pattern complessi. Le funzioni di attivazione pi√π comuni negli strati nascosti includono:\n\nSigmoide: Questa funzione mappa qualsiasi valore reale in un intervallo compreso tra 0 e 1, ed √® definita come: \\[\\text{sigmoide}(z) = \\frac{1}{1 + e^{-z}}\\] La funzione sigmoide √® utile quando si ha bisogno di un output probabilistico, ma pu√≤ soffrire del problema della vanishing gradient, che rende difficile l‚Äôaddestramento di reti profonde.\nReLU (Rectified Linear Unit): Una delle funzioni di attivazione pi√π popolari, definita come: \\[\\text{ReLU}(z) = \\max(0, z)\\] ReLU √® ampiamente utilizzata perch√© risolve in parte il problema della vanishing gradient, accelerando l‚Äôaddestramento delle reti profonde. Tuttavia, pu√≤ soffrire del problema della ‚Äúmorte dei neuroni‚Äù, dove i neuroni possono rimanere bloccati su zero.\nTanh: Un‚Äôalternativa alla funzione sigmoide, mappa i valori in un intervallo tra -1 e 1, ed √® definita come: \\[\\text{tanh}(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\\] Tanh √® spesso preferita alla sigmoide per la sua capacit√† di centrare i dati attorno a zero, migliorando la convergenza del modello.\n\n\n\nFunzioni di Attivazione degli Strati di Uscita\nLa scelta della funzione di attivazione nello strato di uscita dipende dal tipo di problema che il modello deve risolvere:\n\nClassificazione binaria: Si utilizza comunemente la funzione sigmoide nello strato di uscita per ottenere una probabilit√† che l‚Äôoutput appartenga a una delle due classi.\nClassificazione multiclasse: La funzione softmax √® preferita, poich√© mappa i valori di output in un intervallo compreso tra 0 e 1 e la loro somma √® 1, fornendo quindi una distribuzione di probabilit√† tra le diverse classi: \\[\\text{softmax}(z_j) = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}\\] Dove \\(z_j\\) √® l‚Äôoutput per la j-esima classe.\nRegressione: Per problemi di regressione, in genere non si applica alcuna funzione di attivazione nell‚Äôultimo strato (o si utilizza l‚Äôidentit√†) per mantenere l‚Äôoutput come un valore reale continuo.\n\n\n\nFunzioni di Errore\nLe funzioni di errore (o funzioni di perdita) misurano la discrepanza tra l‚Äôoutput predetto dal modello e il valore reale, guidando cos√¨ il processo di apprendimento:\n\nErrore Quadratico Medio (MSE): Utilizzato per problemi di regressione, √® definito come: \\[MSE = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\\] Dove \\(y_i\\) √® il valore reale e \\(\\hat{y}_i\\) √® il valore predetto.\nCross-Entropy Loss: Utilizzata per la classificazione, particolarmente con softmax o sigmoide, misura la distanza tra le distribuzioni di probabilit√†: \\[\\text{Cross-Entropy} = -\\sum_{i=1}^n y_i \\log(\\hat{y}_i)\\]\n\n\n\nAlgoritmo di Backpropagation\nIl backpropagation √® l‚Äôalgoritmo chiave che permette l‚Äôaddestramento delle reti neurali multistrato. Funziona in due fasi:\n\nFeedforward: I dati vengono propagati in avanti attraverso la rete fino a generare un output.\nCalcolo della perdita e propagazione all‚Äôindietro: L‚Äôerrore viene calcolato confrontando l‚Äôoutput predetto con il valore reale. Questo errore viene poi propagato all‚Äôindietro attraverso la rete, calcolando il gradiente della funzione di perdita rispetto ai pesi della rete. I pesi vengono aggiornati utilizzando il gradient descent, minimizzando cos√¨ la funzione di perdita.\n\nIl backpropagation √® iterativo e viene eseguito per molte epoche fino a quando il modello non raggiunge un livello accettabile di precisione.\n\n\nEsempio di Rete MLP\nApplicazione di una rete neurale multistrato (MLP) per la predizione dell‚Äôesito di un caso giudiziario basandosi su tre caratteristiche: complessit√† del caso, esperienza dell‚Äôavvocato, e importanza mediatica. La rete √® composta da:\n\nStrato di input: Tre neuroni, ciascuno corrispondente a una delle caratteristiche del dataset (complessit√† del caso, esperienza dell‚Äôavvocato, importanza mediatica).\nStrati nascosti: Due strati nascosti, il primo con 10 neuroni e il secondo con 5 neuroni, che permettono alla rete di apprendere rappresentazioni pi√π complesse dei dati.\nStrato di output: Un singolo neurone di output, utilizzato per la classificazione binaria (vittoria o sconfitta del caso).\n\nOgni neurone in un determinato strato √® connesso a tutti i neuroni dello strato successivo, consentendo il flusso delle informazioni attraverso la rete durante l‚Äôaddestramento e la predizione. Una rappresentazione grafica di una rete neurale pu√≤ essere ottenuta usando la libreria networkx in Python. Qui di seguito si propone una funzione Python che disegna il grafo di una rete MLP data la sua descrizione in termini di numero di neuroni di ingresso, numero di strati e numero di neuroni per ogni strato e numero di neuroni di uscita.\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n# Funzione per disegnare una rappresentazione grafica della rete MLP\ndef draw_mlp(hidden_layers, input_size, output_size):\n    G = nx.DiGraph()\n    layer_sizes = [input_size] + list(hidden_layers) + [output_size]\n    \n    # Posizionamento dei nodi\n    pos = {}\n    n_layers = len(layer_sizes)\n    v_spacing = 1\n    h_spacing = 1 / float(max(layer_sizes))\n    \n    # Creazione dei nodi\n    for i, layer_size in enumerate(layer_sizes):\n        layer_top = v_spacing * (layer_size - 1) / 2\n        for j in range(layer_size):\n            pos[f'{i}-{j}'] = (i, layer_top - v_spacing * j)\n            G.add_node(f'{i}-{j}')\n    \n    # Creazione degli archi\n    for i, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n        for j in range(layer_size_a):\n            for k in range(layer_size_b):\n                G.add_edge(f'{i}-{j}', f'{i+1}-{k}')\n    \n    # Disegna il grafico\n    plt.figure(figsize=(12, 8))\n    nx.draw(G, pos=pos, with_labels=False, arrows=False, node_size=300, node_color=\"lightblue\")\n    \n    # Etichette\n    for i in range(input_size):\n        pos[f'0-{i}'] = (pos[f'0-{i}'][0] - 0.1, pos[f'0-{i}'][1])\n        plt.text(pos[f'0-{i}'][0], pos[f'0-{i}'][1], f'Input {i+1}', horizontalalignment='right')\n    \n    for i in range(output_size):\n        pos[f'{n_layers-1}-{i}'] = (pos[f'{n_layers-1}-{i}'][0] + 0.1, pos[f'{n_layers-1}-{i}'][1])\n        plt.text(pos[f'{n_layers-1}-{i}'][0], pos[f'{n_layers-1}-{i}'][1], f'Output {i+1}', horizontalalignment='left')\n    \n    plt.title(\"Rappresentazione Grafica della Rete MLP\")\n    plt.show()\n\nUsando la funzione appena introdotta possiamo disegnare la rete MLP usata nell‚Äôesempio come segue:\n\n\n# Parametri della rete MLP utilizzata nell'esempio\nhidden_layers = (10, 5)  # Due strati nascosti con 10 e 5 neuroni rispettivamente\ninput_size = 3  # Tre caratteristiche in input\noutput_size = 1  # Un neurone di output (classificazione binaria)\n\n# Disegnare la rappresentazione della rete MLP\ndraw_mlp(hidden_layers, input_size, output_size)\n\n\n\n\n\n\n\n\nL‚Äôimplementazione in Python della rete MLP per il nostroo problema di classificazione √® la seguente:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay, classification_report\n\n# Simuliamo un dataset per predire se un caso giudiziario sar√† vinto o perso basandosi su tre caratteristiche\n# Ad esempio, complessit√† del caso, esperienza dell'avvocato, e importanza mediatica\n\n# Generare dati di esempio\nX, y = make_classification(n_samples=200, n_features=3, n_informative=3, n_redundant=0, n_clusters_per_class=1, random_state=42)\n\n# Dividere i dati in train e test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Creare e addestrare un modello MLP\nmlp_model = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=1000, random_state=42)\nmlp_model.fit(X_train, y_train)\n\n# Predire sul set di test\ny_pred = mlp_model.predict(X_test)\n\n# Mostrare la matrice di confusione\nConfusionMatrixDisplay.from_estimator(mlp_model, X_test, y_test, display_labels=[\"Perso\", \"Vinto\"], cmap=plt.cm.Blues)\nplt.title('Matrice di Confusione')\nplt.show()\n\n# Visualizzare il rapporto di classificazione\nreport = classification_report(y_test, y_pred, target_names=[\"Perso\", \"Vinto\"])\nprint(report)\n\nc:\\Users\\lcapitanio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n              precision    recall  f1-score   support\n\n       Perso       0.94      0.91      0.93        35\n       Vinto       0.88      0.92      0.90        25\n\n    accuracy                           0.92        60\n   macro avg       0.91      0.92      0.91        60\nweighted avg       0.92      0.92      0.92        60\n\n\n\nAnalisi dei Risultati\n\nMatrice di Confusione: La matrice di confusione mostra le prestazioni del modello nella classificazione dei casi giudiziari come ‚ÄúVinto‚Äù o ‚ÄúPerso‚Äù. Nel set di test, il modello ha classificato correttamente la maggior parte dei casi, con solo pochi errori. La matrice di confusione indica che il modello ha identificato con una buona precisione sia i casi vinti che quelli persi.\nRapporto di Classificazione:\n\nPrecisione: La precisione per i casi persi √® del 94%, mentre per i casi vinti √® dell‚Äô88%. Questo significa che quando il modello prevede un caso come ‚ÄúPerso‚Äù, nel 94% dei casi ha ragione, mentre per i casi ‚ÄúVinto‚Äù, la precisione √® leggermente inferiore.\nRecall: La recall per i casi persi √® del 91% e per i casi vinti √® del 92%. Questo indica che il modello √® riuscito a identificare correttamente la maggior parte dei casi vinti e persi.\nF1-score: L‚ÄôF1-score, che rappresenta un bilanciamento tra precisione e recall, √® del 93% per i casi persi e del 90% per i casi vinti, riflettendo una buona performance complessiva del modello.\n\n\nOsservazioni: - Il modello ha raggiunto un‚Äôaccuratezza complessiva del 92%, che √® un buon risultato considerando che i dati generati non sono perfettamente separabili. - √à importante notare che il modello non ha raggiunto il valore di convergenza entro il numero massimo di iterazioni impostato (1000), come indicato dall‚Äôavviso di convergenza. Questo suggerisce che con ulteriori iterazioni o con l‚Äôottimizzazione dei parametri del modello, le prestazioni potrebbero migliorare ulteriormente. - In sintesi, l‚ÄôMLP si √® dimostrato efficace nel classificare correttamente i casi giudiziari in base alle caratteristiche fornite, anche in presenza di dati non perfettamente distinti. - Questo esempio mostra il potenziale delle reti neurali multistrato per applicazioni giuridiche, come la predizione degli esiti legali, pur sottolineando l‚Äôimportanza di una corretta configurazione e addestramento del modello per ottenere i migliori risultati possibili.\n\n\n\nArchitetture di Reti Neurali Profonde\nLe reti neurali profonde rappresentano una specializzazione e un‚Äôestensione delle MLP. Queste reti, spesso costituite da decine o centinaia di strati nascosti, sono in grado di apprendere rappresentazioni molto pi√π complesse e astratte rispetto alle MLP tradizionali. Ogni strato di una rete profonda elabora i dati in modo pi√π dettagliato, consentendo al modello di catturare caratteristiche gerarchiche dei dati, come pattern semplici nei primi strati e strutture pi√π complesse nei successivi.\nReti Neurali Convoluzionali (CNN)\nLe reti neurali convoluzionali (CNN) sono una classe specializzata di reti neurali artificiali, particolarmente efficaci nell‚Äôelaborazione di dati strutturati a griglia, come le immagini. Il termine ‚Äúconvoluzionale‚Äù √® fondamentale per comprendere il loro funzionamento unico.\nCos‚Äô√® la Convoluzione?\nLa convoluzione √® un‚Äôoperazione matematica che sta alla base di queste reti. In termini semplici, consiste nell‚Äôapplicare un filtro (o kernel) a una porzione dell‚Äôinput, facendolo ‚Äúscorrere‚Äù su tutta l‚Äôimmagine. Questo processo pu√≤ essere immaginato come una lente che si muove sull‚Äôimmagine, focalizzandosi su piccole aree alla volta.\ngraph LR\n    A[Immagine Input] --&gt; B[Applicazione Filtro]\n    B --&gt; C[Feature Map]\n    B --&gt; D[Scorrimento]\n    D --&gt; |Ripeti| B\n    C --&gt; E[Attivazione]\n    E --&gt; F[Pooling]\n    F --&gt; G[Prossimo Strato]\n\nFiltri e Feature Maps:\n\nI filtri sono matrici di pesi che vengono applicati all‚Äôinput.\nOgni filtro √® progettato per rilevare specifiche caratteristiche (come bordi, curve, o texture).\nIl risultato dell‚Äôapplicazione di un filtro √® chiamato ‚Äúfeature map‚Äù.\n\nProcesso di Scorrimento:\n\nIl filtro si muove sistematicamente attraverso l‚Äôimmagine, pixel per pixel.\nAd ogni posizione, esegue una moltiplicazione elemento per elemento e una somma.\nQuesto crea una nuova rappresentazione dell‚Äôimmagine che evidenzia certe caratteristiche.\n\nVantaggi della Convoluzione:\n\nInvarianza spaziale: La stessa caratteristica pu√≤ essere rilevata ovunque nell‚Äôimmagine.\nParametri condivisi: I pesi del filtro sono riutilizzati, riducendo il numero totale di parametri.\nGerarchia di features: Strati pi√π profondi combinano features semplici in rappresentazioni pi√π complesse.\n\n\nLe CNN impilano multiple operazioni di convoluzione, alternate con funzioni di attivazione non lineari (come ReLU) e strati di pooling. Questa architettura permette alla rete di costruire una comprensione gerarchica dell‚Äôinput, partendo da caratteristiche semplici negli strati iniziali (come bordi e texture) fino a concetti pi√π astratti negli strati pi√π profondi (come forme complesse e oggetti interi). Grazie a questa struttura ‚Äúconvoluzionale‚Äù, le CNN sono eccezionalmente efficaci in compiti come il riconoscimento di immagini, la detection di oggetti, e la segmentazione semantica, superando spesso le capacit√† umane in questi domini.\nEsempio di creazione, addestramento e test di una rete convoluzionale Applicazione di una rete convoluzionale (CNN) al dataset CIFAR-10 in Python con la libreria Keras (che fa parte di TensorFlow). Il dataset CIFAR-10 contiene 60.000 immagini a colori di 32x32 pixel suddivise in 10 classi, con 50.000 immagini per il training e 10.000 immagini per il test. Descrizione del Codice: - Caricamento e Preprocessamento dei Dati:Carichiamo il dataset CIFAR-10 gi√† disponibile in Keras e lo dividiamo in training set e test set. Normalizziamo i valori dei pixel per far s√¨ che siano compresi tra 0 e 1. - Visualizzazione delle Immagini:Visualizziamo alcune immagini del training set con i rispettivi nomi delle classi per avere un‚Äôidea del tipo di dati. - Creazione della Rete Convoluzionale:Utilizziamo tre blocchi di convoluzione seguiti da pooling, aumentando il numero di filtri in ogni strato. Alla fine della rete convoluzionale, utilizziamo uno strato Flatten per trasformare i dati in un formato compatibile con uno strato completamente connesso. Lo strato completamente connesso finale ha 10 unit√†, corrispondenti alle 10 classi del dataset CIFAR-10. - Compilazione del Modello: Utilizziamo l‚Äôottimizzatore Adam e la funzione di perdita SparseCategoricalCrossentropy. - Allenamento del Modello: Alleniamo il modello per 10 epoche e visualizziamo la precisione e la perdita sia sul training set che sul validation set. - Valutazione: Alla fine, valutiamo il modello sul test set e stampiamo l‚Äôaccuratezza. - Risultato Atteso: Il modello raggiunger√† un‚Äôaccuratezza intorno al 70-75% sul test set, a seconda della configurazione e dell‚Äôhardware utilizzato.\n\n# Importiamo le librerie necessarie\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\n\n# Carichiamo il dataset CIFAR-10\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n\n# Normalizziamo i valori dei pixel a un intervallo [0, 1]\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\n\n# Mostriamo alcune immagini di esempio dal dataset CIFAR-10\nclass_names = ['Aereo', 'Auto', 'Uccello', 'Gatto', 'Cervo', 'Cane', 'Rana', 'Cavallo', 'Nave', 'Camion']\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i])\n    # Le etichette nel dataset sono numeri interi, dobbiamo mapparle con i nomi delle classi\n    plt.xlabel(class_names[train_labels[i][0]])\nplt.show()\n\n# Creiamo il modello della rete convoluzionale\nmodel = models.Sequential()\n\n# Primo strato convoluzionale\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# Secondo strato convoluzionale\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# Terzo strato convoluzionale\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n\n# Flatten (convertiamo i dati in un vettore 1D)\nmodel.add(layers.Flatten())\n\n# Strato completamente connesso\nmodel.add(layers.Dense(64, activation='relu'))\n\n# Strato di output con 10 unit√† (una per ciascuna classe del CIFAR-10)\nmodel.add(layers.Dense(10))\n\n# Riepilogo della rete\nmodel.summary()\n\n# Compiliamo il modello\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n# Alleniamo il modello\nhistory = model.fit(train_images, train_labels, epochs=10, \n                    validation_data=(test_images, test_labels))\n\n# Visualizziamo i grafici di accuratezza e perdita\nplt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n# Valutiamo il modello sui dati di test\ntest_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\nprint(f'\\nAccuratezza sul test set: {test_acc}')\n\nDownloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 36s 0us/step\n\n\n\n\n\n\n\n\n\nc:\\Users\\lcapitanio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n\n\nModel: \"sequential\"\n\n\n\n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Layer (type)                    ‚îÉ Output Shape           ‚îÉ       Param # ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ conv2d (Conv2D)                 ‚îÇ (None, 30, 30, 32)     ‚îÇ           896 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d (MaxPooling2D)    ‚îÇ (None, 15, 15, 32)     ‚îÇ             0 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_1 (Conv2D)               ‚îÇ (None, 13, 13, 64)     ‚îÇ        18,496 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_1 (MaxPooling2D)  ‚îÇ (None, 6, 6, 64)       ‚îÇ             0 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_2 (Conv2D)               ‚îÇ (None, 4, 4, 64)       ‚îÇ        36,928 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ flatten (Flatten)               ‚îÇ (None, 1024)           ‚îÇ             0 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense (Dense)                   ‚îÇ (None, 64)             ‚îÇ        65,600 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense_1 (Dense)                 ‚îÇ (None, 10)             ‚îÇ           650 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n Total params: 122,570 (478.79 KB)\n\n\n\n Trainable params: 122,570 (478.79 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\nEpoch 1/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 17s 10ms/step - accuracy: 0.3583 - loss: 1.7137 - val_accuracy: 0.5424 - val_loss: 1.2747\nEpoch 2/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18s 11ms/step - accuracy: 0.5744 - loss: 1.1928 - val_accuracy: 0.6309 - val_loss: 1.0408\nEpoch 3/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18s 11ms/step - accuracy: 0.6488 - loss: 1.0025 - val_accuracy: 0.6566 - val_loss: 0.9731\nEpoch 4/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18s 12ms/step - accuracy: 0.6862 - loss: 0.8934 - val_accuracy: 0.6846 - val_loss: 0.9034\nEpoch 5/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21s 13ms/step - accuracy: 0.7160 - loss: 0.8103 - val_accuracy: 0.7025 - val_loss: 0.8726\nEpoch 6/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18s 11ms/step - accuracy: 0.7379 - loss: 0.7481 - val_accuracy: 0.6917 - val_loss: 0.8936\nEpoch 7/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18s 12ms/step - accuracy: 0.7555 - loss: 0.6952 - val_accuracy: 0.7042 - val_loss: 0.8687\nEpoch 8/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19s 12ms/step - accuracy: 0.7762 - loss: 0.6473 - val_accuracy: 0.7215 - val_loss: 0.8195\nEpoch 9/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19s 12ms/step - accuracy: 0.7879 - loss: 0.6004 - val_accuracy: 0.7213 - val_loss: 0.8363\nEpoch 10/10\n1563/1563 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19s 12ms/step - accuracy: 0.8032 - loss: 0.5645 - val_accuracy: 0.7246 - val_loss: 0.8529\n\n\n\n\n\n\n\n\n\n313/313 - 3s - 8ms/step - accuracy: 0.7246 - loss: 0.8529\n\nAccuratezza sul test set: 0.7246000170707703\n\n\n\nReti Neurali Ricorrenti (RNN): Le RNN sono un‚Äôestensione delle MLP per dati sequenziali, come testi o segnali audio. Grazie alle connessioni ricorrenti, le RNN possono mantenere una memoria delle informazioni precedenti nella sequenza, rendendole ideali per compiti che richiedono la modellazione del contesto temporale. Tuttavia, le RNN tradizionali soffrono del problema del vanishing gradient, che pu√≤ ostacolare l‚Äôapprendimento di dipendenze a lungo termine nelle sequenze. Per superare questa limitazione, sono state sviluppate varianti come le LSTM (Long Short-Term Memory) e le GRU (Gated Recurrent Unit), che migliorano la capacit√† della rete di apprendere e mantenere informazioni su lunghe sequenze temporali.\nReti Generative Adversariali (GAN): Le GAN rappresentano un‚Äôarchitettura avanzata che combina due reti, una generativa e una discriminativa, in un quadro competitivo. Queste reti sono in grado di generare nuovi dati simili a quelli reali, estendendo le capacit√† delle MLP in modi creativi e innovativi. La rete generativa tenta di produrre dati falsi che siano indistinguibili dai dati reali, mentre la rete discriminativa cerca di distinguere tra dati reali e falsi. Questo approccio ha portato a notevoli innovazioni nella generazione di immagini realistiche, video, musica e persino testo, aprendo nuove possibilit√† nel campo della creativit√† artificiale e della simulazione.\n\n\n\nTecniche di Addestramento per Reti Profonde\nL‚Äôaddestramento delle reti profonde √® pi√π complesso rispetto a quello delle MLP a causa della maggiore profondit√† e del numero di parametri coinvolti. Il processo di addestramento utilizza algoritmi di ottimizzazione come la discesa del gradiente, ma con alcune sfide specifiche:\n\nProblema del Vanishing Gradient: Nelle reti molto profonde, i gradienti calcolati durante la backpropagation possono diventare molto piccoli, impedendo l‚Äôaggiornamento efficace dei pesi nei primi strati della rete. Questo problema √® particolarmente critico nelle RNN, dove la propagazione dei gradienti attraverso molteplici passi temporali pu√≤ portare alla perdita di informazioni utili. Per mitigare questo problema, si utilizzano funzioni di attivazione come ReLU, che mantengono gradienti pi√π ampi, e tecniche come il batch normalization, che stabilizza e accelera il processo di addestramento.\nBatch Normalization: Questa tecnica normalizza gli input a ciascuno strato per avere una media zero e una varianza unitaria, riducendo cos√¨ il rischio di gradienti esplosivi o vanishing e migliorando la stabilit√† dell‚Äôaddestramento. Il batch normalization √® ampiamente utilizzato nelle reti profonde, poich√© permette un addestramento pi√π efficiente e riduce la sensibilit√† agli iperparametri, facilitando l‚Äôuso di learning rate pi√π elevati.\nDropout: Per prevenire l‚Äôoverfitting, una delle tecniche pi√π comuni √® il dropout, che consiste nel disattivare casualmente alcuni neuroni durante l‚Äôaddestramento, impedendo alla rete di dipendere troppo da specifiche connessioni. Questo forza la rete a generalizzare meglio, migliorando le sue prestazioni su dati mai visti. Durante la fase di inferenza, tutti i neuroni vengono utilizzati, ma i pesi sono scalati per mantenere la coerenza delle attivazioni.\n\n\n\nTecniche di Ottimizzazione dei Parametri delle Reti Profonde\nOltre alle tecniche di addestramento, le reti profonde richiedono l‚Äôuso di tecniche avanzate di ottimizzazione per gestire la complessit√† e migliorare la convergenza:\n\nAlgoritmi di Ottimizzazione: Sebbene la discesa del gradiente stocastica (SGD) sia l‚Äôapproccio di base, varianti pi√π avanzate come Adam (Adaptive Moment Estimation) e RMSprop sono ampiamente utilizzate. Adam, in particolare, combina i vantaggi di AdaGrad (che adatta il learning rate per ogni parametro) e RMSprop (che mantiene un learning rate efficiente per ogni parametro), risultando in una convergenza pi√π rapida e stabile anche in reti molto profonde.\nLearning Rate Scheduling: Il learning rate, ossia la velocit√† con cui vengono aggiornati i pesi, √® un parametro critico che influisce sulla velocit√† e sull‚Äôefficacia dell‚Äôaddestramento. Tecniche come il learning rate scheduling permettono di iniziare l‚Äôaddestramento con un learning rate elevato, che viene ridotto man mano che il modello si avvicina a una soluzione ottimale. Questo aiuta a trovare il minimo globale della funzione di perdita pi√π rapidamente.\nEarly Stopping: Per evitare l‚Äôoverfitting durante l‚Äôaddestramento, l‚Äôearly stopping monitora la performance del modello su un set di validazione e interrompe l‚Äôaddestramento quando le prestazioni iniziano a peggiorare. Questo evita che la rete apprenda troppo i dettagli del set di addestramento, migliorando la generalizzazione.\nUso di modelli pre-addestrati\n\nL‚Äôaddestramento delle reti neurali profonde richiede notevoli risorse computazionali e dataset di grandi dimensioni, rendendo i costi in termini di tempo e potenza di calcolo molto elevati. Per ridurre questi costi, l‚Äôuso di modelli pre-addestrati rappresenta una soluzione efficace, poich√© consente di sfruttare reti gi√† addestrate su ampi dataset e adattarle a specifici problemi con un processo noto come fine-tuning. Ci√≤ permette di evitare il lungo e dispendioso processo di addestramento da zero, ottenendo comunque prestazioni eccellenti.\nLe collezioni di modelli pre-addestrati disponibili su piattaforme come TensorFlow Hub, PyTorch Hub e Hugging Face Model Hub offrono reti avanzate, gi√† ottimizzate, come ResNet, EfficientNet per la visione e BERT, GPT per il linguaggio. Questi modelli, addestrati su dataset estesi, possono essere facilmente utilizzati per applicazioni specifiche con poche risorse computazionali aggiuntive, rendendo il processo pi√π accessibile ed economico senza sacrificare la qualit√† delle prestazioni.\nesempio di uso di rete pre-addestrata\nUsiamo una rete pre-addestrata per il compito di classificazione di aimmagini che abbiamo visto nel paragrafo 4.4.3.2. Per utilizzare una rete preaddestrata con il dataset CIFAR-10, possiamo sfruttare un modello preaddestrato su ImageNet, come ResNet50, e adattarlo al nostro compito tramite il fine-tuning. L‚Äôidea √® quella di caricare il modello preaddestrato, congelare i pesi degli strati inferiori e modificare solo gli ultimi strati per adattare il modello alle 10 classi di CIFAR-10.\nEcco un esempio di di fine tuning di una rete pre-addestrata utilizzando Keras e TensorFlow.\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Carica e prepara il dataset CIFAR-10\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\ny_train = tf.keras.utils.to_categorical(y_train, 10)\ny_test = tf.keras.utils.to_categorical(y_test, 10)\n\n# Data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    zoom_range=0.1\n)\ndatagen.fit(x_train)\n\n# Carica il modello VGG16 preaddestrato senza i layer fully connected\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Fine-tuning: sblocca gli ultimi blocchi convoluzionali\nfor layer in base_model.layers[-4:]:\n    layer.trainable = True\n\n# Crea un nuovo modello aggiungendo layer personalizzati\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(10, activation='softmax')\n])\n\n# Compila il modello\nmodel.compile(optimizer=Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Addestra il modello\nhistory = model.fit(datagen.flow(x_train, y_train, batch_size=16),\n                    steps_per_epoch=len(x_train) // 16,\n                    epochs=5,\n                    validation_data=(x_test, y_test),\n                    verbose=1)\n\n# Valuta il modello sul set di test\ntest_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\nprint(f\"Accuratezza sul set di test: {test_acc:.4f}\")\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Supponiamo che 'history', 'model', 'x_test', 'y_test' siano gi√† definiti dal codice precedente\n\n# Nomi delle classi CIFAR-10\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n# 1. Grafico dell'accuratezza\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# 2. Grafico della loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# 3. Matrice di confusione\ny_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true_classes = np.argmax(y_test, axis=1)\n\ncm = confusion_matrix(y_true_classes, y_pred_classes)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n# 4. Visualizzazione di 20 esempi di immagini classificate\nn_images = 20\nindices = np.random.choice(range(len(x_test)), n_images, replace=False)\n\nplt.figure(figsize=(20, 10))\nfor i, idx in enumerate(indices):\n    plt.subplot(4, 5, i+1)\n    img = x_test[idx]\n    plt.imshow(img)\n    true_label = class_names[y_true_classes[idx]]\n    pred_label = class_names[y_pred_classes[idx]]\n    color = 'green' if true_label == pred_label else 'red'\n    plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n\n# Stampa l'accuratezza complessiva\ntest_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\nprint(f\"Accuratezza complessiva sul set di test: {test_acc:.4f}\")\n\n\n\nApplicazioni e Sfide\nLe applicazioni del deep learning sono vaste e coprono molte aree, dalla visione artificiale all‚Äôelaborazione del linguaggio naturale. In ambito giuridico, le reti profonde possono essere utilizzate per l‚Äôanalisi predittiva, la classificazione automatica di documenti legali e l‚Äôestrazione di informazioni da grandi volumi di testo. Tuttavia, l‚Äôimplementazione del deep learning richiede una grande quantit√† di dati e risorse computazionali, oltre a una profonda comprensione delle reti neurali per evitare problemi di interpretabilit√† e bias. Nonostante queste sfide, il deep learning continua a spingere i confini dell‚Äôintelligenza artificiale, offrendo soluzioni avanzate a problemi complessi che erano precedentemente irrisolvibili.\nMachine learning e linguaggi naturali",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratorio di Intelligenza Artificiale",
    "section": "",
    "text": "Benvenuti\nQuesto sito √® la versione web del libro ‚ÄúLaboratorio di Intelligenza Artificiale in Python‚Äù che vuole essere una guida pratica pensata per professionisti legali senza esperienza di programmazione. Il libro introduce in modo semplice l‚Äôuso di Python per applicazioni nell‚Äôambito giuridico, aiutando a comprendere come l‚Äôintelligenza artificiale pu√≤ trasformare il settore legale.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Laboratorio di Intelligenza Artificiale",
    "section": "License",
    "text": "License\nL‚Äôuso di questo sito √® gratuito ed i suoi contenuti sono sottoposto a una licenza Creative Commons Attribution-NonCommercial-NoDerivs 4.0. Se vuoi avere una copia fisica o una versione e-book del libro puoi ordinarlo da ‚Ä¶; √® stato pubblicato il ‚Ä¶\nSe vuoi contribuire, √® gradito ogni commento e correzione di refusi, puoi farlo su github.com/capitanio/laboratorio-ia.\nLuciano Capitanio",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "0-introduzione.html",
    "href": "0-introduzione.html",
    "title": "Introduzione",
    "section": "",
    "text": "L‚ÄôIntelligenza Artificiale (IA) √® un campo di studio che si occupa della creazione di macchine e software in grado di mostrare comportamenti intelligenti. Questa disciplina √® stata definita per la prima volta da John McCarthy nel 1955 come ‚Äúla scienza e l‚Äôingegneria della costruzione di macchine intelligenti‚Äù (McCarthy et al. 1955).\n\n\n\nIA √® una disciplina di confine\n\n\nL‚ÄôIA √® sia una scienza che una tecnica, un‚Äôarea di ricerca in cui convergono diverse discipline, tra cui l‚Äôinformatica, la statistica e le scienze cognitive.\nL‚ÄôIA si divide principalmente in due categorie: IA debole e IA forte. L‚ÄôIA debole si riferisce a sistemi progettati per eseguire compiti specifici, come il riconoscimento vocale o la guida autonoma. L‚ÄôIA forte, invece, riguarda sistemi che potrebbero possedere una coscienza e un‚Äôintelligenza simile a quella umana (Searle 1980).\nL‚ÄôIA sta trasformando molti settori, tra cui l‚Äôassistenza sanitaria, l‚Äôistruzione, i trasporti e l‚Äôindustria. Ad esempio, nel campo sanitario, l‚ÄôIA supporta i medici nella diagnosi delle malattie e nella creazione di piani di trattamento personalizzati (Jiang et al. 2017).\nNonostante i progressi, l‚ÄôIA presenta diverse sfide, tra cui questioni etiche come la privacy dei dati e l‚Äôimpatto sull‚Äôoccupazione, nonch√© problemi tecnici legati alla comprensione del linguaggio naturale e allo sviluppo di algoritmi di apprendimento automatico efficaci (Russell and Norvig 2016).\nIn conclusione, l‚ÄôIA √® un campo in rapida evoluzione con il potenziale di rivoluzionare la societ√†. Tuttavia, √® essenziale affrontare le sfide etiche e tecniche per garantire che i suoi benefici siano raggiunti in modo sicuro e sostenibile.\n\n\n\n\nJiang, Feng, Yong Jiang, Hui Zhi, Dong Yang, Hua Li, Shanyu Ma, and Yan Wang. 2017. ‚ÄúArtificial Intelligence in Healthcare: Past, Present and Future.‚Äù Stroke and Vascular Neurology.\n\n\nMcCarthy, John, Marvin Minsky, Nathaniel Rochester, and Claude E. Shannon. 1955. A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence.\n\n\nRussell, Stuart, and Peter Norvig. 2016. Artificial Intelligence: A Modern Approach. Pearson.\n\n\nSearle, John R. 1980. ‚ÄúMinds, Brains, and Programs.‚Äù Behavioral and Brain Sciences.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html",
    "href": "1-Turing-vs-Searle.html",
    "title": "Turing vs Searle: Un‚ÄôAnalisi del Pensiero Computazionale e della Coscienza",
    "section": "",
    "text": "Alan Turing e il Test di Turing\nAlan Turing, pioniere dell‚Äôinformatica, propose il ‚ÄúTest di Turing‚Äù nel 1950 come criterio per valutare se una macchina potesse essere considerata intelligente (Turing 1950). Secondo Turing, se un essere umano che comunica con una macchina attraverso uno schermo non riesce a distinguerla da un altro essere umano, allora la macchina pu√≤ essere considerata intelligente.\nPunti chiave del Test di Turing: - Il test misura la capacit√† di imitare il comportamento umano, non la comprensione o la coscienza. - Ha ispirato lo sviluppo di chatbot e sistemi di IA conversazionale.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Turing vs Searle: Un'Analisi del Pensiero Computazionale e della Coscienza</span>"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html#alan-turing-e-il-test-di-turing",
    "href": "1-Turing-vs-Searle.html#alan-turing-e-il-test-di-turing",
    "title": "Turing vs Searle: Un‚ÄôAnalisi del Pensiero Computazionale e della Coscienza",
    "section": "",
    "text": "Immagine generata da DALL-E del Test di Turing\n\n\n\n\n\nCritiche al Test di Turing\nMolti filosofi e scienziati sostengono che il test non catturi la vera natura dell‚Äôintelligenza o della coscienza. John Searle √® uno dei principali critici.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Turing vs Searle: Un'Analisi del Pensiero Computazionale e della Coscienza</span>"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html#john-searle-e-largomento-della-stanza-cinese",
    "href": "1-Turing-vs-Searle.html#john-searle-e-largomento-della-stanza-cinese",
    "title": "Turing vs Searle: Un‚ÄôAnalisi del Pensiero Computazionale e della Coscienza",
    "section": "John Searle e l‚ÄôArgomento della Stanza Cinese",
    "text": "John Searle e l‚ÄôArgomento della Stanza Cinese\n\n\n\nImmagine generata da DALL-E del Test della Stanza Cinese\n\n\nJohn Searle propose l‚Äôesperimento mentale della ‚ÄúStanza Cinese‚Äù nel 1980 come critica al concetto di IA forte. L‚Äôidea √® la seguente:\n\nUna persona che non conosce il cinese si trova in una stanza con un manuale di istruzioni che spiega come rispondere ai messaggi scritti in cinese.\nUsando il manuale, la persona pu√≤ rispondere correttamente ai messaggi senza comprendere realmente il cinese.\nSearle sostiene che le macchine, similmente, possono elaborare simboli senza comprendere il loro significato.\n\nConclusione della Stanza Cinese: - L‚Äôelaborazione simbolica non equivale alla comprensione. - Questo pone un limite all‚Äôidea che una macchina possa essere veramente intelligente.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Turing vs Searle: Un'Analisi del Pensiero Computazionale e della Coscienza</span>"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html#conclusioni",
    "href": "1-Turing-vs-Searle.html#conclusioni",
    "title": "Turing vs Searle: Un‚ÄôAnalisi del Pensiero Computazionale e della Coscienza",
    "section": "Conclusioni",
    "text": "Conclusioni\nIl confronto tra Turing e Searle evidenzia due prospettive opposte sull‚Äôintelligenza artificiale: - Turing vede l‚Äôimitazione come un segno sufficiente di intelligenza. - Searle insiste sulla distinzione tra simulazione e comprensione reale.\nQuesto dibattito rimane centrale nella filosofia dell‚Äôintelligenza artificiale e continua a ispirare nuove domande e riflessioni.\n\n\n\n\nSearle, John R. 1980. ‚ÄúMinds, Brains, and Programs.‚Äù Behavioral and Brain Sciences.\n\n\nTuring, Alan M. 1950. ‚ÄúComputing Machinery and Intelligence.‚Äù Mind.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Turing vs Searle: Un'Analisi del Pensiero Computazionale e della Coscienza</span>"
    ]
  },
  {
    "objectID": "a1-elementi-di-Python.html",
    "href": "a1-elementi-di-Python.html",
    "title": "Appendix A ‚Äî Elementi di Python",
    "section": "",
    "text": "Perch√© Python √® utile in ambito giuridico?\nPython √® particolarmente utile per automatizzare compiti ripetitivi, analizzare grandi quantit√† di dati (ad esempio, sentenze giudiziarie) e sviluppare strumenti personalizzati per supportare il lavoro legale. Con poche righe di codice, √® possibile:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Elementi di Python</span>"
    ]
  },
  {
    "objectID": "a1-elementi-di-Python.html#perch√©-python-√®-utile-in-ambito-giuridico",
    "href": "a1-elementi-di-Python.html#perch√©-python-√®-utile-in-ambito-giuridico",
    "title": "Appendix A ‚Äî Elementi di Python",
    "section": "",
    "text": "Analizzare documenti legali.\nCalcolare sanzioni o durate delle pene.\nAutomatizzare la creazione di report (Srinath 2017).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Elementi di Python</span>"
    ]
  },
  {
    "objectID": "a1-elementi-di-Python.html#introduzione-alla-sintassi-di-python",
    "href": "a1-elementi-di-Python.html#introduzione-alla-sintassi-di-python",
    "title": "Appendix A ‚Äî Elementi di Python",
    "section": "Introduzione alla sintassi di Python",
    "text": "Introduzione alla sintassi di Python\n\n1. Variabili e Tipi di Dati\nLe variabili sono contenitori per dati. Ad esempio, puoi salvare il nome di un giudice o il numero di un fascicolo:\ngiudice = \"Mario Rossi\"  # Nome del giudice\nfascicolo = 2024112345   # Numero del fascicolo\nPython riconosce automaticamente il tipo di dato (stringhe, numeri, ecc.). Non serve dichiararlo (Rossum and Drake 2016).\n\n\n2. Condizioni: Prendere Decisioni\nCon Python, puoi verificare condizioni e decidere quale azione intraprendere. Ad esempio, puoi controllare se un fascicolo √® chiuso:\nfascicolo_chiuso = False  # Il fascicolo non √® ancora chiuso\n\nif fascicolo_chiuso:\n    print(\"Il fascicolo √® chiuso.\")\nelse:\n    print(\"Il fascicolo √® ancora aperto.\")\nNota: Il codice √® sensibile all‚Äôindentazione (spazi all‚Äôinizio di una riga). Assicurati di rispettare la struttura (Lutz 2013)!\n\n\n3. Cicli: Ripetere Azioni\nI cicli permettono di eseguire azioni ripetitive. Ad esempio, puoi stampare l‚Äôelenco di testimoni da interrogare:\ntestimoni = [\"Testimone A\", \"Testimone B\", \"Testimone C\"]\n\nfor testimone in testimoni:\n    print(f\"Interrogare {testimone}\")\nOutput:\nInterrogare Testimone A  \nInterrogare Testimone B  \nInterrogare Testimone C\n\n\n4. Gestione degli Errori\nPython permette di gestire gli errori con eleganza. Ad esempio, se provi ad aprire un file di sentenze che non esiste:\ntry:\n    with open(\"sentenze.txt\", \"r\") as file:\n        contenuto = file.read()\nexcept FileNotFoundError:\n    print(\"Errore: Il file non √® stato trovato.\")\nOutput:\nErrore: Il file non √® stato trovato.\n\n\n5. Strutture Dati Utili\n\nListe\nLe liste sono utili per memorizzare pi√π elementi. Ad esempio, un elenco di articoli di legge:\narticoli = [\"Art. 1\", \"Art. 2\", \"Art. 3\"]\narticoli.append(\"Art. 4\")  # Aggiungi un articolo\nprint(articoli)\n\n\nDizionari\nI dizionari memorizzano dati in coppie chiave-valore. Ad esempio, puoi salvare i dettagli di un fascicolo:\nfascicolo = {\n    \"numero\": \"2024/12345\",\n    \"giudice\": \"Mario Rossi\",\n    \"stato\": \"aperto\"\n}\nprint(fascicolo[\"giudice\"])  # Stampa: Mario Rossi",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Elementi di Python</span>"
    ]
  },
  {
    "objectID": "a1-elementi-di-Python.html#applicazioni-pratiche",
    "href": "a1-elementi-di-Python.html#applicazioni-pratiche",
    "title": "Appendix A ‚Äî Elementi di Python",
    "section": "Applicazioni Pratiche",
    "text": "Applicazioni Pratiche\nCon Python, puoi creare funzioni per automatizzare calcoli giuridici. Ad esempio:\ndef calcola_pena(reato_grave):\n    if reato_grave:\n        return 10  # Anni di reclusione per reato grave\n    else:\n        return 2  # Anni per reati meno gravi\n\npena = calcola_pena(True)\nprint(f\"Anni di reclusione: {pena}\")\nOutput:\nAnni di reclusione: 10\n\nCreazione di Moduli Personalizzati\nPuoi creare file Python con funzioni personalizzate, utili per compiti specifici. Ad esempio, un modulo calcoli_legali.py potrebbe contenere:\ndef calcola_sanzione(sanzione_base, giorni_ritardo, mora=50):\n    return sanzione_base + giorni_ritardo * mora\nE poi importarlo nel tuo programma:\nimport calcoli_legali\n\nsanzione = calcoli_legali.calcola_sanzione(500, 10)\nprint(f\"La sanzione totale √® di {sanzione} euro.\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Elementi di Python</span>"
    ]
  },
  {
    "objectID": "a1-elementi-di-Python.html#conclusione",
    "href": "a1-elementi-di-Python.html#conclusione",
    "title": "Appendix A ‚Äî Elementi di Python",
    "section": "Conclusione",
    "text": "Conclusione\nCon una conoscenza di base di Python, puoi affrontare problemi complessi in modo semplice ed efficiente, rendendo il tuo lavoro legale pi√π rapido e preciso (Foundation 2024).\n\n\n\n\nFoundation, Python Software. 2024. ‚ÄúPython Official Documentation.‚Äù https://docs.python.org/3/.\n\n\nLutz, Mark. 2013. Learning Python. 5th ed. O‚ÄôReilly Media.\n\n\nRossum, Guido Van, and Fred L. Drake. 2016. The Python Language Reference Manual. Python Software Foundation. https://docs.python.org/3/reference/.\n\n\nSrinath, R. 2017. ‚ÄúApplications of Python Programming in Legal Practice.‚Äù Journal of Legal Technology 12: 34‚Äì45.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Elementi di Python</span>"
    ]
  }
]