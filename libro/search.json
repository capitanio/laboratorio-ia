[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratorio di Intelligenza Artificiale",
    "section": "",
    "text": "Prefazione dell’autore\nL’intelligenza artificiale rappresenta una delle tecnologie breakthrough più rilevanti del nostro tempo, capace di incidere in modo profondo su settori tradizionalmente fondati sull’intervento umano e sull’interpretazione, come il diritto. Dall’analisi automatica delle sentenze alla redazione assistita di contratti, dai sistemi predittivi per la valutazione del rischio di recidiva agli strumenti di supporto alla ricerca normativa, l’IA sta entrando nei contesti giuridici con crescente frequenza e rilevanza.\nQuesto volume nasce dall’esigenza di fornire alle studentesse e agli studenti di un corso di laurea in Giurisprudenza una prima alfabetizzazione tecnica e critica rispetto agli strumenti dell’intelligenza artificiale, con particolare riferimento al machine learning e alle sue applicazioni giuridiche. L’approccio è laboratoriale: si parte dai concetti fondamentali, illustrati con chiarezza e rigore, per poi applicarli attraverso esempi concreti in linguaggio Python, oggi uno degli strumenti più diffusi per lo sviluppo di applicazioni intelligenti.\nL’obiettivo non è formare informatici, ma giuristi consapevoli, in grado di comprendere le logiche di funzionamento di un algoritmo, di interrogare criticamente le sue implicazioni normative ed etiche, e di collaborare con competenza a processi di innovazione giuridica. I temi trattati — dalla regressione alla classificazione, dalle reti neurali all’elaborazione del linguaggio naturale — sono accompagnati da casi d’uso ed esercitazioni ispirate al contesto legale, per rendere l’apprendimento significativo e ancorato alla pratica.\nLuciano Capitanio",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefazione dell'autore{.unnumbered}</span>"
    ]
  },
  {
    "objectID": "0-introduzione.html",
    "href": "0-introduzione.html",
    "title": "Introduzione",
    "section": "",
    "text": "L’Intelligenza Artificiale (IA) è una disciplina che si occupa della creazione di macchine e software in grado di esibire comportamenti intelligenti. Questa disciplina è stata definita per la prima volta da John McCarthy nel 1955 come “la scienza e l’ingegneria della costruzione di macchine intelligenti” (McCarthy et al. 1955).\n\n\n\nL’IA è una disciplina di confine\n\n\nL’IA è sia una scienza che una tecnica, un’area di ricerca in cui convergono diverse discipline, tra cui l’informatica, la statistica e le scienze cognitive. L’intelligenza artificiale si distingue principalmente in due categorie: IA debole e IA forte. L’IA debole si riferisce a sistemi progettati per eseguire compiti specifici, come il riconoscimento vocale o la guida autonoma, senza emulare una comprensione generale. L’IA forte, invece, ipotizza sistemi in grado di possedere una coscienza e un’intelligenza paragonabili a quelle umane (Searle 1980). L’IA sta trasformando numerosi settori, tra cui l’assistenza sanitaria, l’istruzione, i trasporti e l’industria. Ad esempio, nel campo sanitario, l’IA supporta i medici nella diagnosi delle malattie e nella creazione di piani di trattamento personalizzati (Jiang et al. 2017). Nel settore giuridico, invece, l’IA viene impiegata per automatizzare l’analisi di documenti legali, come contratti e sentenze, accelerando i processi di revisione e riducendo i costi per studi legali e aziende (Surde and Others 2024). In Italia e in Europa, la regolamentazione dell’IA è un tema centrale per bilanciare innovazione e tutela dei diritti. A livello europeo, l’Unione Europea ha introdotto l’AI Act, un quadro normativo pionieristico che classifica i sistemi di IA in base al rischio, imponendo requisiti più stringenti per applicazioni ad alto rischio, come quelle utilizzate in ambito giudiziario o nella sorveglianza. In Italia, il governo ha adottato strategie nazionali, come il Piano Strategico per l’Intelligenza Artificiale 2022-2024, per promuovere lo sviluppo responsabile dell’IA, con un focus su trasparenza, etica e protezione dei dati personali (European Parliament and Council of the European Union 2024; Governo Italiano 2021). Nonostante i progressi, l’IA presenta diverse sfide, tra cui questioni etiche come la privacy dei dati e l’impatto sull’occupazione, oltre a problemi tecnici legati alla comprensione del linguaggio naturale e allo sviluppo di algoritmi di apprendimento automatico efficaci (Russell and Norvig 2016). In conclusione, l’IA è un campo in rapida evoluzione con il potenziale di rivoluzionare la società. Tuttavia, è essenziale affrontare le sfide etiche e tecniche per garantire che i suoi benefici siano raggiunti in modo sicuro e sostenibile.\n\n\n\n\nEuropean Parliament and Council of the European Union. 2024. “Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 Laying down Harmonised Rules on Artificial Intelligence and Amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU and (EU) 2022/2555 (Artificial Intelligence Act).” 2024/1689. Official Journal of the European Union. Vol. L. European Union. http://data.europa.eu/eli/reg/2024/1689/oj.\n\n\nGoverno Italiano. 2021. “Programma Strategico Per l’intelligenza Artificiale 2022-2024.” Ministero dell’Università e della Ricerca; Ministero dello Sviluppo Economico; Ministro per l’innovazione tecnologica e la transizione digitale. https://assets.innovazione.gov.it/1637777289-programma-strategico-iaweb.pdf.\n\n\nJiang, Feng, Yong Jiang, Hui Zhi, Dong Yang, Hua Li, Shanyu Ma, and Yan Wang. 2017. “Artificial Intelligence in Healthcare: Past, Present and Future.” Stroke and Vascular Neurology.\n\n\nMcCarthy, John, Marvin Minsky, Nathaniel Rochester, and Claude E. Shannon. 1955. A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence.\n\n\nRussell, Stuart, and Peter Norvig. 2016. Artificial Intelligence: A Modern Approach. Pearson.\n\n\nSearle, John R. 1980. “Minds, Brains, and Programs.” Behavioral and Brain Sciences.\n\n\nSurde, Bhushan, and Others. 2024. “The Impact of Artificial Intelligence on Legal Practice: Enhancing Legal Research, Contract Analysis, and Predictive Justice.” International Journal of Advanced Research in Computer and Communication Engineering 13 (1): 1082–85. https://doi.org/10.17148/IJARCCE.2024.131225.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html",
    "href": "1-Turing-vs-Searle.html",
    "title": "2  Turing vs Searle",
    "section": "",
    "text": "2.1 Introduzione\nAlan Turing e John Searle sono due figure centrali nella riflessione sull’intelligenza artificiale e la coscienza. Turing ha introdotto il famoso “Test di Turing” (Turing 1950), concentrandosi sulla capacità delle macchine di simulare il comportamento umano, mentre Searle, con il suo “Argomento della Stanza Cinese”, ha criticato l’idea che una macchina possa davvero comprendere o avere coscienza (Searle 1980).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Turing vs Searle</span>"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html#alan-turing-e-il-test-di-turing",
    "href": "1-Turing-vs-Searle.html#alan-turing-e-il-test-di-turing",
    "title": "2  Turing vs Searle",
    "section": "Alan Turing e il Test di Turing",
    "text": "Alan Turing e il Test di Turing\n\n\n\nImmagine generata da DALL-E del Test di Turing\n\n\nAlan Turing, pioniere dell’informatica, propose il “Test di Turing” nel 1950 come criterio per valutare se una macchina potesse essere considerata intelligente (Turing 1950). Secondo Turing, se un essere umano che comunica con una macchina attraverso uno schermo non riesce a distinguerla da un altro essere umano, allora la macchina può essere considerata intelligente.\nPunti chiave del Test di Turing: - Il test misura la capacità di imitare il comportamento umano, non la comprensione o la coscienza. - Ha ispirato lo sviluppo di chatbot e sistemi di IA conversazionale.\n\n2.1.1 Critiche al Test di Turing\nMolti filosofi e scienziati sostengono che il test non catturi la vera natura dell’intelligenza o della coscienza. John Searle è uno dei principali critici.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Turing vs Searle</span>"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html#john-searle-e-largomento-della-stanza-cinese",
    "href": "1-Turing-vs-Searle.html#john-searle-e-largomento-della-stanza-cinese",
    "title": "2  Turing vs Searle",
    "section": "John Searle e l’Argomento della Stanza Cinese",
    "text": "John Searle e l’Argomento della Stanza Cinese\n\n\n\nImmagine generata da DALL-E del Test della Stanza Cinese\n\n\nJohn Searle propose l’esperimento mentale della “Stanza Cinese” nel 1980 come critica al concetto di IA forte. L’idea è la seguente:\n\nUna persona che non conosce il cinese si trova in una stanza con un manuale di istruzioni che spiega come rispondere ai messaggi scritti in cinese.\nUsando il manuale, la persona può rispondere correttamente ai messaggi senza comprendere realmente il cinese.\nSearle sostiene che le macchine, similmente, possono elaborare simboli senza comprendere il loro significato.\n\nConclusione della Stanza Cinese: - L’elaborazione simbolica non equivale alla comprensione. - Questo pone un limite all’idea che una macchina possa essere veramente intelligente.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Turing vs Searle</span>"
    ]
  },
  {
    "objectID": "1-Turing-vs-Searle.html#conclusioni",
    "href": "1-Turing-vs-Searle.html#conclusioni",
    "title": "2  Turing vs Searle",
    "section": "2.2 Conclusioni",
    "text": "2.2 Conclusioni\nIl confronto tra Turing e Searle evidenzia due prospettive opposte sull’intelligenza artificiale: - Turing vede l’imitazione come un segno sufficiente di intelligenza. - Searle insiste sulla distinzione tra simulazione e comprensione reale.\nQuesto dibattito rimane centrale nella filosofia dell’intelligenza artificiale e continua a ispirare nuove domande e riflessioni.\n\n\n\n\nSearle, John R. 1980. “Minds, Brains, and Programs.” Behavioral and Brain Sciences.\n\n\nTuring, Alan M. 1950. “Computing Machinery and Intelligence.” Mind.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Turing vs Searle</span>"
    ]
  },
  {
    "objectID": "2-1-inferenza-logica.html",
    "href": "2-1-inferenza-logica.html",
    "title": "3  Inferenza Logica",
    "section": "",
    "text": "3.1 Introduzione\nL’inferenza logica è un processo fondamentale nel campo della logica, della matematica e della filosofia, utilizzato per derivare conclusioni a partire da premesse o informazioni date. Questo processo può essere visto come un mezzo per scoprire nuove verità o per confermare la validità di affermazioni esistenti. L’inferenza logica può essere di tre tipi :\nL’inferenza logica è strettamente legata al concetto di validità e di correttezza degli argomenti. Un’argomentazione è valida se la sua struttura logica è tale che, qualora le premesse siano vere, anche la conclusione deve essere vera. Tuttavia, un’argomentazione può essere valida senza essere corretta; per essere corretta, deve avere anche premesse vere. Ad esempio, l’argomentazione “Tutti gli unicorni sono verdi; io possiedo un unicorno; quindi, il mio unicorno è verde” è valida dal punto di vista logico, ma non è corretta perché le premesse non sono vere.\nL’inferenza logica è alla base di molti sistemi di intelligenza artificiale e di calcolo automatico, dove gli algoritmi vengono progettati per inferire nuove informazioni a partire da dati iniziali. Nei sistemi esperti, per esempio, vengono utilizzate regole di inferenza per simulare il processo decisionale umano. In conclusione, l’inferenza logica è uno strumento potente e versatile che permea molte aree del pensiero umano e della tecnologia, consentendo di avanzare nella conoscenza e nella comprensione del mondo che ci circonda.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inferenza Logica</span>"
    ]
  },
  {
    "objectID": "2-1-inferenza-logica.html#introduzione",
    "href": "2-1-inferenza-logica.html#introduzione",
    "title": "3  Inferenza Logica",
    "section": "",
    "text": "inferenza deduttiva : la conclusione deriva necessariamente dalle premesse; se le premesse sono vere, la conclusione non può che essere vera. Un classico esempio di inferenza deduttiva è il sillogismo: “Tutti gli uomini sono mortali; Socrate è un uomo; quindi, Socrate è mortale.” In questo caso, la verità delle premesse garantisce la verità della conclusione.\ninferenza induttiva : partendo da osservazioni specifiche o da una serie di dati, arriva a conclusioni più generali, che non sono necessariamente certe ma probabili. Ad esempio, se si osserva che il sole è sorto ogni giorno, si potrebbe inferire che il sole sorgerà anche domani. Questa forma di inferenza è molto utilizzata nella scienza, dove gli scienziati formulano ipotesi basate su dati osservati e sperimentali.\ninferenza abduttiva : implica la formazione della migliore spiegazione possibile data un insieme di osservazioni. Questo tipo di inferenza è spesso utilizzato nella diagnosi medica, nella ricerca scientifica e nelle indagini criminali, dove si cerca di spiegare i dati osservati nel modo più coerente possibile.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inferenza Logica</span>"
    ]
  },
  {
    "objectID": "2-1-inferenza-logica.html#proposizioni-logiche",
    "href": "2-1-inferenza-logica.html#proposizioni-logiche",
    "title": "3  Inferenza Logica",
    "section": "3.2 Proposizioni Logiche",
    "text": "3.2 Proposizioni Logiche\nLe proposizioni logiche sono dichiarazioni atomiche che possono essere valutate come vere o false. Le proposizioni possono essere combinate utilizzando operatori logici come AND, OR, NOT, IMPLIES, che permettono di costruire regole complesse rappresentate da formule logiche (DeLancey 2017). Ecco alcuni esempi di proposizioni logiche:\n\np: “Il sole è luminoso” (Vero)\nq: “La Luna è fatta di formaggio” (Falso)\nr: “Se piove, allora la strada sarà bagnata” (Condizionale)",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inferenza Logica</span>"
    ]
  },
  {
    "objectID": "2-1-inferenza-logica.html#calcolo-delle-proposizioni-logiche",
    "href": "2-1-inferenza-logica.html#calcolo-delle-proposizioni-logiche",
    "title": "3  Inferenza Logica",
    "section": "3.3 Calcolo delle Proposizioni Logiche",
    "text": "3.3 Calcolo delle Proposizioni Logiche\nLe proposizioni logiche possono essere manipolate utilizzando vari operatori logici che eseguono operazioni specifiche:\n\nCongiunzione (AND): L’operatore AND restituisce vero solo quando entrambe le proposizioni coinvolte sono vere. Ad esempio, se abbiamo due proposizioni p e q, p AND q è vero solo se entrambe p e q sono vere. La cosidetta tabella di verità riportata qui sotto consente di vedere come funziona l’operatore AD.\n\n\nTavola della verità per la congiunzione\n\n\np\nq\np AND q\n\n\n\n\nFalse\nFalse\nFalse\n\n\nFalse\nTrue\nFalse\n\n\nTrue\nFalse\nFalse\n\n\nTrue\nTrue\nTrue\n\n\n\n\nDisgiunzione (OR): L’operatore OR restituisce vero se almeno una delle due proposizioni coinvolte è vera. Ad esempio, p OR q è vero se p è vero oppure se q è vero oppure se entrambi sono veri. La tabella di verità riportata qui sotto consente di vedere come funziona l’operatore OR.\n\n\nTavola della verità per la disgiunzione\n\n\np\nq\np OR q\n\n\n\n\nFalse\nFalse\nFalse\n\n\nFalse\nTrue\nTrue\n\n\nTrue\nFalse\nTrue\n\n\nTrue\nTrue\nTrue\n\n\n\n\nNegazione (NOT - ¬): L’operatore NOT cambia il valore di verità di una proposizione. Ad esempio, ¬p è vero se p è falso e viceversa.\n\n\nTavola della verità per la negazione\n\n\np\n¬p\n\n\n\n\nFalse\nTrue\n\n\nTrue\nFalse\n\n\n\n\nImplicazione (→): L’implicazione è un’operazione logica che collega due proposizioni e stabilisce una relazione di condizionalità. Si rappresenta con il simbolo “→” e si legge come “se… allora”. In un’implicazione del tipo “p → q”, la proposizione p è chiamata l’antecedente e la proposizione q è il conseguente. L’implicazione è falsa solo nel caso in cui l’antecedente è vero e il conseguente è falso. In tutti gli altri casi, l’implicazione è considerata vera. Poiché questa operazione è alla base di molti algoritmi di inferenza, è importante capire come funziona. La tabella di verità riportata qui sotto consente di vedere come funziona l’operatore implicazione.\n\n\nTavola della verità per l’implicazione\n\n\np\nq\np → q\n\n\n\n\nFalse\nFalse\nTrue\n\n\nFalse\nTrue\nTrue\n\n\nTrue\nFalse\nFalse\n\n\nTrue\nTrue\nTrue\n\n\n\nEsempio di Implicazione: supponiamo di avere le seguenti proposizioni: - p: Il sole splende. - q: Faccio una passeggiata.\nL’implicazione che possiamo formulare è: “Se il sole splende, allora faccio una passeggiata”, che si scrive come “p → q”. Dalla tabella della verità, possiamo vedere che in tre dei quattro casi l’implicazione “p → q” è vera. L’unico caso in cui l’implicazione è falsa è quando il sole splende (p è vero) ma non faccio una passeggiata (q è falso).\nQuindi, in base alla logica dell’implicazione, se il sole splende, sto effettivamente facendo una passeggiata o potrei anche non farla (ad eccezione del caso in cui il sole splenda e io non faccia una passeggiata, in cui l’implicazione è falsa).\n\nImplicazione Bilaterale (↔︎): L’implicazione bilaterale è un’operazione logica che stabilisce che due proposizioni sono equivalenti, cioè che entrambe le proposizioni hanno lo stesso valore di verità. Si rappresenta con il simbolo “↔︎” e si legge come “se e solo se”. L’implicazione bilaterale è vera solo quando le proposizioni hanno lo stesso valore di verità, sia entrambe vere che entrambe false.\n\n\nTavola della verità per l’implicazione bilaterale\n\n\np\nq\np ↔︎ q\n\n\n\n\nFalse\nFalse\nTrue\n\n\nFalse\nTrue\nFalse\n\n\nTrue\nFalse\nFalse\n\n\nTrue\nTrue\nTrue\n\n\n\nL’implicazione bilaterale, anche conosciuta come “se e solo se”, è un importante concetto logico che stabilisce che due proposizioni sono logicamente equivalenti, cioè entrambe sono vere o entrambe sono false contemporaneamente.\nEsempio di Implicazione Bilaterale: supponiamo di avere le seguenti proposizioni:\n\np: Oggi è venerdì.\nq: Domani è sabato.\n\nL’implicazione bilaterale tra p e q può essere scritta come p ↔︎ q, che si legge come “Oggi è venerdì se e solo se domani è sabato”.\nDalla tabella di verità, possiamo notare che l’implicazione bilaterale “Oggi è venerdì se e solo se domani è sabato” è vera solo nei casi in cui entrambe le proposizioni sono vere (primo e ultimo caso) o entrambe sono false. Se c’è una discrepanza nelle verità delle proposizioni, l’implicazione bilaterale diventa falsa (secondo e terzo caso).\nQuindi, nel nostro esempio, l’affermazione “Oggi è venerdì se e solo se domani è sabato” è vera solo quando entrambe le proposizioni sono vere o entrambe sono false, evidenziando l’equivalenza logica tra le due proposizioni nel contesto dell’implicazione bilaterale.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inferenza Logica</span>"
    ]
  },
  {
    "objectID": "2-1-inferenza-logica.html#basi-della-conoscenza",
    "href": "2-1-inferenza-logica.html#basi-della-conoscenza",
    "title": "3  Inferenza Logica",
    "section": "3.4 Basi della Conoscenza",
    "text": "3.4 Basi della Conoscenza\nLa base della conoscenza in un agente a inferenza logica è costituita da proposizioni logiche, che sono affermazioni dichiarative che possono essere vere o false. Le proposizioni possono essere atomiche o composte e sono spesso rappresentate utilizzando variabili proposizionali. Queste variabili assumono valori di verità (vero o falso) e vengono combinate tramite operatori logici per formare regole logiche complesse. La base della conoscenza in un sistema logico definisce le relazioni tra le proposizioni e fornisce le fondamenta per il ragionamento e l’inferenza. Un agente a inferenza logica usa la Base della Conoscenza per giungere a conclusioni circa il mondo che la circonda; Per fare ciò ha bisogno di regole di implicazione logica (⊨): Se α ⊨ β, ovvero se α implica logicamente β, in ogni mondo dove α è vera allora β è vera. È diversa dall’implicazione perché non è un connettivo logico ma una relazione che dice che se α è vera allora β è vera e basta! ## Sistemi basati sulla conoscenza\nI sistemi basati sulla conoscenza sono strumenti informatici progettati per emulare il processo decisionale umano attraverso l’utilizzo di una base di conoscenza strutturata. Questi sistemi raccolgono, organizzano e utilizzano informazioni specifiche di un dominio per risolvere problemi complessi che richiedono competenza specialistica. Una componente fondamentale è la base di conoscenza, che contiene fatti, regole ed euristiche rappresentative del sapere umano in un determinato campo. Il motore di inferenza è l’altro elemento chiave: applica regole logiche ai dati presenti nella base di conoscenza per dedurre nuove informazioni o prendere decisioni informate.\n\n\n\nProcesso di creazione e gestione di un sistema basato sulla conoscenza\n\n\nIl processo di creazione di un sistema esperto basato sull’inferenza logica inizia con l’acquisizione della conoscenza, dove gli esperti del dominio collaborano per estrarre informazioni e regole rilevanti. Queste conoscenze vengono poi formalizzate nella rappresentazione della conoscenza, utilizzando strutture come regole if-then, ontologie o reti semantiche, che alimentano la base di conoscenza. Il motore di inferenza viene sviluppato per applicare queste regole logiche ai dati forniti, deducendo nuove informazioni o prendendo decisioni informate. La gestione del sistema include l’aggiornamento continuo della base di conoscenza per riflettere nuove scoperte o cambiamenti nel dominio, nonché la verifica e la validazione del sistema per garantirne l’accuratezza e l’affidabilità. Gli utenti interagiscono con il sistema attraverso un’interfaccia che facilita l’inserimento dei dati e la visualizzazione dei risultati, permettendo anche il feedback per miglioramenti futuri.\nQuesti sistemi trovano applicazione in vari settori, come la medicina, l’ingegneria, la finanza e l’assistenza clienti. Ad esempio, in ambito medico, un sistema basato sulla conoscenza può aiutare nella diagnosi di malattie analizzando sintomi e storie cliniche dei pazienti. L’efficacia di tali sistemi dipende dalla qualità e dall’aggiornamento costante della base di conoscenza, nonché dalla capacità del motore di inferenza di elaborare correttamente le informazioni.\n\n\n\n\n\n\nTip\n\n\n\nI sistemi esperti - Negli anni ’80, l’inferenza logica è stata fondamentale nello sviluppo dei sistemi esperti, strumenti avanzati di intelligenza artificiale progettati per risolvere problemi complessi emulando il ragionamento umano. Due noti prodotti commerciali di quel periodo sono stati MYCIN, un sistema esperto per la diagnosi di infezioni del sangue, e XCON, utilizzato per configurare sistemi di computer VAX di Digital Equipment Corporation. MYCIN e XCON sfruttavano regole di inferenza per elaborare informazioni e fornire raccomandazioni o soluzioni, dimostrando l’efficacia dell’inferenza logica in applicazioni pratiche e commerciali McDermott (1980)\n\n\nUn vantaggio significativo dei sistemi basati sulla conoscenza è la possibilità di conservare e diffondere l’esperienza di esperti, rendendola accessibile a un pubblico più ampio e contribuendo alla standardizzazione delle pratiche. Tuttavia, la creazione e la manutenzione di una base di conoscenza richiedono notevoli risorse e competenze. Con l’avanzamento dell’intelligenza artificiale e dell’apprendimento automatico, questi sistemi continuano a evolversi, integrando nuove tecniche per migliorare l’efficienza, l’accuratezza e la capacità di apprendimento autonomo nelle loro applicazioni.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inferenza Logica</span>"
    ]
  },
  {
    "objectID": "2-1-inferenza-logica.html#sec-lab-inferenza-logica-in-python",
    "href": "2-1-inferenza-logica.html#sec-lab-inferenza-logica-in-python",
    "title": "3  Inferenza Logica",
    "section": "3.5 Laboratorio Python: inferenza logica",
    "text": "3.5 Laboratorio Python: inferenza logica\nIn questo paragrafo, useremo la libreria SymPy dell’ecosistema Python per creare un semplice sistema esperto basato sull’inferenza logica nell’ambito del diritto penale. Questo sistema aiuterà a determinare se determinati comportamenti costituiscono un reato, in base ai fatti noti e alle norme applicabili. Si noti che la libreria SymPy è stata sviluppata per consentire il calcolo simbolico in Python. In questo caso useremo le funzionalità di calcolo simbolico per la rappresentazione della conoscenza e per l’inferenza logica.\n \n(click-ando su questo pulsante aprirete il quaderno all’interno di COLAB di Google dove potrete eseguire il notebook comtenente tutto il codice di questo paragrafo online senza bisogno di avere un ambiente Python sulla vostra macchina.)\n\n3.5.1 Esperimento 1: Semplice applicazione della inferenza logica al Diritto penale\nIl diritto penale si basa su norme che definiscono quali comportamenti sono considerati reati e quali elementi devono essere presenti affinché un’azione sia punibile. Un sistema esperto in questo contesto può aiutare a: - Valutare se un’azione specifica costituisce un reato. - Identificare gli elementi costitutivi del reato. - Fornire una base logica per decisioni legali. Utilizzeremo SymPy per modellare proposizioni logiche, regole legali e per effettuare inferenze.\n\n\n\n\n\n\nCaution\n\n\n\nNota: Assicurati di avere SymPy installato. Altrimenti, installalo da terminale con:\npip install sympy\n\n\nGlossario dei termini usati\n\nFatti: Eventi o comportamenti specifici accaduti, rilevanti per il diritto penale in quanto potenzialmente costituenti reato o circostanze di esclusione della responsabilità.\nReati: Condotte umane attive o omissive, tipiche, antigiuridiche e colpevoli, sanzionate dalla legge penale.\nElementi Costitutivi del Reato: Presupposti oggettivi e soggettivi richiesti dalla norma incriminatrice per configurare un fatto come reato, tra cui la condotta (azione o omissione), il dolo o la colpa, il nesso di causalità e l’assenza di cause di giustificazione.\nRegole Legali: Norme giuridiche che stabiliscono i presupposti di fatto e di diritto in presenza dei quali un comportamento umano è qualificabile come reato e punibile mediante una sanzione.\n\nModellazione con SymPy\n\n# **Passo 1: Importare i Moduli Necessari** \n# Importiamo i moduli necessari da SymPy per \n# lavorare con la logica proposizionale.\n\nfrom sympy import symbols\nfrom sympy.logic.boolalg import And, Or, Not, Implies, Equivalent\nfrom sympy.logic.inference import satisfiable\n\n# **Passo 2: Definire le Proposizioni Logiche** Definiamo le variabili che rappresentano \n# i fatti e gli elementi costitutivi del reato.\n\n# Fatti\nAzione, Intenzione, NessoCausale = symbols('Azione Intenzione NessoCausale')\n\n# Reato\nOmicidio = symbols('Omicidio')\n\n#**Passo 3: Definire le Regole che discendono dal Codice Penale** Ad esempio, secondo il codice \n# penale, l'omicidio richiede: \n# - **Azione**: Causare la morte di una persona. \n# - **Intenzione**: Volontà di causare la morte (dolo). \n# - **Nesso Causale**: La morte è conseguenza dell'azione. Definiamo la regola:\n\n# Regola: \n# Se c'è Azione, Intenzione e Nesso Causale, allora si configura l'Omicidio\n# regola_omicidio: And(Azione, Intenzione, NessoCausale) -&gt; Omicidio\nregola_omicidio = Implies(And(Azione, Intenzione, NessoCausale), Omicidio)\n\n# **Passo 4: Definire i Fatti Noti** \n# Supponiamo di avere i seguenti fatti: \n# - Una persona ha compiuto un'azione che ha causato la morte di un'altra. \n# - Aveva l'intenzione di causare la morte. \n# - Esiste un nesso causale tra l'azione e la morte.\n\nfatto1 = Azione  # L'azione di causare la morte\nfatto2 = Intenzione  # Intenzione di causare la morte\nfatto3 = NessoCausale  # La morte è conseguenza dell'azione\n\n# **Passo 5: Creare la Base di Conoscenza** \n# Combiniamo fatti e regole:\n# Base di conoscenza\nbase_conoscenza = And(fatto1, fatto2, fatto3, regola_omicidio)\n\n# **Passo 6: Inferenza Logica** \n# Verifichiamo se, sulla base dei fatti e delle regole, possiamo concludere che si \n# tratta di omicidio.\n# Verifichiamo se Omicidio è deducibile\nipotesi = And(base_conoscenza, Not(Omicidio))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura il reato di omicidio.\")\nelse:\n    print(\"Non possiamo concludere che si tratti di omicidio.\")\n\nSi configura il reato di omicidio.\n\n\n\n\n3.5.2 Esperimento 2: Mancanza di intenzione\nCaso con Mancanza di Intenzione Supponiamo che l’intenzione non sia presente (ad esempio, si tratta di omicidio colposo).\n\n# Fatti noti senza Intenzione\nfatto1 = Azione\nfatto2 = Not(Intenzione)  # Mancanza di intenzione\nfatto3 = NessoCausale\n\n# Base di conoscenza aggiornata\nbase_conoscenza = And(fatto1, fatto2, fatto3, regola_omicidio)\n# **Inferenza per Omicidio**\n# Inferenza\nipotesi = And(base_conoscenza, Not(Omicidio))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura il reato di omicidio.\")\nelse:\n    print(\"Non possiamo concludere che si tratti di omicidio.\")\n\nNon possiamo concludere che si tratti di omicidio.\n\n\n\n\n3.5.3 Esperimento 3: Omicidio Colposo\nAggiungiamo la regola per l’omicidio colposo:\n\n# Definizione del reato di Omicidio Colposo\nOmicidioColposo = symbols('OmicidioColposo')\n\n# Regola per Omicidio Colposo: \n# Azione e Nesso Causale senza Intenzione\n# regola_omicidio_colposo: And(Azione, Not(Intenzione), NessoCausale) -&gt; OmicidioColposo\nregola_omicidio_colposo = Implies(And(Azione, Not(Intenzione), NessoCausale), OmicidioColposo)\n\n# Aggiorniamo la base di conoscenza\nbase_conoscenza = And(fatto1, fatto2, fatto3, regola_omicidio, regola_omicidio_colposo)\n\n# **Inferenza per Omicidio Colposo**\n# Verifichiamo se si configura l'Omicidio Colposo\nipotesi = And(base_conoscenza, Not(OmicidioColposo))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura il reato di omicidio colposo.\")\nelse:\n    print(\"Non possiamo concludere che si tratti di omicidio colposo.\")\n\nSi configura il reato di omicidio colposo.\n\n\nRicorda che questo è un modello semplificato e che il diritto penale è complesso e richiede una comprensione approfondita per essere modellato accuratamente. Questo sistema può essere un punto di partenza per sviluppi più avanzati e per esplorare l’intersezione tra intelligenza artificiale e diritto. Esplorazione che il lettore è invitato a sviluppare ulteriormente svolgendo gli esercizi proposti.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inferenza Logica</span>"
    ]
  },
  {
    "objectID": "2-1-inferenza-logica.html#esercizi",
    "href": "2-1-inferenza-logica.html#esercizi",
    "title": "3  Inferenza Logica",
    "section": "3.6 Esercizi",
    "text": "3.6 Esercizi\n\n3.6.1 Esercizio 1: Legge di De Morgan\nVerifica la seguente uguaglianza logica (Legge di De Morgan) usando le tavole della verità delle funzioni AND, NOT (¬) e OR :\n¬(A OR B) = ¬A AND ¬B\n\n\n3.6.2 Esercizio 2: semplice sistema esperto per valutare la legittima difesa\nImplementa un sistema esperto per determinare se un caso si configura come legittima difesa utilizzando la logica proposizionale con SymPy.\nLa legittima difesa è ammissibile quando si verificano le seguenti condizioni:\n\nEsistenza di un pericolo attuale: Il pericolo deve essere immediato e concreto.\nMinaccia ingiusta: La minaccia deve essere illegittima o non giustificata.\nNecessità di difendersi: Deve essere impossibile evitare il pericolo in altro modo.\nProporzionalità della difesa: La difesa deve essere adeguata e commisurata alla minaccia.\n\nLa codifica in Python, usando la libreria SymPy, potrebbe essere la seguente:\n\nfrom sympy.logic.boolalg import And, Or, Not, Implies\nfrom sympy import symbols, satisfiable\n\n# Definizione dei simboli\nPericoloAttuale = symbols('PericoloAttuale')\nMinacciaIngiusta = symbols('MinacciaIngiusta')\nNecessitaDifesa = symbols('NecessitaDifesa')\nProporzionalitaDifesa = symbols('ProporzionalitaDifesa')\nLegittimaDifesa = symbols('LegittimaDifesa')\n\n# Definizione della regola per la legittima difesa\nregola_legittima_difesa = Implies(\n    And(PericoloAttuale, MinacciaIngiusta, NecessitaDifesa, ProporzionalitaDifesa),\n    LegittimaDifesa\n)\n\n# Caso di studio: \n# Una persona reagisce a un tentativo di rapina armata con una spinta che fa cadere l'aggressore\nfatto1 = PericoloAttuale      # C'è un rapinatore armato\nfatto2 = MinacciaIngiusta     # La minaccia è ingiusta\nfatto3 = NecessitaDifesa      # Non c'è via di fuga\nfatto4 = ProporzionalitaDifesa # La spinta è proporzionata rispetto alla minaccia\n\n# Base di conoscenza\nbase_conoscenza = And(fatto1, fatto2, fatto3, fatto4, regola_legittima_difesa)\n\n# Verifica se si configura la legittima difesa\nipotesi = And(base_conoscenza, Not(LegittimaDifesa))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura la legittima difesa.\")\nelse:\n    print(\"Non si configura la legittima difesa.\")\n\nSi configura la legittima difesa.\n\n\nAggiungi una nuova regola per l’eccesso colposo di legittima difesa e Implementa l’inferenza per verificare se si configura l’eccesso di legittima difesa\n\n\n3.6.3 Esercizio 3: semplice sistema esperto per valutare la premeditazione\nLa base di consoscenza da modificare è la seguente codificata in Python, usando la libreria SymPy:\n\nfrom sympy.logic.boolalg import And, Or, Not, Implies\nfrom sympy import symbols, satisfiable\n\n# Definizione dei simboli\nPianificazione = symbols('Pianificazione')\nAcquistoStrumenti = symbols('AcquistoStrumenti')\nAppostamento = symbols('Appostamento')\nSceltaVittima = symbols('SceltaVittima')\nPremeditazione = symbols('Premeditazione')\n\n# Definizione della regola per la premeditazione\nregola_premeditazione = Implies(\n    And(Pianificazione, AcquistoStrumenti, Appostamento, SceltaVittima),\n    Premeditazione\n)\n\n# Caso di studio:\n# Un individuo ha commesso un crimine dopo aver:\nfatto1 = Pianificazione      # Pianificato l'azione per settimane\nfatto2 = AcquistoStrumenti  # Acquistato gli strumenti necessari\nfatto3 = Appostamento       # Studiato le abitudini della vittima\nfatto4 = SceltaVittima      # Scelto specificamente la vittima\n\n# Base di conoscenza\nbase_conoscenza = And(fatto1, fatto2, fatto3, fatto4, regola_premeditazione)\n\n# Verifica se si configura la premeditazione\nipotesi = And(base_conoscenza, Not(Premeditazione))\nrisultato = satisfiable(ipotesi)\n\nif not risultato:\n    print(\"Si configura la premeditazione.\")\nelse:\n    print(\"Non si configura la premeditazione.\")\n\nSi configura la premeditazione.\n\n\nAggiungi una nuova regola per distinguere tra premeditazione e dolo eventuale. Implementa l’inferenza per verificare la presenza di circostanze aggravanti\n\n\n\n\nBuchanan, Bruce G., and Edward H. Shortliffe. 1984. Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. Addison-Wesley.\n\n\nDeLancey, Craig. 2017. A Concise Introduction to Logic. Open SUNY. https://open.umn.edu/opentextbooks/textbooks/452.\n\n\nMcDermott, John P. 1980. “RI: An Expert in the Computer Systems Domain.” In AAAI Conference on Artificial Intelligence. https://api.semanticscholar.org/CorpusID:13902711.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inferenza Logica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html",
    "href": "2-2-inferenza-probabilistica.html",
    "title": "4  Inferenza Probabilistica",
    "section": "",
    "text": "4.1 Introduzione\nL’inferenza probabilistica utilizza la teoria delle probabilità per fare previsioni o inferenze basate su dati incompleti o incerti. Questo tipo di inferenza è particolarmente utile in tutti i contesti dove le informazioni possono essere incomplete o incerte.\nL’incertezza può derivare da diversi fattori, come la natura incompleta delle informazioni, la presenza di rumore nei dati, l’aleatorietà degli eventi o la complessità dei problemi da affrontare. Gli agenti artificiali, dotati di capacità di ragionamento probabilistico e di inferenza, sono in grado di valutare le conseguenze di diverse azioni in base alle probabilità associate agli eventi futuri e agli esiti attesi. In pratica, ciò significa che invece di avere risposte binarie (vero o falso), lavoriamo con probabilità, cioè con il grado di certezza o incertezza riguardo a una determinata affermazione o evento.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#teoria-delle-probabilità",
    "href": "2-2-inferenza-probabilistica.html#teoria-delle-probabilità",
    "title": "4  Inferenza Probabilistica",
    "section": "4.2 Teoria delle probabilità",
    "text": "4.2 Teoria delle probabilità\nIl calcolo delle probabilità è una branca della matematica che misura e analizza la probabilità di eventi casuali. La probabilità rappresenta numericamente la possibilità che un evento specifico si verifichi.\n\n“Il concetto di probabilità è il più importante della scienza moderna, soprattutto perché nessuno ha la più pallida idea del suo significato.” (Bertrand Russel) (Russell 1972).\n\nLa teoria della probabilità assume la stessa assunzione ontologica della logica:\n\ni fatti del mondo sono: veri o falsi (con una certa probabilità);\nOgni possibile situazione in cui si trova il nostro agente è un mondo µ;\n\nAd esempio nel caso del gioco del Lotto, per la singola estrazione ci possono essere 90 mondi, uno per ogni numero che può essere estratto.\nOgni mondo µ è un insieme di fatti:\n\nfatti veri (V);\nfatti falsi (F);\nfatti incerti (I)\n\nTale teoria può essere formulata in diversi modi a seconda del tipo di assunzioni iniziali che si utilizzano. In questo testo si utilizza la teoria della probabilità basata sui cosiddetti assiomi di Kolmogorov e per questo detta Teoria Assiomatica della Probabilità(Kolmogorov 1933).\nQuesti assiomi forniscono una struttura matematica rigorosa per la teoria delle probabilità, consentendo di calcolare le probabilità di eventi complessi a partire dalle probabilità di eventi più semplici:\n\nPrimo Assioma (Non-negatività): La probabilità di un evento è sempre un numero reale non negativo:\n\nP(A)≥0 per ogni evento A. Per rappresentare la probabilità di un certo mondo si usa il simbolo P(µ), 0 &lt;= P(µ) &lt;= 1\nP(µ) = 0 significa che il mondo µ non ha nessuna possibilità di verificarsi. Ad esempio la probabilità che al lotto venga estratto il numero 0 (zero)\nP(µ) = 1 significa che il mondo µ è certo. Ad esempio la probabilità che il risultato di una estrazione sia minore o uguale a 90 è 1. Più è «grande» P(µ) è più è verosimile che si verifichi il mondo µ.\n\nSecondo Assioma (Normalizzazione) : La somma delle probabilità di tutti gli eventi possibili nello spazio campione è uguale a 1: P(S) = 1, dove S rappresenta lo spazio campione. Ad esempio, la somma delle probabilità di estrazione di tutti i numeri del lotto è pari a 1\nTerzo Assioma (Additività) : Se A1, A2, A3, … sono eventi mutuamente esclusivi (cioè non possono accadere simultaneamente), allora la probabilità dell’unione di questi eventi è uguale alla somma delle loro probabilità individuarie: P(A1 ∪ A2 ∪ A3 ∪ …) = P(A1) + P(A2) + P(A3) + … Ad esempio, la probabilità di di ottenere un numero pari nel lancio di un dado è data dalla somma delle probabilità di ottenere un 2, un 4 e un 6: P(pari) = P(2) + P(4) + P(6). ​",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#calcolo-della-probabilità-incondizionata-o-a-priori",
    "href": "2-2-inferenza-probabilistica.html#calcolo-della-probabilità-incondizionata-o-a-priori",
    "title": "4  Inferenza Probabilistica",
    "section": "4.3 Calcolo della probabilità incondizionata o a priori",
    "text": "4.3 Calcolo della probabilità incondizionata o a priori\ncalcolo della probabilità di estrazione di un numero x al lotto Usando i tre assiomi di Kolmogorov : si può calcolare la probabilità di estrazione di un numero x al lotto nel seguente modo:\n\nDal primo assioma si ha che P(x) &gt;= 0.\nDal secondo assioma si ha che la somma di tutti i P(x), con x che va da 1 a 90, è pari a 1.\nDal terzo si evince che essendo le probabilità di estrazione di un numero x uguale a quella di estrarre un numero y, con x diverso da y, si ha che la probabilità di estrarre un numero x è pari a 1/90.\n\ncalcolo della probabilità del risultato x nel lancio di un dado Nel lancio di un dado a 6 facce: la probabilità P(n) di ottenere il numero n è P(n) = 1/6 perché all’esito del lancio tutte le facce del dado hanno uguale probabilità.\ncalcolo della probabilità del risultato nel lancio di due dadi : Nell’esito del lancio di due dadi, dobbiamo considerare che i mondi possibili ed equiprobabili sono 6x6=36 e quindi la probabilità di uno di questi mondi è 1/36.\ncalcolo della probabilità del risultato x come somma dei valori nel lancio di due dadi : Nell’esito del lancio di due dadi, se vogliamo calcolare la probabilità che esca un certo valore x come somma dei valori dei due dadi dobbiamo considerare che i valori possibili (da 2 a 12) non sono equiprobabili. Infatti, per esempio, la probabilità di ottenere 2 è 1/36, mentre la probabilità di ottenere 7 è 6/36. Per calcolare la probabilità del valore x è sufficiente contare quanti sono i mondi in cui il valore x si ottiene come somma dei valori dei due dadi e poi dividere per il numero totale di mondi possibili. I possibili risultati del lancio di due dadi sono 36 :\n\nSomma dei valori ne lancio di due dadi\n\n\n+\n1\n2\n3\n4\n5\n6\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n2\n3\n4\n5\n6\n7\n8\n\n\n3\n4\n5\n6\n7\n8\n9\n\n\n4\n5\n6\n7\n8\n9\n10\n\n\n5\n6\n7\n8\n9\n10\n11\n\n\n6\n7\n8\n9\n10\n11\n12\n\n\n\nLa probabilità di ottenere 2 è data dal numero di esiti favorevoli al risultato 2, in questo caso è solo uno, diviso il numero totale di esiti possibili, in questo caso 36. La possibilità di ottenere 3 è data dal numero di esiti favorevoli al risultato 3, in questo caso sono 2, diviso il numero totale di esiti possibili, in questo caso 36. Le probabilità di ottenere 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 sono le seguenti:\n\nP(2)=1/36\nP(3)=2/36\nP(4)=3/36\nP(5)=4/36\nP(6)=5/36\nP(7)=6/36\nP(8)=5/36\nP(9)=4/36\nP(10)=3/36\nP(11)=2/36\nP(12)=1/36",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#variabili-aleatorie",
    "href": "2-2-inferenza-probabilistica.html#variabili-aleatorie",
    "title": "4  Inferenza Probabilistica",
    "section": "4.4 Variabili aleatorie",
    "text": "4.4 Variabili aleatorie\nUna variabile aleatoria nel calcolo delle probabilità è una variabile che può assumere uno dei possibili valori in un certo dominio:\n\nLa variabile lancio nel lancio di un dado può assumere uno dei valori nel dominio {1,2,3,4,5,6}\nLa variabile sentenza nel processo penale può assumere uno dei valori nel dominio {«Non luogo a procedere», «Proscioglimento», «Condanna»}\nLa variabile diagnosi in campo medico può assumere uno dei valori nel dominio {«Malattia», «Non malattia»}.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#distribuzioni-di-probabilità",
    "href": "2-2-inferenza-probabilistica.html#distribuzioni-di-probabilità",
    "title": "4  Inferenza Probabilistica",
    "section": "4.5 Distribuzioni di probabilità",
    "text": "4.5 Distribuzioni di probabilità\nle distribuzioni di probabilità sono funzioni che descrivono la probabilità di ogni possibile valore di una variabile aleatoria. Ad esempio, la distribuzione di probabilità della variabile aleatoria “sentenza” nel processo penale può essere rappresentata come segue: P(sentenza) = {0.1, 0.1, 0.8}. Nel seguito vedremo alcune distribuzioni di probabilità notevoli.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#probabilità-congiunta",
    "href": "2-2-inferenza-probabilistica.html#probabilità-congiunta",
    "title": "4  Inferenza Probabilistica",
    "section": "4.6 Probabilità congiunta",
    "text": "4.6 Probabilità congiunta\nLa probabilità congiunta è la probabilità che due eventi si verifichino contemporaneamente. Ad esempio, la probabilità che un processo penale porti a una condanna e che il condannato sia colpevole è data dalla probabilità congiunta di questi due eventi. Oppure, in ambito medico, la probabilità che un paziente abbia una certa patologia e che il test diagnostico sia positivo è data dalla probabilità congiunta di questi due eventi. Oppure, in ambito metereologico, la probabilità che sia nuvolo e che piova è la probabilità congiunta di questi due eventi:\nprobabilità che sia nuvoloso:\n\n\n\n\nnuvoloso\n¬nuvoloso\n\n\n\n\nP(n)\n0,7\n0,3\n\n\n\nprobabilità che piova:\n\n\n\n\npiove\n¬piove\n\n\n\n\nP(p)\n0,2\n0,8\n\n\n\nprobabilità che sia nuvoloso e piova:\n\n\n\nP(p,n)\nnuvoloso\n¬nuvoloso\n\n\n\n\npiove\n0,55\n0,05\n\n\n¬piove\n0,15\n0,25",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#indipendenza-delle-variabili-aleatorie",
    "href": "2-2-inferenza-probabilistica.html#indipendenza-delle-variabili-aleatorie",
    "title": "4  Inferenza Probabilistica",
    "section": "4.7 Indipendenza delle variabili aleatorie",
    "text": "4.7 Indipendenza delle variabili aleatorie\nL’indipendenza di due eventi indica che il verificarsi di uno non influenza il verificarsi dell’altro. Ad esempio: Lancio di due dadi. Il lancio del primo non influenza il secondo; Il contrario, la dipendenza, indica che il verificarsi di uno influenza il verificarsi dell’altro. Nel caso in cui due variabili aleatorie siano indipendenti si ha la seguente proprietà:\nP(a AND b)=P(a)*P(b)",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#negazione",
    "href": "2-2-inferenza-probabilistica.html#negazione",
    "title": "4  Inferenza Probabilistica",
    "section": "4.8 Negazione",
    "text": "4.8 Negazione\nLa negazione di un evento è l’evento che si verifica quando l’evento originale non si verifica. Ad esempio, la negazione dell’evento “piove” è “non piove”. Oppure, nel lancio di un dado la negazione dell’evento “esce il valore 1” è “esce il valore 2 o 3 o 4 o 5 o 6”.\nSe la probabilità che un evento è α, la probabilità che l’evento non si verifichi è 1 - α.\nP(A) = α, allora P(¬A) = 1 - α",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#inclusione",
    "href": "2-2-inferenza-probabilistica.html#inclusione",
    "title": "4  Inferenza Probabilistica",
    "section": "4.9 Inclusione",
    "text": "4.9 Inclusione\nLa probabilità che si verifichi l’evento a o l’evento b è uguale alla somma delle probabilità dei due eventi meno la probabilità congiunta:\nP(a OR b) = P(a) + P(b) - P(a AND b).\nSi noti che se gli eventi sono incompatibili la probabilità congiunta è nulla!",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#marginalizzazione",
    "href": "2-2-inferenza-probabilistica.html#marginalizzazione",
    "title": "4  Inferenza Probabilistica",
    "section": "4.10 Marginalizzazione",
    "text": "4.10 Marginalizzazione\nLa marginalizzazione è una tecnica statistica utilizzata per calcolare la probabilità complessiva di un evento integrando o sommando le probabilità congiunte rispetto a un insieme di stati possibili. Ad esempio, consideriamo l’evento a (un imputato è condannato) e gli eventi mutuamente esclusivi b (l’imputato è colpevole) e ¬b (l’imputato non è colpevole). La probabilità totale di a si calcola come:\nP(a) = P(a, b) + P(a, ¬b)\ndove P(a, b) è la probabilità che a si verifichi dato che b si verifica, e P(a, ¬b) è la probabilità che a si verifichi dato che ¬b si verifica.\nQuesta somma considera entrambi gli stati possibili del mondo (b e ¬b) per calcolare la probabilità totale di condanna. Poiché b e ¬b sono mutuamente esclusivi, le loro probabilità possono essere sommate senza sovrapposizioni.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#probabilità-condizionata",
    "href": "2-2-inferenza-probabilistica.html#probabilità-condizionata",
    "title": "4  Inferenza Probabilistica",
    "section": "4.11 probabilità condizionata",
    "text": "4.11 probabilità condizionata\nFin qui abbiamo visto casi in cui il singolo evento non era condizionato da altro evento:\n\nPrima estrazione del lotto;\nLancio di uno o due dadi;\n\nCosa succede alla probabilità quando l’avverarsi di una proposizione è condizionata all’avverarsi di un’altra proposizione?\nAd esempio, la probabilità che un imputato sia condannato dato che è colpevole è diversa dalla probabilità che un imputato sia condannato.\nLa probabilità condizionata è la probabilità che un evento si verifichi dato che un altro evento si è verificato.\nÈ possibile fare inferenze a proposito della probabilità di una proposizione ignota A, data la prova B, calcolando P(A/B) (probabilità di A dato che tutto ciò che sappiamo è B) (inferenza probabilistica)\nUn’interrogazione ad un sistema di ragionamento probabilistico chiederà di calcolare il valore di una particolare probabilità condizionata.\nP(a|b) = probabilità dell’evento a dato che noi sappiamo che l’evento b si è verificato. Oppure, “la probabilità di a dato b”.\nLa formula per calcolare la probabilità condizionata di a dato b è la seguente:\n\\[\nP(a|b) =𝑃(a,b)/𝑃(𝑏);\n\\]\n“siamo interessati agli eventi dove a e b sono vere, ma solo nei mondi dove b è vera!” Dalla formula precedente discendono immediatamente le seguenti due formule per il calcolo della probabilità congiunta:\n\\[\nP(a,b)=P(b)P(a|b);\n\\] \\[\nP(a,b)=P(a)P(b|a);\n\\]",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#condizionamento",
    "href": "2-2-inferenza-probabilistica.html#condizionamento",
    "title": "4  Inferenza Probabilistica",
    "section": "4.12 Condizionamento",
    "text": "4.12 Condizionamento\nIl condizionamento discende immediatamente dalla marginalizzazione. La probabilità che si verifichi a è data dalla marginalizzazione della probabilità congiunta di questi due eventi.\n\\[\nP(a) = P(a/b)P(b) + P(a/¬b)P(¬b).\n\\]\nLa probabilità che si verifichi b è disgiunta dalla probabilità che si verifichi ¬b. Quindi, quando si verifica a si ha b oppure ¬b ma non entrambi quindi se sommo le probabilità P(a, b) + P(a,¬b) ottengo P(a).",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#laboratorio-python-inferenza-probabilistica",
    "href": "2-2-inferenza-probabilistica.html#laboratorio-python-inferenza-probabilistica",
    "title": "4  Inferenza Probabilistica",
    "section": "4.13 Laboratorio Python: inferenza probabilistica",
    "text": "4.13 Laboratorio Python: inferenza probabilistica\n\n4.13.1 Esperimento 1: Variabili aleatorie\nNell’inferenza probabilistica si è interessati alla probabilità che una certa variabile aleatoria assuma un certo valore. Ad esempio, in un determinato processo penale si potrebbe avere:\n\nP(sentenza = «Non luogo a procedere») = 0,1\nP(sentenza = «Proscioglimento») = 0,1\nP(sentenza = «Condanna») = 0,8\n\nPer codificare la variabile aleatoria “sentenza” in Python, si può utilizzare ad esempio la struttura dati dizionario che mappa i possibili esiti (“Non luogo a procedere”, “Proscioglimento”, “Condanna”) ai rispettivi valori numerici di probabilità. Ecco un esempio di come si potrebbe codificare la variabile aleatoria “sentenza” in Python utilizzando un dizionario:\n\n# Definizione della variabile aleatoria sentenza con i suoi possibili valori\nsentenza = {\n    \"Non luogo a procedere\": 0.128, # probabilità del 12.8% di non luogo a procedere\n    \"Proscioglimento\": 0.548,       # probabilità del 54.8% di proscioglimento\n    \"Condanna\": 0.324               # probabilità del 32.4% di condanna\n}\nsomma = 0\nfor esito, probabilita in sentenza.items():\n    print(f\"La probabilità di '{esito}' è: {probabilita}\")\n    somma = somma + probabilita\nprint(\" la somma delle probabilità è pari a \", somma)\n\nLa probabilità di 'Non luogo a procedere' è: 0.128\nLa probabilità di 'Proscioglimento' è: 0.548\nLa probabilità di 'Condanna' è: 0.324\n la somma delle probabilità è pari a  1.0\n\n\n\n\n4.13.2 Esperimento 2: Probabilità condizionate\nPosto che si hanno le seguenti variabili aleatorie: - a = condanna - b = prova schiacciante\ne che si hanno le seguenti informazioni raccolte in un contesto giuridico penale:\n\nP(a|b) = 0.95\nP(a|¬b) = 0.2\nP(b) = 0.3\n\nUtilizziamo la formula di condizionamento per calcolare la probabilità di condanna:\nP(a)= P(a|b)P(b) + P(a|¬b)P(¬b);\nLa codifica in Python è la seguente:\n\nPa_cond_b    = 0.95\nPa_cond_nonb = 0.2\nPb = 0.3\nPnonb = 1 - Pb\nPa = Pa_cond_b * Pb + Pa_cond_nonb * Pnonb\nprint(f\"La probabilità che un imputato sia colpevole dato che ci sono prove schiaccianti è: {Pa}\")\n\nLa probabilità che un imputato sia colpevole dato che ci sono prove schiaccianti è: 0.42499999999999993\n\n\n\n\n4.13.3 Esperimento 3: Probabilità congiunta\nSupponiamo di avere le seguenti variabili aleatorie: - a = condanna - b = prova schiacciante\ne che si hanno le seguenti informazioni raccolte in un contesto giuridico penale: - P(a) = 0.8 - P(b) = 0.3 - P(a|b) = 0.95\nPer calcolare la probabilità congiunta di a,b si utilizza la formula: P(a,b) = P(a|b)P(b) La codifica in Python è la seguente:\n\nPa = 0.8\nPb = 0.3\nPa_cond_b = 0.95\nPab = Pa_cond_b * Pb\nprint(f\"La probabilità congiunta di a,b è: {Pab}\")\n\nLa probabilità congiunta di a,b è: 0.285",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-2-inferenza-probabilistica.html#esercizi",
    "href": "2-2-inferenza-probabilistica.html#esercizi",
    "title": "4  Inferenza Probabilistica",
    "section": "4.14 Esercizi",
    "text": "4.14 Esercizi\n\n4.14.1 Esercizio 1: saturazione di una variabile aleatoria\nConsideriamo l’evento a (un imputato è condannato) e gli eventi mutuamente esclusivi b (l’imputato è colpevole) e ¬b (l’imputato non è colpevole). Supponiamo di avere i seguenti valori:\n\nP(a,b) = 0.9\nP(a,¬b) = 0.2\n\nSi calocoli la probabilità di essere condannato P(a).\n\n\n4.14.2 Esercizio 2: probabilità condizionata\nI risultati che si ottengono dall’esperimento di lancio di un dado sono i seguenti:\n\nLancio di due dadi\n\n\n+\n1\n2\n3\n4\n5\n6\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n2\n3\n4\n5\n6\n7\n8\n\n\n3\n4\n5\n6\n7\n8\n9\n\n\n4\n5\n6\n7\n8\n9\n10\n\n\n5\n6\n7\n8\n9\n10\n11\n\n\n6\n7\n8\n9\n10\n11\n12\n\n\n\nQual è la probabilità che si ottenga una somma pari 9 lanciando due dadi se il primo dado è 6, P(9/6)?\n\nSi calcoli tale probabilità condizionata utilizzando la definizione di probabilità condizionata : P(a|b) = P(a,b)/P(b).\nSi ripeta il calcolo applicando la definizione di probabilità. Ovvero, la probabilità di un certo evento è data dal rapporto tra il numero di casi favorevoli e il numero di casi possibili.\n\n\n\n4.14.3 Esercizio 3: probabilità congiunta\nSupponiamo di avere raccolto informazioni su 1.000 casi penali. Per ogni caso, sono state raccolte le seguenti informazioni:\n\nAlibi del sospettato (Sì/No)\nTestimone oculare presente (Sì/No)\nCondanna del sospettato (Sì/No)\n\nIl dataset (l’insieme dei dati raccolti) è il seguente:\n\n\n\nAlibi\nTestimone Oculare\nCondanna\nNumero di Casi\n\n\n\n\nSì\nSì\nSì\n50\n\n\nSì\nSì\nNo\n20\n\n\nSì\nNo\nSì\n30\n\n\nSì\nNo\nNo\n100\n\n\nNo\nSì\nSì\n200\n\n\nNo\nSì\nNo\n50\n\n\nNo\nNo\nSì\n150\n\n\nNo\nNo\nNo\n400\n\n\ntotale\n-\n-\n1.000\n\n\n\nSi calcoli:\n\nla probabilità che un sospettato sia condannato dato che non ha un alibi e c’è un testimone oculare.\nla probabilità che ci sia un testimone oculare dato che il sospettato è stato condannato.\n\n\n\n\n\nKolmogorov, Andrey Nikolaevich. 1933. Grundbegriffe Der Wahrscheinlichkeitsrechnung. Springer.\n\n\nRussell, Bertrand. 1972. An Inquiry into Meaning and Truth. Routledge.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferenza Probabilistica</span>"
    ]
  },
  {
    "objectID": "2-3-inferenza-bayesiana.html",
    "href": "2-3-inferenza-bayesiana.html",
    "title": "5  Inferenza Bayesiana",
    "section": "",
    "text": "5.1 Introduzione\nIl Teorema di Bayes, formalizzato dal reverendo Thomas Bayes nel XVIII secolo, è uno strumento fondamentale nell’ambito della statistica e dell’intelligenza artificiale che permette di aggiornare le nostre credenze riguardo ad un’ipotesi sulla base di nuove evidenze. Le tecniche di inferenza basate su questo teorema sono ampiamente utilizzate in diversi campi, dall’analisi dei dati alla diagnostica medica, dalla finanza alla progettazione di algoritmi di machine learning.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "2-3-inferenza-bayesiana.html#introduzione",
    "href": "2-3-inferenza-bayesiana.html#introduzione",
    "title": "5  Inferenza Bayesiana",
    "section": "",
    "text": "“Mr. Bayes … design … was to find out a method by which we might judge concerning the probability that an event has to happen, in dato circumstances, upon supposition that we know nothing concerning it but that, under the same circumstances, it has happened a certain number of times, and failed a certain other number of times.” - (Richard Price, presentando lo scritto dell’amico Thomas Bayes alla Royal Society of London)",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "2-3-inferenza-bayesiana.html#il-teorema-di-bayes",
    "href": "2-3-inferenza-bayesiana.html#il-teorema-di-bayes",
    "title": "5  Inferenza Bayesiana",
    "section": "5.2 Il Teorema di Bayes",
    "text": "5.2 Il Teorema di Bayes\nIl Teorema di Bayes fornisce un modo per calcolare la probabilità condizionata di un’ipotesi data l’evidenza osservata. Formalmente, il teorema può essere espresso come:\n\\[\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\]\nDove:\n\nP(A|B) è la probabilità dell’ipotesi A dato l’evidenza B.\nP(B|A) è la probabilità dell’evidenza B dato l’ipotesi A.\nP(A) è la probabilità a priori dell’ipotesi A.\nP(B) è la probabilità dell’evidenza B.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "2-3-inferenza-bayesiana.html#applicazioni-pratiche",
    "href": "2-3-inferenza-bayesiana.html#applicazioni-pratiche",
    "title": "5  Inferenza Bayesiana",
    "section": "5.3 Applicazioni Pratiche",
    "text": "5.3 Applicazioni Pratiche\nDiagnostica Medica\nNel campo della diagnostica medica, il Teorema di Bayes è utilizzato per valutare la probabilità che un paziente abbia una certa malattia sulla base dei sintomi presentati e dei risultati dei test di laboratorio. Ad esempio, se la probabilità di un test positivo dato che il paziente ha la malattia e la probabilità che il paziente abbia effettivamente la malattia sono note, il teorema di Bayes può essere impiegato per calcolare la probabilità che il paziente abbia la malattia date le informazioni disponibili.\nFinanza\nNel settore finanziario, il Teorema di Bayes viene adoperato per valutare il rischio e formulare previsioni basate su dati storici e informazioni di mercato. Ad esempio, il teorema può essere utilizzato per stimare la probabilità di un evento futuro, come un aumento dei tassi di interesse, sulla base di indicatori economici attuali.\nMachine Learning\nNei modelli di machine learning, come le reti bayesiane, il Teorema di Bayes svolge un ruolo chiave nell’aggiornare le probabilità delle variabili all’interno del modello in risposta ai nuovi dati. Questo processo di apprendimento bayesiano consente ai modelli di essere più flessibili ed adattabili all’evoluzione dei dati nel tempo.\ndiritto penale\nDalle informazioni (false perché inventate dall’ autore :) ottenute da un ipoteticodi un certo tribunale o dal Ministero della Giustizia abbiamo che\n\n80% degli imputati condannati hanno precedenti penali P(precedenti/condanna) = 0,8;\n10% degli imputati sono condannati P(condanna) = 0,1\n20% degli imputati hanno precedenti penali P(precedenti) = 0,2\n\nApplicando il teorema di Bayes abbiamo che la probabilità che un imputato con precedenti sia condannato è \\[\nP(cond/prec) = P(cond) \\cdot \\frac{P(prec/cond)}{P(prec)} = 0,1 \\cdot \\frac{0,8}{0,2}= 0,4\n\\]\nSi osservi che la probabilità di essere condannati era del 10%. Applicando il teorema di Bayes abbiamo scoperto che la probabilità di essere condannato è del 40% se sappiamo che la persona sottoposta a giudizio ha dei precedenti penali. Ovvero, la probabilità iniziale di essere condannati senza sapere se sono presenti o meno precedenti penali viene moltiplicata per 4 (il cosidetto fattore di Bayes).\nLe tecniche di inferenza basate sul Teorema di Bayes forniscono un approccio potente per il ragionamento probabilistico e l’aggiornamento delle credenze in base alle evidenze disponibili. Utilizzate in una vasta gamma di settori, queste tecniche consentono di prendere decisioni informate e di sfruttare al meglio le informazioni a disposizione. La comprensione e l’applicazione corretta del Teorema di Bayes sono cruciali per ottenere risultati accurati e significativi nelle analisi statistiche e nel machine learning.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "2-3-inferenza-bayesiana.html#reti-di-bayes",
    "href": "2-3-inferenza-bayesiana.html#reti-di-bayes",
    "title": "5  Inferenza Bayesiana",
    "section": "5.4 reti di Bayes",
    "text": "5.4 reti di Bayes\nUna rete bayesiana (BN, Bayesian network) è un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l’uso di un grafo aciclico diretto (DAG).\nPer esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra sintomi e malattie. Dati i sintomi, la rete può essere usata per calcolare la probabilità della presenza di diverse malattie. Ogni nodo della BN rappresenta una variabile aleatoria e ogni freccia dal nodo X al nodo Y indica che X è un genitore di Y. Ovvero, indica che la distribuzione probabilistica di Y dipende da X. Ogni nodo ha la distribuzione probabilistica P(X | Genitori(X)). La definizione della topologia di una BN o rete di credenza è affidata ad un esperto di dominio che stabilisce quali nodi e quali relazioni condizionali di dipendenza sono utili per modellare gli eventi del problema in esame. Ciò equivale a definire la conoscenza del mondo in cui può avvenire un evento. Ovvero, la rete rappresenta le assunzioni che si possono fare su quel dominio. Le probabilità condizionate tra i nodi, gli archi della rete, riassumono un insieme potenzialmente infinito di circostanze a noi ignote e che potrebbero influenzare l’evento esprimendo relazioni causali dirette (causa -&gt; effetto). Una volta definita la topologia bisogna specificare la tabella delle probabilità condizionate associata ad ogni nodo. Ogni riga della tabella esprime la probabilità del valore di ogni nodo per un caso condizionante (combinazione di valori dei nodi genitori produttoria delle prob. condiz.) Un nodo con nessun genitore è rappresentato dalla probabilità a priori.\nAd esempio, la seguente rete bayesiana rappresenta la relazione tra gli eventi che possono condizionare l’arrivo puntuale ad un appuntamento usando un mezzo di trasporto come ad esempio un treno.\n\n\n\nrete di Bayes appuntamento",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "2-3-inferenza-bayesiana.html#laboratorio-di-python",
    "href": "2-3-inferenza-bayesiana.html#laboratorio-di-python",
    "title": "5  Inferenza Bayesiana",
    "section": "5.5 laboratorio di Python",
    "text": "5.5 laboratorio di Python\n\n5.5.1 Esperimento 1 - Inferenza Bayesiana\nLa formula di Bayes descrive la probabilità condizionata di un evento A dato un evento B. La formula è la seguente: \\[    \nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\]\nIl denominatore P(B) può essere calcolato nel seguente modo: \\[\nP(B) = P(B|A) \\cdot P(A) + P(B|\\neg A) \\cdot P(\\neg A)\n\\]\nUna possibile implementazione in Python della formula di Bayes è la seguente:\n\ndef bayes_theorem(p_a, p_b_dato_a, p_b_dato_not_a):\n  # Calcola la probabilità di B dato A\n  p_a_dato_b = (p_b_dato_a * p_a) / (p_b_dato_a * p_a + p_b_dato_not_a * (1 - p_a))\n  return p_a_dato_b\n\nProviamo ad applicare la formula a un semplice caso penale. Immaginiamo di avere le seguenti informazioni:\n\nP(condanna) = 0.1;\nP(precedenti|condanna) = 0.8;\nP(precedenti|non condanna) = 0.1;\n\nCalcoliamo la probabilità di condanna dato che ci sono precedenti penali.\n\n# Esempio di applicazione al caso penale\n# Probabilità a priori\np_precedenti = 0.2  # P(precedenti)\np_condanna = 0.1    # P(condanna)\np_precedenti_dato_condanna = 0.8  # P(precedenti|condanna)\n\n# Calcolo della probabilità di condanna dato che ci sono precedenti\np_condanna_dato_precedenti = bayes_theorem(\n    p_a=p_condanna,\n    p_b_dato_a=p_precedenti_dato_condanna,\n    p_b_dato_not_a=0.1  # P(precedenti|non condanna)\n)\nfattore_bayes = p_condanna_dato_precedenti / p_condanna\n# Stampa i risultati\nprint(f\"La probabilità di condanna a priori è: {p_condanna:.1%}\")\nprint(f\"La probabilità di condanna dato che ci sono precedenti penali è: {p_condanna_dato_precedenti:.1%}\")\nprint(f\"Il fattore di Bayes è: {fattore_bayes:.2f}\")\nprint(f\"Quindi il fatto di sapere che l'imputato ha precedenti penali moltiplica di {fattore_bayes:.2f} volte la probabilità di condanna!\")\n\nLa probabilità di condanna a priori è: 10.0%\nLa probabilità di condanna dato che ci sono precedenti penali è: 47.1%\nIl fattore di Bayes è: 4.71\nQuindi il fatto di sapere che l'imputato ha precedenti penali moltiplica di 4.71 volte la probabilità di condanna!\n\n\n\n\n5.5.2 Esperimento 2 - Reti bayesiane\nScriviamo insieme il codice Python necessario per creare un modello di Rete Bayesiana per analizzare la probabilità di colpevolezza di un sospetto in un’indagine criminale. Tenendo conto del fatto che i modelli sono sempre un’approssimazione del mondo reale, si può utilizzare la teoria delle reti di Bayes per modellare la probabilità di un evento in base a vari fattori di prova. Il modello considera solo tre elementi di prova: la presenza di un’arma (Arma), un movente (Movente) e un alibi (Alibi), e come questi influenzano la probabilità di colpevolezza (Colpevolezza).\nIl codice non richiederà input diretti dall’utente. Invece, definisce la struttura della Rete Bayesiana e imposta le tabelle di probabilità per ciascun fattore basate su valori predefiniti che dovrebbero essere estrapolati da statistiche sulle indagini criminali.\nDescrizione del codice\nL’output di questo codice è:\n\nun modello di Rete Bayesiana verificato;\nla stampa del modello;\nla stampa delle Distribuzioni di Probabilità Condizionata (CPD) per ogni variabile nella rete;\nil grafo della rete Bayesiana.\n\nInizialmente, definiamo la struttura della Rete Bayesiana, mostrando come i fattori di prova (Arma, Movente, Alibi) influenzano la colpevolezza (Colpevolezza). Quindi, definiamo le tabelle di probabilità per ciascun fattore. Ad esempio, la probabilità che un’arma sia presente sia presente sul luogo del delitto la poniamo pari al 70% (0.7) e la sua assenza al 30% (0.3). Più complessa è la definizione della tabella di probabilità per la colpevolezza, che considera tutte le possibili combinazioni dei fattori di prova. Tutte queste tabelle sono aggiunte al modello di Rete Bayesiana. Infine, verifichiamo se il modello è definito correttamente e stampiamo tutte le distribuzioni di probabilità.\nLa logica chiave in questo codice è come esso rappresenta le relazioni tra diversi elementi di prova e la colpevolezza. Ad esempio, la presenza di un’arma, un movente e la mancanza di un alibi aumenterebbero la probabilità di colpevolezza, mentre la loro assenza la diminuirebbe. Questo è riflesso nella tabella di probabilità per ‘Colpevolezza’, che considera tutte le possibili combinazioni di prove:\n\n\n\nArma\nMotivo\nAlibi\nP(Non Colpevole)\nP(Colpevole)\n\n\n\n\n0\n0\n0\n0.9\n0.1\n\n\n0\n0\n1\n0.99\n0.01\n\n\n0\n1\n0\n0.7\n0.3\n\n\n0\n1\n1\n0.79\n0.21\n\n\n1\n0\n0\n0.5\n0.5\n\n\n1\n0\n1\n0.59\n0.41\n\n\n1\n1\n0\n0.2\n0.8\n\n\n1\n1\n1\n0.1\n0.9\n\n\n\nIn questa tabella:\n\n0 rappresenta l’assenza (di arma, movente o alibi)\n1 rappresenta la presenza\n\nLe ultime due colonne mostrano le probabilità di non colpevolezza e colpevolezza per ogni combinazione di evidenze\nQuesta Rete Bayesiana può essere utilizzata per calcolare la probabilità di colpevolezza dato uno scenario di prove, aiutando gli inquirenti a quantificare e ragionare sull’incertezza nei casi criminali.\n\n\n\n\n\n\nCaution\n\n\n\nSe non abbiamo mai installato le librerie pgmpy, networkx e matplotlib, l’interprete Python segnalerà che pgmpy non è riconosciuta. In questo caso è necessario installare le librerie necessarie eseguendo il seguente blocco di codice:\n!pip install pgmpy networkx matplotlib\n\n\n\nfrom pgmpy.models import BayesianNetwork\nfrom pgmpy.factors.discrete import TabularCPD\n\n# Definizione del modello\nmodel = BayesianNetwork([('Arma', 'Colpevolezza'),\n                       ('Movente', 'Colpevolezza'),\n                       ('Alibi', 'Colpevolezza')])\n\n# Definizione delle probabilità condizionate\ncpd_arma = TabularCPD(variable='Arma', variable_card=2,\n                      values=[[0.7], [0.3]])\ncpd_Movente = TabularCPD(variable='Movente', variable_card=2,\n                        values=[[0.6], [0.4]])\ncpd_alibi = TabularCPD(variable='Alibi', variable_card=2,\n                       values=[[0.5], [0.5]])\ncpd_colpevolezza = TabularCPD(variable='Colpevolezza', variable_card=2,\n                              values=[[0.1, 0.01, 0.3, 0.21, 0.5, 0.41, 0.8, 0.9],\n                                      [0.9, 0.99, 0.7, 0.79, 0.5, 0.59, 0.2, 0.1]],\n                              evidence=['Arma', 'Movente', 'Alibi'],\n                              evidence_card=[2, 2, 2])\n\n# Aggiunta delle probabilità condizionate al modello\nmodel.add_cpds(cpd_arma, cpd_Movente, cpd_alibi, cpd_colpevolezza)\n\n# Verifica del modello\nprint(\"Il modello è corretto: \", model.check_model())\n\n# Stampa del modello\nfor cpd in model.get_cpds():\n    print(\"CPD di {variable}:\".format(variable=cpd.variable))\n    print(cpd)\n\nIl modello è corretto:  True\nCPD di Arma:\n+---------+-----+\n| Arma(0) | 0.7 |\n+---------+-----+\n| Arma(1) | 0.3 |\n+---------+-----+\nCPD di Movente:\n+------------+-----+\n| Movente(0) | 0.6 |\n+------------+-----+\n| Movente(1) | 0.4 |\n+------------+-----+\nCPD di Alibi:\n+----------+-----+\n| Alibi(0) | 0.5 |\n+----------+-----+\n| Alibi(1) | 0.5 |\n+----------+-----+\nCPD di Colpevolezza:\n+-----------------+------------+-----+------------+------------+\n| Arma            | Arma(0)    | ... | Arma(1)    | Arma(1)    |\n+-----------------+------------+-----+------------+------------+\n| Movente         | Movente(0) | ... | Movente(1) | Movente(1) |\n+-----------------+------------+-----+------------+------------+\n| Alibi           | Alibi(0)   | ... | Alibi(0)   | Alibi(1)   |\n+-----------------+------------+-----+------------+------------+\n| Colpevolezza(0) | 0.1        | ... | 0.8        | 0.9        |\n+-----------------+------------+-----+------------+------------+\n| Colpevolezza(1) | 0.9        | ... | 0.2        | 0.1        |\n+-----------------+------------+-----+------------+------------+\n\n\nPossiamo anche visualizzare la rete di Bayes con il seguente codice:\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Assumendo che 'model' sia il tuo BayesianNetwork già definito\nG = nx.DiGraph()\nG.add_edges_from(model.edges())\n\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='lightblue',\n        node_size=3000, arrowsize=20, font_size=12, font_weight='bold')\n\nplt.title(\"Rete di Bayes per l'Analisi della Colpevolezza\")\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nInfine, una volta costruita la rete di Bayes possiamo interrogarla per avere una stima della probabilità di un determinato evento. Qual è la probabiltà che un indagato senza alibi, senza movente e in assenza di arma del delitto sia colpevole?\n\nfrom pgmpy.inference import VariableElimination\n\n# Creiamo un oggetto per l'inferenza\ninference = VariableElimination(model)\n\n# Definiamo l'evidenza per la situazione descritta\nevidence = {\n    'Alibi': 0,  # 0 rappresenta l'assenza di alibi\n    'Movente': 0, # 0 rappresenta l'assenza di motivo\n    'Arma': 0    # 0 rappresenta che l'arma non è stata trovata\n}\n\n# Calcoliamo la probabilità di colpevolezza dato l'evidenza\nresult = inference.query(['Colpevolezza'], evidence=evidence)\n\n# Stampiamo il risultato\nprint(\"Probabilità di colpevolezza:\")\nprint(result.values[0])\nprint(\"Probabilità di innocenza:\")\nprint(result.values[1])\n\nProbabilità di colpevolezza:\n0.1\nProbabilità di innocenza:\n0.9\n\n\n\nfrom pgmpy.inference import VariableElimination\n\n# Creiamo un oggetto per l'inferenza\ninference = VariableElimination(model)\n\n# Definiamo l'evidenza per la situazione descritta\nevidence = {\n    'Alibi': 1,   # 1 rappresenta la presenza di alibi\n    'Movente': 0, # 0 rappresenta l'assenza di motivo\n    'Arma': 0     # 0 rappresenta che l'arma non è stata trovata\n}\n\n# Calcoliamo la probabilità di colpevolezza dato l'evidenza\nresult = inference.query(['Colpevolezza'], evidence=evidence)\n\n# Stampiamo il risultato\nprint(\"Probabilità di colpevolezza:\")\nprint(result.values[0])\nprint(\"Probabilità di innocenza:\")\nprint(result.values[1])\n\nProbabilità di colpevolezza:\n0.01\nProbabilità di innocenza:\n0.99",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "2-3-inferenza-bayesiana.html#esercizi",
    "href": "2-3-inferenza-bayesiana.html#esercizi",
    "title": "5  Inferenza Bayesiana",
    "section": "5.6 Esercizi",
    "text": "5.6 Esercizi\n\n5.6.1 Esercizio 1: teorema di Bayes\nSupponiamo di avere raccolto informazioni su 1.000 casi penali. Per ogni caso, sono state raccolte le seguenti informazioni:\n\nAlibi del sospettato (Sì/No)\nTestimone oculare presente (Sì/No)\nCondanna del sospettato (Sì/No)\n\nIl dataset (l’insieme dei dati raccolti) è il seguente:\n\n\n\nAlibi\nTestimone Oculare\nCondanna\nNumero di Casi\n\n\n\n\nSì\nSì\nSì\n50\n\n\nSì\nSì\nNo\n20\n\n\nSì\nNo\nSì\n30\n\n\nSì\nNo\nNo\n100\n\n\nNo\nSì\nSì\n200\n\n\nNo\nSì\nNo\n50\n\n\nNo\nNo\nSì\n150\n\n\nNo\nNo\nNo\n400\n\n\ntotale\n-\n-\n1.000\n\n\n\nSi vuole comprendere l’impatto della assenza di un alibi sulla probabilità di condanna. A questo scopo, si applichi il teorema di Bayes per calcolare la probabilità che un sospettato venga condannato dato che non ha un alibi, cioè \\(P(\\text{Condanna} = \\text{Sì} \\mid \\text{Alibi} = \\text{No})\\). Per comodità si riporta qui di seguito la formula del teorema di Bayes applicata a questo caso specifico:\n\\[\nP(\\text{Cond} = \\text{Sì} \\mid \\text{Alibi} = \\text{No}) = \\frac{P(\\text{Alibi} = \\text{No} \\mid \\text{Cond} = \\text{Sì}) \\times P(\\text{Cond} = \\text{Sì})}{P(\\text{Alibi} = \\text{No})}\n\\]\nOvvero, per risolvere l’esercizio occorre trovare i seguenti valori:\n\n\\(P(\\text{Alibi} = \\text{No} \\mid \\text{Cond} = \\text{Sì})\\)\n\\(P(\\text{Cond} = \\text{Sì})\\)\n\\(P(\\text{Alibi} = \\text{No})\\)\n\n\n\n5.6.2 Esercizio 2: Fattore di Bayes\nSi calcoli il fattore di Bayes per l’inferenza Bayesiana studiata nell’esercizio 1.\n\n\n5.6.3 Esercizio 3: Probabilità a posteriori\nSi calcoli la probabilità che un sospettato venga condannato dato che non ha un alibi e che non ha un testimone oculare.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "2-4-algoritmi-di-ricerca.html",
    "href": "2-4-algoritmi-di-ricerca.html",
    "title": "6  Algoritmi di Ricerca",
    "section": "",
    "text": "6.1 Introduzione\nGli algoritmi di ricerca sono usati in molte applicazioni della intelligenza artificiale, tra cui:\nQuesti algoritmi sono versatili e possono essere adattati a molti altri domini, rendendo la ricerca un’area fondamentale dell’intelligenza artificiale.\nI problemi che si possono affrontare con gli algoritmi di ricerca sono quei problemi dove:\nUn agente che opera in un certo ambiente si trova in uno Stato iniziale (Questo rappresenta la condizione o la configurazione di partenza del problema). Esso, mediante le sue Azioni (le possibili mosse o le transizioni che possono essere effettuate a partire da uno stato) cerca di raggiungere lo stato finale o obiettivo. Il raggiungimento dello stato obiettivo è misurabile mediante un Test obiettivo (goal test) (un criterio che determina se uno stato specifico risolve il problema). Ogni azione o operatore dell’agente ha un costo associato, che può essere costante o variabile a seconda della natura del problema, che può essere misurato mediante una Funzione costo (Il costo può rappresentare, ad esempio, il tempo, lo sforzo o le risorse necessarie per eseguire un’azione).\nA seconda della natura del problema, lo stato iniziale può essere un singolo stato o un insieme di stati. Inoltre, i problemi possono essere classificati in base alla conoscenza che l’agente ha sullo stato in cui si trova e sulle azioni.\nUna volta definito il problema in questi termini, l’algoritmo di ricerca può essere utilizzato per esplorare lo spazio degli stati e trovare una soluzione, che è una sequenza di azioni che porta dallo stato iniziale a uno stato che soddisfa il test obiettivo¹.\nesempio di problema di ricerca\nUn esempio classico di problema che segue questa struttura è il problema del commesso viaggiatore (Travelling Salesman Problem, TSP).\nDato un insieme di città, e note le distanze tra ciascuna coppia di esse, trovare il tragitto di minima percorrenza che un commesso viaggiatore deve seguire per visitare tutte le città una ed una sola volta e ritornare alla città di partenza\nL’obiettivo del problema del commesso viaggiatore è trovare il percorso più breve (o il percorso che minimizza il tempo di viaggio) che visita tutte le città una sola volta e ritorna alla città di partenza. Gli algoritmi di ricerca possono essere utilizzati per esplorare lo spazio degli stati (cioè, tutti i possibili percorsi) e trovare la soluzione ottimale.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmi di Ricerca</span>"
    ]
  },
  {
    "objectID": "2-4-algoritmi-di-ricerca.html#introduzione",
    "href": "2-4-algoritmi-di-ricerca.html#introduzione",
    "title": "6  Algoritmi di Ricerca",
    "section": "",
    "text": "Problemi di pianificazione: trovare una sequenza di azioni per raggiungere un obiettivo.\nRisoluzione di puzzle e giochi: come il cubo di Rubik, gli scacchi o il gioco del 15.\nNavigazione e percorsi: trovare il percorso migliore in mappe o reti stradali.\nOttimizzazione di processi: trovare la configurazione ottimale in problemi complessi.\nScheduling: organizzare attività o risorse in modo efficiente.\nRiconoscimento di pattern: identificare strutture o sequenze in dati complessi.\nDiagnosi medica: identificare possibili malattie basandosi su sintomi.\nElaborazione del linguaggio naturale: analisi sintattica e semantica.\nVisione artificiale: riconoscimento di oggetti e scene in immagini.\nRobotica: pianificazione del movimento e navigazione autonoma.\n\n\n\n\n\n\n\n\n\n\nStato iniziale: Il commesso viaggiatore si trova in una città specifica (ad esempio, Roma) e deve visitare tutte le altre città una sola volta e tornare alla città di partenza.\nAzioni o operatori: Il commesso viaggiatore può scegliere di viaggiare da una città all’altra. Ogni possibile percorso da una città all’altra rappresenta un’azione.\nTest obiettivo (goal test): Il test obiettivo verifica se tutte le città sono state visitate una sola volta e se il commesso viaggiatore è tornato alla città di partenza.\nFunzione costo: Il costo di un percorso può essere la distanza totale percorsa o il tempo totale impiegato per il viaggio.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmi di Ricerca</span>"
    ]
  },
  {
    "objectID": "2-4-algoritmi-di-ricerca.html#sec-algoritm-generale-di-ricerca",
    "href": "2-4-algoritmi-di-ricerca.html#sec-algoritm-generale-di-ricerca",
    "title": "6  Algoritmi di Ricerca",
    "section": "6.2 Algoritmo “generale” di ricerca",
    "text": "6.2 Algoritmo “generale” di ricerca\nIn ogni istante l’agente si troverà davanti un insieme di stati possibili da esplorare. Questo insieme di stati è noto come la frontiera. Abbiamo bisogno di una struttura dati in grado di contenere gli stati della frontiera che l’agente può esplorare.Vedremo almeno due implementazioni. Lo pseudocodice dell’algoritmo “generale” di ricerca è il seguente (Russell and Norvig 2021):\n1. Inizializza la frontiera con lo stato iniziale.\n2. Se la Frontiera è vuota, si tratta di un problema insolubile.\n3.   Rimuovi un nodo dalla frontiera secondo la strategia di ricerca e consideralo come candidato.\n4.   Se il nodo contiene lo stato finale, Restituisci la soluzione. Finito!\n5.    Altrimenti\n6.       Cerca tutti i nodi raggiungibili dal nodo corrente e aggiungili alla frontiera, rispettando la strategia di ricerca.\n7.       Aggiungi il nodo corrente all'insieme dei nodi visitati.\n8. Torna al passo 2.\nL’algoritmo di ricerca generale appena descritto è un approccio generale per risolvere problemi di ricerca. Tuttavia, per risolvere un problema specifico, è necessario specificare una strategia di ricerca. Una strategia di ricerca è una regola che determina l’ordine in cui i nodi vengono esplorati nella frontiera. Le strategie di ricerca possono essere classificate in base a diversi criteri, tra cui: 1. Strategie di ricerca non informate: Queste strategie non utilizzano alcuna informazione aggiuntiva oltre a quella fornita dal problema stesso. 2. Strategie di ricerca informate: Queste strategie utilizzano informazioni aggiuntive per guidare la ricerca. 3. Strategie di ricerca a costo minimo: Queste strategie utilizzano un costo per guidare la ricerca.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmi di Ricerca</span>"
    ]
  },
  {
    "objectID": "2-4-algoritmi-di-ricerca.html#sec-algoritmi-di-ricerca-non-informati",
    "href": "2-4-algoritmi-di-ricerca.html#sec-algoritmi-di-ricerca-non-informati",
    "title": "6  Algoritmi di Ricerca",
    "section": "6.3 Algoritmi di ricerca non informati",
    "text": "6.3 Algoritmi di ricerca non informati\nLe strategie di ricerca non informate sono un tipo di algoritmo di ricerca che non utilizza alcuna conoscenza specifica o informazione aggiuntiva sul problema da risolvere. Questi algoritmi utilizzano solo la struttura del problema e la definizione di stato e azione per esplorare lo spazio degli stati. La scelta del nodo da rimuovere dalla frontiera è basata su una strategia di ricerca, che determina l’ordine in cui i nodi vengono esplorati. Nel laboratorio di Python alla fine di questo capitolo vedremo come si implementano le strategie di ricerca più comuni. Invece, qui di seguito ipotizziamo di voler trovare il percorso più breve tra i nodi A e F del seguente grafo:\n\n\n\n\n\n\ngraph TD\n    A --- B\n    A --- C\n    A --- D\n    B --- E\n    E --- F\n    C --- G\n    C --- H\n    G --- I\n    D --- L\n\nstyle A fill:#f9f,stroke:#333,stroke-width:4px\nstyle L fill:#f9f,stroke:#333,stroke-width:4px\n\n\n\n\nFigure 6.1: Grafo dove cercare il percorso tra il nodo A e il nodo L.\n\n\n\n\n\nNel fare questa ricerca usiamo due strutture per la frontiera:\n\nLo pila: L’ultimo nodo inserito è il primo estratto (LIFO = Last In First Out) come accade per una pila di piatti dove il più in alto è il primo a essere prelevato.\nLa coda: Il primo nodo inserito è il primo estratto (FIFO = First In First Out) come accade per una coda di persone ad uno sportello dove la prima persona in coda è la prima a essere servita.\n\n\nSe applichiamo l’algoritmo generale di ricerca al nostro grafo, utilizzando la strategia di ricerca a pila, o LIFO (Last In, First Out), il nodo più recentemente aggiunto alla frontiera è il primo a essere esplorato. Questo comporta una ricerca in profondità nota come DFS - Depth First Search:\n\nL’algoritmo esplora un ramo del grafo fino a raggiungere un vicolo cieco o la soluzione.\nSe non si trova la soluzione, torna indietro per esplorare altri rami.\n\nNella tabella seguente, mostriamo i passi dell’esecuzione dell’algoritmo con il nodo candidato, il contenuto della frontiera, i nodi visitati e il percorso candidato per ogni passo dell’algoritmo:\n\nricerca del percorso tra i nodi A e L utilizzando la strategia di ricerca a pila\n\n\n\n\n\n\n\n\n\nPasso\nNodo Candidato\nFrontiera\nNodi Visitati\nPercorso\n\n\n\n\n1\nA\n[D, C, B]\n[A]\n[A]\n\n\n2\nB\n[D, C, E]\n[A, B]\n[A, B]\n\n\n3\nE\n[D, C, F]\n[A, B, E]\n[A, B, E]\n\n\n4\nF\n[D, C]\n[A, B, E, F]\n[A, B, E, F]\n\n\n5\nC\n[D, H, G]\n[A, B, E, F, C]\n[A, C]\n\n\n6\nG\n[D, H, I]\n[A, B, E, F, C, G]\n[A, C, G]\n\n\n7\nI\n[D, H]\n[A, B, E, F, C, G, I]\n[A, C, G, I]\n\n\n8\nH\n[D]\n[A, B, E, F, C, G, I, H]\n[A, C, H]\n\n\n9\nD\n[L]\n[A, B, E, F, C, G, I, H, D]\n[A, D]\n\n\n10\nL\n[]\n[A, B, E, F, C, G, I, H, D, L]\n[A, D, L]\n\n\n\nL’esito della ricerca DFS è mostrato nel seguente grafo dove i nodi visitati sono evidenziati in verde e numerati in ordine di visita e il percorso trovato ha i rami di colore rosso:\n\n\n\n\n\n\ngraph TD\n    A(A-1):::start--- B(B-2):::visited\n    A --- C(C-5):::visited\n    A === D(D-9):::visited\n    B --- E(E-3):::visited\n    E --- F(F-4):::visited\n    C --- G(G-6):::visited\n    C --- H(H-8):::visited\n    G --- I(I-7):::visited\n    D ==== L(L-10):::stop\n\nclassDef start fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef stop fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef visited fill:#1f1,stroke:#333,stroke-width:2px;\nlinkStyle 2,8 stroke:#f00,stroke-width:4px;\n\n\n\n\nFigure 6.2: Esito della ricerca DFS: Percorso trovato: [A, D, L].\n\n\n\n\n\nSe applichiamo l’algoritmo generale di ricerca al nostro grafo, utilizzando la strategia di ricerca a coda, o FIFO (First In, First Out), il nodo più vecchio è il primo a essere esplorato. Questo comporta una ricerca in ampiezza nota come BFS - Breath First Search:\n\nL’algoritmo esplora i nodi vicini prima di passare a quelli più lontani.\nTrova sempre il percorso più breve (in termini di numero di nodi).\n\nNella tabella seguente, mostriamo i passi dell’esecuzione dell’algoritmo con il nodo candidato, il contenuto della frontiera, i nodi visitati e il percorso candidato per ogni passo dell’algoritmo:\n\nricerca del percorso tra i nodi A e L utilizzando la strategia di ricerca a coda\n\n\n\n\n\n\n\n\n\nPasso\nNodo Candidato\nFrontiera\nNodi Visitati\nPercorso\n\n\n\n\n1\nA\n[B, C, D]\n[A]\n[A]\n\n\n2\nB\n[C, D, E]\n[A, B]\n[A, B]\n\n\n3\nC\n[D, E, G, H]\n[A, B, C]\n[A, C]\n\n\n4\nD\n[E, G, H, L]\n[A, B, C, D]\n[A, D]\n\n\n5\nL\n[E, G, H]\n[A, B, C, D, L]\n[A, D, L]\n\n\n\nL’esito della ricerca BFS è mostrato nel seguente grafo dove i nodi visitati sono evidenziati in verde e numerati in ordine di visita e il percorso trovato ha i rami di colore rosso:\n\n\n\n\n\n\ngraph TD\n    A(A-1):::start--- B(B-2):::visited\n    A --- C(C-3):::visited\n    A === D(D-4):::visited\n    B --- E\n    E --- F\n    C --- G\n    C --- H\n    G --- I\n    D === L(L-5):::stop\n\nclassDef start fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef stop fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef visited fill:#1f1,stroke:#333,stroke-width:2px;\nlinkStyle 2,8 stroke:#f00,stroke-width:4px;\n\n\n\n\nFigure 6.3: Esito della ricerca BFS: Percorso trovato: [A, D, L].\n\n\n\n\n\nConfrontando i due algoritmi di ricerca, possiamo notare che:\n\nPila (DFS):\n\nEsplora un ramo alla volta.\nPotrebbe visitare più nodi rispetto alla soluzione ottimale.\n\nCoda (BFS):\n\nTrova sempre il percorso più breve in termini di numero di nodi.\nEsplora i nodi livello per livello.\n\n\nIn generale, la scelta tra DFS e BFS dipende dal problema specifico e dalle caratteristiche del grafo.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmi di Ricerca</span>"
    ]
  },
  {
    "objectID": "2-4-algoritmi-di-ricerca.html#sec-algoritmi-di-ricerca-informati",
    "href": "2-4-algoritmi-di-ricerca.html#sec-algoritmi-di-ricerca-informati",
    "title": "6  Algoritmi di Ricerca",
    "section": "6.4 Algoritmi di Ricerca Informati",
    "text": "6.4 Algoritmi di Ricerca Informati\nGli algoritmi di ricerca informati sono una classe di algoritmi che utilizzano informazioni aggiuntive, chiamate euristiche, per guidare il processo di ricerca verso la soluzione in modo più efficiente rispetto agli approcci non informati. L’euristica è una funzione che stima il costo o la distanza dal nodo corrente al nodo obiettivo, fornendo un’indicazione di “quanto vicino” ci si trovi alla soluzione. Gli algoritmi di ricerca informati trovano applicazione in numerosi campi, come l’intelligenza artificiale, la robotica, la pianificazione di percorsi e la risoluzione di problemi di ottimizzazione. La scelta dell’algoritmo più appropriato dipende dalle caratteristiche del problema, come la complessità dello spazio di ricerca, la disponibilità di informazioni euristiche accurate e i requisiti di ottimalità della soluzione.\n\n6.4.1 Euristiche\nLe funzioni euristiche svolgono un ruolo cruciale negli algoritmi di ricerca informati, fornendo una stima della distanza o del costo rimanente per raggiungere la soluzione. Queste funzioni sono progettate per guidare la ricerca in modo intelligente, evitando di esplorare percorsi poco promettenti e concentrandosi sulle regioni dello spazio di ricerca più vicine alla soluzione. Le euristiche dovrebbero essere ammissibili e consistenti:\n\nEuristiche ammissibili:\n\nUna funzione euristica è ammissibile se non sovrastima mai il costo reale per raggiungere l’obiettivo, garantendo che l’algoritmo trovi il percorso ottimale.\nAd esempio, in un problema di navigazione, la distanza in linea retta tra due punti è un’euristica ammissibile.\n\nEuristiche consistenti (o monotone):\n\nUna funzione euristica è consistente se per ogni nodo \\(n\\), il costo stimato dall’euristica soddisfa la disuguaglianza del triangolo:\n\\[\nh(n) \\leq c(n, n') + h(n')\n\\]\nDove \\(c(n, n')\\) è il costo effettivo tra \\(n\\) e \\(n'\\). Questa proprietà garantisce che A* non rientri mai in un nodo già visitato. La progettazione di funzioni euristiche efficaci è spesso una sfida cruciale nell’applicazione degli algoritmi di ricerca informati a problemi complessi del mondo reale.\n\n\n\n\n\nDistanze euclidee e di Manhattan\n\n\nDistanza euclidea : La distanza euclidea, anche nota come distanza in linea retta, è una misura della distanza tra due punti in uno spazio euclideo, come il piano cartesiano o lo spazio tridimensionale. Essa rappresenta la lunghezza del segmento di retta che congiunge i due punti. La formula per calcolare la distanza euclidea tra due punti \\(A=(x_A, y_A)\\) e \\(B=(x_B, y_B)\\) in un piano cartesiano bidimensionale è:\n\\[\nd_{euclide}=\\sqrt{(x_B-x_A)^2+(y_B-Y_A)^2}\n\\]\nLa distanza euclidea è ampiamente utilizzata come funzione euristica negli algoritmi di ricerca informati, come l’algoritmo A*, per stimare la distanza rimanente dalla soluzione. Essa fornisce una stima ammissibile (non sovrastima) della distanza effettiva, soddisfacendo così i requisiti per garantire l’ottimalità dell’algoritmo di ricerca. Tuttavia, la distanza euclidea può essere una stima poco accurata in alcuni contesti, come nei labirinti o in presenza di ostacoli, poiché non tiene conto degli impedimenti lungo il percorso. In questi casi, possono essere utilizzate funzioni euristiche più sofisticate per ottenere stime più precise.\nDistanza di Manhattan : La distanza di Manhattan, anche nota come distanza city-block o distanza del tassista, è una metrica utilizzata per calcolare la distanza tra due punti in uno spazio a coordinate cartesiane. Essa prende il nome dalla griglia di strade di Manhattan, dove i percorsi possibili sono limitati a spostamenti orizzontali e verticali. La formula per calcolare la distanza di Manhattan tra due punti \\(A=(x_A, y_A)\\) e \\(B=(x_B, y_B)\\) in un piano cartesiano bidimensionale è:\n\\[\nd_{Manhattan}=(x_B-x_A)+(y_B-Y_A)\n\\]\nEssenzialmente, la distanza di Manhattan è la somma delle differenze assolute delle coordinate x e y dei due punti.\nLa distanza di Manhattan è spesso utilizzata come funzione euristica negli algoritmi di ricerca informati, come l’algoritmo A*, per risolvere problemi di ricerca su griglie o labirinti. Essa fornisce una stima ammissibile della distanza effettiva, garantendo così l’ottimalità dell’algoritmo di ricerca.\nRispetto alla distanza euclidea, la distanza di Manhattan può essere una stima più accurata in contesti come i labirinti, poiché tiene conto delle restrizioni di movimento lungo le direzioni orizzontali e verticali. Tuttavia, può sottostimare la distanza effettiva in situazioni in cui sono possibili percorsi diagonali.\nNumero di pezzi fuori posto: Usata nei giochi di puzzle (es. il gioco del 15), conta il numero di tessere non in posizione corretta.\n\n\n6.4.2 Greedy Best-First Search\nL’algoritmo utilizza una priority queue, una coda che mantiene i nodi in ordine di priorità, per gestire la frontiera. In questo algoritmo la priorità è determinata unicamente dalla funzione euristica \\(h(n)\\), che stima quanto il nodo \\(n\\) sia vicino all’obiettivo. Funzionamento:\n\nSi inseriscono nella frontiera i nodi vicini al nodo corrente.\nSi estrae il nodo con il valore di \\(h(n)\\) più basso.\nSi ripete fino a raggiungere l’obiettivo o a esaurire i nodi.\n\nQuesto algoritmo è efficiente, ma non garantisce la soluzione ottimale, poiché si basa solo sull’euristica.\nNel laboratorio di Python alla fine di questo capitolo vedremo come si implementa questa strategia di ricerca. Qui di seguito ipotizziamo di voler trovare il percorso più breve tra i nodi due località : Castelnuovo di Porto(RM) e Viale Pola, 12, Roma. Il grafo semplificato è il seguente:\n\n\n\n\n\n\ngraph TD\n    A(Castelnuovo di Porto):::start --- |Flaminia| B(Via Flaminia+GRA)\n    A --- |Tiberina| B\n    A --- |Salaria| D(GRA-Salaria)\n    A --- |E35| C(E35+GRA)\n    B --- |GRA| D\n    C --- |GRA| D\n    D --- |Salaria| E(Viale Pola):::stop\nclassDef start fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef stop fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef visited fill:#1f1,stroke:#333,stroke-width:2px;\n\n\n\n\nFigure 6.4: Esempio di grafo per le funzioni di ricerca informate\n\n\n\n\n\nL’eurstica utilizzata è la distanza euclidea tra i nodi, le località, che è una stima ammissibile:\n\n\n\nlocalità\ndistanza da Via Pola\n\n\n\n\nA - Castelnuovo di Porto\n23\n\n\nB - Via Flaminia+GRA\n7\n\n\nC - E35+GRA\n7\n\n\nD - GRA-Salaria\n8\n\n\nE - Viale Pola\n0\n\n\n\nNella tabella seguente, mostriamo i passi dell’esecuzione dell’algoritmo con il nodo candidato, il contenuto della frontiera, i nodi visitati, il percorso candidato e l’euristica per ogni passo dell’algoritmo:\n\nricerca del percorso tra i nodi A e L utilizzando l’algoritmo Greedy Best-First Search.\n\n\n\n\n\n\n\n\n\n\nPasso\nNodo Candidato\nFrontiera\nNodi Visitati\nPercorso\nEuristica\n\n\n\n\n1\nA\n[(B, 7), (C, 7), (D, 8)]\n[A]\n[A]\n23\n\n\n2\nB\n[(C, 7), (D, 8), (D, 8)]\n[A, B]\n[A, B]\n7\n\n\n3\nC\n[(D, 8), (D, 8)]\n[A, B, C]\n[A, C]\n7\n\n\n4\nD\n[(D, 8)]\n[A, B, C, D]\n[A, D]\n8\n\n\n5\nE\n[]\n[A, B, C, D, E]\n[A, D, E]\n0\n\n\n\nSpiegazione dei Passaggi\n\nPasso 1:\n\nNodo iniziale \\(A\\) viene visitato.\nI vicini \\(B, C, D\\) sono aggiunti alla frontiera con le rispettive euristiche.\nNodo candidato successivo: \\(B\\) (euristica più bassa).\n\nPasso 2:\n\nNodo \\(B\\) viene estratto dalla frontiera e visitato.\nVicino \\(D\\) viene aggiunto di nuovo alla frontiera, ma ha già un’euristica assegnata.\nNodo candidato successivo: \\(C\\) (euristica più bassa).\n\nPasso 3:\n\nNodo \\(C\\) viene estratto e visitato.\nIl vicino \\(D\\) non cambia la priorità della frontiera.\nNodo candidato successivo: \\(D\\) (euristica più bassa).\n\nPasso 4:\n\nNodo \\(D\\) viene estratto e visitato.\nIl vicino \\(E\\) è aggiunto alla frontiera.\nNodo candidato successivo: \\(E\\) (obiettivo raggiunto).\n\nPasso 5:\n\nNodo \\(E\\) viene estratto e visitato.\nIl nodo obiettivo è stato raggiunto, e l’algoritmo termina.\n\n\nPercorso trovato: \\([A, D, E]\\)\nEuristica utilizzata: La scelta dei nodi è basata esclusivamente sul valore \\(h(n)\\), senza considerare il costo effettivo del cammino. Quindi l’algoritmo usato senza altre informazioni oltre alla distanza da Viale Pola indica di percorrere un tratto della salaria fino al GRA e continuare sulla Salaria per raggiungere Viale Pola.\n\n\n6.4.3 A* (A-Star Search)\nL’algoritmo utilizza una priority queue con una funzione di priorità combinata:\n\\[\n  f(n) = g(n) + h(n)\n\\]\nDove:\n\n\\(g(n)\\): costo del percorso dal nodo iniziale al nodo \\(n\\).\n\\(h(n)\\) : stima del costo per raggiungere l’obiettivo da \\(n\\).\n\nFunzionamento:\n\nOgni nodo inserito nella frontiera ha una priorità basata su \\(f(n)\\).\nSi estrae il nodo con il valore di \\(f(n)\\) più basso.\nL’algoritmo continua fino a trovare il nodo obiettivo con il costo più basso.\n\nDifferenza tra Greedy e A*:\n\nGreedy Best-First Search si concentra solo su* \\(h(n)\\) (euristica).\nA* bilancia \\(g(n)\\) (costo effettivo) e \\(h(n)\\) (euristica), garantendo una soluzione ottimale se l’euristica è ammissibile e consistente.\n\nProviamo ad applicare l’algoritmo A* al calcolo del percorso più breve nel caso dell’esempio visto nel paragrafo precedente. Riportiamo qui di seguito il grafo semplificato dove sono riportati anche i valori di costo stimati usando la distanza su strada tra i nodi del grafo:\n\n\n\n\n\ngraph TD\n    A(Castelnuovo di Porto):::start --- |Flaminia, 18| B(Via Flaminia+GRA)\n    A --- |Tiberina, 23| B\n    A --- |Salaria, 27| D(GRA-Salaria)\n    A --- |E35, 21| C(E35+GRA)\n    B --- |GRA, 2| D\n    C --- |GRA, 1| D\n    D --- |Salaria, 9| E(Viale Pola):::stop\nclassDef start fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef stop fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef visited fill:#1f1,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\nL’eurstica utilizzata è la distanza euclidea tra i nodi, le località, che è una stima ammissibile come nel paragrafo precedente:\n\n\n\nlocalità\ndistanza da Via Pola\n\n\n\n\nA - Castelnuovo di Porto\n23\n\n\nB - Via Flaminia+GRA\n7\n\n\nC - E35+GRA\n7\n\n\nD - GRA-Salaria\n8\n\n\nE - Viale Pola\n0\n\n\n\nNella tabella seguente, mostriamo i passi dell’esecuzione dell’algoritmo con il nodo candidato, il contenuto della frontiera, i nodi visitati, il percorso candidato l’euristica, il costo e la priorità combinata per ogni passo dell’algoritmo:\n\nricerca del percorso tra i nodi A e L utilizzando l’algoritmo A*.\n\n\n\n\n\n\n\n\n\n\n\n\nPasso\nNodo Candidato\nFrontiera\nNodi Visitati\nPercorso\n\\(g(n)\\)\n\\(h(n)\\)\n\\(f(n) = g(n) + h(n)\\)\n\n\n\n\n1\nA\n[(B, 18 + 7 = 25), (C, 21 + 7 = 28), (D, 27 + 8 = 35)]\n[A]\n[A]\n0\n23\n23\n\n\n2\nB\n[(C, 28), (D, 35), (D (via B), 20 + 8 = 28)]\n[A, B]\n[A, B]\n18\n7\n25\n\n\n3\nD (via B)\n[(C, 28), (D, 35), (E, 29)]\n[A, B, D]\n[A, B, D]\n20\n8\n28\n\n\n4\nE\n[(C, 28), (D, 35)]\n[A, B, D, E]\n[A, B, D, E]\n29\n0\n29\n\n\n\nSpiegazione dei Passaggi\n\nPasso 1:\n\nPartiamo dal nodo iniziale \\(A\\).\nCalcoliamo \\(f(n) = g(n) + h(n)\\) per tutti i vicini:\n\n\\(B: f(B) = 18 + 7 = 25\\)\n\\(C: f(C) = 21 + 7 = 28\\)\n\\(D: f(D) = 27 + 8 = 35\\)\n\nAggiorniamo la frontiera con i nodi \\(B, C, D\\).\n\nPasso 2:\n\nNodo \\(B\\) ha il valore \\(f(B) = 25\\), il più basso nella frontiera, quindi viene esplorato.\nIl vicino \\(D\\) viene aggiornato con il nuovo costo tramite \\(B\\):\n\n\\(D (via B): g(D) = 20, h(D) = 8, f(D) = 28\\).\n\nLa frontiera è aggiornata.\n\nPasso 3:\n\nNodo \\(D (via B)\\) ha \\(f(D) = 28\\), il più basso nella frontiera, quindi viene esplorato.\nIl vicino \\(E\\) viene aggiunto alla frontiera:\n\n\\(E: g(E) = 29, h(E) = 0, f(E) = 29\\).\n\n\nPasso 4:\n\nNodo \\(E\\) ha \\(f(E) = 29\\), il più basso nella frontiera, quindi viene esplorato.\nObiettivo raggiunto, l’algoritmo termina.\n\n\n\nRisultato\nPercorso trovato: \\([A, B, D, E]\\)\nCosto totale: \\(29\\)\nEuristica e costo combinati garantiscono la soluzione ottimale.\nL’esempio visto mostra come l’algoritmo A* bilancia la ricerca euristica con la ricerca di costo effettivo, fornendo una soluzione ottimale se l’euristica è ammissibile e consistente. In questo caso, l’algoritmo A* suggerisce di passare per il nodo \\(B\\) e poi per il nodo \\(D\\) prima di raggiungere l’obiettivo.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmi di Ricerca</span>"
    ]
  },
  {
    "objectID": "2-4-algoritmi-di-ricerca.html#laboratorio-python",
    "href": "2-4-algoritmi-di-ricerca.html#laboratorio-python",
    "title": "6  Algoritmi di Ricerca",
    "section": "6.5 Laboratorio Python",
    "text": "6.5 Laboratorio Python\n\n6.5.1 Esperimento 1: Algoritmi di ricerca non informata\nL’algoritmo generale di ricerca visto nel paragrafo 6.2 può essere ulteriormente dettaglia in un linguaggio pseudo-Python come segue:\n\nFunzione RicercaGenerale(stato_iniziale, obiettivo, strategia):\n    # Inizializza la frontiera con lo stato iniziale\n    frontiera = CreaStrutturaDati(strategia)\n    Aggiungi(frontiera, stato_iniziale)\n\n    # Inizializza l'insieme dei nodi visitati (opzionale, per evitare cicli)\n    visitati = InsiemeVuoto()\n\n    Mentre la frontiera non è vuota:\n        # Rimuovi un nodo dalla frontiera seguendo la strategia scelta\n        nodo_corrente = Rimuovi(frontiera)\n\n        # Controlla se lo stato corrente soddisfa l'obiettivo\n        Se nodo_corrente == obiettivo:\n            Restituisci \"Soluzione trovata!\"\n\n        # Se il nodo corrente non è stato visitato\n        Se nodo_corrente non è in visitati:\n            # Aggiungi il nodo corrente ai nodi visitati\n            Aggiungi(visitati, nodo_corrente)\n\n            # Espandi il nodo corrente per generare i nodi figli\n            nodi_figli = GeneraFigli(nodo_corrente)\n\n            # Aggiungi i nodi figli alla frontiera\n            Per ogni nodo in nodi_figli:\n                Se nodo non è in visitati e nodo non è nella frontiera:\n                    Aggiungi(frontiera, nodo)\n\n    Restituisci \"Problema senza soluzione\"\nLe struttre dati usate per la frontiera sono le seguenti:\n\nStack: L’ultimo nodo inserito è il primo estratto (LIFO = Last In First Out) –&gt; Algoritmo Depth-First Search (DFS).\nQueue: Il primo nodo inserito è il primo estratto (FIFO = First In First Out) –&gt; Algoritmo Breadth-First Search (BFS).\nPriority Queue: Il nodo con il valore di priorità più alto è il primo estratto –&gt; Usato per Greedy Best-First Search e A*, dove la priorità è determinata da funzioni di costo o euristiche.\n\nL’implementazione in Python di questo algoritmo riportata qui di seguito discende immediatamente dalla implementazione in pseudo-python vista qui sopra. Si noti che la funzione accetta in ingresso un grafo descritto da un dizionarip, uno stato iniziale, ovvero il nome del nodo inziale nel dizionario, uno stato obiettivo, ovvero il nome del nodo da raggiungere nel dizionario, e la strategia non informata che vogliamo usare, DFS o BFS.\n\nfrom collections import deque\n\ndef ricerca_generale(grafo, stato_iniziale, obiettivo, strategia=\"BFS\"):\n    \"\"\"\n    Algoritmo generale di ricerca.\n\n    :param grafo: Dizionario che rappresenta il grafo come lista di adiacenza\n    :param stato_iniziale: Nodo di partenza\n    :param obiettivo: Nodo obiettivo\n    :param strategia: Strategia di ricerca, \"BFS\" (coda) o \"DFS\" (stack)\n    :return: Tupla contenente (percorso dal nodo iniziale al nodo obiettivo, lista dei nodi visitati) o (messaggio di fallimento, lista dei nodi visitati)\n    \"\"\"\n    if strategia == \"BFS\":\n        frontiera = deque([[stato_iniziale]])  # Coda per BFS\n    elif strategia == \"DFS\":\n        frontiera = [[stato_iniziale]]  # Stack per DFS\n    else:\n        raise ValueError(\"Strategia non supportata. Usa 'BFS' o 'DFS'.\")\n\n    visitati = set()  # Insieme dei nodi visitati\n    nodi_visitati = []  # Lista per memorizzare l'ordine dei nodi visitati\n\n    while frontiera:\n        # Rimuovi un percorso dalla frontiera (FIFO per BFS, LIFO per DFS)\n        if strategia == \"BFS\":\n            percorso_corrente = frontiera.popleft()\n        else:  # strategia == \"DFS\"\n            percorso_corrente = frontiera.pop()\n\n        nodo_corrente = percorso_corrente[-1]  # Ultimo nodo nel percorso\n\n        # Controlla se abbiamo raggiunto l'obiettivo\n        if nodo_corrente == obiettivo:\n            return percorso_corrente, nodi_visitati  # Restituisci il percorso completo e i nodi visitati\n\n        # Se il nodo non è stato visitato\n        if nodo_corrente not in visitati:\n            visitati.add(nodo_corrente)  # Segna il nodo come visitato\n            nodi_visitati.append(nodo_corrente)  # Aggiunge il nodo alla lista dei visitati\n\n            # Aggiungi i vicini alla frontiera\n            for vicino in grafo.get(nodo_corrente, []):\n                if vicino not in visitati:\n                    nuovo_percorso = percorso_corrente + [vicino]\n                    frontiera.append(nuovo_percorso)\n\n    return \"Problema senza soluzione\", nodi_visitati\n\nApplichiamo la funzione di ricerca generale al seguente grafo usato nel paragrafo 6.3 che si riporta qui di seguito per comodità:\n\n\n\n\n\n\ngraph TD\n    A --- B\n    A --- C\n    A --- D\n    B --- E\n    E --- F\n    C --- G\n    C --- H\n    G --- I\n    D --- L\n\n\n\n\nFigure 6.5: Esempio di grafo per la funzione di ricerca generale non informata\n\n\n\n\n\nTradotto in Python, il grafo è rappresentato da un dizionario dove le chiavi sono i nodi e i valori sono le liste di nodi adiacenti.\n\ngrafo = {\n    'A': ['B', 'C', 'D'],\n    'B': ['E'],\n    'C': ['G', 'H'],\n    'D': ['L'],\n    'E': ['F'],\n    'G': ['I'],\n    'H': [],\n    'I': [],\n    'F': [],\n    'L': []\n}\n\nCreiamo una semplice funzione Python per vedere il grafo in output su schermo:\n\ndef stampa_grafo(grafo):\n    for nodo, vicini in grafo.items():\n        print(f\"{nodo} -&gt; \", end=\"\")\n        for vicino in vicini:\n            print(f\"{vicino}\", end=\" \")\n        print()  # Nuova linea dopo ogni nodo\n\nProviamo a stampare per verificare di aver caricato il grafo in maniera corretta:\n\nstampa_grafo(grafo)\n\nA -&gt; B C D \nB -&gt; E \nC -&gt; G H \nD -&gt; L \nE -&gt; F \nG -&gt; I \nH -&gt; \nI -&gt; \nF -&gt; \nL -&gt; \n\n\nAdesso proviamo a eseguire la ricerca usando la strategia BFS:\n\n# Esempi di utilizzo\nprint(\"Ricerca BFS:\")\npercorso, visitati = ricerca_generale(grafo, \"A\", \"L\", strategia=\"BFS\")\nprint(\"Nodi visitati:\", visitati)\nprint(\"Percorso completo:\", percorso)\n\nRicerca BFS:\nNodi visitati: ['A', 'B', 'C', 'D', 'E', 'G', 'H']\nPercorso completo: ['A', 'D', 'L']\n\n\nProviamo adesso a eseguire la ricerca usando la strategia DFS:\n\nprint(\"\\nRicerca DFS:\")\npercorso, visitati = ricerca_generale(grafo, \"A\", \"L\", strategia=\"DFS\")\nprint(\"Nodi visitati:\", visitati)\nprint(\"Percorso completo:\", percorso)       \n\n\nRicerca DFS:\nNodi visitati: ['A', 'D']\nPercorso completo: ['A', 'D', 'L']\n\n\nSi noti come, in questo caso, la strategia DFS visiti molti più nodi rispetto alla strategia BFS per arrivare allo stesso percorso come visto nel paragrafo 6.3\n\n\n6.5.2 Esperimento 2: ricerca non informata del cammino in un labirinto\nIl caso del labirinto è un caso particolare di problema di ricerca in un grafo. Cominciamo con la definizione di un labirinto in formato testo. Possiamo descrivere un labirinto come una matrice di caratteri, dove i caratteri rappresentano le celle del labirinto. In particolare possiamo usare i seguenti caratteri:\n\n#: Muro\n: Passaggio libero\nS: Inizio\nE: Fine\n+: Percorso trovato\n-: celle visitate\n\nUn esempio di labirinto è il seguente:\n###                 #########\n#   ###################   # #\n# ####                # # # #\n# ################### # # # #\n#                     # # # #\n##################### # # # #\n#   ##                # # # #\n# # ## ### ## ######### # # #\n# #    #   ##E#         # # #\n# # ## ################ # # #\n### ##             #### # # #\n### ############## ## # # # #\n###             ##    # # # #\n###### ######## ####### # # #\n###### ####             #   #\nS      ######################\nEvidentemente, al di fuori della matrice, il labirinto è circondato da un muro. Prima di tutto dobbiamo leggere il labirinto da un file di testo e trasformarlo in un grafo che rappresenta il labirinto. La funzione prende in input il nome di un file che contiene un labirinto, rappresentato come una griglia 2D di caratteri. Ogni carattere rappresenta elementi diversi: ‘#’ per i muri, ‘S’ per il punto di partenza, ‘E’ per il punto di arrivo e spazi vuoti per i percorsi percorribili. La funzione produce tre risultati: - un dizionario del grafo che mostra come le posizioni del labirinto sono collegate. Il dizionario del grafo usa coppie di coordinate (x,y) come chiavi, con ogni chiave che ha una lista delle coordinate dei vicini raggiungibili. - le coordinate della posizione iniziale - le coordinate della posizione finale.\nIl funzionamento è il seguente: Per ogni posizione nella griglia del labirinto (i due cicli for uno per le righe e uno per le colonne) se non è un muro, controlla se è il punto di partenza (‘S’) o di arrivo (‘E’) e memorizza queste posizioni speciali. Poi, per ogni posizione valida, esamina le quattro possibili direzioni in cui ci si può muovere (su, destra, giù, sinistra) e aggiunge qualsiasi mossa valida alla lista delle connessioni di quella posizione nel grafo.\nLa principale trasformazione dei dati che avviene è la conversione da una rappresentazione a griglia 2D a una struttura a grafo dove ogni posizione è collegata ai suoi vicini accessibili.\nPer esempio, se il labirinto ha un percorso dove ci si può muovere a destra e in basso dalla posizione (1,1), il grafo includerebbe qualcosa come: {(1,1): [(2,1), (1,2)]}, mostrando che dalla posizione (1,1) si possono raggiungere le posizioni (2,1) e (1,2).\n\ndef leggi_labirinto(file_path):\n    \"\"\"\n    Legge un labirinto da un file ASCII e lo trasforma in un grafo.\n    :param file_path: nome del file testo (.txt) contenente il labirinto.\n    :return: Tupla contenente (labirinto, grafo, stato_iniziale, stato_finale.\n    \"\"\"\n    with open(file_path, 'r') as file:\n        labirinto = [list(line.rstrip()) for line in file]\n\n    grafo = {}\n    stato_iniziale = None\n    stato_finale = None\n\n    righe = len(labirinto)\n    colonne = len(labirinto[0])\n\n    for riga in range(righe):\n        for colonna in range(colonne):\n            if labirinto[riga][colonna] in (' ', 'S', 'E'):\n                nodo = (riga, colonna)\n                grafo[nodo] = []\n\n                if labirinto[riga][colonna] == 'S':\n                    stato_iniziale = nodo\n                elif labirinto[riga][colonna] == 'E':\n                    stato_finale = nodo\n\n                # Controlla i vicini (su, giù, sinistra, destra)\n                for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n                    vicinino = (riga + dr, colonna + dc)\n                    if 0 &lt;= vicinino[0] &lt; righe and 0 &lt;= vicinino[1] &lt; colonne and labirinto[vicinino[0]][vicinino[1]] in (' ', 'S', 'E'):\n                        grafo[nodo].append(vicinino)\n\n    return labirinto, grafo, stato_iniziale, stato_finale\n\nAdesso ci occorre una funzione che, dato un labirinto e un percorso, stampa il labirinto con il percorso e i nodi visitati.\n\ndef stampa_labirinto(labirinto):\n    \"\"\"Stampa il labirinto in formato ASCII.\"\"\"\n    for riga in labirinto:\n        print(''.join(riga))\n\ndef stampa_labirinto_con_percorso(labirinto, percorso, visitati):\n    \"\"\"Stampa il labirinto con il percorso e i nodi visitati.\"\"\"\n    labirinto_modificato = [riga.copy() for riga in labirinto]\n\n    for riga, colonna in visitati:\n        if labirinto_modificato[riga][colonna] not in ('S', 'E'):\n            labirinto_modificato[riga][colonna] = '-'\n\n    for riga, colonna in percorso:\n        if labirinto_modificato[riga][colonna] not in ('S', 'E'):\n            labirinto_modificato[riga][colonna] = '+'\n\n    stampa_labirinto(labirinto_modificato)\n\nIpotizzando di aver memorizzato il labirinto nel file “labirinto.txt” possiamo leggerlo e memorizzarlo in un grafo nel seguente modo:\n\nlabirinto, grafo, stato_iniziale, stato_finale = leggi_labirinto(\"labirinto.txt\")\n\nProviamo a risolvere il labirinto con l’algoritmo DFS:\n\npercorso, visitati = ricerca_generale(grafo, stato_iniziale, stato_finale, strategia=\"DFS\")\n\nif isinstance(percorso, list):\n    print(\"\\nLabirinto con percorso trovato:\")\n    stampa_labirinto_con_percorso(labirinto, percorso, visitati)\nelse:\n    print(percorso)\n\n\nLabirinto con percorso trovato:\n###-----------------#########\n#---###################---#-#\n#-####----------------#-#-#-#\n#-###################-#-#-#-#\n#---------------------#-#-#-#\n#####################-#-#-#-#\n#   ##++++++++--------#-#-#-#\n# # ##+### ##+#########-#-#-#\n# #++++#   ##E#---------#-#-#\n# #+##-################-#-#-#\n###+##-------------####-#-#-#\n###+##############-##-#-#-#-#\n###++++---------##----#-#-#-#\n######+########-#######-#-#-#\n######+####-------------#---#\nS++++++######################\n\n\nCome possiamo vedere, l’algoritmo DFS ha trovato un percorso, ma non è l’unico possibile. Per trovare il percorso ha visitatoo molti nodi:\n\nprint(f\"Nodi visitati: {len(visitati)}\")\n\nNodi visitati: 193\n\n\nSe proviamo a risolvere il labirinto con l’algoritmo BFS otteniamo il seguente risultato:\n\npercorso, visitati = ricerca_generale(grafo, stato_iniziale, stato_finale, strategia=\"BFS\")\n\nif isinstance(percorso, list):\n    print(\"\\nLabirinto con percorso trovato:\")\n    stampa_labirinto_con_percorso(labirinto, percorso, visitati)\nelse:\n    print(percorso)\n\n\nLabirinto con percorso trovato:\n###                 #########\n#   ###################   # #\n# ####                # # # #\n# ################### # # # #\n#                     # # # #\n##################### # # # #\n#---##++++++++-       # # # #\n#-#-##+###-##+######### # # #\n#-#++++#---##E#         # # #\n#-#+##-################ # # #\n###+##---------    #### # # #\n###+############## ## # # # #\n###++++---------##    # # # #\n######+########-#######-# # #\n######+####-------------#   #\nS++++++######################\n\n\nPer trovare il percorso ha visitatoo molti nodi:\n\nprint(f\"Nodi visitati: {len(visitati)}\")\n\nNodi visitati: 76\n\n\nCome visto nel paragrafo 6.3 anche in questo caso l’algoritmo BFS trova il percorso più breve visitando un minor numero di nodi rispetto al BFS.\n\n\n6.5.3 Esperimento 3: Algoritmi di ricerca informata\nGli algoritmi di ricerca informata sono una categoria di algoritmi di ricerca che utilizzano informazioni aggiuntive oltre alla struttura del problema per guidare la ricerca verso una soluzione. Queste informazioni aggiuntive sono spesso chiamate euristiche. Vediamo l’esempio proposto nel paragrafo 6.4 :\n\n\n\n\n\ngraph TD\n    A(Castelnuovo di Porto):::start --- |Flaminia| B(Via Flaminia+GRA)\n    A --- |Tiberina| B\n    A --- |Salaria| D(GRA-Salaria)\n    A --- |E35| C(E35+GRA)\n    B --- |GRA| D\n    C --- |GRA| D\n    D --- |Salaria| E(Viale Pola):::stop\nclassDef start fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef stop fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef visited fill:#1f1,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\ngreedy best-first search\nIl grafo, come visto nel paragrafo precedente, può essere rappresentato da un dizionario Python:\n\n# Definizione del grafo come lista di adiacenza\ngrafo = {\n    \"A\": [(\"B\", \"Flaminia\"), (\"C\", \"E35\"), (\"D\", \"Salaria\")],\n    \"B\": [(\"D\", \"GRA\")],\n    \"C\": [(\"D\", \"GRA\")],\n    \"D\": [(\"E\", \"Salaria\")],\n    \"E\": []\n}\n\nMentre l’euristica è rappresentata da un dizionario Python con i nodi come chiavi e i valori euristici, distanza tra il nodo e l’obiettivo, come valori:\n\n# Definizione dei valori euristici\neuristica = {\n    \"A\": 23,\n    \"B\": 7,\n    \"C\": 7,\n    \"D\": 8,\n    \"E\": 0\n}\n\nLa funzione per l’implementazione dell’algoritmo greedy best-first search è facilmente implementabile a partire dalla funzione di ricerca generale vista nel paragrafo modificando la frontiera in una coda a priorità (min-heap) che memorizza i nodi in base al valore di euristica. Inoltre, la funzione di valutazione della frontiera viene modificata per estrarre il nodo con il valore di euristica più basso. La libreria heapq di Python può essere utilizzata per implementare una coda a priorità.\n\nfrom heapq import heappush, heappop\n\ndef greedy_best_first_search(grafo, euristica, start, goal):\n    \"\"\"\n    Esegue la Ricerca Greedy Best-First sul grafo fornito.\n\n    Parametri:\n        grafo (dict): Lista di adiacenza che rappresenta il grafo.\n        euristica (dict): Valori euristici per ogni nodo.\n        start (str): Nodo iniziale.\n        goal (str): Nodo obiettivo.\n\n    Restituisce:\n        list: Percorso dal nodo iniziale al nodo obiettivo.\n    \"\"\"\n    # Coda a priorità (min-heap) per memorizzare (valore euristico, nodo, percorso)\n    coda_prioritaria = []\n    heappush(coda_prioritaria, (euristica[start], start, [start]))\n\n    visitati = set()  # Per tenere traccia dei nodi visitati\n\n    while coda_prioritaria:\n        # Estrai il nodo con il valore euristico più piccolo\n        valore_h, nodo_corrente, percorso = heappop(coda_prioritaria)\n\n        # Se l'obiettivo è raggiunto, restituisci il percorso\n        if nodo_corrente == goal:\n            return percorso\n\n        # Se il nodo è già stato visitato, saltalo\n        if nodo_corrente in visitati:\n            continue\n\n        # Segna il nodo corrente come visitato\n        visitati.add(nodo_corrente)\n\n        # Esplora i vicini\n        for vicino, _ in grafo.get(nodo_corrente, []):\n            if vicino not in visitati:\n                heappush(coda_prioritaria, (euristica[vicino], vicino, percorso + [vicino]))\n\n    # Restituisce una lista vuota se non è stato trovato alcun percorso\n    return []\n\nProviamo a trovare il percorso più breve trale località Castelnuovo di Porto e Viale Pola, ovvero tra i nodi A e E:\n\n# Esecuzione dell'algoritmo\nnodo_iniziale = \"A\"\nnodo_obiettivo = \"E\"\npercorso = greedy_best_first_search(grafo, euristica, nodo_iniziale, nodo_obiettivo)\n\nprint(\"Percorso da\", nodo_iniziale, \"a\", nodo_obiettivo, \":\", percorso)\n\nPercorso da A a E : ['A', 'B', 'D', 'E']\n\n\nQuindi il percorso più breve tra Castelnuovo di Porto e Viale Pola è: [‘A’, ‘B’, ‘D’, ‘E’]\nCioè Castelnuovo di Porto -&gt; Via Flaminia -&gt; GRA -&gt; Salaria -&gt; Viale Pola.\nSi invita il lettore a provare a modificare l’euristica per vedere l’effetto nella ricerca del percorso più breve.\nAlgoritmo A*\nL’algoritmo A* è un algoritmo di ricerca informata che combina l’euristica con la ricerca di costo minimo.\nUsiamo, come esempio, lo stesso grafo del paragrago Section 6.4 e l’euristica definita nel paragrafo precedente.\n\n\n\n\n\ngraph TD\n    A(Castelnuovo di Porto):::start --- |Flaminia, 18| B(Via Flaminia+GRA)\n    A --- |Tiberina, 23| B\n    A --- |Salaria, 27| D(GRA-Salaria)\n    A --- |E35, 21| C(E35+GRA)\n    B --- |GRA, 2| D\n    C --- |GRA, 1| D\n    D --- |Salaria, 9| E(Viale Pola):::stop\n    classDef start fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef stop fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef visited fill:#1f1,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\nCome nel paragrafo precedente, il grafo può essere rappresentato da un dizionario Python. Solo che in questo caso la lista delle adiacenze, oltre ai nomi dei nodi, contiene anche il costo del percorso tra i nodi:\n\n# Definizione del grafo come lista di adiacenza con costi\ngrafo = {\n    \"A\": [(\"B\", 18), (\"C\", 21), (\"D\", 27)],\n    \"B\": [(\"D\", 2)],\n    \"C\": [(\"D\", 1)],\n    \"D\": [(\"E\", 9)],\n    \"E\": []\n}\n\nMentre l’implementazione dell’euristica è la stessa del paragrafo precedente.\n\n# Definizione dei valori euristici\neuristica = {\n    \"A\": 23,\n    \"B\": 7,\n    \"C\": 7,\n    \"D\": 8,\n    \"E\": 0\n}\n\nUna possibile implementazione dell’algoritmo A* basata sull’algoritmo generale di ricerca con l’aggiunta di una coda a priorità basata sulla somma del costo del percorso e dell’euristica, può essere la seguente:\n\nfrom heapq import heappush, heappop\n\ndef a_star_search(grafo, euristica, start, goal):\n    \"\"\"\n    Esegue l'algoritmo A* sul grafo fornito.\n\n    Parametri:\n        grafo (dict): Lista di adiacenza che rappresenta il grafo con costi.\n        euristica (dict): Valori euristici per ogni nodo.\n        start (str): Nodo iniziale.\n        goal (str): Nodo obiettivo.\n\n    Restituisce:\n        list: Percorso dal nodo iniziale al nodo obiettivo.\n    \"\"\"\n    # Coda a priorità (min-heap) per memorizzare (f(n), g(n), nodo, percorso)\n    coda_prioritaria = []\n    heappush(coda_prioritaria, (euristica[start], 0, start, [start]))\n\n    visitati = set()  # Per tenere traccia dei nodi visitati\n\n    while coda_prioritaria:\n        # Estrai il nodo con il valore f(n) più piccolo\n        _, costo_g, nodo_corrente, percorso = heappop(coda_prioritaria)\n\n        # Se l'obiettivo è raggiunto, restituisci il percorso\n        if nodo_corrente == goal:\n            return percorso\n\n        # Se il nodo è già stato visitato, saltalo\n        if nodo_corrente in visitati:\n            continue\n\n        # Segna il nodo corrente come visitato\n        visitati.add(nodo_corrente)\n\n        # Esplora i vicini\n        for vicino, costo in grafo.get(nodo_corrente, []):\n            if vicino not in visitati:\n                nuovo_costo_g = costo_g + costo\n                valore_f = nuovo_costo_g + euristica[vicino]\n                heappush(coda_prioritaria, (valore_f, nuovo_costo_g, vicino, percorso + [vicino]))\n\n    # Restituisce una lista vuota se non è stato trovato alcun percorso\n    return []\n\nProviamo a trovare il percorso più breve trale località Castelnuovo di Porto e Viale Pola, ovvero tra i nodi A e E:\n\n# Esecuzione dell'algoritmo\nnodo_iniziale = \"A\"\nnodo_obiettivo = \"E\"\npercorso = a_star_search(grafo, euristica, nodo_iniziale, nodo_obiettivo)\n\nprint(\"Percorso da\", nodo_iniziale, \"a\", nodo_obiettivo, \":\", percorso)\n\nPercorso da A a E : ['A', 'B', 'D', 'E']\n\n\nQuindi il percorso più breve tra Castelnuovo di Porto e Viale Pola è: [‘A’, ‘B’, ‘D’, ‘E’] Cioè Castelnuovo di Porto -&gt; Via Flaminia -&gt; GRA -&gt; Salaria -&gt; Viale Pola. Quindi l’algoritmo A* ha trovato lo stesso percorso trovato con l’algoritmo di ricerca informata greedy best first search. Questo perche la funzione di costo associato a ogni arco è esattamente l distanza stradale tra i nodi. Si invita il lettore a provare a modificare la funzione di costo per vedere l’effetto nella ricerca del percorso più breve. Ad esempio si potrebbe modificare il costo tra i nodi A e B e tra A e C impostandolo a 50 per simulare un cantiere su Flaminia e Tiberina che rallenta di molto il traffico e vedere quale percorso suggerisce A* in questo caso.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmi di Ricerca</span>"
    ]
  },
  {
    "objectID": "2-4-algoritmi-di-ricerca.html#esercizi",
    "href": "2-4-algoritmi-di-ricerca.html#esercizi",
    "title": "6  Algoritmi di Ricerca",
    "section": "6.6 Esercizi",
    "text": "6.6 Esercizi\n\n6.6.1 Esercizio 1: percorso più breve\nConsidera il seguente grafo:\n\n\n\n\n\ngraph TD\n    S(Start):::start --- A\n    S --- B\n    A --- C\n    A --- D\n    B --- D\n    B --- E\n    C --- F\n    D --- F\n    E --- F\n    F --- G(Goal):::stop\nclassDef start fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef stop fill:#f9f,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\n\nDisegna la sequenza dei passi per trovare il percorso più breve da S a G utilizzando le seguenti strategie di ricerca:\n\nDepth-First Search (DFS)\nBreadth-First Search (BFS)\n\nQuale dei due algoritmi visita meno nodi? Giustifica la tua risposta.\nIndica quale algoritmo garantisce sempre di trovare il percorso più breve e perché.\n\n\n\n6.6.2 Esercizio 2: progetto euristiche\nSupponi di avere una griglia 5x5 rappresentante un labirinto, con il punto di partenza S in (0, 0) e il punto di arrivo E in (4, 4). Alcune celle sono bloccate e non possono essere attraversate:\nS _ _ _ _\n_ # _ # _\n_ _ _ # _\n# _ # _ _\n_ _ _ _ E\n\nProgetta due euristiche ammissibili per il problema:\n\nUna basata sulla distanza di Manhattan.\nUna basata sulla distanza euclidea.\n\nApplica entrambe le euristiche per stimare il costo dal punto di partenza (0, 0) al punto di arrivo (4, 4).\nQuale delle due euristiche è più precisa nel guidare la ricerca?\n\n\n\n6.6.3 Esercizio 3: algoritmi di ricerca informati\nConsidera il seguente grafo con costi sugli archi e valori euristici per ogni nodo:\n\n\n\n\n\ngraph TD\n    A:::start ---|3| B\n    A ---|4| C\n    B ---|2| D\n    B ---|5| E\n    C ---|1| D\n    C ---|6| E\n    D ---|7| F(Goal):::stop\n    E ---|2| F\nclassDef start fill:#f9f,stroke:#333,stroke-width:2px;\nclassDef stop fill:#f9f,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\nEuristiche: - A: 10 - B: 8 - C: 6 - D: 5 - E: 3 - F: 0\n\nApplica l’algoritmo Greedy Best-First Search per trovare il percorso da A a F. Registra tutti i passi in una tabella (candidato, frontiera, percorso, euristica).\nApplica l’algoritmo A* allo stesso grafo e registra i passi.\nConfronta i risultati ottenuti e discuti i vantaggi di A* rispetto al Greedy Best-First Search.\n\n\n\n\n\nRussell, Stuart J., and Peter Norvig. 2021. Intelligenza Artificiale. Un Approccio Moderno. Edited by Francesco Amigoni (Ed. Italiana). Pearson.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmi di Ricerca</span>"
    ]
  },
  {
    "objectID": "2-5-algoritmi-equitativi.html",
    "href": "2-5-algoritmi-equitativi.html",
    "title": "7  Algoritmi Equitativi",
    "section": "",
    "text": "7.1 Introduzione\nIn questo capitolo, esploreremo gli algoritmi di ripartizione equitativa, utili per garantire che le risorse o i beni siano distribuiti in modo equo tra le parti interessate in vari scenari, dalla divisione dei beni durante un divorzio alla distribuzione di fondi di emergenza in situazioni di crisi.\nI criteri di equità applicabili possono variare in base al contesto e alle esigenze specifiche. Alcuni criteri comuni esposti in (Brams and Taylor 1996) includono:\nGli algoritmi di suddivisione equa cercano di trovare soluzioni che bilancino questi criteri, a seconda delle specifiche esigenze del contesto in cui vengono applicati come descritto da (Robertson and Webb 1998).",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Algoritmi Equitativi</span>"
    ]
  },
  {
    "objectID": "2-5-algoritmi-equitativi.html#introduzione",
    "href": "2-5-algoritmi-equitativi.html#introduzione",
    "title": "7  Algoritmi Equitativi",
    "section": "",
    "text": "Proporzionalità: Ogni partecipante riceve una quota proporzionale alle proprie pretese o contributi.\nInvidia-zero: Nessun partecipante deve preferire la parte assegnata a un altro partecipante alla propria parte.\nEfficienza Pareto: Non è possibile riassegnare le risorse in modo che qualcuno sia in una situazione migliore senza che qualcun altro sia in una situazione peggiore.\nEquità equitativa: Ogni partecipante percepisce di aver ricevuto una parte equa in base a criteri specifici.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Algoritmi Equitativi</span>"
    ]
  },
  {
    "objectID": "2-5-algoritmi-equitativi.html#glossario-regole-e-assunzioni",
    "href": "2-5-algoritmi-equitativi.html#glossario-regole-e-assunzioni",
    "title": "7  Algoritmi Equitativi",
    "section": "7.2 glossario, regole e assunzioni",
    "text": "7.2 glossario, regole e assunzioni\n\n7.2.1 glossario\n\nagenti partecipanti : gli agenti o partecipanti che devono mettersi d’accordo sulla divisione di un certo numero di beni.\nbeni : gli oggetti o le risorse che devono essere suddivisi tra gli agenti.\nBeni divisibili : beni che possono essere suddivisi in parti più piccole senza perdere il loro valore intrinseco (es. cibo, denaro o immobili).\nBeni indivisibili : beni che non possono essere suddivisi senza perdere il loro valore o funzionalità (es. un’auto, un’opera d’arte o un ruolo o incarico specifico).\nBeni Combinati : beni che sono una combinazione di elementi divisibili e indivisibili (es. un’azienda, un’iniziativa di beneficenza o un’organizzazione).\nBeni con Valore Soggettivo: come oggetti con valore sentimentale o elementi artistici o culturali, il cui valore può dipendere dal gusto personale.\nBeni con Valore Complesso: come proprietà immobiliari o attività commerciali, che possono avere un valore complesso che dipende dalla loro funzionalità e dalla loro posizione.\nBeni Temporanei : beni che possono essere utilizzati per un certo periodo di tempo e poi riassegnati (es. uso di risorse comuni, servizi o turni di lavoro).\nBeni Digitali : beni che possono essere duplicati e condivisi senza perdere valore (es. software, contenuti digitali).\n\n\n\n7.2.2 Regole\nAffinché la divisione di un bene S sia equa in (Moulin 2003) si osserva che devono essere soddisfatte le seguenti condizioni:\n\ni giocatori devono essere partecipanti volontari e accettare le regole del gioco come vincolanti.\nI giocatori devono agire razionalmente secondo il loro sistema di credenze.\nLe regole della matematica si applicano quando si assegnano valori agli oggetti in S.\nSolo i giocatori sono coinvolti nel gioco, non ci sono agenti esterni come avvocati o altri intermediari.\n\nSe i giocatori seguono le regole, il gioco terminerà dopo un numero finito di mosse dei giocatori e risulterà in una divisione di S.\n\n\n7.2.3 Assunzioni\nGli algoritmi si basano sulle seguenti assunzionimere quanto segue:\n\nTutti i giocatori giocano in modo corretto.\nNon hanno informazioni precedenti sui gusti o le avversioni degli altri giocatori.\nNon assegnano valori in modo da manipolare il gioco.\nTutti i giocatori hanno uguali diritti nella condivisione dell’insieme S. In altre parole, se ci sono tre giocatori, ogni giocatore ha diritto ad almeno 1/3 di S.\n\nSe queste assunzioni non sono soddisfatte, la divisione potrebbe non essere completamente equa.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Algoritmi Equitativi</span>"
    ]
  },
  {
    "objectID": "2-5-algoritmi-equitativi.html#algoritmi-di-ripartizione-equitativa",
    "href": "2-5-algoritmi-equitativi.html#algoritmi-di-ripartizione-equitativa",
    "title": "7  Algoritmi Equitativi",
    "section": "7.3 Algoritmi di Ripartizione Equitativa",
    "text": "7.3 Algoritmi di Ripartizione Equitativa\n\n7.3.1 Il problema della divisione equa\nUn problema tipico di ripartizione equa può essere formulato come segue: Alice, Bruno, Carla e Davide hanno una torta. La torta è divisa in 4 parti non necessariamente uguali e non con la stessa farcitura e/o copertura. In questo caso le porzioni di torta si intendono indivisibili. Questa assunzione è importante perché se le porzioni di torta fossero divisibili, allora la soluzione sarebbe banale. Ognuno dei 4 partecipanti ha una sua preferenza per ognuna delle quattro parti. Le preferenze sono riassunte nella seguente tabella:\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nLa domanda che ci si pone è: Quale porzione di torta considererebbe equa ogni giocatore? È importante ricordare che un algoritmo di ripartizione equa si basa sulle assunzioni del paragrafo 7.2.3. Pertanto, ogni giocatore ha espresso la propria preferenza senza conoscere le preferenze degli altri partecipanti.\nUn semplice algoritmo di ripartizione equa descritto in (Brams and Taylor 1996)può essere descritto come segue:\n1. **Preparazione:**\n   - Prendi le preferenze di ogni partecipante.\n   - Crea una lista dei partecipanti e una lista delle loro preferenze per ogni porzione.\n\n2. **Assegnazione:**\n   - Per ogni porzione disponibile:\n     - Trova il partecipante che preferisce di più quella porzione tra quelli che non hanno ancora ricevuto una porzione.\n     - Assegna quella porzione a quel partecipante.\n\n3. **Risultato:**\n   - Crea un elenco dove ogni partecipante è associato alla porzione che ha ricevuto.\n\nQuesto algoritmo assegna le porzioni di torta in base alle preferenze dei partecipanti, garantendo che ogni partecipante riceva almeno una porzione. Applicando questo semplice algoritmo al esempio sopra descritto si ottiene la soluzione illustrata nella tabella seguente, dove è evidenziata in grassetto la porzione assegnata a ciascun giocatore, rispettando le preferenze manifestate.\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nSi veda il paragrafo 7.4.1 per una implementazione in Python di questo algoritmo.\nEvidentemente, l’algoritmo proposto non è l’unica soluzione possibile e può dare origine a situazioni di iniquità o di conflitti. Ad esempio se le preferenze dei partecipanti sono:\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n20%\n40%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nSi noti il conflitto tra Alice e Carla per la porzione 2. La soluzione a cui arriva l’algoritmo visto è:\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nIn questo caso, Carla riceve una porzione per la quale ha espresso un interesse minore e potrebbe invidiare Alice, che ha ottenuto proprio la porzione che lei avrebbe preferito.\n\n\n7.3.2 Valore soggettivo di un bene\nPrima di trattare l’argomento dell’invidia, c’è un altro aspetto interessante da approfondire: il valore soggettivo del bene. Ad esempio, nella suddivisione esaminata, se la torta costa 18 €, quale sarebbe il valore economico di ogni porzione di torta per ciascun partecipante? Tenendo conto che le preferenze sono le seguenti:\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\nAlice ha il 50% di prefernenze per la porzione 2 quindi per lei la porzione 2 vale il 50% di 18€ = 9€ e così via. La tabella dei valori delle singole perzioni per ogni partecipante è la seguente:\n\n\n\nPartecipante\nporzione 1\nporzione 2\nporzione 3\nporzione 4\n\n\n\n\nAlice\n1,80€\n9,00€\n5,40€\n1,80€\n\n\nBruno\n5,40€\n5,40€\n1,80€\n5,40€\n\n\nCarla\n7,20€\n3,60€\n3,60€\n3,60€\n\n\nDavide\n4,50€\n4,50€\n4,50€\n4,50€\n\n\n\nVediamo un altro esempio di calcolo del valore soggettivo di un bene. Alice vede una torta che costa 18€ di cui una metà al cioccolato e l’altra al pistacchio. Ad Alice piace il cioccolato molto più che il pistacchio. Quindi, Alice valuta la porzione al cioccolato al 90% e la porzione al pistacchio al 10%. Quindi Alice valuta la metà al cioccolato al 90% di 18€ = 16,20€ e la metà al pistacchio al 10% di 18€ = 1,80€.\nIn generale, il valore soggettivo di un bene può essere influenzato da una varietà di fattori, che riflettono le percezioni individuali e le circostanze specifiche. Ecco alcuni degli aspetti principali che possono influenzare il valore soggettivo:\n\nScarsità : Un bene raro o difficile da reperire tende ad avere un valore soggettivo più elevato1. Domanda: La popolarità o la desiderabilità di un bene possono aumentarne il valore percepito1.\nPreferenze personali : Gli interessi, i gusti e le preferenze individuali giocano un ruolo significativo nel determinare il valore di un bene per una persona1.\nSignificato culturale : Il valore di un bene può essere influenzato dal suo significato o dalla sua importanza in una determinata cultura.\nCircostanze situazionali : Eventi specifici o situazioni particolari possono alterare il valore di un bene. Ad esempio, l’acqua potrebbe avere un valore molto più alto in un deserto rispetto a una città2.\nAffinità personale : Il legame emotivo o la storia personale con un bene possono aumentarne il valore per un individuo2.\nIncertezza e mancanza di conoscenza : A volte le persone possono valutare l’importanza di un bene in modo non conforme alla sua reale importanza a causa dell’incertezza o della mancanza di informazioni.\n\nQuesti fattori dimostrano che il valore di un bene non è fisso o intrinseco, ma è piuttosto determinato dalle percezioni e dalle circostanze individuali. La teoria del valore soggettivo sostiene che il valore di un bene dipende dall’ambiente e dalle persone che lo percepiscono, piuttosto che dai costi di produzione o dal lavoro necessario per crearlo1.\n\n\n7.3.3 Mitigazione dell’invidia\nCome anticipato, è necessario approfondire il problema della divisione equa senza invidia affrontato nel dettaglio in (Procaccia 2013) al quale si rimanda per ulteriori approfondimenti sul tema. Immaginiamo due amici, Alice e Bruno, che devono dividersi una serie di oggetti di valore in modo che nessuno dei due si senta invidioso dell’altro. Ad esempio, supponiamo che Alice e Bruno debbano dividersi i seguenti beni indivisibili con le rispettive valutazioni avendo ognuno a disposizione 10 punti da assegnare in totale:\n\n\n\nOggetto\nAlice\nBruno\n\n\n\n\norologio\n4\n2\n\n\nlibro\n2\n3\n\n\npenna\n2\n3\n\n\nquadro\n2\n2\n\n\n\nPer tenere conto dell’invidia l’algoritmo proposto nel precedente paragrafo 7.3.1 non è sufficiente e può essere modificato come segue come discusso in (Lipton et al. 2004):\n1. **Preparazione:**\n   - Prendi le preferenze di ogni partecipante.\n   - Ordina le preferenze di ogni partecipante in ordine decrescente.\n\n2. **Processo Iterativo:**\n   - **Prima Fase - Assegnazione Tentativa:**\n     - Inizia con la porzione che ha il punteggio più alto per ogni partecipante.\n     - Ogni partecipante \"propone\" la sua porzione preferita.\n     - Se una porzione è proposta da più partecipanti, scegli quello che la preferisce di più (in caso di pari merito, scegli arbitrariamente).\n\n   - **Seconda Fase - Risoluzione delle invidie:**\n     - Controlla se esiste invidia:\n       - Per ogni partecipante, confronta la sua porzione assegnata con quella di ogni altro partecipante. Se preferisce la porzione di un altro, si dice che \"invidia\" quell'altro partecipante.\n     - Se c'è invidia:\n       - Il partecipante invidioso \"prova\" a prendere la porzione invidiata.\n       - Se il possessore attuale della porzione preferisce ancora la sua attuale porzione rispetto a quella che potrebbe ottenere, mantiene la sua.\n       - Altrimenti, scambiano le porzioni.\n     - Ripeti questo processo finché non ci sono più invidie.\n\n3. **Risultato:**\n   - L'allocazione finale è dove nessuna persona invidia l'altra.\nApplicando questo algoritmo alle preferenze di Alice e Bruno, otteniamo la allocazione descritta dalla seguente tabella, dove 0 e 1 indicano bene non allocato e bene allocato rispettivamente:\n\n\n\npartecipante\norologio\nlibro\npenna\nquadro\n\n\n\n\nAlice\n1\n0\n0\n1\n\n\nBruno\n0\n1\n1\n0\n\n\n\nAlice riceve l’orologio e il quadro, mentre Bruno riceve il libro e la penna, garantendo che nessuno dei due si senta invidioso dell’altro. Nel paragrafo 7.4.2 è mostrata l’implementazione di un algoritmo di divisione equa senza invidia in Python.\nPer chi volesse applicare gli algoritmi equitativi in casi reali su una piattaforma online si segnala l’interessante sito web Spliddit Algorithms che fornisce un’ampia gamma di algoritmi equitativi (Goldman and Procaccia 2014).",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Algoritmi Equitativi</span>"
    ]
  },
  {
    "objectID": "2-5-algoritmi-equitativi.html#laboratorio-python",
    "href": "2-5-algoritmi-equitativi.html#laboratorio-python",
    "title": "7  Algoritmi Equitativi",
    "section": "7.4 Laboratorio Python",
    "text": "7.4 Laboratorio Python\n\n7.4.1 Esperimento 1: Algoritmo di divisione equa semplice\nIl codice che segue è l’implementazione dell’algorimo di divisione equa semplice.\n\ndef divisione_equa(preferenze):\n    # 1. **Inizializzazione** : Converti il dizionario delle preferenze in una lista \n    # di tuple per una gestione più semplice\n    partecipanti = list(preferenze.keys())\n    valori_preferenze = list(preferenze.values())\n\n    # Numero di partecipanti e porzioni\n    num_partecipanti = len(partecipanti)\n    num_porzioni = len(valori_preferenze[0])\n\n    # Inizializza la lista di allocazione\n    allocazione = [-1] * num_partecipanti\n    porzioni_usate = [False] * num_porzioni\n\n    # 2. **Funzione `trova_preferenza_massima`** : Funzione per trovare il partecipante \n    # con la preferenza più alta per una data porzione\n    def trova_preferenza_massima(porzione):\n        preferenza_massima = -1\n        indice_partecipante = -1\n        for i in range(num_partecipanti):\n            if valori_preferenze[i][porzione] &gt; preferenza_massima and allocazione[i] == -1:\n                preferenza_massima = valori_preferenze[i][porzione]\n                indice_partecipante = i\n        return indice_partecipante\n\n    # 3. **Assegnazione delle Porzioni** : Assegna le porzioni ai partecipanti\n    for porzione in range(num_porzioni):\n        indice_partecipante = trova_preferenza_massima(porzione)\n        allocazione[indice_partecipante] = porzione\n        porzioni_usate[porzione] = True\n\n    # 4. **Creazione del Risultato** : Crea un dizionario di risultato per mappare \n    # i partecipanti alle loro porzioni allocate\n    risultato = {partecipanti[i]: f\"porzione {allocazione[i] + 1}\" \\\n                 for i in range(num_partecipanti)}\n\n    return risultato\n\n# 5. **Esecuzione del Codice**: Esegui il codice con le preferenze fornite\n\n# Preferenze dei partecipanti\npreferenze = {\n    'Alice': [10, 50, 30, 10],  # Preferenze per le porzioni 1, 2, 3, e 4\n    'Bruno': [30, 30, 10, 30],\n    'Carla': [40, 20, 20, 20],\n    'Davide': [25, 25, 25, 25]\n}\n\nprint(\"Preferenze dei partecipanti:\")\nfor p in preferenze:\n    print(p, preferenze[p])\n\n\n# Trova la divisione equa delle porzioni\nallocazione = divisione_equa(preferenze)\n\n# Stampa il risultato\nprint(\"Una divisione equa delle porzioni è la seguente:\")\nfor partecipante, porzione in allocazione.items():\n    print(f\"{partecipante} riceve {porzione}\")\n\nPreferenze dei partecipanti:\nAlice [10, 50, 30, 10]\nBruno [30, 30, 10, 30]\nCarla [40, 20, 20, 20]\nDavide [25, 25, 25, 25]\nUna divisione equa delle porzioni è la seguente:\nAlice riceve porzione 2\nBruno riceve porzione 4\nCarla riceve porzione 1\nDavide riceve porzione 3\n\n\nIl semplice codice Python proposto implementa un algoritmpo di divisione equa nel seguente modo:\n\nInizializzazione:\n\nConvertiamo il dizionario delle preferenze in una lista di tuple per una gestione più semplice.\nOtteniamo i nomi dei partecipanti e le loro preferenze.\nInizializziamo le liste allocazione e porzioni_usate per tenere traccia delle porzioni assegnate e delle porzioni già utilizzate.\n\nFunzione trova_preferenza_massima:\n\nQuesta funzione trova il partecipante con la preferenza più alta per una data porzione che non ha ancora ricevuto una porzione.\nScorre tutti i partecipanti e confronta le loro preferenze per la porzione corrente, restituendo l’indice del partecipante con la preferenza massima.\n\nAssegnazione delle Porzioni:\n\nPer ogni porzione, troviamo il partecipante con la preferenza più alta utilizzando la funzione trova_preferenza_massima.\nAssegniamo la porzione a quel partecipante e segniamo la porzione come utilizzata.\n\nCreazione del Risultato:\n\nCreiamo un dizionario risultato che mappa i partecipanti alle loro porzioni assegnate.\nRestituiamo il dizionario risultato.\n\nEsecuzione del Codice:\n\nDefiniamo le preferenze dei partecipanti.\nChiamiamo la funzione divisione_equa per ottenere la divisione delle porzioni.\nStampiamo il risultato.\n\n\n\n\n7.4.2 Esperimento 2: Algoritmo di divisione equa senza invidia\nNwl seguito si propone una implementazione dell’algoritmo envy free in Python nel caso di beni indivisibili:\n\ndef allocazione_senza_invidia(beni, valutazioni):\n    \"\"\"\n    Algoritmo senza invidia per la divisione di beni indivisibili tra più persone.\n\n    beni: lista di beni da dividere\n    valutazioni: dizionario con le valutazioni dei beni per ciascun partecipante\n    \"\"\"\n    partecipanti = list(valutazioni.keys())\n    \n    # Inizializzazione delle assegnazioni\n    assegnazione = {p: [] for p in partecipanti}\n    valori_totali = {p: 0 for p in partecipanti}\n\n    # Ordinamento dei beni in base alla somma delle valutazioni di tutti\n    beni_ordinati = sorted(beni, \n                          key=lambda x: sum(valutazioni[p][x] for p in partecipanti), \n                          reverse=True)\n\n    # Prima assegnazione dei beni\n    for bene in beni_ordinati:\n        # Trova il partecipante con il valore totale minimo\n        min_partecipante = min(partecipanti, key=lambda p: valori_totali[p])\n        assegnazione[min_partecipante].append(bene)\n        valori_totali[min_partecipante] += valutazioni[min_partecipante][bene]\n\n    # Verifica e correzione delle invidie\n    for bene in beni_ordinati:\n        for p1 in partecipanti:\n            for p2 in partecipanti:\n                if p1 != p2 and bene in assegnazione[p2]:\n                    if valutazioni[p1][bene] &gt; valutazioni[p2][bene] and \\\n                       valori_totali[p1] &lt; valori_totali[p2]:\n                        assegnazione[p2].remove(bene)\n                        assegnazione[p1].append(bene)\n                        valori_totali[p1] += valutazioni[p1][bene]\n                        valori_totali[p2] -= valutazioni[p2][bene]\n\n    return assegnazione\n\nL’algoritmo implementa una divisione equa di beni indivisibili tra più persone, cercando di minimizzare l’invidia tra i partecipanti. Analizziamo il codice passo per passo.\n\nDefinizione della Funzione:\ndef allocazione_senza_invidia(beni, valutazioni):\n\nDefinisce una funzione chiamata allocazione_senza_invidia che accetta due parametri:\n\nbeni: lista degli oggetti da dividere\nvalutazioni: dizionario con le valutazioni di ogni partecipante per ogni bene\n\n\nInizializzazione delle Assegnazioni:\npartecipanti = list(valutazioni.keys())\nassegnazione = {p: [] for p in partecipanti}\nvalori_totali = {p: 0 for p in partecipanti}\nQuesta fase\n\nEstrae la lista dei partecipanti\nCrea un dizionario vuoto per tracciare i beni assegnati\nInizializza a zero i valori totali per ogni partecipante\n\nOrdinamento dei Beni:\nbeni_ordinati = sorted(beni, \n                       key=lambda x: sum(valutazioni[p][x] for p in partecipanti), reverse=True)\n\nI beni vengono ordinati in base al loro valore totale (somma delle valutazioni di tutti i partecipanti) in ordine decrescente.\n\nPrima assegnazione dei Beni:\nfor bene in beni_ordinati:\n  min_partecipante = min(partecipanti, key=lambda p: valori_totali[p])\n  assegnazione[min_partecipante].append(bene)\n  valori_totali[min_partecipante] += valutazioni[min_partecipante][bene]\nPer ogni bene:\n\nTrova il partecipante con il minor valore totale\nAssegna il bene a quel partecipante\nAggiorna il valore totale del partecipante\n\nVerifica e Correzione delle Invidie:\nfor bene in beni_ordinati:\nfor p1 in partecipanti:\n    for p2 in partecipanti:\n        if p1 != p2 and bene in assegnazione[p2]:\n            if valutazioni[p1][bene] &gt; valutazioni[p2][bene] and \\\n               valori_totali[p1] &lt; valori_totali[p2]:\n                assegnazione[p2].remove(bene)\n                assegnazione[p1].append(bene)\n                valori_totali[p1] += valutazioni[p1][bene]\n                valori_totali[p2] -= valutazioni[p2][bene]\nQuesta fase verifica e corregge eventuali invidie:\n\nControlla ogni coppia di partecipanti\nSe un partecipante valuta più un bene assegnato a un altro e ha un valore totale minore di quello dell’altro, effettua uno scambio di beni.\n\nRitorno delle Assegnazioni:\nreturn assegnazione\n\nRestituisce il dizionario delle assegnazioni finali.\n\n\nCaso d’Uso\nDivisione di una serie di oggetti di valore tra Alice e Bruno, in modo che nessuno dei due si senta invidioso dell’altro. Ad esempio, supponiamo che Alice e Bruno debbano dividersi i seguenti beni con le rispettive valutazioni personali:\n\nbeni = ['orologio', 'libro', 'penna', 'quadro']\nvalutazioni = {\n    'Alice': {'orologio': 4, 'libro': 2, 'penna': 2, 'quadro': 2},\n    'Bruno': {'orologio': 2, 'libro': 3, 'penna': 3, 'quadro': 2}\n}\n\nUtilizzando la funzione allocazione_senza_invidia, possiamo ottenere una divisione equa:\n\nrisultato = allocazione_senza_invidia(beni, valutazioni)\nprint(\"Allocazione finale:\")\nfor persona, oggetti in risultato.items():\n    print(f\"{persona}: {oggetti}\")\n\nAllocazione finale:\nAlice: ['orologio', 'quadro']\nBruno: ['libro', 'penna']",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Algoritmi Equitativi</span>"
    ]
  },
  {
    "objectID": "2-5-algoritmi-equitativi.html#esercizi",
    "href": "2-5-algoritmi-equitativi.html#esercizi",
    "title": "7  Algoritmi Equitativi",
    "section": "7.5 esercizi",
    "text": "7.5 esercizi\n\n7.5.1 Esercizio 1: divisione equa di una torta\nHai quattro partecipanti (Alice, Bruno, Carla, e Davide) che devono dividersi una torta con quattro porzioni, ciascuna con percentuali di preferenza diverse:\n\n\n\nPartecipante\nPorzione 1\nPorzione 2\nPorzione 3\nPorzione 4\n\n\n\n\nAlice\n10%\n50%\n30%\n10%\n\n\nBruno\n30%\n30%\n10%\n30%\n\n\nCarla\n40%\n20%\n20%\n20%\n\n\nDavide\n25%\n25%\n25%\n25%\n\n\n\n\nAssegna le porzioni usando l’algoritmo semplice di ripartizione equa descritto nel testo.\nAnalizza la distribuzione ottenuta e discuti se i partecipanti potrebbero sentirsi invidiosi delle porzioni assegnate.\nProponi una soluzione alternativa per mitigare eventuali invidie.\n\n\n\n7.5.2 Esercizio 2: divisione beni indivisibili con valori soggettivi\nUn gruppo di tre amici deve dividersi un insieme di beni con valori soggettivi assegnati a ciascun bene da ogni partecipante. I beni e le rispettive valutazioni sono:\n\n\n\nBene\nValore per Alice\nValore per Bruno\nValore per Carla\n\n\n\n\nLaptop\n€900\n€850\n€1000\n\n\nSmartphone\n€700\n€750\n€700\n\n\nTablet\n€400\n€300\n€350\n\n\n\n\nCalcola il valore totale dei beni assegnati a ciascun partecipante se si utilizza un algoritmo semplice basato su massimizzazione delle preferenze individuali.\nValuta se l’assegnazione è equa e giustifica la tua risposta.\nProponi un’assegnazione alternativa che riduca l’invidia tra i partecipanti.\n\n\n\n7.5.3 Esercizio 3: divisione di beni indivisibili con valutazioni soggettive\nDue amici, Alice e Bruno, devono dividersi i seguenti beni indivisibili, con un massimo di 10 punti da distribuire in totale come valutazione personale per ogni partecipante:\n\n\n\nBene\nValutazione di Alice\nValutazione di Bruno\n\n\n\n\nBicicletta\n6\n4\n\n\nOrologio\n2\n3\n\n\nLibro\n2\n3\n\n\n\n\nUtilizza l’algoritmo senza invidia descritto nel testo per assegnare i beni.\nSpiega perché la soluzione ottenuta è senza invidia, oppure discuti eventuali problemi riscontrati.\nCalcola l’equità in termini di punti assegnati e confronta con un’assegnazione casuale dei beni.\n\n\n\n\n\nBrams, Steven J., and Alan D. Taylor. 1996. Fair Division: From Cake-Cutting to Dispute Resolution. Cambridge University Press.\n\n\nGoldman, J., and A. D. Procaccia. 2014. “Spliddit: Unleashing Fair Division Algorithms.” ACM SIGecom Exchanges 13 (2): 41–46.\n\n\nLipton, Richard J., Evangelos Markakis, Elchanan Mossel, and Amin Saberi. 2004. “On Approximately Fair Allocations of Indivisible Goods.” Proceedings of the 5th ACM Conference on Electronic Commerce, 125–31.\n\n\nMoulin, Herv ’e. 2003. Fair Division and Collective Welfare. MIT Press.\n\n\nProcaccia, Ariel D. 2013. “Cake Cutting Algorithms.” Handbook of Computational Social Choice, 311–30.\n\n\nRobertson, Jack, and William Webb. 1998. Cake-Cutting Algorithms: Be Fair If You Can. A K Peters/CRC Press.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Algoritmi Equitativi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html",
    "href": "2-6-algoritmi-predittivi.html",
    "title": "8  Algoritmi Predittivi",
    "section": "",
    "text": "8.1 Introduzione\nGli algoritmi predittivi rappresentano un salto qualitativo rispetto agli algoritmi deterministici e probabilistici visti nei capitoli precedenti(Bishop 2006). Mentre gli algoritmi deterministici seguono regole ben definite per raggiungere una soluzione e gli algoritmi probabilistici utilizzano la probabilità per gestire l’incertezza, gli algoritmi predittivi apprendono dai dati per costruire modelli capaci di fare previsioni su eventi futuri.\nDifferenze principali:\nLa vera forza degli algoritmi predittivi risiede nella loro capacità di migliorare le decisioni grazie all’apprendimento automatico. Possono affrontare scenari complessi dove non esistono regole fisse e dove i dati contengono rumore o incertezza. Gli algoritmi di predizione sono usati per creare modelli basati sull’ apprendedimento dei dati misurati o prodotti in un certo dominio applicativo al fine di fare previsioni su eventi futuri. Questi algoritmi possono essere classificati in diverse categorie in base al tipo di apprendimento, al tipo di output, e alle tecniche utilizzate (Murphy 2012):\nClassificazione Basata sul Tipo di Apprendimento:\nClassificazione Basata sul Tipo di Output:\nClassificazione Basata sulle Tecniche Utilizzate:\nOgni algoritmo ha i suoi vantaggi e svantaggi, e la scelta dipende da vari fattori come la dimensione e la natura del dataset, la velocità richiesta, la trasparenza del modello e la capacità di gestire dati non lineari o mancanti. Ad esempio, gli alberi decisionali sono facili da interpretare ma possono soffrire di overfitting, mentre le SVM sono efficaci con dataset di piccole dimensioni ma meno efficienti con dataset molto grandi². L’agente deve imparare a riconoscere alcune configurazioni del suo percepito sulla base di un esperienza fatta su casi detti di training e deve essere in grado di riconoscere un nuovo percepito mai visto prima. Il percepito dell’agente è composto da dati, caratteristiche, che possono essere di tipo continuo (es. temperatura) o categoriali (es. colore rosso). I dati categoriali possono essere ordinabili (es. scarso, insufficiente, …) o non ordinabili (es. sesso) All’agente può essere chiesto di predire un dato continuo, nel qual caso si tratta di predizione o regressione, oppure può essere chiesto di predire un dato categoriale, nel qual caso si tratta di classificazione. Il processo di predizione segue il seguente flusso:\nflowchart TD\n    A[1.Definizione del Problema] --&gt; B(2.Raccolta dei Dati)\n    B --&gt; C(3.Pre-elaborazione dei Dati)\n    C --&gt; D(4.Divisione dei dati)\n    D --&gt; E(5.Scelta dell'algoritmo)\n    E --&gt; F(6.Addestramento del Modello)\n    F --&gt; G{7valutazione risultati modello}\n    G --&gt;|valutazione scarsa| H(8.Ottimizzazione parametri)\n    H --&gt; F\n    G --&gt;|9.valutazione buona| I(Deployment)\n    G --&gt;|10.modello inadeguato|E\n    I --&gt; L(11.Monitoraggio e manutenzione)\n\n\n\n\nFigure 8.1: Diagramma di flusso del processo di predizione\nNei prossimi paragrafi si presenterà una descrizione di ognuno di questi passi con la descrizione di un caso concreto di previsione della probabilità che un imputato in libertà vigilata commetta un nuovo reato. Si veda (Inc. 2018) per la descrizione di un applicativo di questo tipo in uso presso gli organi giudiziari negli Stati Uniti.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#introduzione",
    "href": "2-6-algoritmi-predittivi.html#introduzione",
    "title": "8  Algoritmi Predittivi",
    "section": "",
    "text": "Deterministici:\n\nProducono lo stesso risultato ogni volta con gli stessi input.\nNon gestiscono incertezza o variabilità nei dati.\nEsempio: algoritmi di ricerca in grafi (DFS, BFS).\n\nProbabilistici:\n\nIncludono l’incertezza nei calcoli.\nBasati su modelli matematici che stimano la probabilità di eventi.\nEsempio: filtri email o algoritmi Bayesiani.\n\nPredittivi:\n\nSi basano sull’apprendimento dai dati per costruire modelli.\nAdattano il comportamento in base a nuove informazioni.\nPossono gestire sia dati complessi che non lineari.\nEsempi: regressione lineare, reti neurali, support vector machine (SVM).\n\n\n\n\n\nApprendimento Supervisionato: Gli algoritmi di apprendimento supervisionato richiedono un set di dati etichettato per l’addestramento. Utilizzano queste etichette per apprendere una funzione che mappa gli input agli output desiderati. Esempi includono la regressione lineare, gli alberi decisionali e le reti neurali¹.\nApprendimento Non Supervisionato: Questi algoritmi scoprono pattern nascosti o strutture nei dati non etichettati. Tecniche comuni sono la clusterizzazione e la riduzione della dimensionalità¹.\nApprendimento Semi-supervisionato e Rinforzato: Combinano elementi dei primi due tipi, utilizzando un piccolo set di dati etichettati insieme a una grande quantità di dati non etichettati, o apprendendo attraverso il rinforzo da un ambiente¹.\n\n\n\nClassificazione: Quando l’output è una categoria, come “spam” o “non spam” in un filtro di posta elettronica, si parla di classificazione. Gli algoritmi di classificazione assegnano un’etichetta discreta a un’istanza di input¹.\nRegressione: Se l’output è un valore continuo, come il prezzo di una casa, si utilizza la regressione. Gli algoritmi di regressione prevedono un valore numerico basato sugli input¹.\nRanking: Alcuni algoritmi ordinano gli elementi in base alla probabilità di appartenenza a una certa categoria o valore¹.\n\n\n\nAlberi Decisionali: Suddividono i dati in modo gerarchico basandosi su attributi specifici. Sono semplici da interpretare ma possono soffrire di overfitting².\nRandom Forest: Una collezione di alberi decisionali che riduce il rischio di overfitting e gestisce meglio le variabili non correlate².\nSupport Vector Machine (SVM): Trovano il miglior iperpiano che separa i dati in classi. Sono efficaci in spazi ad alta dimensionalità².\nK-Nearest Neighbors (K-NN): Classificano i nuovi dati in base alla classe più comune tra i vicini più prossimi. Sono semplici da implementare ma computazionalmente costosi².\nReti Neurali: Sono modelli ispirati al funzionamento del cervello umano e possono catturare relazioni complesse nei dati¹.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#definizione-del-problema",
    "href": "2-6-algoritmi-predittivi.html#definizione-del-problema",
    "title": "8  Algoritmi Predittivi",
    "section": "8.2 Definizione del Problema",
    "text": "8.2 Definizione del Problema\nQuestp è il primo passo nel processo di predizione nell’intelligenza artificiale. Questa fase richiede una comprensione chiara e precisa dell’obiettivo che si desidera raggiungere con l’algoritmo di predizione. Che si tratti di prevedere il comportamento del consumatore, di diagnosticare malattie o di identificare frodi, è fondamentale stabilire parametri chiari e misurabili. La definizione del problema guida tutte le fasi successive, dalla raccolta dei dati alla scelta dell’algoritmo più adatto, assicurando che l’intero processo sia allineato con l’obiettivo finale. Un’accurata definizione del problema è la base per un modello predittivo efficace e funzionale. esempio pratico: Prevedere la probabilità che un imputato in libertà vigilata commetta un nuovo reato.\n\nObiettivo: Stimare il rischio di recidiva.\nDati necessari: Età, tipo di reato precedente, durata della libertà vigilata.\nIpotesi: Alcuni fattori, come precedenti specifici, possono aumentare il rischio.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#raccolta-dei-dati",
    "href": "2-6-algoritmi-predittivi.html#raccolta-dei-dati",
    "title": "8  Algoritmi Predittivi",
    "section": "8.3 Raccolta dei Dati",
    "text": "8.3 Raccolta dei Dati\nSi tratta di acquisire informazioni rilevanti per il problema da risolvere. Questo processo non si limita alla mera acquisizione di dati grezzi; è una pratica strategica che trasforma questi dati in insights preziosi, capaci di guidare decisioni informate. I dati possono essere raccolti da fonti interne come database aziendali, o esterne come social media, sensori IoT (Internet of Things), o registri pubblici. La raccolta deve essere sistematica e organizzata, assicurando che i dati siano accurati, completi e aggiornati. È fondamentale anche considerare la privacy e la sicurezza dei dati durante la raccolta e l’elaborazione. Esempio Pratico: Raccolta di dati da archivi giudiziari, registri penitenziari e rapporti sociali.\n\nFonti: Sentenze, relazioni degli assistenti sociali.\nDati:\n\nEtà: 25, 30, 35, 40, 45, 50, 55, 60, 65, 70\nTipo di reato: furto, furto con violenza, omicidio, omicidio con violenza, …\nDurata della libertà vigilata: 1 mese, 3 mesi, 6 mesi, 1 anno, 2 anni, 3 anni, 4 anni, 5 anni, 6 anni, 7 anni\n…\n\nRisultato:\n\nRischio di recidiva: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\n\nConsiderazioni: Garantire la protezione dei dati personali e una raccolta dei dei dati bilanciata tra le classi sottostanti il fenomeno da studiare per evitare una eccessiva polarizzazione dei dati.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#pre-elaborazione-dei-dati",
    "href": "2-6-algoritmi-predittivi.html#pre-elaborazione-dei-dati",
    "title": "8  Algoritmi Predittivi",
    "section": "8.4 Pre-elaborazione dei Dati",
    "text": "8.4 Pre-elaborazione dei Dati\nSi prepara il dataset per garantire che l’algoritmo di machine learning funzioni in modo ottimale. Questo passo include diverse attività chiave:\n\nPulizia dei dati: correzione o rimozione di dati errati, corrotti, duplicati o non pertinenti. La pulizia assicura che il modello non apprenda da informazioni fuorvianti o irrilevanti.\nGestione dei valori mancanti: I dati incompleti sono comuni in molti dataset. La gestione dei valori mancanti può includere tecniche come l’imputazione, dove i valori mancanti sono sostituiti con stime, o l’eliminazione delle righe o colonne con dati mancanti.\nNormalizzazione: scalatura dei dati in modo che attributi con ampi intervalli di valori non dominino quelli con intervalli più stretti. La normalizzazione è essenziale per algoritmi che sono sensibili alle scale dei dati, come la regressione lineare o le reti neurali.\nRiduzione della dimensionalità: Tecniche come l’Analisi delle Componenti Principali (PCA) sono utilizzate per ridurre il numero di variabili nel dataset, mantenendo solo quelle più informative. Questo non solo semplifica il modello, ma può anche migliorare le prestazioni riducendo il rischio di overfitting. Esempio Pratico:\nPulizia: Rimuovere duplicati o incongruenze nei dati delle sentenze.\nGestione dei valori mancanti: Stimare dati mancanti, come la durata del procedimento.\nNormalizzazione: Uniformare i dati, ad esempio convertendo valute in una stessa unità.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#divisione-dei-dati",
    "href": "2-6-algoritmi-predittivi.html#divisione-dei-dati",
    "title": "8  Algoritmi Predittivi",
    "section": "8.5 Divisione dei Dati",
    "text": "8.5 Divisione dei Dati\nSi separa il dataset in due o più gruppi per diversi scopi: addestramento, validazione e test. Questa divisione serve per avere dati per valutare l’efficacia e la generalizzabilità del modello predittivo. Il set di addestramento è utilizzato per insegnare all’algoritmo a riconoscere i pattern nei dati. Il set di validazione, quando presente, aiuta a ottimizzare i parametri del modello e a prevenire l’overfitting. Infine, il set di test serve a valutare le prestazioni del modello su dati non visti durante l’addestramento, fornendo una stima dell’errore di generalizzazione. La proporzione della divisione può variare, ma una suddivisione comune è 70% per l’addestramento, 15% per la validazione e 15% per il test. È importante che la divisione dei dati sia rappresentativa dell’intero dataset, quindi tecniche come il campionamento stratificato possono essere utilizzate per mantenere la stessa distribuzione delle classi in ciascun set. Esempio Pratico:\n\nDivisione: 70% addestramento, 15% validazione, 15% test.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#scelta-dell-algoritmo",
    "href": "2-6-algoritmi-predittivi.html#scelta-dell-algoritmo",
    "title": "8  Algoritmi Predittivi",
    "section": "8.6 Scelta dell’ algoritmo",
    "text": "8.6 Scelta dell’ algoritmo\nLa scelta dell’algoritmo determina l’approccio con cui il modello analizzerà i dati e farà previsioni (James et al. 2013). La selezione dell’algoritmo dipende da vari fattori, tra cui il tipo di problema (classificazione, regressione, clustering), la natura dei dati, la dimensione del dataset e le risorse computazionali disponibili. Ad esempio, per problemi di classificazione, algoritmi come le reti neurali, le macchine a vettori di supporto (SVM) e gli alberi decisionali sono spesso utilizzati. Per la regressione, si possono considerare algoritmi come la regressione lineare, la regressione polinomiale o le reti neurali. È importante anche considerare la complessità dell’algoritmo: algoritmi più complessi possono offrire maggiore accuratezza, ma richiedono più tempo e risorse per l’addestramento. Esempio Pratico: In questo si potrebbe usare un algoritmo di regressione, come una Random Forest Regressor, per stimare la probabilità di recidiva.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#addestramento-del-modello",
    "href": "2-6-algoritmi-predittivi.html#addestramento-del-modello",
    "title": "8  Algoritmi Predittivi",
    "section": "8.7 Addestramento del modello",
    "text": "8.7 Addestramento del modello\nL’addestramento di un modello di machine learning è un processo iterativo che consiste nell’esporre un algoritmo a un ampio dataset di apprendimento, con l’obiettivo di insegnargli a riconoscere pattern e a fare predizioni accurate su nuovi dati (Hastie, Tibshirani, and Friedman 2009). La qualità e l’efficacia di un modello dipendono fortemente dalla scelta dell’algoritmo, dalla qualità dei dati e dalle tecniche di addestramento utilizzate. Modalità di apprendimento Esistono diverse modalità di apprendimento:\n\nApprendimento supervisionato: Il modello viene addestrato su un dataset etichettato, dove ogni esempio è associato a una risposta corretta. L’obiettivo è insegnare al modello a mappare nuovi input alle loro rispettive etichette.\nApprendimento non supervisionato: Il modello lavora con dati non etichettati, cercando di scoprire strutture nascoste nei dati, come gruppi di dati simili (clustering).\nApprendimento semi-supervisionato: Combina elementi dei due approcci precedenti, utilizzando sia dati etichettati che non etichettati.\n\nL’addestramento di modelli complessi richiede risorse computazionali significative. Le GPU e le TPU sono hardware specializzati che accelerano i calcoli necessari per l’addestramento di reti neurali profonde. Inoltre, sono necessari software specifici per definire le architetture delle reti neurali e gestire il processo di addestramento. Nel processo di addestramento occorre spesso intervenire manualmente per regolare i parametri del modello, come la dimensione del batch, la velocità di apprendimento e la regolarizzazione per evitare fenomeni come l’overfitting e l’underfitting:\n\nOverfitting: Si verifica quando il modello si adatta troppo ai dati di addestramento, perdendo la capacità di generalizzare a nuovi dati. In questo caso, il modello memorizza i dettagli specifici dei dati di addestramento invece di apprendere le caratteristiche generali.\nUnderfitting: Si verifica quando il modello è troppo semplice per catturare la complessità dei dati. In questo caso, il modello non è in grado di apprendere le relazioni significative tra le variabili.\n\nL’addestramento di modelli di machine learning solleva importanti questioni etiche. È fondamentale utilizzare dataset rappresentativi e bilanciati per evitare bias e discriminazioni. Inoltre, è necessario considerare le potenziali conseguenze negative dell’utilizzo di modelli in contesti reali, come la privacy e la sicurezza dei dati. Esempio Pratico: Nel caso in studio si tratterà di addestrare il modello scelto con dati storici su imputati e loro comportamenti post-processo.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#valutazione-del-modello",
    "href": "2-6-algoritmi-predittivi.html#valutazione-del-modello",
    "title": "8  Algoritmi Predittivi",
    "section": "8.8 Valutazione del modello",
    "text": "8.8 Valutazione del modello\nLa valutazione del modello è una fase cruciale nel processo di sviluppo di un modello di machine learning, poiché consente di misurare la capacità del modello addestrato di generalizzare a nuovi dati, ovvero di fare predizioni accurate su esempi che non ha mai visto durante l’addestramento. Le metriche di valutazione variano a seconda del tipo di problema:\n\nproblemi di classificazione, si utilizzano metriche come: Matrice di confusione: una tabella che mostra il numero di casi classificati correttamente e erroneamente in ogni classe.\n\nAccuratezza: misura la percentuale di casi classificati correttamente.\nPrecisione: misura la percentuale di veri positivi (cioè quei casi che effettivamente appartengono alla classe positiva) tra i casi classificati come positivi.\nRichiamo: misura la percentuale di veri positivi tra tutti i casi positivi reali.\nF1-score: misura la media armonica tra precisione e richiamo.\nCurva ROC (Receiver Operating Characteristic) con l’area sotto la curva (AUC): misura la capacità del modello di distinguere correttamente tra le classi.\n\nproblemi di regressione, si utilizzano metriche come:\n\nErrore quadratico medio (MSE): misura la differenza media quadratica tra i valori predetti dal modello e i valori reali.\nCoefficiente di determinazione (R²): misura la percentuale di variazione dei valori predetti rispetto ai valori reali.\n\n\nAnalisi dei risultati L’analisi dei risultati della valutazione permette di identificare eventuali problemi come l’overfitting o l’underfitting. L’overfitting si verifica quando il modello si adatta troppo ai dati di addestramento, perdendo la capacità di generalizzare a nuovi dati. L’underfitting si verifica quando il modello è troppo semplice e non riesce a catturare la complessità dei dati. Esempio pratico: nel caso in studio di modello di machine learning addestrato per predire la probabilità di recidività di un reo in base ai dati raccolti sullo stesso. Dopo l’addestramento, il modello viene valutato su un dataset di test che contiene informazioni su nuovi reati. Utilizzando la Cross-validation, calcolando metriche come l’accuratezza e il richiamo, possiamo valutare l’affidabilità delle predizioni del modello. Un’alta accuratezza indica che il modello è generalmente corretto nelle sue previsioni, mentre un alto richiamo indica che il modello è bravo a identificare i reati che effettivamente si sono verificati.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#ottimizzazione-degli-iperparametri",
    "href": "2-6-algoritmi-predittivi.html#ottimizzazione-degli-iperparametri",
    "title": "8  Algoritmi Predittivi",
    "section": "8.9 Ottimizzazione degli iperparametri",
    "text": "8.9 Ottimizzazione degli iperparametri\nL’ottimizzazione degli iperparametri è un processo iterativo che consiste nel regolare i parametri esterni al modello che non vengono appresi durante l’addestramento, ma che influenzano significativamente le sue prestazioni. Esempi di iperparametri includono il tasso di apprendimento, la profondità di un albero decisionale o il numero di neuroni in una rete neurale. L’obiettivo dell’ottimizzazione è individuare la combinazione di iperparametri che massimizza le prestazioni del modello su un dataset di valutazione indipendente. Per raggiungere questo obiettivo, si utilizzano diverse tecniche, tra cui:\n\nRicerca a griglia: Esplora sistematicamente tutte le possibili combinazioni di iperparametri all’interno di un intervallo specificato.\nRicerca casuale: Seleziona casualmente combinazioni di iperparametri, potendo essere più efficiente della ricerca a griglia in spazi di ricerca ampi.\nOttimizzazione bayesiana: Utilizza modelli probabilistici per guidare la ricerca verso le regioni dello spazio degli iperparametri più promettenti.\n\nPer valutare l’efficacia delle diverse combinazioni di iperparametri, si ricorre alla validazione incrociata. Questa tecnica consiste nel suddividere il dataset in più parti, addestrando il modello su una parte e valutandolo sulle altre. Ripetendo questo processo multiple volte, si ottiene una stima più robusta delle prestazioni del modello. Tecniche come l’early stopping possono essere utilizzate per migliorare ulteriormente il processo di ottimizzazione. L’early stopping consiste nell’interrompere l’addestramento quando le prestazioni del modello sul dataset di convalida iniziano a peggiorare, evitando così l’overfitting.\nEsempio pratico: Nel caso in studio si procederà a regolare i parametri della Random Forest Regressor, come il numero di alberi (n_estimators) o la profondità massima degli alberi (max_depth), per migliorare le prestazioni. Una possibile metodologia di ottimizzazione potrebbe essere di utilizzare una ricerca a griglia per identificare i migliori iperparametri. Ad esempio, testare diversi valori di n_estimators (100, 200, 500) e max_depth (5, 10, 15). La validazione incrociata può essere utilizzata per valutare le prestazioni del modello su diversi set di dati di addestramento e convalida.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#deployment",
    "href": "2-6-algoritmi-predittivi.html#deployment",
    "title": "8  Algoritmi Predittivi",
    "section": "8.10 Deployment",
    "text": "8.10 Deployment\nIl deployment è la fase finale del processo di predizione, in cui il modello addestrato e ottimizzato viene messo in produzione per essere utilizzato in applicazioni reali. Questa fase implica la preparazione del modello per l’integrazione con sistemi esistenti, garantendo che sia scalabile, affidabile e sicuro. Il deployment può avvenire su diverse piattaforme, come server locali, cloud o dispositivi edge (dispositivi periferici che elaborano i dati vicino alla fonte, riducendo la latenza e il carico sui server centrali), a seconda delle esigenze dell’applicazione. È importante notare che l’hardware necessario per il deployment è diverso da quello utilizzato per l’addestramento. Durante l’addestramento, sono necessarie risorse computazionali elevate, come GPU o TPU, per gestire i complessi calcoli e l’ottimizzazione dei parametri del modello. Tuttavia, una volta che il modello è addestrato, il deployment richiede meno potenza computazionale, poiché il modello deve solo eseguire previsioni basate sui dati in ingresso. Questo permette di utilizzare hardware meno potente e più economico per il deployment, riducendo i costi operativi.\nSfide del deployment:\n\nScalabilità: Il sistema di deployment deve essere in grado di gestire un aumento del carico di lavoro e di scalare in modo elastico per soddisfare le esigenze dell’applicazione.\nAffidabilità: Il modello deve essere disponibile e funzionante in modo continuo, minimizzando i tempi di fermo e garantendo la qualità delle previsioni.\nSicurezza: È fondamentale proteggere il modello e i dati sensibili da accessi non autorizzati e attacchi informatici.\n\nesempio pratico: nel caso in studio si procederà a creare un’applicazione web che consenta agli utenti di inserire i dati di input e ricevere le previsioni del modello. Questa applicazione sarà ospitata su un server web e sarà accessibile tramite un’interfaccia web nella quale sarà necessario implementare un sistema di autenticazione per garantire che solo gli utenti autorizzati possano accedere al modello. Se si prevede che il modello sarà utilizzato in un’applicazione mobile, sarà necessario sviluppare un’interfaccia utente per dispositivi mobili che consenta agli utenti di inserire i dati di input e ricevere le previsioni. Per garantire prestazioni elevate, il modello può essere deployato su un server cloud scalabile, come AWS (Amazon Web Services) o GCP (Google Cloud Platform).Monitorando le prestazioni del modello, è possibile fare aggiustamenti e aggiornamenti per mantenere alta la qualità delle previsioni.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#monitoraggio-e-manutenzione",
    "href": "2-6-algoritmi-predittivi.html#monitoraggio-e-manutenzione",
    "title": "8  Algoritmi Predittivi",
    "section": "8.11 Monitoraggio e manutenzione",
    "text": "8.11 Monitoraggio e manutenzione\nIl monitoraggio e la manutenzione sono attività cruciali nel ciclo di vita di un modello di predizione, volte a garantire che il modello rimanga accurato e affidabile nel tempo(Kuhn and Johnson 2013). Dopo il deployment, è essenziale monitorare continuamente le prestazioni del modello per rilevare eventuali degradi dovuti a cambiamenti nei dati o nel contesto operativo. Questo può includere il monitoraggio di indicatori di degrado come:\n\nAumento dell’errore di previsione: Se il modello inizia a fare più errori nelle previsioni rispetto a prima, potrebbe essere un segnale di degrado. Questo può essere misurato attraverso metriche come l’errore quadratico medio (MSE) per i modelli di regressione o l’accuratezza per i modelli di classificazione.\nDiminuzione dell’accuratezza: Un calo nell’accuratezza complessiva del modello indica che le previsioni non sono più affidabili come in passato.\nAumento dei falsi positivi/negativi: Per i modelli di classificazione, un aumento dei falsi positivi (previsioni errate di eventi positivi) o dei falsi negativi (previsioni errate di eventi negativi) può indicare che il modello non sta più funzionando correttamente.\nCambiamenti nelle distribuzioni dei dati: Se i dati in ingresso cambiano significativamente rispetto ai dati su cui il modello è stato addestrato, il modello potrebbe non essere più in grado di generalizzare correttamente. Questo può essere monitorato attraverso tecniche di drift detection.\nAumento del tempo di risposta: Se il modello impiega più tempo per fare previsioni, potrebbe essere un segnale che qualcosa non va, come un sovraccarico computazionale o inefficienze nel codice.\n\nLa manutenzione del modello può comportare aggiornamenti periodici, riaddestramento con nuovi dati e ottimizzazioni per adattarsi a nuove condizioni. Inoltre, è importante implementare sistemi di allerta per notificare tempestivamente eventuali problemi. La manutenzione preventiva e correttiva aiuta a mantenere il modello efficiente e a evitare errori significativi che potrebbero influenzare le decisioni basate sulle sue previsioni. Esempio pratico: Nel caso in studio, il monitoraggio del modello di previsione potrebbero includere la verifica regolare dell’MSE e del’R² su nuovi dati. Mentre la manutenzione potrebbe includere l’aggiornamento periodico, ad esempio ogni 6 mesi, del modello con nuovi dati per garantire prestazioni ottimali.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#laboratorio-python",
    "href": "2-6-algoritmi-predittivi.html#laboratorio-python",
    "title": "8  Algoritmi Predittivi",
    "section": "8.12 Laboratorio Python",
    "text": "8.12 Laboratorio Python\n\n8.12.1 Esperimento 1: Predizione della recidiva parte A: creazione di un dataset di addestramento e test simulato\nVediamo un esempio in Python che implementa il processo predittivo per il caso giuridico di previsione della probabilità di recidiva utilizzando una Random Forest Regressor. Questo esempio utilizza diviso in 3 parti si basa su dati simulati per illustrare il flusso completo, dalla generazione dei dati fino alla valutazione del modello.\n\n\n\n\n\n\nCaution\n\n\n\nSe non è stato già fatto, installare le librerie necessarie con il seguente comando da eseguire nella shell:\npip install numpy pandas sklearn matplotlib\n\n\nIn questa primo esperimento l’obiettivo principale è generare dati dall’aspetto realistico su persone che sono in libertà vigilata (rilascio supervisionato dopo un reato) e calcolare il loro rischio di recidiva. Questi dati simulati verranno successivamente utilizzati per addestrare e testare un modello predittivo, che è una pratica comune nel machine learning quando si vuole sperimentare prima di utilizzare dati reali e sensibili. Il codice non riceve input esterni dagli utenti. Invece, genera i propri dati utilizzando la generazione di numeri casuali. Tuttavia, utilizza diversi parametri predefiniti per controllare la simulazione:\n\nNumero di campioni (1000 persone)\nFasce d’età (da 18 a 70 anni)\nDurata della libertà vigilata (da 1 a 60 mesi)\nTipi di reati precedenti (furto, reato violento, omicidio)\nStato lavorativo (lavoro stabile o no)\nSupporto familiare (presente o assente)\n\nIl codice segue una sequenza chiara: genera caratteristiche individuali casualmente, poi le combina usando una formula ponderata per calcolare il rischio. Un passaggio cruciale è il “clipping” del punteggio di rischio finale per assicurarsi che rimanga tra 0 e 1, poiché le probabilità non possono essere negative o maggiori del 100%.\nIl seed casuale (impostato a 42) garantisce che ogni volta che esegui questo codice, ottieni esattamente gli stessi dati “casuali”, il che è importante per esperimenti scientifici riproducibili. Infine, tutti i dati generati vengono organizzati in un DataFrame pandas (pensalo come un foglio di calcolo digitale) e visualizza le prime righe così puoi vedere com’è fatto il dataset simulato.\nQuesto approccio permette a ricercatori e sviluppatori di testare i loro algoritmi di predizione su dati realistici senza problemi di privacy, prima di applicarli a veri fascicoli giudiziari.\n\nimport numpy as np\nimport pandas as pd\n\n# Simulazione dei dati con relazioni realistiche\nnp.random.seed(42)\nnum_samples = 1000\n\n# Generazione delle variabili\neta = np.random.randint(18, 70, size=num_samples)\ndurata_liberta_vigilata = np.random.randint(1, 60, size=num_samples)  # Durata in mesi\nreato_precedente = np.random.choice([0, 1, 2], size=num_samples, p=[0.5, 0.3, 0.2])  # Furto, violenza privata, omicidio\nlavoro_stabile = np.random.choice([0, 1], size=num_samples, p=[0.6, 0.4])\nsupporto_familiare = np.random.choice([0, 1], size=num_samples, p=[0.4, 0.6])\n\n# Calcolo del rischio di recidiva basato su regole\nrischio_recidiva = (\n    0.6 * (1 - lavoro_stabile) +\n    0.5 * (1 - supporto_familiare) +\n    0.4 * (reato_precedente / 2) +\n    0.3 * (1 / durata_liberta_vigilata) +\n    0.2 * (1 / (eta - 17))\n)\nrischio_recidiva = np.clip(rischio_recidiva, 0, 1)  # Limitare il rischio tra 0 e 1\n\n# Creazione del DataFrame\ndata = {\n    'eta': eta,\n    'durata_liberta_vigilata': durata_liberta_vigilata,\n    'reato_precedente': reato_precedente,\n    'lavoro_stabile': lavoro_stabile,\n    'supporto_familiare': supporto_familiare,\n    'rischio_recidiva': rischio_recidiva\n}\n\ndf = pd.DataFrame(data)\n\n# Visualizzazione iniziale dei dati\nprint(\"Esempio di dati simulati:\")\nprint(df.head())\n\nEsempio di dati simulati:\n   eta  durata_liberta_vigilata  reato_precedente  lavoro_stabile  \\\n0   56                       35                 2               0   \n1   69                       51                 1               0   \n2   46                       15                 0               1   \n3   32                       25                 1               0   \n4   60                       55                 1               1   \n\n   supporto_familiare  rischio_recidiva  \n0                   0          1.000000  \n1                   0          1.000000  \n2                   0          0.526897  \n3                   0          1.000000  \n4                   0          0.710106  \n\n\nSi noti che i dati generati sono memorizzati in una struttura dati chiamata Dataframe. Si tratta di una particolare struttura dati fornita dalla libreria pandas di Python che rappresenta essenzialmente una tabella, molto simile a un foglio di calcolo di Excel o a una tabella di un database. Possiamo immaginarla come una griglia con righe e colonne: ogni riga rappresenta un record (in questo caso, una persona) e ogni colonna rappresenta una caratteristica o variabile (come età, tipo di reato, ecc.). Questa struttura dati è diventata molto popolare nel mondo del machine learning perché è molto flessibile e può gestire una grande quantità di dati in modo efficiente. Con questa struttura dati, è possibile eseguire operazioni come la selezione di righe o colonne specifiche, la manipolazione dei dati, la creazione di nuovi dati basati su quelli esistenti e molto altro. Inoltre, le librerie di machine learning come scikit-learn richiedono spesso che i dati siano organizzati in questo formato per poter essere utilizzati.\n\n\n8.12.2 Esperimento 2: Predizione della recidiva parte B: Addestramento e test del modello\nIn questo esperimento, il modello Random Forest Regressor viene addestrato utilizzando i dati simulati e quindi viene utilizzato per fare previsioni sui dati di test. Per prima cosa, i dati sono divisi in input (X) e output (y), dove X contiene tutte le caratteristiche (ad esempio, età, tipo di reato precedente, ecc.) e y contiene il rischio di recidiva. Successivamente, i dati sono divisi in set di addestramento e test utilizzando la funzione train_test_split di scikit-learn. Il modello Random Forest Regressor viene addestrato utilizzando i dati di addestramento e quindi viene utilizzato per fare previsioni sui dati di test.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Divisione dei dati in input (X) e output (y)\nX = df.drop('rischio_recidiva', axis=1)\ny = df['rischio_recidiva']\n\n# Divisione in training e test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Creazione e addestramento del modello Random Forest Regressor\nrf_model = RandomForestRegressor(random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Predizione sui dati di test\ny_pred = rf_model.predict(X_test)\n\n# Valutazione del modello\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"\\nRisultati del modello:\")\nprint(f\"Mean Squared Error (MSE): {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n\n\nRisultati del modello:\nMean Squared Error (MSE): 0.0004\nR^2 Score: 0.9966\n\n\n\n\n8.12.3 Esperimento 3: Predizione della recidiva parte C: Ottimizzazione degli iperparametri del modello e visualizzazione dei risultati\nIn questa parte dell’esperimento, viene visualizzato un grafico per confrontare i valori reali di rischio di recidiva con i valori predetti dal modello. Inoltre, viene utilizzato GridSearchCV per ottimizzare gli iperparametri del modello Random Forest Regressor. Questo processo di ottimizzazione è importante perché aiuta a trovare la combinazione migliore di parametri che migliorano le prestazioni del modello. Infine, i risultati dell’ottimizzazione vengono visualizzati in un grafico.\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\n\n# Visualizzazione dei risultati\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred, alpha=0.7)\nplt.plot([0, 1], [0, 1], '--', color='red', label='Predizione Perfetta')\nplt.xlabel(\"Valori Reali di Rischio di Recidiva\")\nplt.ylabel(\"Valori Predetti di Rischio di Recidiva\")\nplt.title(\"Confronto tra Valori Reali e Predetti\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Ottimizzazione degli iperparametri con GridSearchCV\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [5, 10, 15],\n    'min_samples_split': [2, 5, 10]\n}\n\ngrid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nprint(\"\\nMigliori parametri trovati con GridSearchCV:\")\nprint(grid_search.best_params_)\n\n# Addestramento del modello ottimizzato\nbest_rf_model = grid_search.best_estimator_\n\n# Predizione e valutazione con il modello ottimizzato\ny_pred_optimized = best_rf_model.predict(X_test)\noptimized_mse = mean_squared_error(y_test, y_pred_optimized)\noptimized_r2 = r2_score(y_test, y_pred_optimized)\n\n# Visualizzazione dei risultati\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred_optimized, alpha=0.7)\nplt.plot([0, 1], [0, 1], '--', color='red', label='Predizione Perfetta')\nplt.xlabel(\"Valori Reali di Rischio di Recidiva\")\nplt.ylabel(\"Valori Predetti di Rischio di Recidiva\")\nplt.title(\"Confronto tra Valori Reali e Predetti  con parametri ottimizzati\")\nplt.legend()\nplt.grid()\nplt.show()\n\nprint(\"\\nRisultati del modello ottimizzato:\")\nprint(f\"Mean Squared Error (MSE): {optimized_mse:.4f}\")\nprint(f\"R^2 Score: {optimized_r2:.4f}\")\n\n\n\n\n\n\n\n\nFitting 5 folds for each of 27 candidates, totalling 135 fits\n\nMigliori parametri trovati con GridSearchCV:\n{'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 300}\n\n\n\n\n\n\n\n\n\n\nRisultati del modello ottimizzato:\nMean Squared Error (MSE): 0.0003\nR^2 Score: 0.9967",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "2-6-algoritmi-predittivi.html#esercizi",
    "href": "2-6-algoritmi-predittivi.html#esercizi",
    "title": "8  Algoritmi Predittivi",
    "section": "8.13 Esercizi",
    "text": "8.13 Esercizi\n\n8.13.1 Esercizio 1: Analisi delle variabili significative\nObiettivo: Identificare le variabili più importanti nel determinare il rischio di recidiva.\nSupponendo di avere un modello di Random Forest Regressor già addestrato con i dati di rischio di recidiva:\n\nUtilizza la funzione feature_importances_ della Random Forest per identificare l’importanza relativa delle variabili di input.\nOrdina le variabili in base alla loro importanza decrescente.\nRispondi alle seguenti domande:\n\nQuali sono le tre variabili più significative?\nCome pensi che queste variabili influenzino il rischio di recidiva?\n\n\n\n\n8.13.2 Esercizio 2: Creazione di un dataset realistico\nObiettivo: Simulare un dataset che rifletta il comportamento reale di imputati in libertà vigilata.\n\nSimula un dataset di almeno 500 imputati includendo le seguenti variabili:\n\nEtà.\nTipo di reato precedente (furto, violenza, omicidio).\nDurata della libertà vigilata (in mesi).\nPresenza di un lavoro stabile (sì/no).\nSupporto familiare (sì/no).\n\nAssegna il rischio di recidiva utilizzando una funzione che tenga conto delle variabili sopra indicate (ad esempio, un punteggio più alto per imputati senza lavoro stabile o con reati più gravi).\nVisualizza la distribuzione del rischio di recidiva nel dataset utilizzando un grafico.\n\n\n\n8.13.3 Esercizio 3: Valutazione di un modello predittivo\nObiettivo: Valutare le prestazioni di un modello predittivo per il rischio di recidiva.\n\nAddestra un modello di Random Forest Regressor utilizzando un dataset simulato.\nDividi i dati in training e test set con una proporzione 80/20.\nValuta il modello utilizzando le seguenti metriche:\n\nMean Squared Error (MSE).\nR² Score.\n\nInterpreta i risultati:\n\nIl modello è efficace? Quali sono i possibili miglioramenti?\nQuali interventi (ad esempio, ottimizzazione degli iperparametri) potresti fare per migliorare le prestazioni?\n\n\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer.\n\n\nInc., Northpointe. 2018. Correctional Offender Management Profiling for Alternative Sanctions (COMPAS). https://bja.ojp.gov/sites/g/files/xyckuh186/files/media/document/compas.pdf.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An Introduction to Statistical Learning. Springer.\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive Modeling. Springer.\n\n\nMurphy, Kevin P. 2012. Machine Learning: A Probabilistic Perspective. MIT Press.",
    "crumbs": [
      "Algoritmi",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algoritmi Predittivi</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html",
    "href": "3-1-apprendimento-supervisionato.html",
    "title": "9  Apprendimento Supervisionato",
    "section": "",
    "text": "9.1 Introduzione\nL’apprendimento supervisionato è un sottoinsieme del machine learning che si occupa di costruire modelli predittivi utilizzando un dataset etichettato, dove ogni esempio di input è associato a un output corrispondente (l’etichetta). Il processo di apprendimento supervisionato può essere visto come una forma di mappatura funzionale (f: X Y), dove (X) rappresenta lo spazio degli input (caratteristiche o feature) e (Y) rappresenta lo spazio degli output (etichette). L’obiettivo principale è imparare una funzione (f) che, dato un nuovo input, sia in grado di predire l’output corretto. Il processo di addestramento coinvolge due fasi principali: l’apprendimento e la generalizzazione. Durante la fase di apprendimento, il modello viene addestrato su un insieme di dati di addestramento, cercando di minimizzare la funzione di perdita, che misura la discrepanza tra le previsioni del modello e le etichette effettive. Successivamente, nella fase di generalizzazione, il modello viene testato su nuovi dati non visti per valutare la sua capacità di fare previsioni accurate al di fuori del set di addestramento. I principi fondamentali che guidano l’apprendimento supervisionato includono la funzione di perdita, che determina quanto una previsione è lontana dal valore vero; l’ottimizzazione, che è il processo attraverso il quale il modello migliora le sue previsioni iterativamente; e il bias-variance tradeoff, che è il bilanciamento tra un modello troppo semplice (alto bias) e uno troppo complesso (alta varianza).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#classificazione",
    "href": "3-1-apprendimento-supervisionato.html#classificazione",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.2 Classificazione",
    "text": "9.2 Classificazione\nLa classificazione è una tecnica di apprendimento supervisionato in cui l’obiettivo è assegnare una classe o etichetta specifica a un input, in base a un insieme di dati di addestramento. Esistono vari tipi di problemi di classificazione:\n\nClassificazione binaria: Qui, l’output è limitato a due classi, come “sì” o “no”, “spam” o “non spam”. Questo tipo di problema è comune in scenari come la diagnosi medica (es. malato o non malato) e nella sicurezza informatica (es. email sicura o phishing). Tra le tecniche utilizzate si possono citare approcci come le reti neurali e le macchine a vettori di supporto (SVM)\nClassificazione multiclasse: In questo caso, l’output può appartenere a una di più classi (es. classificare un documento come “legale”, “finanziario” o “scientifico”). Le tecniche utilizzate possono includere approcci come la regressione logistica multinomiale, le reti neurali e l’applicazione multipla di macchine a vettori di supporto (SVM).\nClassificazione multilabel: Qui, un singolo input può essere associato a più classi contemporaneamente (es. un articolo di giornale che potrebbe essere classificato sia come “politico” che come “economico”). Tecniche come l’approccio One-vs-All e le reti neurali sono frequentemente utilizzate in questi contesti.\n\nUn punto di interesse particolare nella classificazione è il concetto di boundary decisionale. Questo rappresenta il confine nello spazio delle caratteristiche che separa le diverse classi. Nei modelli lineari, questo confine è una linea retta o un iperpiano, mentre nei modelli non lineari può assumere forme molto più complesse.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#regressione",
    "href": "3-1-apprendimento-supervisionato.html#regressione",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.3 Regressione",
    "text": "9.3 Regressione\nLa regressione è un tipo di problema di apprendimento supervisionato, focalizzato sulla previsione di un valore continuo piuttosto che su una classe discreta. A differenza della classificazione, dove l’output è un’etichetta, nella regressione l’output è un valore numerico che può variare su un intervallo continuo.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#algoritmi-principali-dellapprendimento-supervisionato",
    "href": "3-1-apprendimento-supervisionato.html#algoritmi-principali-dellapprendimento-supervisionato",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.4 Algoritmi Principali dell’Apprendimento Supervisionato",
    "text": "9.4 Algoritmi Principali dell’Apprendimento Supervisionato\nL’apprendimento supervisionato si avvale di una vasta gamma di algoritmi che possono essere utilizzati per risolvere problemi sia di classificazione che di regressione. Ogni algoritmo ha caratteristiche specifiche che lo rendono più o meno adatto a particolari tipi di dati e problemi. Di seguito, verranno presentati alcuni dei principali algoritmi utilizzati nell’apprendimento supervisionato.\n\n9.4.1 Regressione Lineare\nLa regressione lineare è uno degli algoritmi più semplici e ampiamente utilizzati per problemi di regressione. Assume una relazione lineare tra le variabili indipendenti e la variabile dipendente e cerca di trovare la retta (o l’iperpiano nel caso di più variabili indipendenti) che meglio approssima i dati. La semplicità della regressione lineare la rende facile da interpretare, ma la sua capacità di modellare solo relazioni lineari può limitare la sua applicabilità in scenari più complessi.\n\n\n9.4.2 Regressione Logistica\nLa regressione logistica è un algoritmo di classificazione che viene utilizzato quando l’output è binario. A differenza della regressione lineare, la regressione logistica utilizza una funzione logistica (o sigmoide) per modellare la probabilità che un dato appartenga a una classe specifica. Questo approccio è ampiamente utilizzato per problemi come la classificazione di e-mail come “spam” o “non spam” o per la predizione di eventi binari (es. successo o fallimento di un’azione legale).\n\n\n9.4.3 Alberi di Decisione\nGli alberi di decisione sono modelli non parametrici che possono essere utilizzati sia per la classificazione che per la regressione. Essi segmentano il dataset in sottogruppi omogenei attraverso una serie di decisioni basate sui valori delle caratteristiche. Ogni nodo dell’albero rappresenta una decisione basata su una caratteristica, e i rami rappresentano le possibili conseguenze di tale decisione. Gli alberi di decisione sono facili da interpretare e visualizzare, il che li rende particolarmente utili quando è necessaria una comprensione trasparente del processo decisionale. Tuttavia, gli alberi di decisione possono essere inclini all’overfitting, specialmente se non adeguatamente potati.\n\n\n9.4.4 Random Forest\nIl Random Forest è un metodo ensemble basato su alberi di decisione. Consiste in un insieme di alberi di decisione indipendenti addestrati su diverse porzioni del dataset (attraverso il bootstrapping) e utilizzando un sottoinsieme casuale di caratteristiche. Il risultato finale è ottenuto aggregando le previsioni di tutti gli alberi (es. tramite voto di maggioranza per la classificazione o media per la regressione). Questa tecnica riduce significativamente il rischio di overfitting rispetto a un singolo albero di decisione e migliora la precisione e la robustezza del modello.\n\n\n9.4.5 Support Vector Machines (SVM)\nLe Support Vector Machines (SVM) sono algoritmi molto potenti sia per la classificazione. Il loro obiettivo è trovare un iperpiano ottimale che separi i dati di diverse classi con il massimo margine possibile. Le SVM sono particolarmente efficaci in spazi ad alta dimensionalità e possono essere estese per gestire separazioni non lineari utilizzando il kernel trick, che permette di mappare i dati in uno spazio di dimensione superiore dove la separazione diventa lineare.\n\n\n9.4.6 k-Nearest Neighbors (k-NN)\nIl k-Nearest Neighbors (k-NN) è un algoritmo di classificazione basato su un’idea semplice ma efficace: per predire l’etichetta di un nuovo dato, si cercano i k punti più vicini nel dataset di addestramento e si assegna al nuovo dato la classe maggioritaria (nel caso di classificazione) o la media dei valori (nel caso di regressione). Il k-NN è molto intuitivo e non richiede una fase di addestramento, ma può diventare inefficiente con dataset molto grandi o in presenza di rumore.\n\n\n9.4.7 Reti Neurali\nLe reti neurali sono modelli ispirati al funzionamento del cervello umano e sono particolarmente potenti per la modellazione di relazioni non lineari complesse. Una rete neurale è composta da strati di nodi (neuroni) interconnessi, dove ciascun nodo applica una funzione non lineare ai dati in ingresso e trasmette il risultato ai nodi dello strato successivo. Le reti neurali possono essere utilizzate sia per la classificazione che per la regressione, ma richiedono un’attenta configurazione dei parametri e una grande quantità di dati per addestramento.\n\nPercettrone Multistrato (MLP): È una delle architetture più semplici di reti neurali, composto da uno o più strati nascosti tra l’input e l’output. Il MLP è capace di apprendere rappresentazioni complesse dei dati, ma richiede un’attenta configurazione dei parametri e una grande quantità di dati per addestramento.\nReti Neurali Convoluzionali (CNN): Utilizzate principalmente per l’elaborazione di immagini, le CNN applicano convoluzioni ai dati in ingresso per estrarre automaticamente caratteristiche di alto livello. Sono particolarmente efficaci in problemi di riconoscimento di immagini e visione artificiale.\nReti Neurali Ricorrenti (RNN): Progettate per gestire dati sequenziali come testi o serie temporali, le RNN hanno connessioni che permettono l’uso di informazioni provenienti da precedenti stati dell’input. Questo le rende ideali per problemi come la modellazione del linguaggio naturale o la previsione di sequenze.\n\n\n\n9.4.8 Gradient Boosting Machines (GBM)\nIl Gradient Boosting è una tecnica di ensemble che costruisce modelli in modo sequenziale, dove ogni nuovo modello cerca di correggere gli errori commessi dai modelli precedenti. I modelli individuali sono generalmente alberi di decisione semplici (stump), e il risultato finale è una somma ponderata di questi alberi. Algoritmi popolari come XGBoost e LightGBM sono varianti ottimizzate del Gradient Boosting, note per la loro efficacia e velocità, specialmente in competizioni di machine learning.\n\n\n9.4.9 Naive Bayes\nIl Naive Bayes è un algoritmo di classificazione basato sul teorema di Bayes, con l’assunzione “naive” che le caratteristiche siano indipendenti l’una dall’altra, una ipotesi raramente vera nel mondo reale. Nonostante questa assunzione, il Naive Bayes è sorprendentemente efficace, specialmente per problemi di classificazione testuale come la categorizzazione di documenti o l’analisi del sentiment.\n\n\n9.4.10 Ensemble Learning\nL’ensemble learning combina le previsioni di più modelli per ottenere un risultato finale più robusto e accurato. Oltre al Random Forest e al Gradient Boosting, altre tecniche di ensemble includono il bagging e lo stacking. Il bagging riduce la varianza addestrando lo stesso modello su diverse porzioni del dataset, mentre lo stacking combina le previsioni di diversi modelli tramite un meta-modello, che apprende a pesare le diverse previsioni.\n\n\n9.4.11 Conclusioni\nCiascuno degli algoritmi discussi ha punti di forza e di debolezza che lo rendono più o meno adatto a particolari problemi di apprendimento supervisionato. La scelta dell’algoritmo più appropriato dipende dalla natura del problema, dalla quantità e qualità dei dati disponibili e dalle specifiche esigenze dell’applicazione. In contesti giuridici, dove la trasparenza e l’interpretabile sono spesso fondamentali, gli algoritmi semplici e interpretabili come gli alberi di decisione o la regressione logistica potrebbero essere preferibili, mentre in applicazioni più complesse come l’analisi di grandi volumi di dati testuali, algoritmi più sofisticati come le reti neurali o le tecniche di ensemble possono offrire prestazioni superiori.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#apprendimento-per-rinforzo",
    "href": "3-1-apprendimento-supervisionato.html#apprendimento-per-rinforzo",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.5 Apprendimento per Rinforzo",
    "text": "9.5 Apprendimento per Rinforzo\nL’apprendimento per rinforzo (Reinforcement Learning, RL) si distingue dagli altri tipi di apprendimento supervisionato in quanto l’agente apprende attraverso l’interazione diretta con l’ambiente, senza avere accesso diretto a una serie di etichette corrette per ogni azione. In RL, l’agente prende decisioni sequenziali e riceve ricompense (o punizioni) che riflettono l’efficacia delle sue azioni. Il compito dell’agente è quindi quello di imparare una politica, o strategia, che massimizza la ricompensa totale nel tempo. Gli elementi chiave nell’apprendimento per rinforzo includono:\n\nAgente: L’entità che prende decisioni nell’ambiente.\nAmbiente: Il contesto in cui l’agente opera e da cui riceve feedback sotto forma di ricompense.\nPolitica (Policy): La strategia che l’agente segue per determinare quali azioni intraprendere in ogni stato.\nFunzione di valore (Value Function): Una funzione che valuta l’utilità di essere in un certo stato, dato un insieme di azioni future possibili.\nFunzione di ricompensa (Reward Function): Una funzione che fornisce un feedback immediato sulle azioni dell’agente.\n\n\n9.5.1 Algoritmi Principali\n\nAlgoritmo di Monte Carlo (MC): Questo algoritmo valuta le politiche basandosi sui risultati di una serie di episodi completi. È un algoritmo on-policy, il che significa che l’agente deve seguire la politica corrente per apprendere.\nQ-Learning: È uno degli algoritmi di apprendimento per rinforzo più semplici e più conosciuti. Q-Learning si basa sull’apprendimento della funzione Q, che stima la qualità (o valore) di un’azione in un dato stato. L’agente utilizza questa funzione per decidere quali azioni intraprendere al fine di massimizzare la ricompensa cumulativa. Q-Learning è un algoritmo off-policy, il che significa che l’agente può apprendere la politica ottimale indipendentemente dalla politica attualmente seguita.\nDeep Q-Networks (DQN): Estende Q-Learning utilizzando reti neurali profonde per approssimare la funzione Q, consentendo così di gestire ambienti con spazi di stato molto grandi o continui. Questo approccio è stato utilizzato con successo in diversi contesti, tra cui il superamento delle prestazioni umane in giochi complessi come Atari.\n\n\n\n9.5.2 Applicazioni\nL’apprendimento per rinforzo è utilizzato in un’ampia varietà di applicazioni, che vanno dai giochi (es. scacchi, Go, e videogiochi come quelli sviluppati da OpenAI e DeepMind) alla robotica (es. robot che imparano a camminare o manipolare oggetti), fino a scenari come la guida autonoma. Nell’ambito giuridico, potrebbe essere applicato per ottimizzare flussi di lavoro complessi, simulare scenari di negoziazione o migliorare i processi decisionali attraverso simulazioni avanzate.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#overfitting-e-underfitting",
    "href": "3-1-apprendimento-supervisionato.html#overfitting-e-underfitting",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.6 Overfitting e Underfitting",
    "text": "9.6 Overfitting e Underfitting\nL’overfitting e l’underfitting sono due delle principali problematiche che emergono nell’apprendimento supervisionato e possono influenzare significativamente la capacità di un modello di generalizzare su nuovi dati.\n\nOverfitting: Si verifica quando un modello diventa troppo complesso, catturando non solo i pattern rilevanti nei dati di addestramento ma anche il rumore. Un modello overfit avrà prestazioni eccellenti sui dati di addestramento ma scarse prestazioni su dati nuovi e non visti. Questo problema può essere mitigato attraverso tecniche come la regolarizzazione (es. Lasso, Ridge), l’early stopping (interrompere l’addestramento prima che il modello inizi a memorizzare il rumore), e l’utilizzo di più dati o di modelli più semplici.\nUnderfitting: Si verifica quando un modello è troppo semplice per rappresentare adeguatamente i dati. Un modello underfit avrà scarse prestazioni sia sui dati di addestramento che sui dati di test, poiché non riesce a catturare i pattern sottostanti. Per evitare l’underfitting, è necessario aumentare la complessità del modello o migliorare la qualità dei dati.\n\nL’obiettivo nella costruzione di un modello è trovare il giusto equilibrio tra bias e varianza, in modo da ottenere un modello che sia abbastanza complesso da catturare i pattern rilevanti nei dati senza diventare così complesso da catturare anche il rumore.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#valutazione-dei-modelli",
    "href": "3-1-apprendimento-supervisionato.html#valutazione-dei-modelli",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.7 Valutazione dei Modelli",
    "text": "9.7 Valutazione dei Modelli\nLa valutazione dei modelli è un passo critico per garantire che un modello di apprendimento supervisionato sia accurato, robusto e generalizzabile a dati non visti. La scelta delle metriche di valutazione dipende dal tipo di problema (classificazione o regressione) e dalle specifiche esigenze dell’applicazione. Innanzitutto, è importante sottolineare che la valutazione dei modelli si effettua sui dati di test, non sui dati di addestramento. Il modello deve dimostrare la capacità di generalizzare, ossia di fare previsioni accurate su nuovi dati che non ha mai visto prima.\n\n9.7.1 Valutazione nei Problemi di Classificazione\nPer i problemi di classificazione binaria (due classi, ad esempio A e B), le metriche di valutazione più comuni si basano sulla misurazione dei seguenti valori:\n\nVeri Positivi (VP): il modello ha correttamente predetto che un certo numero di casi appartiene alla classe A e questi effettivamente appartengono alla classe A.\nFalsi Positivi (FP): il modello ha predetto che un certo numero di casi appartiene alla classe A, ma in realtà appartengono alla classe B.\nVeri Negativi (VN): il modello ha correttamente predetto che un certo numero di casi appartiene alla classe B e questi effettivamente appartengono alla classe B.\nFalsi Negativi (FN): il modello ha predetto che un certo numero di casi appartiene alla classe B, ma in realtà appartengono alla classe A.\n\nLe metriche di valutazione comuni includono:\n\nMatrice di Confusione\nLa matrice di confusione riassume i valori di VP, FP, VN e FN in una tabella. È utile per analizzare in dettaglio le prestazioni del modello. La forma standard della matrice di confusione per un problema di classificazione binaria è la seguente:\n\\[\n\\text{Matrice di Confusione} =\n\\begin{bmatrix}\nVP & FP \\\\\nFN & VN\n\\end{bmatrix}\n\\]\nQuesta rappresentazione permette di identificare rapidamente dove il modello ha successo e dove commette errori.\nAccuratezza\nÈ la proporzione di previsioni corrette sul totale delle previsioni. Tuttavia, in presenza di classi sbilanciate, l’accuratezza può essere ingannevole.\n\\[\n\\text{Accuratezza} = \\frac{VP + VN}{VP + FP + VN + FN};\n\\]\nPrecisione e Recall\n\nPrecisione: misura la proporzione di veri positivi rispetto al totale delle predizioni positive.\n\\[\n\\text{Precisione} = \\frac{VP}{VP + FP};\n\\]\nRecall (o Sensibilità): misura la proporzione di veri positivi rispetto al totale dei casi positivi reali.\n\\[\n\\text{Recall} = \\frac{VP}{VP + FN};\n\\]\n\nF1-Score\nÈ la media armonica tra precisione e recall, utile quando è necessario bilanciare entrambe le metriche.\n\\[\n\\text{F1-Score} = 2 \\cdot \\frac{\\text{Precisione} \\cdot \\text{Recall}}{\\text{Precisione} + \\text{Recall}};\n\\]\nAUC-ROC (Area Under the Curve - Receiver Operating Characteristic)\nLa curva ROC (Receiver Operating Characteristic) è un grafico che mostra la capacità di un classificatore binario di distinguere tra due classi, variando la soglia di classificazione. Si costruisce tracciando il tasso di veri positivi \\(TPR\\) contro il tasso di falsi positivi \\(FPR\\) per diverse soglie di decisione. L’AUC è l’area sotto questa curva:\n\n\nAUC = 1: Modello perfetto.\nAUC = 0.5: Modello casuale (nessuna capacità di discriminazione).\nAUC &lt; 0.5: Modello peggiore del caso casuale (probabile errore nel modello o nei dati).\n\n\n\n\ncurva ROC.png\n\n\n\n\n9.7.2 Valutazione nei Problemi di Regressione\n\nErrore Quadratico Medio (MSE - Mean Square Error):\nL’Errore Quadratico Medio misura la media dei quadrati degli errori tra le previsioni del modello \\(\\hat{y}_i\\) e i valori reali \\(y_i\\). La formula è: \\[\n\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n\\] dove \\(n\\) è il numero totale di osservazioni.\nIl MSE penalizza maggiormente gli errori grandi, rendendolo particolarmente sensibile ai valori anomali (outlier). È una delle metriche più comuni nei problemi di regressione.\nErrore Assoluto Medio (MAE - Mean Absolute Error):\nL’Errore Assoluto Medio misura la media delle differenze assolute tra le previsioni \\(\\hat{y}_i\\)$ e i valori reali \\(y_i\\). La formula è \\[\n\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n\\]\ndove \\(n\\) è il numero totale di osservazioni. A differenza del MSE, il MAE non eleva al quadrato gli errori, il che lo rende meno sensibile agli outlier. È una scelta utile quando si desidera una valutazione robusta degli errori medi.\nR² (R-quadrato):\nIl coefficiente di determinazione \\(R^2\\) rappresenta la proporzione della varianza spiegata dal modello rispetto alla varianza totale nei dati. La formula è:\n\\[\nR^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n\\]\ndove \\(\\bar{y}\\) è la media dei valori reali.\nUn valore di \\(R^2\\) vicino a 1 indica che il modello spiega bene la varianza dei dati, mentre un valore vicino a 0 indica il contrario. Tuttavia, questa metrica può risultare fuorviante in alcuni contesti, come in presenza di variabili irrilevanti.\nCross-Validation:\nLa cross-validation è una tecnica fondamentale per valutare la capacità di generalizzazione di un modello. Tra le varianti più comuni, la k-fold cross-validation suddivide il dataset in k sottoinsiemi \\(k\\)-folds. Il modello viene addestrato \\(k\\) volte, utilizzando ogni volta un fold diverso come set di test e gli altri \\(k-1\\) come set di addestramento. Il punteggio finale è la media dei punteggi calcolati su ciascun fold:\n\\[\n\\text{Score medio} = \\frac{1}{k} \\sum_{j=1}^{k} \\text{Score}_j\n\\]\nQuesto metodo riduce il rischio di overfitting e fornisce una stima più affidabile delle prestazioni.\nBias e Varianza:\nIl bilanciamento tra bias e varianza è cruciale nei problemi di regressione. Il bias rappresenta l’errore sistematico introdotto da un modello troppo semplice, che non cattura la complessità dei dati (underfitting). La varianza, invece, misura quanto il modello è sensibile alle variazioni nei dati di addestramento, portando a overfitting.\nIl tradeoff bias-varianza può essere visualizzato come:\n\\[\n\\text{Errore totale} = \\text{Bias}^2 + \\text{Varianza} + \\text{Rumore}\n\\]\nDove il rumore è l’errore irreducibile presente nei dati. Tecniche come la regolarizzazione (ad esempio, Ridge o Lasso), la scelta di modelli meno complessi o l’ottimizzazione degli iperparametri possono aiutare a trovare il giusto equilibrio.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#laboratorio-python",
    "href": "3-1-apprendimento-supervisionato.html#laboratorio-python",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.8 Laboratorio Python",
    "text": "9.8 Laboratorio Python\n\n9.8.1 Esperimento 1: Predizione della Recidiva su nuovi dati\nIn questo esperimento Python, procedendo come per l’esperimento in Section 8.12.1 simuleremo un dataset per prevedere la recidiva penale (recidivo o non recidivo) utilizzando un modello di classificazione. Creeremo un trend realistico: ad esempio, chi non ha un lavoro stabile e ha un reato precedente più grave avrà maggiore probabilità di essere recidivo. Infine, esamineremo un nuovo caso e prevederemo la probabilità di recidiva. Per comprendere il codice possiamo pensarlo composto da tre parti:\n\nGenerazione dei dati: Simuliamo variabili come età, gravità del reato, lavoro stabile e supporto familiare.\nAddestramento del modello: Usiamo una Random Forest Classifier.\nValutazione del modello: Misuriamo l’accuratezza e visualizziamo i risultati in una matrice di confusione.\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Generazione dei dati simulati\nnp.random.seed(42)\nnum_samples = 1000\n\neta = np.random.randint(18, 70, num_samples)\ngravita_reato = np.random.choice([1, 2, 3], size=num_samples, p=[0.5, 0.3, 0.2])  # 1=furto, 2=violenza, 3=omicidio\nlavoro_stabile = np.random.choice([0, 1], size=num_samples, p=[0.6, 0.4])\nsupporto_familiare = np.random.choice([0, 1], size=num_samples, p=[0.4, 0.6])\n\n# Probabilità di recidiva basata su regole realistiche\nrecidiva_prob = (\n    0.4 * (1 - lavoro_stabile) +\n    0.3 * (3 - gravita_reato) +\n    0.3 * (1 - supporto_familiare)\n)\nrecidiva = (recidiva_prob &gt; np.random.rand(num_samples)).astype(int)\n\n# Creazione del DataFrame\ndata = pd.DataFrame({\n    'eta': eta,\n    'gravita_reato': gravita_reato,\n    'lavoro_stabile': lavoro_stabile,\n    'supporto_familiare': supporto_familiare,\n    'recidiva': recidiva\n})\n\n# Divisione del dataset\nX = data[['eta', 'gravita_reato', 'lavoro_stabile', 'supporto_familiare']]\ny = data['recidiva']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Addestramento del modello\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predizioni e valutazione\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Accuratezza del modello: {accuracy:.2f}\")\n\n# Matrice di confusione\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non Recidivo\", \"Recidivo\"])\ndisp.plot(cmap=plt.cm.Blues)\nplt.title(\"Matrice di Confusione\")\nplt.show()\n\nAccuratezza del modello: 0.79\n\n\n\n\n\n\n\n\n\nAdesso, supponiamo di avere un nuovo soggetto con le seguenti caratteristiche:\n\nEtà: 30 anni\nGravità del reato: 2 (violenza)\nLavoro stabile: No\nSupporto familiare: Sì\n\nPossiamo chiedere al modello di calcolare la probabilità che questo soggetto sia recidivo.\n\n# Nuovo soggetto\nnuovo_soggetto = pd.DataFrame({\n    'eta': [30],\n    'gravita_reato': [2],\n    'lavoro_stabile': [0],  # No\n    'supporto_familiare': [1]  # Sì\n})\n\n# Predizione del rischio di recidiva\nrischio_recidiva = model.predict_proba(nuovo_soggetto)[:, 1][0]  # Probabilità di essere recidivo\nclasse_predetta = model.predict(nuovo_soggetto)[0]\nprint(\"dati del nuovo soggetto:\")\nprint(nuovo_soggetto)\nprint(f\"Probabilità di recidiva: {rischio_recidiva:.2f}\")\nprint(f\"Classe Predetta: {'Recidivo' if classe_predetta == 1 else 'Non Recidivo'}\")\n\ndati del nuovo soggetto:\n   eta  gravita_reato  lavoro_stabile  supporto_familiare\n0   30              2               0                   1\nProbabilità di recidiva: 1.00\nClasse Predetta: Recidivo\n\n\nOvviamente, questo è solo un esempio di base. Nella pratica, si dovrebbero considerare anche la normalizzazione dei dati, la gestione delle variabili categoriali e l’ottimizzazione degli iperparametri per migliorare le prestazioni. Ciononostante, si invita il lettore a provare a modificare i dati e i modelli per comprendere meglio il funzionamento dei modelli di apprendimento supervisionato.\n\n\n9.8.2 Esperimento 2: Regressione del Costo di un Immobile\nIn questo esempio, simuleremo un dataset per prevedere il costo di un immobile. Usiamo un trend realistico: immobili più grandi, in quartieri più costosi e con più bagni avranno un prezzo più alto. Per comprendere il codice possiamo pensarlo composto da tre parti:\n\nGenerazione dei dati: Simuliamo variabili come superficie, numero di bagni e punteggio del quartiere.\nAddestramento del modello: Usiamo una Random Forest Regressor.\nValutazione del modello: Visualizziamo i risultati in un grafico di dispersione.\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generazione dei dati simulati\nnp.random.seed(42)\nnum_samples = 500\n\nsuperficie = np.random.randint(50, 300, num_samples)  # Superficie in m²\nbagni = np.random.randint(1, 4, num_samples)  # Numero di bagni\nquartiere = np.random.randint(1, 6, num_samples)  # Punteggio del quartiere (1-5)\n\n# Prezzo basato su regole realistiche\nprezzo = (\n    superficie * 3000 +\n    bagni * 10000 +\n    quartiere * 20000 +\n    np.random.normal(0, 5000, num_samples)  # Rumore casuale\n)\n\n# Creazione del DataFrame\ndata = pd.DataFrame({\n    'superficie': superficie,\n    'bagni': bagni,\n    'quartiere': quartiere,\n    'prezzo': prezzo\n})\n\n# Divisione del dataset\nX = data[['superficie', 'bagni', 'quartiere']]\ny = data['prezzo']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Addestramento del modello\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predizioni e valutazione\ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Errore Quadratico Medio (MSE): {mse:.2f}\")\nprint(f\"R² Score: {r2:.2f}\")\n\n# Grafico di dispersione\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred, alpha=0.7)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red', label='Predizione Perfetta')\nplt.xlabel(\"Prezzo Reale (€)\")\nplt.ylabel(\"Prezzo Predetto (€)\")\nplt.title(\"Confronto tra Prezzo Reale e Prezzo Predetto\")\nplt.legend()\nplt.grid()\nplt.show()\n\nErrore Quadratico Medio (MSE): 121692189.69\nR² Score: 1.00\n\n\n\n\n\n\n\n\n\nSupponiamo di avere un nuovo immobile con le seguenti caratteristiche:\n\nSuperficie: 120 m²\nNumero di bagni: 2\nPunteggio del quartiere: 4\n\nIl modello calcolerà il prezzo stimato per questo immobile.\n\n# Nuovo immobile\nnuovo_immobile = pd.DataFrame({\n    'superficie': [120],\n    'bagni': [2],\n    'quartiere': [4]\n})\n\n# Predizione del prezzo dell'immobile\nprezzo_stimato = model.predict(nuovo_immobile)[0]\n\n# Stampa dei dati del nuovo immobile\nprint(\"dati del nuovo immobile:\")\nprint(nuovo_immobile)\n\n# Stampa del prezzo stimato\nprint(f\"Prezzo stimato per il nuovo immobile: €{prezzo_stimato:,.2f}\")\n\ndati del nuovo immobile:\n   superficie  bagni  quartiere\n0         120      2          4\nPrezzo stimato per il nuovo immobile: €438,061.61\n\n\nOccorre ricordare che i dati sono simulati generando dei numeri casuali. Quindi, i legami tra le variabili e le uscite sono altrettanto casuali e potrebbero non essere realistici. Ciononostante, si invita il lettore a provare a modificare i dati e i modelli per comprendere meglio il funzionamento dei modelli di apprendimento supervisionato.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-1-apprendimento-supervisionato.html#esercizi",
    "href": "3-1-apprendimento-supervisionato.html#esercizi",
    "title": "9  Apprendimento Supervisionato",
    "section": "9.9 Esercizi",
    "text": "9.9 Esercizi\n\n9.9.1 Esercizio 1: Calcolo delle Metriche di Classificazione\nConsideriamo un modello utilizzato per predire la recidiva penale, dove l’obiettivo è determinare se un individuo sarà recidivo (1) o non recidivo (0) entro un certo periodo di tempo. Supponiamo di avere un dataset di test composto da 100 individui, e il modello ha prodotto le seguenti previsioni:\n\nVeri Positivi (VP): 40 (il modello ha correttamente predetto che 40 individui sarebbero recidivi)\nFalsi Positivi (FP): 10 (il modello ha predetto che 10 individui sarebbero recidivi, ma in realtà non lo sono)\nVeri Negativi (VN): 30 (il modello ha correttamente predetto che 30 individui non sarebbero recidivi)\nFalsi Negativi (FN): 20 (il modello ha predetto che 20 individui non sarebbero recidivi, ma in realtà lo sono)\n\nIl lettore calcoli i seguenti valori commentando i risultati ottenuti:\n\nAccuratezza (Accuracy)\nPrecisione (Precision)\nTasso di Recall (Recall)\nTasso di Falso Positivo (False Positive Rate - FPR)\nTasso di Falso Negativo (False Negative Rate - FNR)\n\n\n\n9.9.2 Esercizio 2: Calcolo delle Metriche di regressione\nConsideriamo un modello di regressione utilizzato per predire il valore di un immobile. Supponiamo di avere un dataset di test con i valori reali di 5 immobili e le previsioni del modello, come mostrato nella tabella seguente:\n\n\n\nImmobile\nValore Reale (€)\nValore Predetto (€)\n\n\n\n\n1\n300,000\n310,000\n\n\n2\n450,000\n430,000\n\n\n3\n500,000\n490,000\n\n\n4\n400,000\n420,000\n\n\n5\n350,000\n345,000\n\n\n\nIl lettore calcoli i seguenti valori commentando i risultati ottenuti:\n\nErrore Assoluto Medio (MAE)\nErrore Quadratico Medio (MSE)\nErrore Quadratico Medio Radice (RMSE)\nR² (R-quadrato)\n\n### Esercizio 3: Analisi del Rischio di Credito\nUna banca vuole sviluppare un modello di apprendimento supervisionato per valutare il rischio di credito dei richiedenti prestiti. L’obiettivo è prevedere se un richiedente sarà in grado di rimborsare il prestito o se c’è un’alta probabilità di inadempienza (default). Per fare ciò la banca ha a disposizione un dataset storico con le informazioni sui clienti e sui prestiti già erogati. Dataset (Simulato):\n\nEtà : Età del richiedente (valore numerico, in anni).\nReddito Annuale : Reddito annuo del richiedente (valore numerico, in euro).\nAnni di Impiego : Anni di impiego del richiedente (valore numerico).\nImporto del Prestito : Importo del prestito richiesto (valore numerico, in euro).\nPunteggio di Credito : Punteggio di credito del richiedente (valore numerico, tra 300 e 850).\nPresenza di Garante : Se il richiedente ha presentato un garante (valore binario: 0 = No, 1 = Sì).\nStato di Inadempienza : Se il richiedente è andato in default sul prestito (valore binario: 0 = No, 1 = Sì).\n\nIl lettore è invitato a:\n\nspiegare se si tratta di un problema di apprendimento supervisionato o non supervisionato.\nindichi il tipo di problema di apprendimento supervisionato è (classificazione o regressione).\nindichi qual è la variabile target (o etichetta) in questo problema?\nindichi quali sono le feature?",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Apprendimento Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-2-apprendimento-non-supervisionato.html",
    "href": "3-2-apprendimento-non-supervisionato.html",
    "title": "10  Apprendimento Non Supervisionato",
    "section": "",
    "text": "10.1 Introduzione\nL’apprendimento non supervisionato è un ramo del machine learning in cui i modelli vengono addestrati su dati senza etichette, ossia senza output conosciuti. L’obiettivo è scoprire strutture, pattern o relazioni nascoste all’interno dei dati. A differenza dell’apprendimento supervisionato, che richiede un dataset etichettato, l’apprendimento non supervisionato si concentra su come raggruppare dati simili o ridurre la complessità dei dati mantenendo le informazioni essenziali. Di seguito esamineremo i principali approcci e tecniche utilizzati in questo campo.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Apprendimento Non Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-2-apprendimento-non-supervisionato.html#clustering",
    "href": "3-2-apprendimento-non-supervisionato.html#clustering",
    "title": "10  Apprendimento Non Supervisionato",
    "section": "10.2 Clustering",
    "text": "10.2 Clustering\nIl clustering è una tecnica di apprendimento non supervisionato che mira a raggruppare i dati in gruppi (cluster) in base alla somiglianza tra gli elementi. Gli elementi all’interno di un cluster sono più simili tra loro rispetto a quelli di cluster differenti. Questa tecnica è ampiamente utilizzata per esplorare la struttura sottostante dei dati e per identificare segmenti naturali all’interno di un dataset.\nEsistono vari metodi di clustering, tra cui:\n\nK-means: Uno degli algoritmi di clustering più popolari, il k-means divide il dataset in k cluster, dove k è un numero predefinito. L’algoritmo funziona iterativamente, assegnando ogni punto dati al cluster il cui centroide è il più vicino e poi aggiornando i centroidi in base ai punti assegnati. Il processo continua fino a che i centroidi non cambiano più o le assegnazioni dei punti si stabilizzano. K-means è semplice ed efficace, ma può essere sensibile alla scelta di k e ai valori iniziali dei centroidi (MacQueen 1967).\nAgglomerative Hierarchical Clustering: Questo approccio costruisce una gerarchia di cluster attraverso un processo iterativo in cui ogni punto dati inizia come un cluster separato, e a ogni passo, i due cluster più vicini vengono uniti. Questo processo continua fino a che tutti i punti dati non appartengono a un singolo cluster. Il risultato può essere rappresentato come un dendrogramma, che visualizza la struttura gerarchica dei cluster. Questo metodo è utile per esplorare la struttura dei dati a diversi livelli di granularità (Rokach and Maimon 2005).\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise): DBSCAN è un algoritmo di clustering basato sulla densità che identifica cluster di alta densità separati da aree di bassa densità. A differenza di k-means, DBSCAN non richiede di specificare il numero di cluster in anticipo e può identificare cluster di forma arbitraria, oltre a gestire outlier in modo naturale (Ester et al. 1996).\n\n\n10.2.1 Confronto tra Metodi\n\n\n\n\n\n\n\n\nMetodo\nVantaggi\nSvantaggi\n\n\n\n\nK-means\nSemplice da implementare; efficiente su grandi dataset\nSensibile alla scelta di k e ai valori iniziali dei centroidi\n\n\nHierarchical Clustering\nRappresentazione visiva con dendrogrammi; non richiede k iniziale\nPoco scalabile su grandi dataset\n\n\nDBSCAN\nRileva cluster di forma arbitraria; gestisce outlier\nRichiede tuning accurato dei parametri eps e minPts",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Apprendimento Non Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-2-apprendimento-non-supervisionato.html#riduzione-della-dimensionalità",
    "href": "3-2-apprendimento-non-supervisionato.html#riduzione-della-dimensionalità",
    "title": "10  Apprendimento Non Supervisionato",
    "section": "10.3 Riduzione della Dimensionalità",
    "text": "10.3 Riduzione della Dimensionalità\nLa riduzione della dimensionalità è una tecnica che mira a ridurre il numero di variabili (o caratteristiche) nel dataset mantenendo la maggior parte dell’informazione rilevante. Questo è particolarmente utile quando si lavora con dati ad alta dimensionalità, dove un numero elevato di variabili può complicare l’analisi e aumentare il rischio di overfitting.\nAlcuni dei metodi principali per la riduzione della dimensionalità includono:\n\nPrincipal Component Analysis (PCA): PCA è una tecnica matematica che trasforma i dati in un nuovo spazio di coordinate ridotto, dove le nuove variabili (componenti principali) sono combinazioni lineari delle variabili originali. Le componenti principali sono ordinate in modo tale che la prima componente catturi la massima varianza nei dati, la seconda componente catturi la seconda massima varianza, e così via. Riducendo il numero di componenti principali, PCA può ridurre la dimensionalità dei dati preservando gran parte dell’informazione originale (Hotelling 1933).\nt-SNE (t-Distributed Stochastic Neighbor Embedding): t-SNE è una tecnica di riduzione della dimensionalità non lineare che è particolarmente efficace per la visualizzazione di dati ad alta dimensionalità. Riduce i dati in uno spazio a 2 o 3 dimensioni, preservando le relazioni di vicinanza tra i punti dati, il che lo rende ideale per visualizzare cluster naturali nei dati (Van der Maaten and Hinton 2008).\nAutoencoder: Gli autoencoder sono reti neurali progettate per imparare una rappresentazione compressa dei dati. Sono composti da due parti: l’encoder, che riduce i dati in uno spazio a bassa dimensionalità, e il decoder, che ricostruisce i dati originali dalla rappresentazione compressa. Gli autoencoder sono particolarmente utili per la riduzione della dimensionalità in problemi complessi dove le relazioni tra le variabili non sono lineari (Hinton and Salakhutdinov 2006).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Apprendimento Non Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-2-apprendimento-non-supervisionato.html#applicazioni",
    "href": "3-2-apprendimento-non-supervisionato.html#applicazioni",
    "title": "10  Apprendimento Non Supervisionato",
    "section": "10.4 Applicazioni",
    "text": "10.4 Applicazioni\nL’apprendimento non supervisionato trova applicazione in una vasta gamma di settori e problemi, soprattutto in contesti in cui i dati non sono etichettati e l’obiettivo è scoprire strutture nascoste o ridurre la complessità dei dati. Alcune delle principali applicazioni includono:\n\nSegmentazione del Mercato: Le tecniche di clustering come k-means e GMM sono utilizzate per segmentare i clienti in gruppi omogenei in base ai loro comportamenti o caratteristiche, permettendo strategie di marketing mirate e personalizzate.\nAnalisi delle Reti Sociali: L’apprendimento non supervisionato può essere utilizzato per identificare comunità o gruppi di interesse all’interno di reti sociali, analizzando le connessioni tra individui o entità (Newman 2004).\nRilevamento delle Anomalie: Algoritmi come DBSCAN sono utilizzati per identificare outlier o anomalie nei dati, come transazioni fraudolente, guasti nei sistemi o attività insolite.\nPreprocessing dei Dati per Modelli Supervisionati: La riduzione della dimensionalità attraverso PCA o autoencoder è spesso utilizzata come fase di preprocessing per migliorare le prestazioni di modelli di apprendimento supervisionato, riducendo il rumore e la complessità dei dati.\nVisualizzazione dei Dati: Tecniche come t-SNE sono utilizzate per ridurre la dimensionalità dei dati ad alta complessità, facilitando la visualizzazione e l’interpretazione delle strutture interne dei dati, come cluster o pattern nascosti.\n\nIn ambito giuridico, l’apprendimento non supervisionato può essere utilizzato per:\n\nL’analisi di grandi volumi di documenti legali, identificando temi ricorrenti o gruppi di casi simili.\nLa scoperta di pattern nei dati dei casi giudiziari, come tipologie di reati o fattori comuni nei procedimenti legali.\nLa segmentazione dei casi giudiziari, utile per organizzare i casi in categorie omogenee.\nIl rilevamento delle anomalie nei contratti legali o nelle transazioni finanziarie.\n\nQueste tecniche forniscono strumenti potenti per esplorare e comprendere i dati in modo più profondo, senza la necessità di etichette predefinite.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Apprendimento Non Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-2-apprendimento-non-supervisionato.html#laboratorio-python",
    "href": "3-2-apprendimento-non-supervisionato.html#laboratorio-python",
    "title": "10  Apprendimento Non Supervisionato",
    "section": "10.5 Laboratorio Python",
    "text": "10.5 Laboratorio Python\n\n10.5.1 Esperimento 1: Segmentazione di documenti legali con K-means\nIn questo esperimento Python, utilizziamo l’algoritmo K-means per raggruppare documenti legali basandoci sulla frequenza delle parole chiave presenti nei documenti. Si ipotizza che i documenti legali possano appartenere a categorie specifiche, come Contratti, Reati, Proprietà Privata, Assicurazioni, e Contratti di Lavoro. In particolare, si ipotizza che siano presenti 3 categorie principali. Il numero di cluster (K) è impostato a 3.\nIl funzionamento del semplice codice che segue può essere descritto come segue:\n\nSi caricano le stop word della lingua italiana in modo che il codice possa rimuovere correttamente le parole comuni in italiano come “il”, “di”, “la”, migliorando la qualità del clustering K Stop Words Italiane;\nI documenti legali sono trasformati in vettori numerici usando la tecnica TF-IDF, che calcola l’importanza delle parole in ciascun documento.\nL’algoritmo K-means raggruppa i documenti in 3 cluster (ad esempio, Contratti, Reati, Proprietà Privata).\nOgni documento viene assegnato a un cluster in base alla somiglianza del suo contenuto con altri documenti.\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nimport nltk\n\n# Scarica le stop words italiane\nnltk.download('stopwords')\nstop_words_italiane = stopwords.words('italian')\n\n# Dati simulati: estratti di documenti legali\ndocumenti_legali = [\n    \"Il contratto di locazione è regolato dal Codice Civile.\",\n    \"Il reato di furto è punito secondo l'articolo 624.\",\n    \"La proprietà privata è garantita dalla Costituzione.\",\n    \"L'assicurazione copre i danni derivanti da incidenti stradali.\",\n    \"Il contratto di lavoro subordinato deve rispettare le norme vigenti.\",\n    \"Il Codice Penale stabilisce le pene per i reati contro la persona. Le pene sono determinate dalla gravità del reato.\",\n    \"Le controversie contrattuali sono risolte tramite arbitrato.\",\n]\n\n# Trasformazione dei documenti in rappresentazioni numeriche (TF-IDF)\nvectorizer = TfidfVectorizer(stop_words=stop_words_italiane)\nX = vectorizer.fit_transform(documenti_legali)\n\n# Applicazione di K-means\nkmeans = KMeans(n_clusters=3, random_state=42)\nkmeans.fit(X)\n\n# Etichette dei cluster\nlabels = kmeans.labels_\n\n# Visualizzazione dei risultati\nfor i, documento in enumerate(documenti_legali):\n    print(f\"Documento: {documento}\")\n    print(f\"Appartiene al cluster: {labels[i]}\\n\")\n\nDocumento: Il contratto di locazione è regolato dal Codice Civile.\nAppartiene al cluster: 2\n\nDocumento: Il reato di furto è punito secondo l'articolo 624.\nAppartiene al cluster: 1\n\nDocumento: La proprietà privata è garantita dalla Costituzione.\nAppartiene al cluster: 0\n\nDocumento: L'assicurazione copre i danni derivanti da incidenti stradali.\nAppartiene al cluster: 0\n\nDocumento: Il contratto di lavoro subordinato deve rispettare le norme vigenti.\nAppartiene al cluster: 2\n\nDocumento: Il Codice Penale stabilisce le pene per i reati contro la persona. Le pene sono determinate dalla gravità del reato.\nAppartiene al cluster: 1\n\nDocumento: Le controversie contrattuali sono risolte tramite arbitrato.\nAppartiene al cluster: 0\n\n\n\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\lcapitanio\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nC:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning:\n\nCould not find the number of physical cores for the following reason:\n[WinError 2] Impossibile trovare il file specificato\nReturning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n\n  File \"C:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n    cpu_info = subprocess.run(\n               ^^^^^^^^^^^^^^^\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 548, in run\n    with Popen(*popenargs, **kwargs) as process:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1026, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1538, in _execute_child\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n\n\n10.5.2 Esperimento 2: Identificazione di anomalie nei dati giudiziari con DBSCAN\nIn questo epserimento useremo l’algoritmo DBSCAN per analizzare un dataset multivariato simulato in ambito giuridico. L’obiettivo è individuare pattern o anomalie nei dati relativi a sentenze legali. Il funzionamento del codice che segue può essere descritto come segue:\n\nViene generato un dataset simulato contenente variabili come numero di testimoni, durata dei processi, gravità del reato, ecc.\nL’algoritmo DBSCAN viene applicato per identificare cluster di casi simili e individuare eventuali anomalie o outlier. DBSCAN assegna il valore -1 ai punti considerati outlier.\nI risultati vengono visualizzati graficamente in 2D (numero di testimoni contro durata dei processi), con cluster distinti identificati da colori diversi, per una comprensione visiva dei cluster e delle anomalie. In particolare, il cluster -1 è quello composto dalle anomalie.\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Generazione di dati simulati: caratteristiche di sentenze legali\nnp.random.seed(42)\n\n# Creazione di variabili\nnumero_testimoni = np.random.randint(1, 10, size=200)  # Numero di testimoni per caso\ndurata_processi = np.random.normal(loc=12, scale=4, size=200)  # Durata dei processi in mesi\ngravita_reato = np.random.randint(1, 5, size=200)  # Gravità del reato (1=leggera, 4=grave)\n\n# Creazione di outlier\noutlier_testimoni = [20, 25]\noutlier_durata = [40, 50]\noutlier_gravita = [5, 5]\n\n# Inserimento degli outlier nei dati\nnumero_testimoni = np.append(numero_testimoni, outlier_testimoni)\ndurata_processi = np.append(durata_processi, outlier_durata)\ngravita_reato = np.append(gravita_reato, outlier_gravita)\n\n# Combinazione delle variabili in un DataFrame\ndata = pd.DataFrame({\n    'Numero_Testimoni': numero_testimoni,\n    'Durata_Processi': durata_processi,\n    'Gravita_Reato': gravita_reato\n})\n\n# Standardizzazione dei dati\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data)\n\n# Applicazione dell'algoritmo DBSCAN\ndbscan = DBSCAN(eps=1.5, min_samples=5)  # Parametri regolabili\nlabels = dbscan.fit_predict(data_scaled)\n\n# Aggiunta delle etichette al DataFrame\ndata['Cluster'] = labels\n\n# Visualizzazione dei risultati\nprint(\"Esempio di cluster individuati:\")\nprint(data.head())\n\n# Visualizzazione in 2D (numero testimoni vs durata processi)\nplt.figure(figsize=(10, 6))\nfor cluster in np.unique(labels):\n    cluster_data = data[data['Cluster'] == cluster]\n    plt.scatter(cluster_data['Numero_Testimoni'], cluster_data['Durata_Processi'], label=f\"Cluster {cluster}\", alpha=0.7)\n\nplt.title(\"Cluster di Dati Legali (Numero Testimoni vs Durata Processi)\")\nplt.xlabel(\"Numero Testimoni\")\nplt.ylabel(\"Durata Processi (mesi)\")\nplt.legend()\nplt.grid()\nplt.show()\n\nEsempio di cluster individuati:\n   Numero_Testimoni  Durata_Processi  Gravita_Reato  Cluster\n0                 7        10.446942              3        0\n1                 4         8.457951              3        0\n2                 8        10.573020              1        0\n3                 5        14.224487              4        0\n4                 7        16.175442              2        0\n\n\n\n\n\n\n\n\n\nCon questo approccio, è possibile identificare sia i cluster naturali nei dati sia eventuali anomalie (outlier), che potrebbero rappresentare sentenze particolarmente atipiche o significative.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Apprendimento Non Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-2-apprendimento-non-supervisionato.html#esercizi",
    "href": "3-2-apprendimento-non-supervisionato.html#esercizi",
    "title": "10  Apprendimento Non Supervisionato",
    "section": "10.6 Esercizi",
    "text": "10.6 Esercizi\n\n10.6.1 Esercizio 1: Analisi delle variabili rilevanti per il clustering dei casi giudiziari\nUn’agenzia governativa sta analizzando un dataset relativo ai casi giudiziari per identificare gruppi omogenei di processi. Le variabili disponibili includono:\n\nDurata del processo (in mesi).\nTipologia di reato (furto, frode, omicidio, ecc.).\nNumero di testimoni ascoltati.\nGravità della pena prevista (da 1 a 5).\n\nDomande:\n\nQuali variabili pensi siano più rilevanti per identificare cluster di processi simili? Motiva la tua scelta.\nSpiega come la scelta delle variabili potrebbe influenzare il risultato del clustering.\nQuali misure adotteresti per assicurarti che i dati siano ben preparati prima di applicare un algoritmo di clustering?\n\n\n\n10.6.2 Esercizio 2: Interpretazione dei risultati del clustering e loro applicazione nel sistema giudiziario\nImmagina di aver applicato un algoritmo di clustering a un dataset giuridico e di aver ottenuto tre cluster con le seguenti caratteristiche medie:\n\nCluster 1: Durata del processo breve (6 mesi), reati di bassa gravità (furto), pochi testimoni (1-2).\nCluster 2: Durata media (18 mesi), reati di gravità moderata (frode), testimoni multipli (5-10).\nCluster 3: Durata lunga (36 mesi), reati gravi (omicidio), molti testimoni (15-20).\n\nDomande:\n\nQuali interpretazioni puoi dare ai tre cluster? Ad esempio, rappresentano categorie specifiche di processi?\nCome potrebbero questi risultati essere utilizzati per migliorare l’efficienza del sistema giudiziario?\nSe ci fossero casi che non si adattano a nessun cluster, come li gestiresti?\n\n\n\n10.6.3 Esercizio 3: Riduzione della dimensionalità per semplificare l’analisi dei dati legali\nUn ricercatore sta analizzando un dataset di documenti legali che contiene centinaia di variabili, come parole chiave, lunghezza del documento e numero di citazioni. Il ricercatore vuole semplificare il dataset utilizzando una tecnica di riduzione della dimensionalità come PCA (Principal Component Analysis).\nDomande:\n\nQuali vantaggi offre l’uso di una tecnica come PCA in questo caso?\nDopo aver ridotto la dimensionalità dei dati, come valuteresti se l’informazione essenziale è stata preservata?\nIn che modo l’analisi dei dati ridotti potrebbe facilitare l’identificazione di pattern nei documenti legali?\n\n\n\n\n\nEster, Martin, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. “A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.” In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining (KDD-96), 226–31.\n\n\nHinton, Geoffrey E, and Ruslan R Salakhutdinov. 2006. “Reducing the Dimensionality of Data with Neural Networks.” Science 313 (5786): 504–7.\n\n\nHotelling, Harold. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417–41.\n\n\nMacQueen, James. 1967. Some Methods for Classification and Analysis of Multivariate Observations. University of California Press.\n\n\nNewman, Mark EJ. 2004. “Fast Algorithm for Detecting Community Structure in Networks.” Physical Review E 69 (6): 066133.\n\n\nRokach, Lior, and Oded Maimon. 2005. “Clustering Methods: A Review.” Data Mining and Knowledge Discovery Handbook, 321–52.\n\n\nVan der Maaten, Laurens, and Geoffrey Hinton. 2008. “Visualizing Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Apprendimento Non Supervisionato</span>"
    ]
  },
  {
    "objectID": "3-3-bias.html",
    "href": "3-3-bias.html",
    "title": "11  Bias",
    "section": "",
    "text": "11.1 Introduzione\nIl bias nei modelli di machine learning è una questione critica, soprattutto in settori sensibili come il diritto, dove le decisioni automatizzate possono avere implicazioni significative su persone fisiche, sulle persone giuridiche e sulla società in generale. Il bias può portare a previsioni errate e ingiuste, perpetuando disuguaglianze sociali e legali. Quindi, la comprensione e la gestione del bias sono essenziali per garantire la trasparenza e la giustizia nei sistemi legali e sociali.\nIn questa sezione, esploreremo in dettaglio le diverse tipologie di bias, le cause e gli impatti che esse possono avere, e le tecniche per mitigare questi bias, con esempi pratici che illustrano il problema.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bias</span>"
    ]
  },
  {
    "objectID": "3-3-bias.html#tipologie-di-bias",
    "href": "3-3-bias.html#tipologie-di-bias",
    "title": "11  Bias",
    "section": "11.2 Tipologie di Bias",
    "text": "11.2 Tipologie di Bias\nI modelli di machine learning possono essere affetti da vari tipi di bias, ciascuno con caratteristiche specifiche e potenziali impatti:\n\nBias di Selezione: Si verifica quando il dataset utilizzato per addestrare il modello non rappresenta adeguatamente la popolazione o il fenomeno che si intende modellare. Ad esempio, immaginate un modello di machine learning sviluppato per predire il successo di un’azione legale basato su dati storici. Se il dataset include solo casi di successo e non quelli falliti, il modello potrebbe sovrastimare le probabilità di successo.\nBias di Conferma: Questo tipo di bias emerge quando i dati o le caratteristiche selezionate per il modello confermano preconcetti o ipotesi preesistenti. Ad esempio, un modello per la concessione del credito che utilizza dati storici potrebbe favorire inconsciamente gli individui di una determinata etnia o genere.\nBias di Sopravvivenza: Si verifica quando l’analisi si basa solo sui dati relativi ai “sopravvissuti” a un determinato processo, ignorando i casi che non ce l’hanno fatta. Ad esempio, se un’analisi per determinare i fattori di successo per avviare uno studio legale si basa solo su studi legali che sono riusciti, si ignoreranno i casi di studi legali che hanno fallito.\nBias Sistemico: Riflette le disuguaglianze o le discriminazioni già presenti nei dati storici e nei sistemi sociali. Ad esempio, un modello che predice la recidiva basato su dati storici che riflettono pratiche discriminatorie della polizia potrebbe perpetuare tali discriminazioni.\nBias Algoritmico: Questo tipo di bias è introdotto dall’algoritmo stesso, spesso a causa di obiettivi di ottimizzazione che non rappresentano adeguatamente il problema. Ad esempio, un algoritmo di scoring creditizio ottimizzato esclusivamente per ridurre i tassi di insolvenza potrebbe penalizzare ingiustamente gruppi demografici con meno accesso al credito.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bias</span>"
    ]
  },
  {
    "objectID": "3-3-bias.html#cause-e-impatti-del-bias",
    "href": "3-3-bias.html#cause-e-impatti-del-bias",
    "title": "11  Bias",
    "section": "11.3 Cause e Impatti del Bias",
    "text": "11.3 Cause e Impatti del Bias\n\n11.3.1 Cause del Bias\n\nDataset Non Rappresentativi: Uno dei motivi principali del bias è l’uso di dataset non rappresentativi della popolazione target. Ad esempio, se un modello di predizione della recidiva è addestrato principalmente su dati relativi a reati minori, potrebbe non essere accurato quando applicato a reati più gravi.\nScelte di Modellazione: Le decisioni prese durante la fase di modellazione, come la selezione delle caratteristiche o la scelta dell’algoritmo, possono introdurre bias. Per esempio, includere variabili come il “quartiere di residenza” in un modello potrebbe introdurre bias socio-economici.\nFeedback Loop: Un feedback loop si verifica quando le previsioni di un modello influenzano i dati futuri, rafforzando il bias. Ad esempio, un sistema di polizia predittiva che invia più pattuglie in quartieri già sorvegliati potrebbe generare più arresti in quelle aree, creando un ciclo che perpetua il bias.\n\n\n\n11.3.2 Impatti del Bias\n\nDiscriminazione: Un modello biased può perpetuare o amplificare disuguaglianze esistenti. Ad esempio, se un modello di scoring creditizio discrimina contro minoranze etniche, potrebbe negare l’accesso al credito a persone meritevoli.\nPerdita di Fiducia: Sistemi percepiti come ingiusti o discriminatori possono compromettere la fiducia del pubblico.\nConseguenze Legali: L’uso di modelli biased in decisioni legali può portare a contenziosi e danni reputazionali per le istituzioni, oltre a violare normative sulla non discriminazione.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bias</span>"
    ]
  },
  {
    "objectID": "3-3-bias.html#tecniche-di-mitigazione-del-bias",
    "href": "3-3-bias.html#tecniche-di-mitigazione-del-bias",
    "title": "11  Bias",
    "section": "11.4 Tecniche di Mitigazione del Bias",
    "text": "11.4 Tecniche di Mitigazione del Bias\n\nRaccolta e Preparazione dei Dati: Assicurarsi che il dataset sia rappresentativo della popolazione target.\nPre-processing dei Dati: Applicare tecniche per ridurre il bias prima dell’addestramento, come la rimozione di caratteristiche correlate al bias (ad esempio, genere o etnia).\nModellazione In-process: Utilizzare regolarizzazioni che penalizzano il modello se sfrutta caratteristiche correlate al bias.\nPost-processing: Correggere il bias nelle previsioni del modello, ad esempio attraverso la calibrazione delle probabilità predette.\nMonitoraggio e Aggiornamento Continuo: Valutare e aggiornare periodicamente i modelli per garantire che il bias non peggiori.\nAnalisi di Impatto e Auditing: Condurre audit regolari per identificare e correggere bias, coinvolgendo esperti tecnici ed etici.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bias</span>"
    ]
  },
  {
    "objectID": "3-3-bias.html#conclusione",
    "href": "3-3-bias.html#conclusione",
    "title": "11  Bias",
    "section": "11.5 Conclusione",
    "text": "11.5 Conclusione\nLa gestione del bias nei modelli di machine learning è essenziale per garantire che le applicazioni dell’IA, soprattutto in ambiti sensibili come il diritto, siano eque e giuste. Attraverso l’adozione di tecniche appropriate di mitigazione del bias, è possibile sviluppare modelli che rispettino i principi di equità e non discriminazione, minimizzando il rischio di perpetuare disuguaglianze e promuovendo decisioni più giuste e trasparenti.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bias</span>"
    ]
  },
  {
    "objectID": "3-3-bias.html#laboratorio-in-python",
    "href": "3-3-bias.html#laboratorio-in-python",
    "title": "11  Bias",
    "section": "11.6 Laboratorio in Python",
    "text": "11.6 Laboratorio in Python\n\n11.6.1 Esperimento 1: Bias di Selezione\nSimuliamo un dataset dove la popolazione rappresentata è squilibrata tra due gruppi. Addestriamo un modello e analizziamo l’accuratezza per ciascun gruppo.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\n\n# Simulazione di un dataset con bias di selezione\nnp.random.seed(42)\nn_samples = 500\n\n# Gruppo A (es. uomini)\nX_A = np.random.normal(loc=50, scale=10, size=(int(n_samples * 0.8), 1))  # più rappresentato\ny_A = (X_A.flatten() &gt; 50).astype(int)  # outcome dipende dal valore\n\n# Gruppo B (es. donne), sottorappresentato\nX_B = np.random.normal(loc=50, scale=10, size=(int(n_samples * 0.2), 1))\ny_B = (X_B.flatten() &gt; 50).astype(int)\n\n# Combinazione dei dati\nX = np.vstack((X_A, X_B))\ny = np.concatenate((y_A, y_B))\ngroups = np.array(['A'] * len(X_A) + ['B'] * len(X_B))\n\n# Divisione del dataset\nX_train, X_test, y_train, y_test, groups_train, groups_test = train_test_split(X, y, groups, test_size=0.3, random_state=42)\n\n# Addestramento modello\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predizioni\ny_pred = model.predict(X_test)\n\n# Accuratezza complessiva\nacc = accuracy_score(y_test, y_pred)\n\n# Accuratezza per gruppo\nacc_A = accuracy_score(y_test[groups_test == 'A'], y_pred[groups_test == 'A'])\nacc_B = accuracy_score(y_test[groups_test == 'B'], y_pred[groups_test == 'B'])\n\n# Matrice di confusione\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()\nplt.title(\"Matrice di Confusione - Bias di Selezione\")\nplt.show()\n\n# Visualizzazione delle accuratezze\nsns.barplot(x=['Totale', 'Gruppo A', 'Gruppo B'], y=[acc, acc_A, acc_B])\nplt.title('Accuratezza per Gruppo')\nplt.ylabel('Accuratezza')\nplt.ylim(0, 1)\nplt.grid(True)\nplt.show()\n\nacc, acc_A, acc_B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI risultati dell’esperimento sul bias di selezione sono i seguenti:\n\nAccuratezza complessiva: 99.3%\nAccuratezza sul Gruppo A (maggiormente rappresentato): 100%\nAccuratezza sul Gruppo B (sottorappresentato): 96.8%\n\nQuesto esperimento evidenzia il pericolo del bias di selezione, un problema comune nei sistemi di classificazione. Anche se il modello ha un’elevata accuratezza complessiva, la sua performance sul gruppo sottorappresentato è significativamente inferiore. Questo dimostra come un modello possa essere ingiusto verso alcune categorie, anche se sembra essere accurato in generale.\n\n\n11.6.2 Esperimento 2: Bias Sistemico\nL’obiettivo di questo esperimento è dimostrare l’effetto di un bias sistemico di genere in un modello di selezione del personale. A questo scopo simuliamo un processo di selezione del personale in cui, a parità di esperienza e età, le donne vengono penalizzate sistematicamente rispetto agli uomini. Usiamo un dataset artificiale in cui il genere influisce negativamente sulla probabilità di assunzione, creando così un bias sistemico.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Generazione dati simulati\nnp.random.seed(42)\nn = 1000\nesperienza = np.random.normal(5, 2, n)\neta = np.random.normal(35, 5, n)\ngenere = np.random.choice([0, 1], size=n)  # 0 = femmina, 1 = maschio\n\n# Bias sistemico: penalizzazione delle donne (genere=0)\nlogits = 0.5 * esperienza + 0.1 * eta + 1.0 * genere - 7.5\nprob_assunzione = 1 / (1 + np.exp(-logits))\nassunto = np.random.binomial(1, prob_assunzione)\n\n# Dataset\ndf = pd.DataFrame({\n    'esperienza': esperienza,\n    'eta': eta,\n    'genere': genere,\n    'assunto': assunto\n})\n\n# Split e normalizzazione\nX = df[['esperienza', 'eta', 'genere']]\ny = df['assunto']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Modello\nmodel = LogisticRegression()\nmodel.fit(X_train_scaled, y_train)\ny_pred = model.predict(X_test_scaled)\n\n# Classificazione report\nreport = classification_report(y_test, y_pred, output_dict=True)\nreport_df = pd.DataFrame(report).transpose()\n\n# Grafico: distribuzione delle probabilità predette per maschi e femmine\nprob_pred = model.predict_proba(X_test_scaled)[:, 1]\nX_test_with_probs = pd.DataFrame(X_test_scaled, columns=['esperienza', 'eta', 'genere'])\nX_test_with_probs['prob_assunto'] = prob_pred\nX_test_with_probs['genere'] = X_test['genere'].values\n\n# Plot\nplt.figure(figsize=(10, 6))\nfor g, label in zip([0, 1], ['Femmine', 'Maschi']):\n    subset = X_test_with_probs[X_test_with_probs['genere'] == g]\n    plt.hist(subset['prob_assunto'], bins=25, alpha=0.6, label=label, density=True)\nplt.xlabel('Probabilità Predetta di Assunzione')\nplt.ylabel('Densità')\nplt.title('Distribuzione della Probabilità di Assunzione per Genere')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nImportazione delle librerie\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import ConfusionMatrixDisplay, classification_report\nfrom sklearn.model_selection import train_test_split\nQueste librerie permettono di:\n\ncreare e gestire dati (numpy, pandas)\nvisualizzare grafici (matplotlib)\ncreare e valutare un modello di regressione logistica (sklearn)\n\n\n\nGenerazione del dataset simulato\n\nnp.random.seed(42)\nn = 1000\ngenere = np.random.binomial(1, 0.5, n)  # 0=f, 1=m\nesperienza = np.random.normal(5 + genere*1.5, 1, n)  # maschi con +1.5 anni\neta = np.random.normal(35, 5, n)\nQui generiamo 1000 candidati:\n\ngenere: 0 = femmina, 1 = maschio, distribuiti equamente.\nesperienza: in media, i maschi hanno più esperienza (bias indotto).\netà: distribuita normalmente.\n\nbias = -0.8 * (1 - genere)  # penalizzazione per le donne\nlogits = 0.3*esperienza + 0.05*eta + bias\nprob = 1 / (1 + np.exp(-logits))\nassunto = np.random.binomial(1, prob)\n\nCalcoliamo la probabilità di assunzione come combinazione lineare delle variabili, con un bias penalizzante per le donne.\nLa variabile assunto simula se il candidato viene assunto.\n\n\nAddestramento del modello\n\nX = np.column_stack((esperienza, eta, genere))\ny = assunto\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nAddestriamo un modello di regressione logistica per predire l’assunzione.\nUsiamo il genere come input, quindi il modello può apprendere e replicare il bias.\n\n\nVisualizzazione del bias\n\nX_df = pd.DataFrame(X_test, columns=[\"esperienza\", \"eta\", \"genere\"])\nX_df[\"prob_pred\"] = model.predict_proba(X_test)[:,1]\nX_df[\"genere\"] = X_df[\"genere\"].astype(int)\n\nplt.figure(figsize=(8, 6))\nfor g in [0, 1]:\n    subset = X_df[X_df[\"genere\"] == g]\n    label = \"Femmine\" if g == 0 else \"Maschi\"\n    plt.hist(subset[\"prob_pred\"], bins=20, alpha=0.5, label=label, density=True)\n\nplt.title(\"Distribuzione delle probabilità predette di assunzione per genere\")\nplt.xlabel(\"Probabilità predetta di assunzione\")\nplt.ylabel(\"Densità\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\nIstogramma delle probabilità predette per ciascun genere.\nMostra chiaramente che i maschi hanno più probabilità di essere assunti, anche a parità di altre condizioni.\n\nQuesto esperimento dimostra visivamente e quantitativamente:\n\nl’effetto del bias sistemico,\ncome esso possa essere appreso e amplificato da un modello,\nperché sia cruciale rimuovere variabili sensibili o applicare strategie di mitigazione.\n\n\n\n11.6.3 Esperimento 2: Bias di razza nella valutazione del rischio di recidiva\nObiettivo di questo esperimento è dimostrare come un modello predittivo possa riflettere o amplificare bias razziali analizzando la distribuzione delle probabilità predette per la recidiva in due gruppi demografici distinti.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\n# 1. Simulazione dataset giustizia penale con possibile bias razziale\nnp.random.seed(42)\nn = 1000\n# Variabile sensibile: razza (0=gruppo A, 1=gruppo B)\nrazza = np.random.binomial(1, 0.5, n)\n\n# Caratteristiche: numero precedenti penali, età\nprecedenti = np.random.poisson(2 + razza * 0.5, n)  # il gruppo B ha in media più precedenti\neta = np.random.normal(35, 5, n)\n\n# Probabilità \"vera\" di recidiva senza bias\nlogits_veri = 0.8 * precedenti + 0.02 * eta\nprob_vera = 1 / (1 + np.exp(-logits_veri))\nrecidiva_reale = np.random.binomial(1, prob_vera)\n\n# Sistema giudiziario introduce un bias implicito (più severo con gruppo B)\nbias = 0.7 * razza\nlogits_predetti = logits_veri + bias\nprob_predetta = 1 / (1 + np.exp(-logits_predetti))\nrecidiva_predetta = np.random.binomial(1, prob_predetta)\n\n# 2. Addestramento modello su dati \"biasati\"\nX = np.column_stack((precedenti, eta, razza))\ny = recidiva_predetta\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprobs = model.predict_proba(X_test)[:, 1]\n\n# 3. Analisi dell'equità: confronto distribuzioni delle probabilità predette per gruppo\nX_test_df = pd.DataFrame(X_test, columns=[\"precedenti\", \"eta\", \"razza\"])\nX_test_df[\"prob_pred\"] = probs\nX_test_df[\"razza\"] = X_test_df[\"razza\"].astype(int)\n\n# 4. Grafico della distribuzione predetta per razza\nplt.figure(figsize=(8, 6))\nfor r in [0, 1]:\n    subset = X_test_df[X_test_df[\"razza\"] == r]\n    label = \"Gruppo A\" if r == 0 else \"Gruppo B\"\n    plt.hist(subset[\"prob_pred\"], bins=20, alpha=0.6, label=label, density=True)\n\nplt.title(\"Distribuzione delle probabilità predette di recidiva per gruppo razziale\")\nplt.xlabel(\"Probabilità predetta di recidiva\")\nplt.ylabel(\"Densità\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# 5. Rapporto di classificazione\nreport = classification_report(y_test, y_pred, target_names=[\"No recidiva\", \"Recidiva\"])\nreport\n\n\n\n\n\n\n\n\nC:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n\nPrecision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nC:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n\nPrecision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nC:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n\nPrecision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n'              precision    recall  f1-score   support\\n\\n No recidiva       0.00      0.00      0.00        26\\n    Recidiva       0.91      1.00      0.95       274\\n\\n    accuracy                           0.91       300\\n   macro avg       0.46      0.50      0.48       300\\nweighted avg       0.83      0.91      0.87       300\\n'\n\n\nIl codice Python simula un dataset di giustizia penale con possibile bias razziale. Il modello predittivo apprende e amplifica questo bias, mostrando come la distribuzione delle probabilità predette sia diversa per i due gruppi.\n\nSimulazione dei dati\n\nAbbiamo simulato un dataset di 1.000 soggetti nel contesto della giustizia penale, con le seguenti caratteristiche:\n\nRazza (0=Gruppo A, 1=Gruppo B)\nNumero di precedenti penali\nEtà\n\nLa variabile sensibile è la razza. Abbiamo introdotto un bias implicito che aumenta il rischio predetto di recidiva per il gruppo B, anche a parità di condizioni con il gruppo A.\n\nAddestramento del modello\n\nÈ stato addestrato un modello di regressione logistica sui dati biasati per simulare l’apprendimento in un ambiente non equo.\n\nAnalisi dell’equità\n\nAbbiamo calcolato le probabilità predette di recidiva per ogni soggetto nel test set e confrontato graficamente le distribuzioni nei due gruppi razziali.\n\nRisultati\n\nIl grafico mostra chiaramente che il gruppo B riceve sistematicamente predizioni di rischio più alte, anche a parità di precedenti e di età. Questo è un segnale diretto di bias sistemico nel processo predittivo.\n\nValutazione delle prestazioni\n\nDal report di classificazione:\n\nIl modello ha una accuratezza del 91%, ma è totalmente sbilanciato: non predice mai la classe “No recidiva” (precision = 0.00, recall = 0.00).\nQuesto è un esempio perfetto di come un modello possa sembrare “accurato” ma essere profondamente ingiusto.\n\nL’esperimento dimostra che:\n\nIl bias può essere introdotto nei dati, non necessariamente nel modello.\nÈ fondamentale analizzare le predizioni per sottogruppi (e.g., gruppi razziali, genere, età).\nAnche modelli con alta accuratezza possono comportarsi in modo discriminatorio, e le metriche aggregate possono mascherare queste disuguaglianze.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bias</span>"
    ]
  },
  {
    "objectID": "3-3-bias.html#esercizi",
    "href": "3-3-bias.html#esercizi",
    "title": "11  Bias",
    "section": "11.7 Esercizi",
    "text": "11.7 Esercizi\n\n11.7.1 Esercizio 1: Identificazione dei Bias nei Dati\nObiettivo: Riconoscere le diverse tipologie di bias in un contesto giuridico.\nScenario: Un tribunale sta implementando un sistema di intelligenza artificiale per prevedere la probabilità di recidiva degli imputati. Il modello è stato addestrato su dati storici, che includono informazioni su età, genere, reati precedenti e quartiere di residenza.\nDopo alcuni mesi di utilizzo, emergono alcune anomalie:\n\nIl modello assegna un rischio di recidiva più alto agli imputati provenienti da determinati quartieri.\nLe donne ricevono punteggi di recidiva inferiori rispetto agli uomini, anche a parità di altri fattori.\nGli imputati di età inferiore ai 30 anni vengono spesso classificati come ad alto rischio di recidiva, anche se alcuni non hanno precedenti gravi.\n\nDomande:\n\nQuali tipi di bias sono presenti in questo modello? (Selezione, conferma, sopravvivenza, sistemico, algoritmico)\nQuali potrebbero essere le cause di questi bias nei dati storici utilizzati per l’addestramento?\nQuali soluzioni potrebbero essere adottate per mitigare questi bias?\n\n\n\n11.7.2 Esercizio 2: Bias e Implicazioni Giuridiche\nObiettivo: Analizzare le conseguenze legali ed etiche dei bias nei sistemi di intelligenza artificiale.\nScenario: Un’azienda sviluppa un software di selezione del personale basato su machine learning, addestrato con dati storici dell’azienda stessa. Dopo l’implementazione, emerge che il software tende a selezionare prevalentemente uomini per le posizioni manageriali.\nAlcuni dipendenti sollevano preoccupazioni e accusano l’azienda di discriminazione indiretta. Un comitato interno analizza i dati e scopre che, negli ultimi 10 anni, il 75% dei dirigenti assunti erano uomini, e il modello ha imparato a replicare questa tendenza.\nDomande:\n\nQuale tipologia di bias sta influenzando il sistema di selezione del personale?\nQuali sono le potenziali violazioni legali che potrebbero derivare dall’uso di questo modello? (Es. discriminazione, violazione delle pari opportunità)\nQuali azioni correttive potrebbero essere intraprese per rendere il sistema più equo?\n\n\n\n11.7.3 Esercizio 3: Analisi di un Caso Reale di Bias Algoritmico\nObiettivo: Riflettere sugli effetti reali del bias nei modelli di machine learning.\nAttività:\n\nRicerca un caso reale (esempio: COMPAS, bias nei sistemi di riconoscimento facciale, discriminazione nei sistemi di credito).\nDescrivi il problema: Qual era il bias riscontrato nel modello?\nAnalizza le conseguenze: Quali impatti ha avuto il bias sulle persone o sulle istituzioni coinvolte?\nValuta le misure adottate: Sono state prese azioni per correggere il bias? Se sì, quali?\n\nSuggerimento: Se non trovi un caso, puoi analizzare il caso COMPAS, un software utilizzato negli USA per prevedere la recidiva criminale, che ha mostrato discriminazioni razziali nelle sue previsioni.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bias</span>"
    ]
  },
  {
    "objectID": "3-4-regressione-lineare-e-logistica.html",
    "href": "3-4-regressione-lineare-e-logistica.html",
    "title": "12  Regressione Lineare e Logistica",
    "section": "",
    "text": "12.1 Introduzione alla Regressione Lineare\nLa regressione lineare è uno degli algoritmi più semplici ed efficaci per prevedere un valore continuo. Questo modello è alla base di numerosi metodi statistici e di machine learning ed è utilizzato in svariati contesti, dalla finanza alla giurisprudenza (Bishop 2006).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Regressione Lineare e Logistica</span>"
    ]
  },
  {
    "objectID": "3-4-regressione-lineare-e-logistica.html#introduzione-alla-regressione-lineare",
    "href": "3-4-regressione-lineare-e-logistica.html#introduzione-alla-regressione-lineare",
    "title": "12  Regressione Lineare e Logistica",
    "section": "",
    "text": "12.1.1 Definizione Matematica\nMatematicamente, la regressione lineare è descritta dall’equazione:\n\\[\\hat{y} = \\beta_0 + \\beta_1 x_1\\]\nDove: - \\(\\hat{y}\\) è il valore predetto della variabile dipendente. - \\(x_1\\) è la variabile indipendente. - \\(\\beta_0\\) è l’intercetta (valore di \\(\\hat{y}\\) quando \\(x_1 = 0\\)). - \\(\\beta_1\\) è il coefficiente di regressione che determina l’influenza di \\(x_1\\) su \\(\\hat{y}\\).\nL’obiettivo della regressione lineare è trovare i coefficienti che minimizzano l’errore quadratico medio (Mean Squared Error, MSE):\n\\[MSE = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2\\]\nQuesta funzione di errore misura la differenza tra i valori reali e quelli predetti. La regressione lineare utilizza metodi come i minimi quadrati o la discesa del gradiente per trovare i valori ottimali di \\(\\beta\\) (Hastie, Tibshirani, and Friedman 2009).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Regressione Lineare e Logistica</span>"
    ]
  },
  {
    "objectID": "3-4-regressione-lineare-e-logistica.html#regressione-lineare-multipla",
    "href": "3-4-regressione-lineare-e-logistica.html#regressione-lineare-multipla",
    "title": "12  Regressione Lineare e Logistica",
    "section": "12.2 Regressione Lineare Multipla",
    "text": "12.2 Regressione Lineare Multipla\nLa regressione lineare multipla è un’estensione della regressione lineare semplice che include più variabili indipendenti. È particolarmente utile quando si vogliono modellare relazioni più complesse tra variabili.\n\n12.2.1 Definizione Matematica\nLa formula della regressione lineare multipla è:\n\\[\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\\]\nDove: - \\(\\hat{y}\\) è la variabile dipendente predetta. - \\(x_1, x_2, \\dots, x_n\\) sono le variabili indipendenti. - \\(\\beta_0\\) è l’intercetta. - \\(\\beta_1, \\beta_2, \\dots, \\beta_n\\) sono i coefficienti di regressione che indicano il peso di ogni variabile indipendente.\nL’obiettivo rimane lo stesso: minimizzare l’errore tra le previsioni e i valori reali. Tuttavia, con più variabili, il modello diventa più complesso e richiede strumenti avanzati per identificare le variabili più rilevanti.\n\n\n12.2.2 Selezione delle Variabili Più Influenti\nQuando si lavora con la regressione lineare multipla, una delle sfide principali è determinare quali variabili indipendenti influenzano maggiormente la variabile dipendente. L’uso di troppe variabili può portare a overfitting, mentre l’esclusione di variabili importanti può causare underfitting.\n\n12.2.2.1 Metodi per la Selezione delle Variabili\nAlcuni metodi per selezionare le variabili più influenti includono:\n\nAnalisi dei Coefficienti: Se un coefficiente \\(\\beta_i\\) è vicino a zero, la variabile corrispondente potrebbe avere un impatto trascurabile.\nEliminazione Stepwise (Backward o Forward Selection): Tecniche iterative per rimuovere o aggiungere variabili in base alla loro significatività statistica.\nLASSO (Least Absolute Shrinkage and Selection Operator): Metodo di regressione che impone una penalizzazione sui coefficienti, riducendo a zero quelli meno rilevanti.\nImportanza delle Variabili nei Modelli di Alberi: Anche se si sta usando la regressione, tecniche come le random forest possono aiutare a identificare le variabili più influenti.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Regressione Lineare e Logistica</span>"
    ]
  },
  {
    "objectID": "3-4-regressione-lineare-e-logistica.html#introduzione-alla-regressione-logistica",
    "href": "3-4-regressione-lineare-e-logistica.html#introduzione-alla-regressione-logistica",
    "title": "12  Regressione Lineare e Logistica",
    "section": "12.3 Introduzione alla Regressione Logistica",
    "text": "12.3 Introduzione alla Regressione Logistica\nLa regressione logistica è una tecnica di classificazione utilizzata quando la variabile dipendente può assumere due valori distinti, come “colpevole” o “non colpevole”. Questo metodo è ampiamente utilizzato per la valutazione del rischio di recidiva (Kleinberg, Mullainathan, and Raghavan 2018).\n\n12.3.1 Definizione Matematica\nLa regressione logistica applica una trasformazione sigmoide alla regressione lineare:\n\\[\n\\hat{y} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n)}}\n\\]\nLa funzione sigmoide restituisce valori tra 0 e 1, interpretati come probabilità. Se \\(\\hat{y} &gt; 0.5\\), il modello assegna la classe 1, altrimenti assegna la classe 0.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Regressione Lineare e Logistica</span>"
    ]
  },
  {
    "objectID": "3-4-regressione-lineare-e-logistica.html#connessione-con-le-reti-neurali",
    "href": "3-4-regressione-lineare-e-logistica.html#connessione-con-le-reti-neurali",
    "title": "12  Regressione Lineare e Logistica",
    "section": "12.4 Connessione con le Reti Neurali",
    "text": "12.4 Connessione con le Reti Neurali\nLe reti neurali sono un’estensione della regressione lineare e logistica. Ogni neurone in una rete neurale esegue una combinazione lineare delle variabili di input, seguita da una funzione di attivazione, proprio come nella regressione logistica. Comprendere questi modelli è essenziale per lo studio del deep learning (Goodfellow, Bengio, and Courville 2016).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Regressione Lineare e Logistica</span>"
    ]
  },
  {
    "objectID": "3-4-regressione-lineare-e-logistica.html#laboratorio-di-python",
    "href": "3-4-regressione-lineare-e-logistica.html#laboratorio-di-python",
    "title": "12  Regressione Lineare e Logistica",
    "section": "12.5 Laboratorio di Python",
    "text": "12.5 Laboratorio di Python\n\n12.5.1 Esperimento 1: Regressione Lineare (Stima del prezzo di un immobile)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generazione dati simulati\nnp.random.seed(42)\nX = np.random.normal(100, 20, 50).reshape(-1, 1)  \ny = 200 + 2 * X.flatten() + np.random.normal(0, 15, X.shape[0])\n\n# Creazione e addestramento del modello\nmodel = LinearRegression()\nmodel.fit(X, y)\ny_pred = model.predict(X)\n\n# Visualizzazione\nplt.figure(figsize=(10, 6))\nplt.scatter(X, y, color='blue', label='Dati reali')\nplt.plot(X, y_pred, color='red', label='Regressione lineare')\nplt.xlabel('Metri quadrati')\nplt.ylabel('Prezzo (migliaia di euro)')\nplt.title('Regressione Lineare: Predizione del Prezzo di un Immobile')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice Python implementa un semplice modello di regressione lineare per stimare il prezzo di un immobile in base alla sua superficie (metri quadrati). Vediamo passo dopo passo cosa fa il codice.\n1. Importazione delle librerie\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nnumpy → usato per generare e manipolare dati numerici.\nmatplotlib.pyplot → usato per creare grafici.\nsklearn.linear_model.LinearRegression → implementa un modello di regressione lineare.\n\n2. Generazione dei dati simulati\nnp.random.seed(42)\nX = np.random.normal(100, 20, 50).reshape(-1, 1)  \ny = 200 + 2 * X.flatten() + np.random.normal(0, 15, X.shape[0])\n\nnp.random.seed(42) → imposta un seme per la generazione casuale, garantendo che i risultati siano riproducibili.\nnp.random.normal(100, 20, 50) → genera 50 numeri casuali con media 100 e deviazione standard 20 (rappresentano i metri quadrati delle case).\nreshape(-1, 1) → trasforma l’array in una matrice con una colonna e 50 righe (richiesto da sklearn).\ny = 200 + 2 * X.flatten() + np.random.normal(0, 15, X.shape[0]) → crea i prezzi delle case seguendo una relazione lineare:\n\n200 è l’intercetta (prezzo base).\n2 * X significa che il prezzo aumenta di 2 unità per ogni metro quadrato in più.\nnp.random.normal(0, 15, X.shape[0]) aggiunge rumore casuale ai prezzi per simulare dati reali.\n\n\n3. Creazione e addestramento del modello di regressione lineare\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nLinearRegression() → crea un modello di regressione lineare.\nmodel.fit(X, y) → addestra il modello usando i dati (X come input e y come output).\n\n4. Predizione dei valori\ny_pred = model.predict(X)\n\nmodel.predict(X) → usa il modello addestrato per calcolare il prezzo stimato delle case.\n\n5. Visualizzazione dei risultati\nplt.figure(figsize=(10, 6))\nplt.scatter(X, y, color='blue', label='Dati reali')\nplt.plot(X, y_pred, color='red', label='Regressione lineare')\nplt.xlabel('Metri quadrati')\nplt.ylabel('Prezzo (migliaia di euro)')\nplt.title('Regressione Lineare: Predizione del Prezzo di un Immobile')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.scatter(X, y, color=‘blue’, label=‘Dati reali’) → disegna un grafico a dispersione con i dati reali (metri quadrati vs prezzo).\nplt.plot(X, y_pred, color=‘red’, label=‘Regressione lineare’) → disegna la linea di regressione che approssima i dati.\nAggiunge etichette, legenda e griglia per migliorare la leggibilità.\n\nCosa rappresenta il grafico?\n\nI punti blu sono i dati reali (metri quadrati vs prezzo dell’immobile).\nLa linea rossa rappresenta la retta della regressione lineare, ovvero la previsione del modello.\nL’obiettivo è trovare la linea che meglio approssima i dati per poter stimare il prezzo di una casa conoscendone solo i metri quadrati.\n\nConclusione: Il modello impara una relazione lineare tra la superficie dell’immobile e il prezzo, permettendo di stimare il valore di case future basandosi sui metri quadrati!\n\n\n12.5.2 Esperimento 2: Regressione Lineare Multipla\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.linear_model import LinearRegression\n\n# Creazione di un dataset simulato\nnp.random.seed(42)\nn = 100\nX1 = np.random.rand(n) * 100  # Variabile indipendente 1 (es. età)\nX2 = np.random.rand(n) * 50   # Variabile indipendente 2 (es. anni di esperienza)\ny = 30 + 2.5 * X1 + 1.8 * X2 + np.random.normal(0, 10, n)  # Output con rumore\n\n# Creazione del modello di regressione lineare multipla\nX = np.column_stack((X1, X2))\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predizione dei valori\ny_pred = model.predict(X)\n\n# Visualizzazione dei coefficienti\nprint(\"Coefficienti:\", model.coef_)\nprint(\"Intercetta:\", model.intercept_)\n\n# Creazione del grafico 3D per visualizzare i dati e il piano di regressione\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(111, projection='3d')\n\n# Scatter plot dei dati reali\nax.scatter(X1, X2, y, color='blue', label='Dati reali')\n\n# Creazione della superficie di regressione\nX1_grid, X2_grid = np.meshgrid(np.linspace(X1.min(), X1.max(), 20),\n                               np.linspace(X2.min(), X2.max(), 20))\ny_grid = (model.intercept_ + model.coef_[0] * X1_grid + model.coef_[1] * X2_grid)\n\nax.plot_surface(X1_grid, X2_grid, y_grid, color='red', alpha=0.5)\n\n# Etichette degli assi\nax.set_xlabel(\"Età\")\nax.set_ylabel(\"Anni di esperienza\")\nax.set_zlabel(\"Salario stimato\")\nax.set_title(\"Regressione Lineare Multipla\")\nplt.legend()\nplt.show()\n\nCoefficienti: [2.46582747 1.94386228]\nIntercetta: 29.106100364500747\n\n\n\n\n\n\n\n\n\nQuesto codice Python implementa un semplice modello di regressione lineare multipla per stimare il salario di un impiegato in base all’ età e agli anni di esperienza dell’impiegato. Vediamo passo dopo passo cosa fa il codice.\n1 Generazione dei dati Il codice genera un dataset simulato con 100 osservazioni e due variabili indipendenti:\n\nX1: età della persona (tra 0 e 100 anni).\nX2: anni di esperienza lavorativa (tra 0 e 50 anni).\ny: salario stimato in base a un modello lineare con una certa variabilità casuale (rumore).\n\nLa relazione tra le variabili è definita dalla formula:\n\\[\ny = 30 + 2.5 \\times X1 + 1.8 \\times X2 + \\text{rumore casuale}\n\\]\n\nIl valore 30 è l’intercetta (valore base del salario).\n2.5 è il peso dell’età (ogni anno di età in più aumenta il salario di 2.5 unità).\n1.8 è il peso degli anni di esperienza (ogni anno di esperienza in più aumenta il salario di 1.8 unità).\nIl rumore introduce variazioni casuali per simulare dati realistici.\n\n2 Creazione del modello Dopo aver organizzato i dati in una matrice X, il codice utilizza LinearRegression() di Scikit-Learn per addestrare il modello:\nmodel.fit(X, y)\nQuesto calcola i coefficienti che meglio approssimano la relazione tra le variabili.\n3 Predizione e interpretazione dei coefficienti Dopo l’addestramento, vengono stampati i coefficienti stimati:\nprint(\"Coefficienti:\", model.coef_)\nprint(\"Intercetta:\", model.intercept_)\nQuesti valori ci dicono quanto l’età e l’esperienza influenzano il salario.\n4 Visualizzazione grafica - Il grafico 3D mostra i punti blu (dati reali) e il piano rosso che rappresenta la superficie di regressione. - Il modello cerca di minimizzare la distanza tra il piano e i punti reali.\nIn questo epserimento abbiamo visto come applicare la regressione lineare multipla per prevedere un valore (salario) in base a più variabili (età ed esperienza).\n\n\n12.5.3 Esperimento 3: Regressione Logistica\nIn questo esperimento simuliamo un’applicazione della regressione logistica in ambito penale, con l’obiettivo di prevedere la probabilità di recidiva di un imputato sulla base di:\n\nEtà,\nPresenza di precedenti penali.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    confusion_matrix, ConfusionMatrixDisplay, classification_report\n)\n\n# 1. Simulazione dati: rischio di recidiva in funzione di età e precedenti\nnp.random.seed(42)\nn = 500\neta = np.random.randint(18, 60, n)  # età tra 18 e 60\nprecedenti = np.random.binomial(1, 0.4, n)  # 0 = nessun precedente, 1 = precedenti\n\n# Funzione probabilità: maggiore con precedenti e minore età\np_recidiva = 1 / (1 + np.exp(-(-4 + 0.08 * (60 - eta) + 2.5 * precedenti)))\ny = np.random.binomial(1, p_recidiva)\n\n# Preparazione dataset\nX = np.column_stack((eta, precedenti))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 2. Regressione Logistica\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_prob = model.predict_proba(X_test)[:, 1]\n\n# 3. Valutazione\ncm = confusion_matrix(y_test, y_pred)\nreport = classification_report(y_test, y_pred, output_dict=True)\n\n# 4. Visualizzazione\nConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No recidiva\", \"Recidiva\"]).plot()\n\n# Decision boundary\nplt.figure(figsize=(10, 6))\nplt.scatter(X_test[:, 0], y_prob, c=X_test[:, 1], cmap='coolwarm', edgecolor='k')\nplt.xlabel(\"Età\")\nplt.ylabel(\"Probabilità predetta di recidiva\")\nplt.title(\"Probabilità di recidiva in funzione dell'età e dei precedenti\")\nplt.colorbar(label=\"Precedenti (0=No, 1=Sì)\")\nplt.grid(True)\nplt.show()\n\n(report, model.coef_, model.intercept_)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n({'0': {'precision': 0.8543689320388349,\n   'recall': 0.8627450980392157,\n   'f1-score': 0.8585365853658536,\n   'support': 102.0},\n  '1': {'precision': 0.7021276595744681,\n   'recall': 0.6875,\n   'f1-score': 0.6947368421052632,\n   'support': 48.0},\n  'accuracy': 0.8066666666666666,\n  'macro avg': {'precision': 0.7782482958066514,\n   'recall': 0.7751225490196079,\n   'f1-score': 0.7766367137355584,\n   'support': 150.0},\n  'weighted avg': {'precision': 0.8056517248502376,\n   'recall': 0.8066666666666666,\n   'f1-score': 0.8061206675224647,\n   'support': 150.0}},\n array([[-0.07867108,  2.46644213]]),\n array([0.90914022]))\n\n\nIl codice Python implementa un semplice modello di regressione logistica per prevedere la probabilità di recidiva di un imputato sulla base di età e presenza di precedenti penali. Vediamo passo dopo passo cosa fa il codice.\nAbbiamo generato un dataset fittizio di 500 imputati, in cui:\n\nL’età è compresa tra 18 e 60 anni.\nIl 40% ha precedenti penali.\nLa probabilità di recidiva è più alta per:\n\nimputati con precedenti,\nimputati più giovani.\n\n\nQuesta probabilità è calcolata con una funzione logistica:\n\\[\np = \\frac{1}{1 + \\exp(-(-4 + 0.08 \\cdot (60 - \\text{età}) + 2.5 \\cdot \\text{precedenti}))}\n\\]\nI valori di y (recidiva sì/no) sono stati estratti in base a questa probabilità.\nAbbiamo addestrato una regressione logistica sui dati, divisi in train e test set.\nIl modello ha appreso i seguenti coefficienti:\n\nEtà: −0.078 → l’aumento dell’età riduce la probabilità di recidiva.\nPrecedenti: +2.47 → avere precedenti penali aumenta significativamente la probabilità.\n\nIntercetta: +0.91\nPer quanto concerne l’accuratezza del modello, abbiamo ottenuto:\nAccuratezza complessiva: 80.6% Precisione per la classe “recidiva”: 70.2% Richiamo (recall) per “recidiva”: 68.8%\nLa matrice di confusione mostra una buona capacità del modello nel distinguere tra recidiva e non recidiva.\nNel secondo grafico, ogni punto rappresenta un imputato del test set:\n\nX: Età\nY: Probabilità predetta di recidiva\nColore: Presenza di precedenti (blu = no, rosso = sì)\n\nLa curva mostra come la probabilità predetta diminuisce con l’età e aumenta sensibilmente in presenza di precedenti penali.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Regressione Lineare e Logistica</span>"
    ]
  },
  {
    "objectID": "3-4-regressione-lineare-e-logistica.html#esercizi",
    "href": "3-4-regressione-lineare-e-logistica.html#esercizi",
    "title": "12  Regressione Lineare e Logistica",
    "section": "12.6 Esercizi",
    "text": "12.6 Esercizi\n\n12.6.1 Esercizio 1: Analisi delle Variabili\nQuali tecniche si possono usare per selezionare le variabili più influenti in una regressione lineare multipla?\n\n\n12.6.2 Esercizio 2: Interpretazione della Regressione Logistica\nSe un coefficiente della regressione logistica ha valore negativo, cosa implica per la probabilità predetta?\n\n\n12.6.3 Esercizio 3: Effetti di un Dataset Sbilanciato\nUn dataset con il 90% dei casi appartenenti a una sola classe può influenzare la regressione logistica? Come si può correggere questo problema?\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press. https://www.deeplearningbook.org/.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer.\n\n\nKleinberg, Jon, Sendhil Mullainathan, and Manish Raghavan. 2018. “Human Decisions and Machine Predictions.” The Quarterly Journal of Economics 133 (1): 237–93.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Regressione Lineare e Logistica</span>"
    ]
  },
  {
    "objectID": "3-5-perceptrone.html",
    "href": "3-5-perceptrone.html",
    "title": "13  Percetptrone",
    "section": "",
    "text": "13.1 Introduzione\nIl percettrone è un modello semplificato del funzionamento di una cellula nervosa, proposto da Frank Rosenblatt nel 1958 (Rosenblatt 1958). Rappresenta la base su cui si sono costruite le moderne reti neurali ed è in grado di risolvere problemi di classificazione linearmente separabili. La sua semplicità lo rende un ottimo punto di partenza per comprendere i principi fondamentali del machine learning.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Percetptrone</span>"
    ]
  },
  {
    "objectID": "3-5-perceptrone.html#struttura-e-funzionamento",
    "href": "3-5-perceptrone.html#struttura-e-funzionamento",
    "title": "13  Percetptrone",
    "section": "13.2 Struttura e Funzionamento",
    "text": "13.2 Struttura e Funzionamento\nIl percettrone prende in input un vettore di caratteristiche numeriche ( x = (x_1, x_2, , x_n) ) e calcola una somma pesata:\n\\[\nz = \\sum_{i=1}^n w_i x_i + b\n\\]\nDove: - \\(w_i\\) sono i pesi, - $b è il bias.\nIl risultato \\(z\\) viene trasformato da una funzione di attivazione che produce l’output del modello:\n\\[\n\\hat{y} = f(z)\n\\]\nNel percettrone classico, la funzione \\(f\\) è la funzione a soglia:\n\\[\n\\hat{y} =\n\\begin{cases}\n1 & \\text{se } z \\geq 0 \\\\\n0 & \\text{se } z &lt; 0\n\\end{cases}\n\\]",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Percetptrone</span>"
    ]
  },
  {
    "objectID": "3-5-perceptrone.html#addestramento-del-percettrone",
    "href": "3-5-perceptrone.html#addestramento-del-percettrone",
    "title": "13  Percetptrone",
    "section": "13.3 Addestramento del Percettrone",
    "text": "13.3 Addestramento del Percettrone\nIl modello viene addestrato con l’algoritmo di aggiornamento del percettrone. Per ogni errore di classificazione, i pesi vengono aggiornati come segue:\n\\[\nw_i \\leftarrow w_i + \\eta \\cdot (y - \\hat{y}) \\cdot x_i\n\\]\n\\[\nb \\leftarrow b + \\eta \\cdot (y - \\hat{y})\n\\]\nDove: - \\(\\eta\\) è il tasso di apprendimento (learning rate), - \\(y\\) è il valore reale, - \\(\\hat{y}\\) è il valore predetto.\nQuesto processo continua finché il modello non commette più errori (o si raggiunge un numero massimo di iterazioni).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Percetptrone</span>"
    ]
  },
  {
    "objectID": "3-5-perceptrone.html#funzioni-di-attivazione",
    "href": "3-5-perceptrone.html#funzioni-di-attivazione",
    "title": "13  Percetptrone",
    "section": "13.4 Funzioni di Attivazione",
    "text": "13.4 Funzioni di Attivazione\nOltre alla soglia, esistono molte altre funzioni di attivazione usate nei neuroni artificiali:\n\n13.4.1 Funzione Sigmoide\n\\[\nf(z) = \\frac{1}{1 + e^{-z}}\n\\]\n\nOutput continuo tra 0 e 1.\nUsata nei modelli probabilistici, come la regressione logistica.\n\n\n\n13.4.2 Funzione Tanh\n\\[\nf(z) = \\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n\\]\n\nOutput tra -1 e 1.\nPiù centrata rispetto alla sigmoide.\n\n\n\n13.4.3 Funzione ReLU (Rectified Linear Unit)\n\\[\nf(z) = \\max(0, z)\n\\]\n\nAttiva solo valori positivi.\nMolto usata nelle reti neurali profonde (Goodfellow, Bengio, and Courville 2016).\n\nL’andamento delle funzioni di attivazioni viste è mostrato nel seguente grafico.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nz = np.linspace(-10, 10, 100)\nsigmoid = 1 / (1 + np.exp(-z))\ntanh = np.tanh(z)\nrelu = np.maximum(0, z)\n\nplt.figure(figsize=(10, 6))\nplt.plot(z, sigmoid, label='Sigmoide', color='blue')\nplt.plot(z, tanh, label='Tanh', color='green')\nplt.plot(z, relu, label='ReLU', color='red')\nplt.axhline(0, color='gray', linestyle='--')\nplt.axvline(0, color='gray', linestyle='--')\nplt.title(\"Principali Funzioni di Attivazione\")\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Percetptrone</span>"
    ]
  },
  {
    "objectID": "3-5-perceptrone.html#limitazioni",
    "href": "3-5-perceptrone.html#limitazioni",
    "title": "13  Percetptrone",
    "section": "13.5 Limitazioni",
    "text": "13.5 Limitazioni\nIl percettrone può risolvere solo problemi linearmente separabili, cioè in cui una retta (o un iperpiano) può separare le classi. Per problemi più complessi, si usano reti neurali multilivello (MLP), in grado di apprendere anche confini non lineari (Haykin 2009).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Percetptrone</span>"
    ]
  },
  {
    "objectID": "3-5-perceptrone.html#laboratorio-di-python",
    "href": "3-5-perceptrone.html#laboratorio-di-python",
    "title": "13  Percetptrone",
    "section": "13.6 Laboratorio di Python",
    "text": "13.6 Laboratorio di Python\n\n13.6.1 Esperimento 1: Implementazione di un perceptrone\nIn questo esperimento sviluppiamo una implementazione del perceptrone senza fare uso di librerie esterne e lo useremo in un problema di classificazione con classi linearmente separabili. Le sole librerie usata sono random per la generazione di numeri casuali per simulare i dati e matplotlib per graficare i risultati. I dati simulati sono costruti per essere linearmente separabili.\n\nimport random\nimport matplotlib.pyplot as plt\n\n# -----------------------\n# 1. Generazione del dataset\n# -----------------------\n\nrandom.seed(42)\nn_samples = 100\nX = []\ny = []\n\nfor _ in range(n_samples):\n    x1 = random.uniform(0, 10)\n    x2 = random.uniform(0, 10)\n    label = 1 if x1 + x2 &gt; 10 else 0  # Separazione lineare lungo la diagonale x1 + x2 = 10\n    X.append([x1, x2])\n    y.append(label)\n\n# Suddividiamo manualmente in training e test set\nsplit_index = int(0.8 * n_samples)\nX_train = X[:split_index]\ny_train = y[:split_index]\nX_test = X[split_index:]\ny_test = y[split_index:]\n\n# -----------------------\n# 2. Funzioni del Percettrone\n# -----------------------\n\ndef step_function(z):\n    return 1 if z &gt;= 0 else 0\n\ndef predict(x, weights, bias):\n    z = sum(w * xi for w, xi in zip(weights, x)) + bias\n    return step_function(z)\n\ndef train_perceptrone(X_train, y_train, learning_rate=0.1, epochs=10):\n    n_features = len(X_train[0])\n    weights = [0.0 for _ in range(n_features)]\n    bias = 0.0\n\n    for epoch in range(epochs):\n        for x, label in zip(X_train, y_train):\n            y_pred = predict(x, weights, bias)\n            error = label - y_pred\n            # Aggiornamento pesi e bias\n            for i in range(n_features):\n                weights[i] += learning_rate * error * x[i]\n            bias += learning_rate * error\n    return weights, bias\n\n# -----------------------\n# 3. Addestramento del modello\n# -----------------------\n\nweights, bias = train_perceptrone(X_train, y_train, learning_rate=0.1, epochs=30)\n\n# -----------------------\n# 4. Valutazione e Matrice di Confusione\n# -----------------------\n\nTP = FP = TN = FN = 0\ny_pred_test = []\n\nfor x, label in zip(X_test, y_test):\n    y_hat = predict(x, weights, bias)\n    y_pred_test.append(y_hat)\n    if y_hat == 1 and label == 1:\n        TP += 1\n    elif y_hat == 1 and label == 0:\n        FP += 1\n    elif y_hat == 0 and label == 0:\n        TN += 1\n    elif y_hat == 0 and label == 1:\n        FN += 1\n\nprint(\"Matrice di Confusione (senza librerie esterne):\")\nprint(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\naccuracy = (TP + TN) / len(y_test)\nprint(f\"Accuratezza: {accuracy:.2f}\")\n\n# -----------------------\n# 5. Visualizzazione\n# -----------------------\n\nx1_pos = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 1]\nx2_pos = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 1]\nx1_neg = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 0]\nx2_neg = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 0]\n\nplt.figure(figsize=(8, 6))\nplt.scatter(x1_pos, x2_pos, c='green', label='Classe 1 (Reale)', marker='x')\nplt.scatter(x1_neg, x2_neg, c='blue', label='Classe 0 (Reale)', marker='o')\n\n# Linea di decisione: w1*x1 + w2*x2 + b = 0 =&gt; x2 = -(w1*x1 + b)/w2\nx1_vals = [i for i in range(0, 11)]\nif weights[1] != 0:\n    x2_vals = [-(weights[0]*x + bias)/weights[1] for x in x1_vals]\n    plt.plot(x1_vals, x2_vals, '--', color='black', label='Confine decisionale')\n\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.title(\"Percettrone - Separazione tra classi\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\nMatrice di Confusione (senza librerie esterne):\nTP: 9, FP: 0, TN: 11, FN: 0\nAccuratezza: 1.00\n\n\n\n\n\n\n\n\n\nIl codice Python usato per l’implementazione del perceptrone e per il grafico dei risultati segue la seguente logica:\n\nGenerazione dati Simuliamo 100 punti 2D. I punti per cui \\(x_1 + x_2 &gt; 10\\) sono etichettati come classe 1, altrimenti classe 0.\nImplementazione del percettrone\n\n\nstep_function(z): restituisce 1 se la somma è maggiore o uguale a zero, altrimenti 0.\npredict(x, weights, bias): calcola il valore di \\(z\\) e applica la funzione di attivazione.\ntrain_perceptrone(): implementa l’algoritmo di apprendimento con aggiornamento dei pesi.\n\n\nAddestramento Il modello viene addestrato per 20 epoche (ripetizioni del dataset) su 80% dei dati.\nMatrice di confusione Calcolo dei 4 elementi della matrice di confusione:\n\n\nTP: (True Positive = Vero Positivo) predetto 1 e vero 1\nTN: (True Negative = Vero Negativo) predetto 0 e vero 0\nFP: (False Positive = Falso Positivo) predetto 1 e vero 0 (falso allarme)\nFN: (False Negative = Falso Negativo) predetto 0 e vero 1 (falso negativo)\n\n\nVisualizzazione Il grafico mostra:\n\n\nI punti veri (blu per classe 0, verde per classe 1).\nIl confine decisionale calcolato con la formula della retta.\n\nRisultato atteso\nCon dati così semplici e ben separabili, il percettrone dovrebbe ottenere una accuratezza alta (quasi 100%).\n\n\n13.6.2 Esperimento 2: il perceptrone bel caso di classi concentriche\nIl codice Python che segue implementa un semplice modello di classificatore a perceptrone usando la sola libreria random per la generazione di numeri casuali per simulare i dati e matplotlib per graficare i risultati. I dati simulati sono distribuiti su due corone circolari concentriche e quindi non linearmente separabili.\n\nimport math\nimport random\nimport matplotlib.pyplot as plt\n\n# -------------------------------\n# 1. Generazione del dataset circolare\n# -------------------------------\n\ndef genera_cerchi(n_samples):\n    X = []\n    y = []\n    for _ in range(n_samples):\n        r = random.uniform(0, 1)\n        angle = random.uniform(0, 2 * math.pi)\n        if r &lt; 0.5:\n            radius = random.uniform(1, 2)\n            label = 0\n        else:\n            radius = random.uniform(3, 4)\n            label = 1\n        x1 = radius * math.cos(angle)\n        x2 = radius * math.sin(angle)\n        X.append([x1, x2])\n        y.append(label)\n    return X, y\n\nrandom.seed(42)\nX, y = genera_cerchi(200)\n\n# Suddividiamo in training e test set\nsplit_index = int(0.8 * len(X))\nX_train = X[:split_index]\ny_train = y[:split_index]\nX_test = X[split_index:]\ny_test = y[split_index:]\n\n# -------------------------------\n# 2. Percettrone da zero\n# -------------------------------\n\ndef step_function(z):\n    return 1 if z &gt;= 0 else 0\n\ndef predict(x, weights, bias):\n    z = sum(w * xi for w, xi in zip(weights, x)) + bias\n    return step_function(z)\n\ndef train_perceptrone(X, y, learning_rate=0.1, epochs=20):\n    n_features = len(X[0])\n    weights = [0.0 for _ in range(n_features)]\n    bias = 0.0\n    for epoch in range(epochs):\n        for xi, yi in zip(X, y):\n            y_pred = predict(xi, weights, bias)\n            error = yi - y_pred\n            for i in range(n_features):\n                weights[i] += learning_rate * error * xi[i]\n            bias += learning_rate * error\n    return weights, bias\n\n# Addestramento\nweights, bias = train_perceptrone(X_train, y_train)\n\n# -------------------------------\n# 3. Valutazione\n# -------------------------------\n\nTP = FP = TN = FN = 0\ny_pred_test = []\n\nfor x, label in zip(X_test, y_test):\n    y_hat = predict(x, weights, bias)\n    y_pred_test.append(y_hat)\n    if y_hat == 1 and label == 1:\n        TP += 1\n    elif y_hat == 1 and label == 0:\n        FP += 1\n    elif y_hat == 0 and label == 0:\n        TN += 1\n    elif y_hat == 0 and label == 1:\n        FN += 1\n\nprint(\"Matrice di confusione:\")\nprint(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\naccuracy = (TP + TN) / len(y_test)\nprint(f\"Accuratezza: {accuracy:.2f}\")\n\n# -------------------------------\n# 4. Visualizzazione\n# -------------------------------\n\n# Colori reali\nx1_pos = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 1]\nx2_pos = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 1]\nx1_neg = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 0]\nx2_neg = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 0]\n\nplt.figure(figsize=(8, 6))\nplt.scatter(x1_pos, x2_pos, color='green', label='Classe 1 (Reale)', marker='x')\nplt.scatter(x1_neg, x2_neg, color='blue', label='Classe 0 (Reale)', marker='o')\n\n# Linea di decisione (valida solo per separazione lineare)\nx_vals = [i / 10.0 for i in range(-40, 41)]\nif weights[1] != 0:\n    y_vals = [-(weights[0]*x + bias)/weights[1] for x in x_vals]\n    plt.plot(x_vals, y_vals, '--', color='black', label='Confine decisionale')\n\nplt.title(\"Percettrone su dati non linearmente separabili\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\nMatrice di confusione:\nTP: 13, FP: 16, TN: 4, FN: 7\nAccuratezza: 0.42\n\n\n\n\n\n\n\n\n\nL’esito dell’esperimento mostra chiaramente ciò che già sapevamo bene: Il percettrone può apprendere solo confini lineari. In questo caso:\n\nI dati sono disposti in cerchi concentrici, cioè non possono essere separati con una retta.\nIl percettrone cerca una retta per dividere i dati… ma non riesce e commette molti errori.\nL’accuratezza è bassa (minore del 50%).\nIl grafico mostra che la linea di decisione non riesce a separare correttamente le due classi.\n\nIn casi come questo servono modelli di reti neurali più avanzati come le reti neurali multistrato (MLP) .",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Percetptrone</span>"
    ]
  },
  {
    "objectID": "3-5-perceptrone.html#esercizi",
    "href": "3-5-perceptrone.html#esercizi",
    "title": "13  Percetptrone",
    "section": "13.7 Esercizi",
    "text": "13.7 Esercizi\n\n13.7.1 Esercizio 1: Comprendere la classificazione lineare\nSpiega con parole tue cosa significa che un problema è linearmente separabile. Fai un esempio nel contesto giuridico in cui questo tipo di separazione potrebbe essere realistico.\n\n\n13.7.2 Esercizio 2: Aggiornamento dei pesi\nDati i seguenti valori:\n\ninput \\(x = [2, -1]\\)\npesi iniziali \\(w = [0.5, 0.5]\\)\nbias \\(b = 0.2\\)\napprendimento \\(\\eta = 0.1\\)\noutput vero \\(y = 1\\)\noutput predetto \\(\\hat{y} = 0\\)\n\nCalcola i nuovi valori di \\(w\\) e \\(b\\) dopo un singolo aggiornamento.\n\n\n13.7.3 Esercizio 3: Vantaggi e limiti del modello\nQuali sono i principali vantaggi e limiti dell’utilizzo del percettrone in ambito giuridico? Riporta almeno un esempio per ciascun caso.\n\n\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press. https://www.deeplearningbook.org/.\n\n\nHaykin, Simon. 2009. Neural Networks and Learning Machines. 3rd ed. Pearson.\n\n\nRosenblatt, Frank. 1958. The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain. Psychological Review. Vol. 65. 6. American Psychological Association.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Percetptrone</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html",
    "href": "3-6-deep-learning.html",
    "title": "14  Deep learning",
    "section": "",
    "text": "14.1 Introduzione\nIl deep learning è una sottocategoria avanzata del machine learning che sfrutta reti neurali profonde per affrontare problemi complessi, caratterizzati da grandi quantità di dati e dalla necessità di apprendere rappresentazioni astratte e stratificate delle informazioni(Goodfellow, Bengio, and Courville 2016). Il viaggio nel deep learning inizia spesso con le Reti Neurali Multistrato (MLP), che rappresentano il primo passo verso la comprensione delle reti neurali profonde.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#reti-neurali-multistrato-mlp",
    "href": "3-6-deep-learning.html#reti-neurali-multistrato-mlp",
    "title": "14  Deep learning",
    "section": "14.2 Reti Neurali Multistrato (MLP)",
    "text": "14.2 Reti Neurali Multistrato (MLP)\nLe Reti Neurali Multistrato (MLP = Multi Layer Perceptron) sono una forma di rete neurale feedforward, composte da uno strato di input, uno o più strati nascosti e uno strato di output. Le MLP sono in grado di apprendere rappresentazioni non lineari dei dati grazie all’uso di funzioni di attivazione non lineari nei neuroni dei loro strati nascosti. Sebbene siano efficaci per molti compiti, le MLP tradizionali hanno una capacità limitata di affrontare problemi particolarmente complessi, poiché sono generalmente composte da pochi strati nascosti. L’addestramento delle MLP avviene attraverso l’algoritmo di backpropagation, che calcola e minimizza l’errore del modello aggiornando i pesi dei collegamenti tra i neuroni(Haykin 2009). Questa tecnica è fondamentale non solo per le MLP, ma anche per le reti neurali più complesse utilizzate nel deep learning.\n\n14.2.1 Architettura delle MLP\nUn MLP può essere configurato in diverse architetture a seconda del problema da risolvere. La configurazione più comune è quella con un singolo strato di input, uno o più strati nascosti e uno strato di output. Ogni neurone in uno strato è collegato a tutti i neuroni dello strato successivo, rendendo la rete completamente connessa.\n\nReti con un solo strato nascosto: Questo è il tipo più semplice di MLP, in cui un singolo strato nascosto è sufficiente per risolvere problemi relativamente semplici o linearmente separabili con una funzione di attivazione non lineare.\nReti con più strati nascosti: Quando i dati presentano una complessità maggiore, un MLP con più strati nascosti può catturare pattern più complessi. Ogni strato aggiuntivo consente alla rete di apprendere rappresentazioni intermedie che possono essere utilizzate per ottenere una predizione finale più accurata.\nDeep MLP: Quando il numero di strati nascosti aumenta significativamente, la rete viene considerata “profonda” (deep). Questi modelli, sebbene potenti, richiedono una maggiore attenzione durante l’addestramento per evitare problemi come l’overfitting o la vanishing gradient problem.\n\n\n\n14.2.2 Funzioni di Attivazione\nLe funzioni di attivazione sono cruciali per introdurre la non linearità nelle reti neurali, permettendo al modello multistrato di apprendere pattern complessi. Come visto in Section 13.6.2 un singolo perceptrone non riesce a classificare dati che non sono lineramente separabili. In questi casi occorre usare una rete multistrato con funzioni di attivazione non lineari nei neuroni artificiali degli strati intermedi. La non linearità è fondamentale: se si usassero solo funzioni di attivazione lineari, l’intera rete si comporterebbe come un singolo strato lineare. In altre parole, l’uscita sarebbe ancora una combinazione lineare degli ingressi, rendendo la rete incapace di apprendere relazioni complesse e limitandola a definire solo classificatori lineari (anche se in modo più articolato). Al contrario, la combinazione di funzioni non lineari dà la possibilità di approssimare funzioni complesse e definire curve di separazione tra classi (o superfici in più dimensioni) arbitrariamente elaborate. Si veda Section 14.9.2 per una soluzione al problema di classificare dati distribuiti in classi concentriche con reti multistrato. Le funzioni di attivazione più comuni negli strati nascosti includono:\n\nSigmoide: Questa funzione mappa qualsiasi valore reale in un intervallo compreso tra 0 e 1, ed è definita come:\n\\[\\text{sigmoide}(z) = \\frac{1}{1 + e^{-z}}\\] La funzione sigmoide è utile quando si ha bisogno di un output probabilistico, ma può soffrire del problema della vanishing gradient, che rende difficile l’addestramento di reti profonde.\nReLU (Rectified Linear Unit): Una delle funzioni di attivazione più popolari, definita come:\n\\[\n\\text{ReLU}(z) = \\max(0, z)\n\\]\nReLU è ampiamente utilizzata perché risolve in parte il problema della vanishing gradient, accelerando l’addestramento delle reti profonde. Tuttavia, può soffrire del problema della “morte dei neuroni”, dove i neuroni possono rimanere bloccati su zero.\nTanh: Un’alternativa alla funzione sigmoide, mappa i valori in un intervallo tra -1 e 1, ed è definita come:\n\\[\n\\text{tanh}(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n\\]\nTanh è spesso preferita alla sigmoide per la sua capacità di centrare i dati attorno a zero, migliorando la convergenza del modello.\n\n\n\n14.2.3 Funzioni di Attivazione degli Strati di Uscita\nLa scelta della funzione di attivazione nello strato di uscita dipende dal tipo di problema che il modello deve risolvere:\n\nClassificazione binaria: Si utilizza comunemente la funzione sigmoide nello strato di uscita per ottenere una probabilità che l’output appartenga a una delle due classi.\nClassificazione multiclasse: La funzione softmax è preferita, poiché mappa i valori di output in un intervallo compreso tra 0 e 1 e la loro somma è 1, fornendo quindi una distribuzione di probabilità tra le diverse classi:\n\\[\n\\text{softmax}(z_j) = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}\n\\] Dove \\(z_j\\) è l’output per la j-esima classe.\nRegressione: Per problemi di regressione, in genere non si applica alcuna funzione di attivazione nell’ultimo strato (o si utilizza l’identità) per mantenere l’output come un valore reale continuo.\n\n\n\n14.2.4 Funzioni di Errore\nLe funzioni di errore (o funzioni di perdita) misurano la discrepanza tra l’output predetto dal modello e il valore reale, guidando così il processo di apprendimento:\n\nErrore Quadratico Medio (MSE): Utilizzato per problemi di regressione, è definito come:\n\\[\nMSE = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\n\\]\nDove \\(y_i\\) è il valore reale e \\(\\hat{y}_i\\) è il valore predetto.\nCross-Entropy Loss: Utilizzata per la classificazione, particolarmente con softmax o sigmoide, misura la distanza tra le distribuzioni di probabilità:\n\\[\n\\text{Cross-Entropy} = -\\sum_{i=1}^n y_i \\log(\\hat{y}_i)\n\\]",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#algoritmo-di-backpropagation",
    "href": "3-6-deep-learning.html#algoritmo-di-backpropagation",
    "title": "14  Deep learning",
    "section": "14.3 Algoritmo di Backpropagation",
    "text": "14.3 Algoritmo di Backpropagation\nIl backpropagation è l’algoritmo chiave che permette l’addestramento delle reti neurali multistrato(Rumelhart, Hinton, and Williams 1986). Funziona in due fasi principali:\n\nFeedforward: I dati vengono propagati in avanti attraverso la rete fino a generare un output.\nCalcolo della perdita e propagazione all’indietro: L’errore viene calcolato confrontando l’output predetto con il valore reale. Questo errore viene poi propagato all’indietro attraverso la rete, calcolando il gradiente della funzione di perdita rispetto ai pesi della rete. I pesi vengono aggiornati utilizzando l’ottimizzazione tramite discesa del gradiente, minimizzando così la funzione di perdita.\n\nIl processo è iterativo e viene ripetuto molte volte fino a quando il modello non raggiunge un buon livello di accuratezza.\n\n14.3.1 Epoche e apprendimento iterativo\nUn’epoca (epoch) rappresenta un ciclo completo attraverso l’intero dataset di addestramento. Durante un’epoca, tutti gli esempi presenti nel dataset vengono utilizzati per aggiornare i pesi del modello. Tuttavia, per migliorare l’efficienza e la stabilità dell’apprendimento, il dataset viene tipicamente suddiviso in batch.\n\n\n14.3.2 Batch di dati di addestramento\nUn batch è un sottoinsieme del dataset utilizzato per aggiornare i pesi una volta. Questo approccio prende il nome di addestramento mini-batch. Esistono tre strategie principali:\n\nBatch learning: tutto il dataset viene usato in un solo passo per ogni aggiornamento dei pesi. È computazionalmente intenso.\nStochastic Gradient Descent (SGD): ogni esempio di addestramento aggiorna i pesi immediatamente. È rumoroso ma può favorire la convergenza a un minimo globale.\nMini-batch Gradient Descent: è il metodo più usato. I dati sono suddivisi in piccoli gruppi (batch), e ciascun batch viene utilizzato per calcolare un aggiornamento dei pesi. Questo equilibrio consente stabilità ed efficienza.\n\nAd esempio, se abbiamo 10.000 esempi e un batch size di 100, avremo 100 batch per ogni epoca. Durante ogni epoca, il modello vedrà l’intero dataset, ma aggiornando i pesi 100 volte invece di una sola.\nOrganizzare l’apprendimento su più epoche permette alla rete di apprendere progressivamente dai dati. Durante l’addestramento, è comune monitorare l’errore sul set di validazione per evitare l’overfitting e applicare tecniche come l’early stopping, che interrompe l’addestramento se le prestazioni peggiorano su tale set.\nIn sintesi, l’algoritmo di backpropagation con l’organizzazione in epoche e batch costituisce il cuore del processo di apprendimento nelle reti neurali profonde, permettendo l’ottimizzazione dei pesi in modo efficiente e scalabile.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#architetture-di-reti-neurali-profonde",
    "href": "3-6-deep-learning.html#architetture-di-reti-neurali-profonde",
    "title": "14  Deep learning",
    "section": "14.4 Architetture di Reti Neurali Profonde",
    "text": "14.4 Architetture di Reti Neurali Profonde\nLe reti neurali profonde rappresentano una specializzazione e un’estensione delle MLP. Queste reti, spesso costituite da decine o centinaia di strati nascosti, sono in grado di apprendere rappresentazioni molto più complesse e astratte rispetto alle MLP tradizionali. Ogni strato di una rete profonda elabora i dati in modo più dettagliato, consentendo al modello di catturare caratteristiche gerarchiche dei dati, come pattern semplici nei primi strati e strutture più complesse nei successivi.\n\n14.4.1 Reti Neurali Convoluzionali (CNN)\nLe reti neurali convoluzionali (CNN) sono una classe specializzata di reti neurali artificiali, particolarmente efficaci nell’elaborazione di dati strutturati a griglia, come le immagini (LeCun, Bengio, and Hinton 2015). Il termine “convoluzionale” è fondamentale per comprendere il loro funzionamento unico.\nCos’è la Convoluzione? La convoluzione è un’operazione matematica che sta alla base di queste reti. In termini semplici, consiste nell’applicare un filtro (o kernel) a una porzione dell’input, facendolo “scorrere” su tutta l’immagine. Questo processo può essere immaginato come una lente che si muove sull’immagine, focalizzandosi su piccole aree alla volta.\n\n\n\n\n\ngraph LR\n    A[Immagine Input] --&gt; B[Applicazione Filtro]\n    B --&gt; C[Feature Map]\n    B --&gt; D[Scorrimento]\n    D --&gt; |Ripeti| B\n    C --&gt; E[Attivazione]\n    E --&gt; F[Pooling]\n    F --&gt; G[Prossimo Strato]\n\n\n\n\n\n\n\nFiltri e Feature Maps:\n\nI filtri sono matrici di pesi che vengono applicati all’input.\nOgni filtro è progettato per rilevare specifiche caratteristiche (come bordi, curve, o texture).\nIl risultato dell’applicazione di un filtro è chiamato “feature map”.\n\nProcesso di Scorrimento:\n\nIl filtro si muove sistematicamente attraverso l’immagine, pixel per pixel.\nAd ogni posizione, esegue una moltiplicazione elemento per elemento e una somma.\nQuesto crea una nuova rappresentazione dell’immagine che evidenzia certe caratteristiche.\n\nVantaggi della Convoluzione:\n\nInvarianza spaziale: La stessa caratteristica può essere rilevata ovunque nell’immagine.\nParametri condivisi: I pesi del filtro sono riutilizzati, riducendo il numero totale di parametri.\nGerarchia di features: Strati più profondi combinano features semplici in rappresentazioni più complesse.\n\n\nLe CNN impilano multiple operazioni di convoluzione, alternate con funzioni di attivazione non lineari (come ReLU) e strati di pooling. Questa architettura permette alla rete di costruire una comprensione gerarchica dell’input, partendo da caratteristiche semplici negli strati iniziali (come bordi e texture) fino a concetti più astratti negli strati più profondi (come forme complesse e oggetti interi). Grazie a questa struttura “convoluzionale”, le CNN sono eccezionalmente efficaci in compiti come il riconoscimento di immagini, l’individuazione di oggetti, e la segmentazione semantica, superando spesso le capacità umane in questi domini.\n\n\n14.4.2 Reti Neurali Ricorrenti (RNN)\nLe RNN sono un’estensione delle MLP per dati sequenziali, come testi o segnali audio. Grazie alle connessioni ricorrenti, le RNN possono mantenere una memoria delle informazioni precedenti nella sequenza, rendendole ideali per compiti che richiedono la modellazione del contesto temporale. Tuttavia, le RNN tradizionali soffrono del problema del vanishing gradient, che può ostacolare l’apprendimento di dipendenze a lungo termine nelle sequenze. Per superare questa limitazione, sono state sviluppate varianti come le LSTM (Long Short-Term Memory) e le GRU (Gated Recurrent Unit), che migliorano la capacità della rete di apprendere e mantenere informazioni su lunghe sequenze temporali(Karpathy 2015).\n\n\n14.4.3 Reti Generative Adversariali (GAN)\nLe GAN rappresentano un’architettura avanzata che contrappone due reti neurali, una generativa e una discriminativa, in un meccanismo competitivo (o framework competitivo)(Goodfellow et al. 2014). Queste reti sono in grado di generare nuovi dati simili a quelli reali, estendendo le capacità delle MLP in modi creativi e innovativi. La rete generativa tenta di produrre dati falsi che siano indistinguibili dai dati reali, mentre la rete discriminativa cerca di distinguere tra dati reali e falsi. Questo approccio ha portato a notevoli innovazioni nella generazione di immagini realistiche, video, musica e persino testo, aprendo nuove possibilità nel campo della creatività artificiale e della simulazione.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#tecniche-di-addestramento-per-reti-profonde",
    "href": "3-6-deep-learning.html#tecniche-di-addestramento-per-reti-profonde",
    "title": "14  Deep learning",
    "section": "14.5 Tecniche di Addestramento per Reti Profonde",
    "text": "14.5 Tecniche di Addestramento per Reti Profonde\nL’addestramento delle reti profonde è più complesso rispetto a quello delle MLP a causa della maggiore profondità e del numero di parametri coinvolti. Il processo di addestramento utilizza algoritmi di ottimizzazione come la discesa del gradiente, ma con alcune sfide specifiche:\n\nProblema del Vanishing Gradient: Nelle reti molto profonde, i gradienti calcolati durante la backpropagation possono diventare molto piccoli, impedendo l’aggiornamento efficace dei pesi nei primi strati della rete. Questo problema è particolarmente critico nelle RNN, dove la propagazione dei gradienti attraverso molteplici passi temporali può portare alla perdita di informazioni utili. Per mitigare questo problema, si utilizzano funzioni di attivazione come ReLU, che mantengono gradienti più ampi, e tecniche come il batch normalization, che stabilizza e accelera il processo di addestramento.\nBatch Normalization: Questa tecnica normalizza gli input a ciascuno strato per avere una media zero e una varianza unitaria, riducendo così il rischio di gradienti esplosivi o vanishing e migliorando la stabilità dell’addestramento. Il batch normalization è ampiamente utilizzato nelle reti profonde, poiché permette un addestramento più efficiente e riduce la sensibilità agli iperparametri, facilitando l’uso di learning rate più elevati.\nDropout: Per prevenire l’overfitting, una delle tecniche più comuni è il dropout, che consiste nel disattivare casualmente alcuni neuroni durante l’addestramento, impedendo alla rete di dipendere troppo da specifiche connessioni. Questo forza la rete a generalizzare meglio, migliorando le sue prestazioni su dati mai visti. Durante la fase di inferenza, tutti i neuroni vengono utilizzati, ma i pesi sono scalati per mantenere la coerenza delle attivazioni.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#tecniche-di-ottimizzazione-dei-parametri-delle-reti-profonde",
    "href": "3-6-deep-learning.html#tecniche-di-ottimizzazione-dei-parametri-delle-reti-profonde",
    "title": "14  Deep learning",
    "section": "14.6 Tecniche di Ottimizzazione dei Parametri delle Reti Profonde",
    "text": "14.6 Tecniche di Ottimizzazione dei Parametri delle Reti Profonde\nOltre alle tecniche di addestramento, le reti profonde richiedono l’uso di tecniche avanzate di ottimizzazione per gestire la complessità e migliorare la convergenza:\n\nAlgoritmi di Ottimizzazione: Sebbene la discesa del gradiente stocastica (SGD) sia l’approccio di base, varianti più avanzate come Adam (Adaptive Moment Estimation) e RMSprop sono ampiamente utilizzate. Adam, in particolare, combina i vantaggi di AdaGrad (che adatta il learning rate per ogni parametro) e RMSprop (che mantiene un learning rate efficiente per ogni parametro), risultando in una convergenza più rapida e stabile anche in reti molto profonde.\nLearning Rate Scheduling: Il learning rate, ossia la velocità con cui vengono aggiornati i pesi, è un parametro critico che influisce sulla velocità e sull’efficacia dell’addestramento. Tecniche come il learning rate scheduling permettono di iniziare l’addestramento con un learning rate elevato, che viene ridotto man mano che il modello si avvicina a una soluzione ottimale. Questo aiuta a trovare il minimo globale della funzione di perdita più rapidamente.\nEarly Stopping: Per evitare l’overfitting durante l’addestramento, l’early stopping monitora la performance del modello su un set di validazione e interrompe l’addestramento quando le prestazioni iniziano a peggiorare. Questo evita che la rete apprenda troppo i dettagli del set di addestramento, migliorando la generalizzazione.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#uso-di-modelli-pre-addestrati",
    "href": "3-6-deep-learning.html#uso-di-modelli-pre-addestrati",
    "title": "14  Deep learning",
    "section": "14.7 Uso di modelli pre-addestrati",
    "text": "14.7 Uso di modelli pre-addestrati\nL’addestramento delle reti neurali profonde richiede notevoli risorse computazionali e dataset di grandi dimensioni, rendendo i costi in termini di tempo e potenza di calcolo molto elevati. Per ridurre questi costi, l’uso di modelli pre-addestrati rappresenta una soluzione efficace, poiché consente di sfruttare reti già addestrate su ampi dataset e adattarle a specifici problemi con un processo noto come fine-tuning. Ciò permette di evitare il lungo e dispendioso processo di addestramento da zero, ottenendo comunque prestazioni eccellenti.\nLe collezioni di modelli pre-addestrati disponibili su piattaforme come TensorFlow Hub, PyTorch Hub e Hugging Face Model Hub offrono reti avanzate, già ottimizzate, come ResNet, EfficientNet per la visione e BERT, GPT per il linguaggio. Questi modelli, addestrati su dataset estesi, possono essere facilmente utilizzati per applicazioni specifiche con poche risorse computazionali aggiuntive, rendendo il processo più accessibile ed economico senza sacrificare la qualità delle prestazioni.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#applicazioni-e-sfide",
    "href": "3-6-deep-learning.html#applicazioni-e-sfide",
    "title": "14  Deep learning",
    "section": "14.8 Applicazioni e Sfide",
    "text": "14.8 Applicazioni e Sfide\nLe applicazioni del deep learning sono vaste e coprono molte aree, dalla visione artificiale all’elaborazione del linguaggio naturale. In ambito giuridico, le reti profonde possono essere utilizzate per l’analisi predittiva, la classificazione automatica di documenti legali e l’estrazione di informazioni da grandi volumi di testo. Tuttavia, l’implementazione del deep learning richiede una grande quantità di dati e risorse computazionali, oltre a una profonda comprensione delle reti neurali per evitare problemi di interpretabilità e bias. Nonostante queste sfide, il deep learning continua a spingere i confini dell’intelligenza artificiale, offrendo soluzioni avanzate a problemi complessi che erano precedentemente irrisolvibili.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#laboratorio-python",
    "href": "3-6-deep-learning.html#laboratorio-python",
    "title": "14  Deep learning",
    "section": "14.9 Laboratorio Python",
    "text": "14.9 Laboratorio Python\n\n14.9.1 Esperimento 1: Rappresentazione grafiche di reti neurali multistrato\nIn questo esperimento vogliamo programmare una funzione in grado di realizzare una rappresentazione grafica di una rete neurale. A tale scopo adotteremo la libreria Python networkx. La funzione draw_mlp riceve in ingresso la descrizione della rete multistrato in termini di numero di neuroni di ingresso, numero di strati e numero di neuroni per ogni strato e numero di neuroni di uscita. Il risultato della funzione è il disegno del grafo della rete MLP.\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n# Funzione per disegnare una rappresentazione grafica della rete MLP\ndef draw_mlp(hidden_layers, input_size, output_size):\n    G = nx.DiGraph()\n    layer_sizes = [input_size] + list(hidden_layers) + [output_size]\n    \n    # Posizionamento dei nodi\n    pos = {}\n    n_layers = len(layer_sizes)\n    v_spacing = 1\n    \n    # Creazione dei nodi\n    for i, layer_size in enumerate(layer_sizes):\n        layer_top = v_spacing * (layer_size - 1) / 2\n        for j in range(layer_size):\n            pos[f'{i}-{j}'] = (i, layer_top - v_spacing * j)\n            G.add_node(f'{i}-{j}')\n    \n    # Creazione degli archi\n    for i, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n        for j in range(layer_size_a):\n            for k in range(layer_size_b):\n                G.add_edge(f'{i}-{j}', f'{i+1}-{k}')\n    \n    # Disegna il grafico\n    plt.figure(figsize=(12, 8))\n    nx.draw(G, pos=pos, with_labels=False, arrows=False, node_size=300, node_color=\"lightblue\")\n    \n    # Etichette\n    for i in range(input_size):\n        pos[f'0-{i}'] = (pos[f'0-{i}'][0] - 0.1, pos[f'0-{i}'][1])\n        plt.text(pos[f'0-{i}'][0], pos[f'0-{i}'][1], f'Input {i+1}', horizontalalignment='right')\n    \n    for i in range(output_size):\n        pos[f'{n_layers-1}-{i}'] = (pos[f'{n_layers-1}-{i}'][0] + 0.1, pos[f'{n_layers-1}-{i}'][1])\n        plt.text(pos[f'{n_layers-1}-{i}'][0], pos[f'{n_layers-1}-{i}'][1], f'Output {i+1}', horizontalalignment='left')\n    \n    plt.title(\"Rappresentazione Grafica della Rete MLP\")\n    plt.show()\n\nApplichiamo la funzione draw_mlp() al caso di una rete con 4 ingressi 3 strati nascosti da 3, 9 e 3 neuroni rispettivamente e 1 neurone di uscita:\n\n# Parametri della rete MLP utilizzata nell'esempio\nhidden_layers = (3,9, 3)  # Due strati nascosti con 10 e 5 neuroni rispettivamente\ninput_size = 4  # Due caratteristiche in input\noutput_size = 1  # Un neurone di output (classificazione binaria)\n\n# Disegnare la rappresentazione della rete MLP\ndraw_mlp(hidden_layers, input_size, output_size)\n\n\n\n\n\n\n\n\n\n\n14.9.2 Esperimento 2: Rete MLP applicata al caso di classi concentriche\nIn questo esperimento vogliamo applicare una rete multistrato al problema della classificazione binaria nel caso di un dataset bidimensionale composto da due classi concentrichele La rete è composta da:\n\nStrato di input: Due ingressi, ciascuno corrispondente a una delle caratteristiche del dataset (x1,x2).\nStrati nascosti: Due strati nascosti, il primo con 10 neuroni e il secondo con 5 neuroni, che permettono alla rete di apprendere rappresentazioni più complesse dei dati grazie alla funzione di attivazione non lineare “relu” adottata. Ogni neurone in un determinato strato è connesso a tutti i neuroni dello strato successivo, consentendo il flusso delle informazioni attraverso la rete durante l’addestramento e la predizione.\nStrato di output: Un singolo neurone di output, utilizzato per la classificazione binaria (classe 0, class 1).\n\nUsando la funzione introdotta nell’esempio 1 possiamo disegnare la rete MLP che vogliamo adottare per risolvere il problem di classificazione nel caso di classi concentriche.\n\n# Parametri della rete MLP utilizzata nell'esempio\nhidden_layers = (10, 5)  # Due strati nascosti con 10 e 5 neuroni rispettivamente\ninput_size = 2  # Due caratteristiche in input\noutput_size = 1  # Un neurone di output (classificazione binaria)\n\n# Disegnare la rappresentazione della rete MLP\ndraw_mlp(hidden_layers, input_size, output_size)\n\n\n\n\n\n\n\n\n\n# Importa le librerie necessarie\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import StandardScaler\n\n# 1. Generazione dei dati: due classi concentriche\ndef generate_concentric_circles(n_samples=500, noise=0.1):\n    np.random.seed(42)\n    n_samples_per_class = n_samples // 2\n    angles = np.random.rand(n_samples_per_class) * 2 * np.pi\n\n    inner_radius = 1 + noise * np.random.randn(n_samples_per_class)\n    outer_radius = 3 + noise * np.random.randn(n_samples_per_class)\n\n    inner_x = np.stack([inner_radius * np.cos(angles), inner_radius * np.sin(angles)], axis=1)\n    outer_x = np.stack([outer_radius * np.cos(angles), outer_radius * np.sin(angles)], axis=1)\n\n    X = np.concatenate([inner_x, outer_x], axis=0)\n    y = np.array([0] * n_samples_per_class + [1] * n_samples_per_class)\n\n    return X, y\n\nX, y = generate_concentric_circles()\n\n# 2. Visualizzazione dei dati\nplt.figure(figsize=(6, 6))\nplt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], c='blue', label='Classe 0')\nplt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], c='green', label='Classe 1')\nplt.title('Dati con Classi Concentriche')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# 3. Divisione del dataset e normalizzazione\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# 4. Creazione e addestramento del modello MLP\nmodel = MLPClassifier(hidden_layer_sizes=(10, 5), activation='relu', max_iter=1000, random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\n# 5. Valutazione: matrice di confusione\ny_pred = model.predict(X_test_scaled)\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Classe 0\", \"Classe 1\"])\ndisp.plot(cmap=plt.cm.Blues)\nplt.title(\"Matrice di Confusione\")\nplt.show()\n\n# 6. Grafico della superficie di decisione\nh = .02  # step size\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\ngrid = np.c_[xx.ravel(), yy.ravel()]\ngrid_scaled = scaler.transform(grid)\nZ = model.predict(grid_scaled)\nZ = Z.reshape(xx.shape)\n\nplt.figure(figsize=(8, 6))\nplt.contourf(xx, yy, Z, cmap=plt.cm.Pastel2, alpha=0.8)\nplt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], c='blue', label='Classe 0', edgecolors='k')\nplt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], c='green', label='Classe 1', edgecolors='k')\nplt.title(\"Superficie di Decisione del Modello MLP\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIl codice Python scritto per questo esperimento segue la seguente logica:\n\nGenerazione dei dati: Due insiemi di punti sono distribuiti in cerchi concentrici: il primo (classe 0) vicino all’origine, il secondo (classe 1) su un raggio maggiore. La forma dei dati rende il problema non linearmente separabile.\nVisualizzazione: Il primo grafico mostra chiaramente la distribuzione circolare dei due insiemi di punti.\nPreprocessing: I dati vengono suddivisi in un training e test set (70% - 30%) e normalizzati con StandardScaler.\nModello MLP: È stata creata una rete con due strati nascosti (10 e 5 neuroni) e funzione di attivazione ReLU. La rete viene addestrata per classificare i dati.\nValutazione: Viene calcolata e mostrata la matrice di confusione, che evidenzia l’accuratezza del modello nel distinguere le due classi.\nSuperficie di decisione: Il terzo grafico mostra come la rete ha appreso a separare le due classi: la forma curva della regione di decisione indica che il modello ha effettivamente appreso la complessità dei dati, superando i limiti del percettrone semplice (che può solo separare linearmente).\n\n\n\n14.9.3 Esperimento 3: Rete MLP per la predizione dell’esito di un caso giudiziario\nApplicazione di una rete neurale multistrato (MLP) per la predizione dell’esito di un caso giudiziario basandosi su tre caratteristiche: complessità del caso, esperienza dell’avvocato, e importanza mediatica. La rete è composta da:\n\nStrato di input: Tre ingressi, ciascuno corrispondente a una delle caratteristiche del dataset (complessità del caso, esperienza dell’avvocato, importanza mediatica).\nStrati nascosti: Due strati nascosti, il primo con 10 neuroni e il secondo con 5 neuroni, che permettono alla rete di apprendere rappresentazioni più complesse dei dati.\nStrato di output: Un singolo neurone di output, utilizzato per la classificazione binaria (vittoria o sconfitta del caso).\n\nUsando la funzione introdotta nell’esempio 1 possiamo disegnare la rete MLP che vogliamo adottare per risolvere il problem di classificazione in studio. Si noti che è necessario eseguire il codice dell’esempio 1 per poter eseguire il seguente codice altrimenti Python segnalerà come errore il fatto di non conoscere la funzione draw_mlp().\n\n# Parametri della rete MLP utilizzata nell'esempio\nhidden_layers = (10, 5)  # Due strati nascosti con 10 e 5 neuroni rispettivamente\ninput_size = 3  # Tre caratteristiche in input\noutput_size = 1  # Un neurone di output (classificazione binaria)\n\n# Disegnare la rappresentazione della rete MLP\ndraw_mlp(hidden_layers, input_size, output_size)\n\n\n\n\n\n\n\n\nL’implementazione in Python della rete MLP per il nostro problema di classificazione è la seguente:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay, classification_report\nfrom sklearn.preprocessing import StandardScaler # Aggiunto import\n\n# Simuliamo un dataset per predire se un caso giudiziario sarà vinto o perso basandosi su tre caratteristiche\n# Ad esempio, complessità del caso, esperienza dell'avvocato, e importanza mediatica\n\n# Generare dati di esempio\nX, y = make_classification(n_samples=200, n_features=3, n_informative=3, n_redundant=0, n_clusters_per_class=1, random_state=42)\n\n# Dividere i dati in train e test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# --&gt; Aggiunta sezione per lo scaling\n# Scalare i dati (buona pratica per MLP)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# &lt;-- Fine sezione scaling\n\n# Creare e addestrare un modello MLP usando i dati scalati\nmlp_model = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=1000, random_state=42)\nmlp_model.fit(X_train_scaled, y_train) # Usa X_train_scaled\n\n# Predire sul set di test scalato\ny_pred = mlp_model.predict(X_test_scaled) # Usa X_test_scaled\n\n# Mostrare la matrice di confusione usando i dati scalati\nConfusionMatrixDisplay.from_estimator(mlp_model, X_test_scaled, y_test, display_labels=[\"Perso\", \"Vinto\"], cmap=plt.cm.Blues) # Usa X_test_scaled\nplt.title('Matrice di Confusione')\nplt.show()\n\n# Visualizzare il rapporto di classificazione\nreport = classification_report(y_test, y_pred, target_names=[\"Perso\", \"Vinto\"])\nprint(report)\n\n\n\n\n\n\n\n\n              precision    recall  f1-score   support\n\n       Perso       0.97      1.00      0.99        35\n       Vinto       1.00      0.96      0.98        25\n\n    accuracy                           0.98        60\n   macro avg       0.99      0.98      0.98        60\nweighted avg       0.98      0.98      0.98        60\n\n\n\nAnalisi dei Risultati\n\nMatrice di Confusione: La matrice di confusione mostra le prestazioni del modello nella classificazione dei casi giudiziari come “Vinto” o “Perso”. Nel set di test, il modello ha classificato correttamente la maggior parte dei casi, con solo pochi errori. La matrice di confusione indica che il modello ha identificato con una buona precisione sia i casi vinti che quelli persi.\nRapporto di Classificazione:\n\nPrecisione: La precisione per i casi persi è del 97%, mentre per i casi vinti è dell’100%. Questo significa che quando il modello prevede un caso come “Perso”, nel 97% dei casi ha ragione, mentre per i casi “Vinto”, la precisione è del 100%.\nRecall: La recall per i casi persi è del 100% e per i casi vinti è del 96%. Questo indica che il modello è riuscito a identificare correttamente la quasi totalità dei casi vinti e persi.\nF1-score: L’F1-score, che rappresenta un bilanciamento tra precisione e recall, è del 99% per i casi persi e del 98% per i casi vinti, riflettendo una ottima performance complessiva del modello.\n\n\nOsservazioni: - Il modello ha raggiunto un’accuratezza complessiva del 98%, che è un buon risultato considerando che i dati generati non sono perfettamente separabili. - È importante notare che il modello non ha raggiunto il valore di convergenza entro il numero massimo di iterazioni impostato (1000), come indicato dall’avviso di convergenza. Questo suggerisce che con ulteriori iterazioni o con l’ottimizzazione dei parametri del modello, le prestazioni potrebbero migliorare ulteriormente. - In sintesi, l’MLP si è dimostrato efficace nel classificare correttamente i casi giudiziari in base alle caratteristiche fornite, anche in presenza di dati non perfettamente distinti. - Questo esempio mostra il potenziale delle reti neurali multistrato per applicazioni giuridiche, come la predizione degli esiti legali, pur sottolineando l’importanza di una corretta configurazione e addestramento del modello per ottenere i migliori risultati possibili.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-6-deep-learning.html#esercizi",
    "href": "3-6-deep-learning.html#esercizi",
    "title": "14  Deep learning",
    "section": "14.10 Esercizi",
    "text": "14.10 Esercizi\n\n14.10.1 Esercizio 1: Funzioni di attivazione non lineari\nSpiega il ruolo delle funzioni di attivazione non lineari nelle reti MLP: - Perché non è sufficiente usare solo funzioni lineari?\n- Cosa accadrebbe alla capacità della rete di apprendere pattern complessi?\n\n\n14.10.2 Esercizio 2: Confronto tra architetture neurali\nMetti a confronto CNN, RNN e GAN:\n\nQual è il tipo di dati o problema che ciascuna architettura affronta meglio?\n\nIn quali contesti applicativi (es. immagine, testo, generazione di contenuti) useresti ognuna?\n\n\n\n14.10.3 Esercizio 3: Vantaggi dei modelli pre-addestrati\nSpiega perché può essere utile utilizzare modelli pre-addestrati:\n\nQuali sono i principali benefici in termini di tempo, accuratezza e risorse computazionali?\n\nIn quali situazioni l’uso di un modello pre-addestrato è particolarmente indicato?\n\n\n\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press. https://www.deeplearningbook.org/.\n\n\nGoodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Nets.” In Advances in Neural Information Processing Systems, 2672–80.\n\n\nHaykin, Simon. 2009. Neural Networks and Learning Machines. 3rd ed. Pearson.\n\n\nKarpathy, Andrej. 2015. “The Unreasonable Effectiveness of Recurrent Neural Networks.” https://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n\n\nLeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. “Deep Learning.” Nature 521 (7553): 436–44.\n\n\nRumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1986. “Learning Representations by Back-Propagating Errors.” Nature 323: 533–36.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Deep learning</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html",
    "href": "3-7-elaborazione-linguaggio-naturale.html",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "",
    "text": "15.1 Introduzione\nIl linguaggio naturale è la lingua parlata o scritta che usiamo quotidianamente per comunicare. È ricco, complesso e carico di ambiguità. Un frammento di testo può contenere riferimenti impliciti, sinonimi, metafore e strutture grammaticali variabili. Ad esempio, la frase “Marta ha visto Luca in giardino con il binocolo” è ambigua: chi osserva con il binocolo? Chi è osservato con il binocolo? Per un sistema NLP, risolvere questa ambiguità richiede di analizzare il contesto o utilizzare modelli avanzati come i Transformer (Vaswani et al. 2017).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#obiettivi-dellnlp",
    "href": "3-7-elaborazione-linguaggio-naturale.html#obiettivi-dellnlp",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.2 Obiettivi dell’NLP",
    "text": "15.2 Obiettivi dell’NLP\nL’elaborazione del linguaggio naturale (NLP) è un processo che acquisisce una porzione di testo, chiamata documento (anche se si tratta di una parola o una frase), la scompone in unità elementari dette token e procede con fasi di analisi, comprensione e generazione. Ad esempio, in ambito giuridico, l’NLP può estrarre clausole chiave da un contratto o generare riassunti di sentenze (Surden 2019).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#acquisizione",
    "href": "3-7-elaborazione-linguaggio-naturale.html#acquisizione",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.3 Acquisizione",
    "text": "15.3 Acquisizione\nL’acquisizione del documento inizia con la raccolta dei dati, che possono essere testuali o audio. I dati testuali sono codificati in sequenze di caratteri, mentre i dati audio sono trasformati in campioni digitali e convertiti in testo. Al termine, il documento è pronto per l’elaborazione, memorizzabile in un file di testo o in un database.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#pre-elaborazione",
    "href": "3-7-elaborazione-linguaggio-naturale.html#pre-elaborazione",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.4 Pre-elaborazione",
    "text": "15.4 Pre-elaborazione\nLa pre-elaborazione è fondamentale per preparare i dati testuali all’analisi, riducendo complessità, ridondanza e variabilità del linguaggio naturale. Serve a:\n\nRiduzione della complessità: testi più semplici per modelli più efficienti.\nMigliore rappresentazione: vettori numerici più rappresentativi del significato.\nMigliore generalizzazione: evita che i modelli apprendano rumore linguistico.\n\nLe principali operazioni sono:\n\nTokenizzazione: suddivide il testo in token (parole, frasi o caratteri).\nEsempio: “La giustizia è uguale per tutti.” → [“La”, “giustizia”, “è”, “uguale”, “per”, “tutti”, “.”]\nRimozione della punteggiatura: elimina segni non utili all’analisi.\nNormalizzazione del testo: standardizza le parole, ad esempio:\n\nConversione in minuscolo.\n\nEspansione di forme contratte (“don’t” → “do not”).\n\nRimozione delle stopword: elimina parole frequenti ma poco rilevanti (“il”, “e”, “di”).\nStemming e lemmatizzazione:\n\nStemming: riduce una parola alla radice (“giudicando” → “giudic”).\n\nLemmatizzazione: riduce alla forma base, considerando il contesto (“giudicando” → “giudicare”).\n\nRimozione di cifre o caratteri speciali: utile se non rilevanti.\nCorrezione ortografica (facoltativa): migliora la qualità dei dati.\n\nLa scelta delle tecniche dipende dall’applicazione: per analisi giuridiche o traduzioni, la lemmatizzazione è preferibile; per compiti generali, basta lo stemming. Al termine, si ottiene un documento di token o parole, pronti per essere convertiti in numeri.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#word-embeddings",
    "href": "3-7-elaborazione-linguaggio-naturale.html#word-embeddings",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.5 Word Embeddings",
    "text": "15.5 Word Embeddings\nI word embeddings convertono le parole in vettori numerici per l’elaborazione computazionale. Questi vettori, in uno spazio multidimensionale, catturano le relazioni tra parole in modo compatto ed efficiente, consentendo l’applicazione di algoritmi di machine learning e deep learning (Mikolov et al. 2013). Sono essenziali per attività come l’analisi del sentiment, la classificazione del testo, la traduzione, il riconoscimento di entità nominate e il question answering. Negli ultimi anni, numerosi articoli scientifici hanno esplorato questo tema (Semanticscholar.org).\n\n15.5.1 Proprietà Sintattiche dei Word Embeddings\nI word embeddings catturano informazioni sulla struttura grammaticale. Parole con ruoli sintattici simili si trovano vicine nello spazio vettoriale, riflettendo la coerenza sintattica. Ad esempio, la relazione tra “veloce” e “velocemente” è simile a quella tra “lento” e “lentamente”, esprimibile come: vector(\"velocemente\") - vector(\"veloce\") + vector(\"lento\") ≈ vector(\"lentamente\"). Questa capacità emerge dalle co-occorrenze nei corpora di testo ed è utile per il part-of-speech tagging e il parsing sintattico.\nI word embeddings codificano anche relazioni morfologiche: “cane” e “cani” o “camminare” e “camminato” sono vicini, riflettendo una comprensione implicita della morfologia. Modelli come Word2Vec e GloVe non codificano direttamente l’ordine delle parole, ma lo catturano indirettamente tramite co-occorrenze locali. I Transformer (es. BERT) invece considerano l’intero contesto (Devlin et al. 2019).\nUn’altra proprietà è la similitudine funzionale: parole sostituibili in una frase, come “cane” e “gatto” in “Il cane abbaia” e “Il gatto miagola”, hanno vettori simili, utile per l’analisi sintattica e l’estrazione di relazioni.\n\n\n\n\n\n\n\n\nAnalogia\nOperazione Vettoriale\nRisultato Atteso\n\n\n\n\nVeloce : Velocemente :: Lento :?\nvector(\"velocemente\") - vector(\"veloce\") + vector(\"lento\")\nvector(\"lentamente\")\n\n\nRe : Regno :: Regina :\nvector(\"regno\") - vector(\"re\") + vector(\"regina\")\nvector(\"reginato\")\n\n\nCamminare : Camminato :: Correre :?\nvector(\"camminato\") - vector(\"camminare\") + vector(\"correre\")\nvector(\"corso\")\n\n\n\n\n\n15.5.2 Proprietà Semantiche dei Word Embeddings\nI word embeddings eccellono nel catturare il significato delle parole, posizionando termini simili (es. “cane” e “gatto”) vicini nello spazio vettoriale. La similarità semantica è misurabile con la similarità cosinusoidale: valori alti indicano significati affini. Ad esempio, “automobile” e “veicolo” sono più vicini di “cane” e “gatto”, riflettendo gradi di relazione.\nCodificano anche relazioni is-a (iponimia/iperonimia): “automobile” è vicino a “veicolo”, suo iperonimo. L’analogia “re” - “uomo” + “donna” ≈ “regina” dimostra come catturino relazioni semantiche complesse. Gli antonimi (es. “caldo” e “freddo”) sono distanti, ma possono condividere un campo semantico (es. temperatura). Inoltre, raggruppano parole per temi: “ospedale”, “chirurgo” e “infermiere” formano un cluster sanitario.\n\n\n15.5.3 Tecniche di Generazione\n\nWord2Vec: Usa reti neurali per apprendere vettori, con Skip-Gram (predice il contesto da una parola) e CBOW (predice la parola dal contesto), efficace per analogie semantiche (Mikolov et al. 2013).\nGloVe: Basato su una matrice di co-occorrenza globale, bilancia relazioni locali e globali (Pennington, Socher, and Manning 2014).\nFastText: Estende Word2Vec rappresentando parole come n-grammi di caratteri, ideale per parole rare e lingue morfologicamente ricche (Bojanowski et al. 2017).\nELMo: Genera embedding contestuali, analizzando l’intera frase per cogliere sfumature (Peters et al. 2018).\nTransformer (es. BERT, RoBERTa): Usa l’attenzione per modellare dipendenze a lunga distanza, migliorando la comprensione sintattica e semantica (Devlin et al. 2019; Y. Liu et al. 2019).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#sentence-embeddings",
    "href": "3-7-elaborazione-linguaggio-naturale.html#sentence-embeddings",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.6 Sentence Embeddings",
    "text": "15.6 Sentence Embeddings\nI sentence embeddings rappresentano il significato di intere frasi in vettori, posizionando frasi simili vicine nello spazio vettoriale. Superano i word embeddings, catturando il senso di un pensiero completo, e migliorano attività come classificazione, traduzione e generazione di testo (Reimers and Gurevych 2019).\n\n15.6.1 Proprietà dei Sentence Embeddings\nI sentence embeddings codificano il significato complessivo della frase, superando i limiti dei singoli termini. Sono vettori densi in spazi multidimensionali, con modelli come BERT che catturano il contesto di ogni parola. Preservano struttura sintattica e semantica, mappando frasi di lunghezza variabile in vettori fissi per l’apprendimento automatico. Alcuni, multilingue, codificano testi di lingue diverse in uno spazio condiviso, utili per applicazioni cross-linguali.\n\n\n15.6.2 Applicazioni\n\nRicerca semantica e recupero: Cerca in base al significato, es. “migliori ristoranti” restituisce “locali di alta cucina”.\nClassificazione del testo: Classifica articoli (es. sport, politica) in base al significato complessivo.\nAnalisi del sentiment: Determina se una recensione è positiva o negativa, considerando l’intera frase.\nRilevamento di parafrasi: Identifica frasi con lo stesso significato, es. domande duplicate in forum.\nQuestion answering: Trova risposte pertinenti confrontando similarità semantiche.\nTraduzione automatica: Migliora la fluidità, cogliendo il contesto della frase.\nClustering e modellazione di argomenti: Raggruppa documenti simili per tema.\nRetrieval-Augmented Generation (RAG): Recupera passaggi rilevanti per risposte coerenti.\nGenerazione di testo: Produce testo contestualmente appropriato.\n\n\n\n15.6.3 Tecniche per la Generazione di Sentence Embeddings\n\nMedia dei word embeddings: Metodo base, ma perde ordine e relazioni complesse.\nModelli dedicati: Sentence-BERT, Universal Sentence Encoder e InferSent generano embedding di alta qualità (Reimers and Gurevych 2019; Cer et al. 2018).\nTransformer: BERT, RoBERTa e altri usano pooling (es. media, token CLS) per sfruttare il contesto (Devlin et al. 2019).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#transformer",
    "href": "3-7-elaborazione-linguaggio-naturale.html#transformer",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.7 Transformer",
    "text": "15.7 Transformer\nLa comprensione e generazione del linguaggio naturale sono essenziali in ambito legale, per analizzare contratti o sentenze. Le reti neurali ricorrenti (RNN), come le LSTM, perdono informazioni su testi lunghi. I Transformer, introdotti nel 2017, rivoluzionano l’NLP con il meccanismo di attenzione (Vaswani et al. 2017).\n\n15.7.1 Il Cuore dei Transformer: l’attenzione\nL’attenzione si concentra sulle parti rilevanti di un testo. In una clausola come “Il locatore, dopo aver ricevuto il pagamento del canone mensile entro il 5 del mese, garantisce al conduttore l’uso esclusivo dei locali commerciali situati in Via Roma 10, salvo eventuali violazioni delle norme di sicurezza specificate nell’Allegato B”, il modello collega “conduttore” a “locatore” e “Allegato B”, dando meno peso a “mensile” o “5”.\nL’attenzione si calcola con:\n\\[\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n\\]\n\nQ (Query): rappresenta la parola analizzata (es. “conduttore”).\nK (Key): valuta la rilevanza di altre parole.\nV (Value): aggrega le informazioni ponderate.\n√d_k: normalizza i punteggi per stabilità.\nsoftmax: trasforma i punteggi in pesi.\n\n\n\n\nParola (Key)\nPeso di Attenzione (ipotetico)\n\n\n\n\nlocatore\n0.25\n\n\nlocali commerciali\n0.20\n\n\nAllegato B\n0.15\n\n\nal\n0.10\n\n\ncanone\n0.05\n\n\nmensile\n0.02\n\n\ndopo\n0.01\n\n\n5\n0.01\n\n\n\nQuesto collega parole distanti, cruciale per contratti o pareri legali.\n\n\n15.7.2 Multi-Head Attention: Vedere il Linguaggio da Diverse Prospettive\nLa multi-head attention esegue l’attenzione in parallelo: una testa analizza la sintassi, un’altra la semantica, per una comprensione più completa.\n\n\n15.7.3 L’Architettura del Transformer: Encoder e Decoder\n\nEncoder: Trasforma il testo (es. un contratto) in vettori ricchi di contesto, con strati di multi-head attention e reti feed-forward.\nDecoder: Usa l’output dell’encoder e le parole generate per produrre testi, come riassunti o risposte.\n\n\n\n15.7.4 Perché i Transformer Hanno Rivoluzionato l’NLP?\n\nParallelizzazione: Elabora tutte le parole simultaneamente, più veloce delle RNN.\nDipendenze a lunga distanza: Collega informazioni distanti, es. clausole e allegati.\nScalabilità: Modelli come BERT e GPT eccellono su grandi dataset, utili per:\n\nClassificazione di documenti legali.\nRicerca giuridica.\nGenerazione e traduzione di testi.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#large-language-models-llm",
    "href": "3-7-elaborazione-linguaggio-naturale.html#large-language-models-llm",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.8 Large Language Models (LLM)",
    "text": "15.8 Large Language Models (LLM)\nUn LLM è un modello di machine learning addestrato su vasti corpora di testo per comprendere e generare linguaggio, utile per classificazione, ricerca, generazione e traduzione (Brown et al. 2020). Modelli noti includono:\n\nGPT-4 (OpenAI): Denso, multimodale, contesto fino a 128K token.\nGrok (xAI): Progettato per risposte rapide e analisi di dati social.\nClaude (Anthropic): Sicuro, con contesto fino a 200K token.\nGemini (Google DeepMind): Multimodale, contesto fino a 1M token.\nDeepSeek (DeepSeek AI): MoE, efficiente, 671B parametri.\nQwen (Alibaba): MoE, multilingue, 128K token.\n\nSono accessibili come chatbot (per prompt testuali) o API (per richieste HTTP). I costi variano in base al provider, al modello, al volume di token e alla regione. Per dettagli, consultare i siti ufficiali (es. https://x.ai/grok per Grok, https://openai.com per GPT).\n\n\n\n\n\n\nTip\n\n\n\nMixture of Experts (MoE) I modelli Mixture of Experts (MoE) dividono un problema complesso in sottoproblemi, assegnandoli a “esperti” specializzati (sottoreti neurali). Una rete di gating sceglie l’esperto adatto per l’input. L’attivazione sparsa coinvolge solo alcuni esperti, riducendo il carico computazionale pur mantenendo molti parametri (Shazeer et al. 2017).\n\n\n\n15.8.1 Prompt Engineering\nLa prompt engineering ottimizza i prompt per ottenere risposte precise e coerenti dagli LLM, strutturando istruzioni, contesti ed esempi per massimizzare rilevanza e accuratezza (P. Liu et al. 2023).\n\n15.8.1.1 Strategie di Prompt Engineering\n\nSpecificità del prompt: Istruzioni chiare evitano ambiguità.\nEsempio: “Riassumi la sentenza Cass. Civ., Sez. Unite, n. 500/1999, evidenziando i punti salienti relativi all’articolo 2043 del Codice Civile in materia di danno ingiusto, e indica la ratio decidendi in non più di 200 parole.”\nFew-shot prompting: Fornisce esempi di input/output.\nEsempio: “Esempio 1: Input: ‘Clausola di riservatezza per contratto di lavoro.’ Output: ‘Il dipendente si impegna a mantenere riservate le informazioni aziendali, pena il risarcimento del danno.’ Ora, scrivi una clausola per un contratto di locazione che preveda un indennizzo per mancato preavviso di recesso.”\nChain-of-thought prompting: Esplicita i passaggi logici.\nEsempio: “Considera un caso di responsabilità contrattuale: [descrizione]. Pensa: 1. Quali sono gli elementi della responsabilità? 2. Le prove dimostrano l’inadempimento? 3. C’è un nesso di causalità? 4. Quali sono le conseguenze giuridiche? Concludi.”\nImpersonificazione di un ruolo: Simula un professionista.\nEsempio: “Agisci come un giudice della Corte Costituzionale. Esamina la legittimità costituzionale dell’articolo X della legge Y, con un parere formale e motivato.”\n\n\n\n\n15.8.2 Modelli LLM “Locali”\nL’uso di LLM via API di provider come OpenAI o Google è costoso e pone problemi di privacy. I modelli locali si eseguono su CPU e GPU standard, usando tecniche come:\n\nQuantizzazione: Riduce i pesi a 8, 4 o 2 bit (GPTQ, bitsandbytes) (Dettmers et al. 2023).\nDistillazione: Un modello piccolo imita uno grande (DistilBERT) (Sanh et al. 2019).\nPruning: Elimina pesi poco rilevanti.\nLow-Rank Adaptation (LoRA): Aggiunge matrici addestrabili ai pesi congelati (Hu et al. 2021).\nMoE: Attiva solo sotto-reti rilevanti (Shazeer et al. 2017).\nOttimizzazione hardware: Usa ONNX, TensorRT, GGUF.\n\nPiattaforme open source:\n\n\n\n\n\n\n\n\nPiattaforma\nDescrizione\nSupporto modelli\n\n\n\n\nllama.cpp\nEsecuzione di LLaMA su CPU, anche mobile.\nGGUF (LLaMA, Mistral)\n\n\nMLC LLM\nCompilatore per WebGPU, iOS, Android.\nLLaMA, Mistral, Qwen\n\n\nOllama\nEsecuzione semplice con un comando.\nLLaMA, Mistral, Gemma\n\n\n\nPiattaforme proprietarie:\n\n\n\n\n\n\n\n\nPiattaforma\nDescrizione\nNote\n\n\n\n\nOpenVINO™\nOttimizza modelli su CPU e VPU (Intel).\nSupporta ONNX\n\n\nNVIDIA TensorRT-LLM\nOttimizza LLM su GPU NVIDIA.\nUso enterprise\n\n\n\nNota: FlashAttention è una tecnica per ottimizzare l’attenzione, riducendo il consumo di memoria (Dao et al. 2022).",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#applicazioni-in-giurisprudenza",
    "href": "3-7-elaborazione-linguaggio-naturale.html#applicazioni-in-giurisprudenza",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.9 Applicazioni in Giurisprudenza",
    "text": "15.9 Applicazioni in Giurisprudenza\nL’NLP rivoluziona il settore legale (Surden 2019; Ashley 2017):\n\nAnalisi legale:\n\nRevisiona contratti per clausole o ambiguità.\n\nCerca precedenti con NER e topic modeling.\n\nInterpreta leggi con analisi semantica.\n\nAssistenza giuridica:\n\nChatbot per consulenza preliminare.\n\nAutomatizza risposte e gestione clienti.\n\nPrevisione di esiti: Analizza sentenze per prevedere risultati.\nGestione documentale:\n\nClassifica e archivia documenti.\n\nEstrae dati chiave per database.\n\nSupporto alla decisione: Aiuta i giudici con citazioni e precedenti.\nCompliance e due diligence: Monitora conformità e rischi.\nInnovazione: Crea modelli di documenti e simula negoziazioni.\nEtica e accessibilità: Traduce testi e semplifica il linguaggio legale.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#sfide-e-considerazioni-etiche",
    "href": "3-7-elaborazione-linguaggio-naturale.html#sfide-e-considerazioni-etiche",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.10 Sfide e Considerazioni Etiche",
    "text": "15.10 Sfide e Considerazioni Etiche\n\nBias e neutralità: Gli LLM possono amplificare pregiudizi; servono dati diversificati e de-biasing (Bender et al. 2021).\nPrivacy: Rispettare il GDPR, anonimizzando i dati.\nResponsabilità e trasparenza: Chiarire chi è responsabile per errori e rendere i modelli spiegabili.\nAccuratezza: Verifica umana per evitare errori gravi.\nEquità nell’accesso: Evitare divari tra grandi e piccoli studi legali.\nManipolazione: Rilevare falsi documenti generati.\nEtica: Bilanciare automazione e impatto sul lavoro.\nRegolamentazione: Collaborare per norme sull’NLP.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#conclusioni",
    "href": "3-7-elaborazione-linguaggio-naturale.html#conclusioni",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.11 Conclusioni",
    "text": "15.11 Conclusioni\nL’NLP offre strumenti potenti per la giurisprudenza, ma richiede attenzione a etica e implicazioni legali. Questo capitolo introduce l’NLP e le sue applicazioni, preparando a ulteriori ricerche.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#laboratorio-di-python",
    "href": "3-7-elaborazione-linguaggio-naturale.html#laboratorio-di-python",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.12 Laboratorio di Python",
    "text": "15.12 Laboratorio di Python\n\n15.12.1 Esperimento 1: Introduzione ai Word Embeddings\nIn questo esperimento vogliamo implementare i word embedding in maniera semplificata e intuitiva per cercare di capire le notevoli proprietà che riescono a esprimere. I word embeddings sono vettori numerici. Qui li rappresentiamo in 3D con assi per regalità, genere ed età per parole come “re”, “regina”, ecc.\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\n\n# Word embeddings semplificati\nword_embeddings = {\n    \"re\": [5.0, 5.0, 5.0],\n    \"regina\": [5.0, -5.0, 5.0],\n    \"principe\": [3.0, 5.0, 2.0],\n    \"principessa\": [3.0, -5.0, 2.0],\n    \"uomo\": [1.0, 5.0, 5.0],\n    \"donna\": [1.0, -5.0, 5.0]\n}\n\nwords = list(word_embeddings.keys())\nembeddings = list(word_embeddings.values())\n\n# Grafico 3D\nfig = plt.figure(figsize=(12, 8))\nax = fig.add_subplot(111, projection='3d')\nx = [emb[0] for emb in embeddings]\ny = [emb[1] for emb in embeddings]\nz = [emb[2] for emb in embeddings]\nax.scatter(x, y, z, s=100)\nfor i, word in enumerate(words):\n    ax.text(embeddings[i][0], embeddings[i][1], embeddings[i][2], word)\nax.set_xlabel('Regalità')\nax.set_ylabel('Genere')\nax.set_zlabel('Età')\nax.set_title('Visualizzazione 3D dei Word Embeddings')\nax.view_init(elev=20, azim=7)\nplt.show()\n\n# Distanza coseno\ndef distanza_coseno(vec1, vec2):\n    prodotto_scalare = np.dot(vec1, vec2)\n    norma_vec1 = np.linalg.norm(vec1)\n    norma_vec2 = np.linalg.norm(vec2)\n    return 1 - (prodotto_scalare / (norma_vec1 * norma_vec2))\n\n# Matrice delle distanze\nn_words = len(words)\nmatrice_distanze = [[0.0] * n_words for _ in range(n_words)]\nfor i in range(n_words):\n    for j in range(n_words):\n        matrice_distanze[i][j] = distanza_coseno(embeddings[i], embeddings[j])\n\n# Visualizzazione\nprint(\"Matrice delle distanze coseno:\")\nprint(\"          \", end=\"\")\nfor word in words:\n    print(f\"{word:&gt;10}\", end=\"\")\nprint()\nfor i, word1 in enumerate(words):\n    print(f\"{word1:10}\", end=\"\")\n    for j in range(n_words):\n        print(f\"{matrice_distanze[i][j]:10.3f}\", end=\"\")\n    print()\n\n# Calcolo di \"regina\"\ndef sottrai_vec(vec1, vec2):\n    return np.array(vec1) - np.array(vec2)\ndef somma_vec(vec1, vec2):\n    return np.array(vec1) + np.array(vec2)\n\nprint(\"Word embedding di regina:\")\nprint(word_embeddings[\"regina\"])\nprint(\"Word embedding calcolato: regina = re - uomo + donna\")\nprint(somma_vec(sottrai_vec(word_embeddings[\"re\"], word_embeddings[\"uomo\"]), word_embeddings[\"donna\"]))\n\n\n\n\n\n\n\n\nMatrice delle distanze coseno:\n                  re    regina  principeprincipessa      uomo     donna\nre             0.000     0.667     0.063     1.000     0.111     0.919\nregina         0.667     0.000     1.000     0.063     0.919     0.111\nprincipe       0.063     1.000    -0.000     1.316     0.137     1.273\nprincipessa     1.000     0.063     1.316    -0.000     1.273     0.137\nuomo           0.111     0.919     0.137     1.273     0.000     0.980\ndonna          0.919     0.111     1.273     0.137     0.980     0.000\nWord embedding di regina:\n[5.0, -5.0, 5.0]\nWord embedding calcolato: regina = re - uomo + donna\n[ 5. -5.  5.]\n\n\nI risulrari numerici dell’esperimento ci mostrano che anche se in una versione molto semplificata, i word embedding sono in grado di esprimere proprietà come la regalità, il genere e l’età. Infatti si noti come sottraendo a re uomo si ottiene la regalità che può essere sommata a donna per ottenere regina.\n\n\n15.12.2 Esperimento 2: Analisi del Sentiment\nIn questo esperimento vogliamo stimare il sentiment (molto negativo, negativo, neutrale, positivo, molto positivo) di un frammento di testo. A questo scopo usiamo un modello addestrato su più lingue per stimare il sentiment in frammenti di testo in Italiano e Giapponese.Il modello prescelto è tabularisai/multilingual-sentiment-analysis di Hugging Face.\n\n\n\n\n\n\nCaution\n\n\n\nNota: Richiede pip install transformers e una connessione per scaricare il modello.\n\n\n\nfrom transformers import pipeline\n\n# Pipeline con modello multilingue\npipe = pipeline(\"text-classification\", model=\"tabularisai/multilingual-sentiment-analysis\")\n\n# Testo in Italiano\nfrase = \"Questo prodotto non è fatto bene.\"\nrisultato = pipe(frase)\nprint(frase)\nprint(risultato)\n\n# Testo tradotto in Giapponese \nfrase = \"この製品はよく作られていません。\"\nrisultato = pipe(frase)\nprint(frase)\nprint(risultato)\n\nWARNING:tensorflow:From C:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nQuesto prodotto non è fatto bene.\n[{'label': 'Negative', 'score': 0.5313267111778259}]\nこの製品はよく作られていません。\n[{'label': 'Negative', 'score': 0.48841869831085205}]\n\n\nL’output dell’esperimento ci dice che entrambre le frasi sono considerate negative. Si noti come la frase in Giapponese sia la traduzione della frase in Italiano fatta da un traduttore basato su LLM e non mostrato in questo esempio.\n\n\n15.12.3 Esperimento 3: Sistema di Domanda-Risposta su un Testo Giuridico\nIn questo esperimento vogliamo implementare un semplicissimo sistema che ci consenta di di dialogare con un breve testo giuridico. Facendo domande e ottenendo risposte sui contenuti del testo.Il modello adottato è “deepset/roberta-base-squad2” sempre da Hugging Faceper rispondere a domande su un testo giuridico.\n\n\n\n\n\n\nCaution\n\n\n\nNota: Richiede pip install transformers e una connessione per scaricare il modello.\n\n\n\nfrom transformers import pipeline\n\n# Pipeline per question answering\nqa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n\n# Contesto giuridico\ncontesto = \"\"\"\nL'articolo 3 della Costituzione italiana stabilisce che tutti i cittadini hanno pari dignità sociale e sono eguali davanti alla legge,\nsenza distinzione di sesso, razza, lingua, religione, opinioni politiche, condizioni personali e sociali.\nÈ compito della Repubblica rimuovere gli ostacoli di ordine economico e sociale che,\nlimitando di fatto la libertà e l'eguaglianza dei cittadini, impediscono il pieno sviluppo della persona umana.\n\"\"\"\n\n# Domande\ndomanda1 = \"Qual è il compito della Repubblica?\"\nrisultato1 = qa_pipeline(question=domanda1, context=contesto)\nprint(f\"Domanda: {domanda1}\")\nprint(f\"Risposta: {risultato1['answer']}\\n\")\n\ndomanda2 = \"Chi ha pari dignità sociale?\"\nrisultato2 = qa_pipeline(question=domanda2, context=contesto)\nprint(f\"Domanda: {domanda2}\")\nprint(f\"Risposta: {risultato2['answer']}\\n\")\n\ndomanda3 = \"Quale articolo della Costituzione stabilisce che tutti i cittadini hanno pari dignità sociale?\"\nrisultato3 = qa_pipeline(question=domanda3, context=contesto)\nprint(f\"Domanda: {domanda3}\")\nprint(f\"Risposta: {risultato3['answer']}\\n\")\n\nDomanda: Qual è il compito della Repubblica?\nRisposta: rimuovere gli ostacoli\n\nDomanda: Chi ha pari dignità sociale?\nRisposta: tutti i cittadini\n\nDomanda: Quale articolo della Costituzione stabilisce che tutti i cittadini hanno pari dignità sociale?\nRisposta: L'articolo 3\n\n\n\nDall’output dell’esperimento possiamo vedere che il sistema è in grado di rispondere a domande sul testo giuridico. Ovviamente il sistema non è in grado di rispondere a domande il cui oggetto non è specificato nel testo. Inoltre, la brevità del testo usata non consente di rispondere a domande che richiedono un’analisi più approfondita.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  },
  {
    "objectID": "3-7-elaborazione-linguaggio-naturale.html#esercizi",
    "href": "3-7-elaborazione-linguaggio-naturale.html#esercizi",
    "title": "15  Elaborazione del Linguaggio Naturale",
    "section": "15.13 Esercizi",
    "text": "15.13 Esercizi\n\n15.13.1 Esercizio 1: Pre-elaborazione di un Testo Giuridico\nScegli un breve articolo di legge o una clausola contrattuale (es. dall’articolo 3 della Costituzione italiana o da un contratto di locazione). Scrivi un programma Python che applichi le seguenti operazioni di pre-elaborazione: tokenizzazione, rimozione delle stopword (usando una lista predefinita, es. da nltk), conversione in minuscolo e lemmatizzazione (con spacy o nltk). Visualizza il testo originale e quello pre-elaborato. Rifletti: quali operazioni sono più utili per preparare il testo a un’analisi semantica in ambito legale?\n\n\n15.13.2 Esercizio 2: Creazione di un prompt efficace\nProgetta un prompt per un Large Language Model (es. usando few-shot prompting o chain-of-thought) per generare un riassunto di una sentenza giuridica (es. Cass. Civ., Sez. Unite, n. 500/1999). Il prompt deve specificare: lunghezza massima (es. 150 parole), elementi chiave da includere (es. fatti, decisione, ratio decidendi) e tono formale. Testa il prompt con un modello accessibile (es. tramite Hugging Face o un’API gratuita) e valuta la qualità del riassunto prodotto. Quali modifiche al prompt migliorerebbero la precisione e la chiarezza del risultato?\n\n\n15.13.3 Esercizio 3: Analisi semantica con word embeddings\nModifica il codice dell’Esempio 1 del laboratorio Python per aggiungere nuove parole legate al contesto giuridico (es. “giudice”, “avvocato”, “tribunale”, “sentenza”). Assegna loro vettori 3D basati su tre dimensioni rilevanti (es. autorità, ruolo, formalità). Calcola la similarità cosinusoidale tra queste parole e visualizza i risultati in una matrice. Estendi il codice per verificare un’analogia giuridica (es. “giudice : tribunale :: avvocato : ?”). Discuti come i word embeddings potrebbero supportare la ricerca di precedenti legali o l’estrazione di concetti da documenti giuridici.\n\n\n\n\nAshley, Kevin D. 2017. “Artificial Intelligence and Legal Analytics: New Tools for Law Practice in the Digital Age.” Cambridge University Press.\n\n\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Margaret Shmitchell. 2021. “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610–23.\n\n\nBojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. “Enriching Word Vectors with Subword Information.” Transactions of the Association for Computational Linguistics 5: 135–46.\n\n\nBrown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” Advances in Neural Information Processing Systems 33: 1877–1901.\n\n\nCer, Daniel, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, et al. 2018. “Universal Sentence Encoder.” arXiv Preprint arXiv:1803.11175.\n\n\nDao, Tri, Daniel Y Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022. “FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.” Advances in Neural Information Processing Systems 35: 16344–59.\n\n\nDettmers, Tim, Artem Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023. “QLoRA: Efficient Finetuning of Quantized LLMs.” arXiv Preprint arXiv:2305.14314.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding.” Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–86.\n\n\nHu, Edward J, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. “LoRA: Low-Rank Adaptation of Large Language Models.” arXiv Preprint arXiv:2106.09685.\n\n\nLiu, Pengfei, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. “Prompt Engineering for Large Language Models.” arXiv Preprint arXiv:2307.09067.\n\n\nLiu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. “RoBERTa: A Robustly Optimized BERT Pretraining Approach.” arXiv Preprint arXiv:1907.11692.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” https://arxiv.org/abs/1301.3781.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher D Manning. 2014. “GloVe: Global Vectors for Word Representation.” Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 1532–43.\n\n\nPeters, Matthew E, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. “Deep Contextualized Word Representations.” arXiv Preprint arXiv:1802.05365.\n\n\nReimers, Nils, and Iryna Gurevych. 2019. “Sentence-BERT: Sentence Embeddings Using Siamese BERT-Networks.” Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 3982–92.\n\n\nSanh, Victor, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. “DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter.” arXiv Preprint arXiv:1910.01108.\n\n\nShazeer, Noam, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Geoffrey Hinton, Quoc Le, and Jeff Dean. 2017. “Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer.” arXiv Preprint arXiv:1701.06538.\n\n\nSurden, Harry. 2019. “Artificial Intelligence and Law: An Overview.” Georgia State University Law Review 35 (4): 1305–37.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” Advances in Neural Information Processing Systems 30.",
    "crumbs": [
      "Machine learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Elaborazione del Linguaggio Naturale</span>"
    ]
  }
]