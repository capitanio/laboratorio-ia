{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Percetptrone\n",
        "\n",
        "## Laboratorio di Python\n",
        "\n",
        "### Esperimento 1: Implementazione di un perceptrone\n",
        "\n",
        "In questo esperimento sviluppiamo una implementazione del perceptrone senza fare uso di librerie esterne e lo useremo in un problema di classificazione con classi linearmente separabili.\n",
        "Le sole librerie usata sono **random** per la generazione di numeri casuali per simulare i dati e **matplotlib** per graficare i risultati.\n",
        "I dati simulati sono costruti per essere linearmente separabili."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------\n",
        "# 1. Generazione del dataset\n",
        "# -----------------------\n",
        "\n",
        "random.seed(42)\n",
        "n_samples = 100\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for _ in range(n_samples):\n",
        "    x1 = random.uniform(0, 10)\n",
        "    x2 = random.uniform(0, 10)\n",
        "    label = 1 if x1 + x2 > 10 else 0  # Separazione lineare lungo la diagonale x1 + x2 = 10\n",
        "    X.append([x1, x2])\n",
        "    y.append(label)\n",
        "\n",
        "# Suddividiamo manualmente in training e test set\n",
        "split_index = int(0.8 * n_samples)\n",
        "X_train = X[:split_index]\n",
        "y_train = y[:split_index]\n",
        "X_test = X[split_index:]\n",
        "y_test = y[split_index:]\n",
        "\n",
        "# -----------------------\n",
        "# 2. Funzioni del Percettrone\n",
        "# -----------------------\n",
        "\n",
        "def step_function(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "\n",
        "def predict(x, weights, bias):\n",
        "    z = sum(w * xi for w, xi in zip(weights, x)) + bias\n",
        "    return step_function(z)\n",
        "\n",
        "def train_perceptrone(X_train, y_train, learning_rate=0.1, epochs=10):\n",
        "    n_features = len(X_train[0])\n",
        "    weights = [0.0 for _ in range(n_features)]\n",
        "    bias = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for x, label in zip(X_train, y_train):\n",
        "            y_pred = predict(x, weights, bias)\n",
        "            error = label - y_pred\n",
        "            # Aggiornamento pesi e bias\n",
        "            for i in range(n_features):\n",
        "                weights[i] += learning_rate * error * x[i]\n",
        "            bias += learning_rate * error\n",
        "    return weights, bias\n",
        "\n",
        "# -----------------------\n",
        "# 3. Addestramento del modello\n",
        "# -----------------------\n",
        "\n",
        "weights, bias = train_perceptrone(X_train, y_train, learning_rate=0.1, epochs=30)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Valutazione e Matrice di Confusione\n",
        "# -----------------------\n",
        "\n",
        "TP = FP = TN = FN = 0\n",
        "y_pred_test = []\n",
        "\n",
        "for x, label in zip(X_test, y_test):\n",
        "    y_hat = predict(x, weights, bias)\n",
        "    y_pred_test.append(y_hat)\n",
        "    if y_hat == 1 and label == 1:\n",
        "        TP += 1\n",
        "    elif y_hat == 1 and label == 0:\n",
        "        FP += 1\n",
        "    elif y_hat == 0 and label == 0:\n",
        "        TN += 1\n",
        "    elif y_hat == 0 and label == 1:\n",
        "        FN += 1\n",
        "\n",
        "print(\"Matrice di Confusione (senza librerie esterne):\")\n",
        "print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
        "accuracy = (TP + TN) / len(y_test)\n",
        "print(f\"Accuratezza: {accuracy:.2f}\")\n",
        "\n",
        "# -----------------------\n",
        "# 5. Visualizzazione\n",
        "# -----------------------\n",
        "\n",
        "x1_pos = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 1]\n",
        "x2_pos = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 1]\n",
        "x1_neg = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 0]\n",
        "x2_neg = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 0]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x1_pos, x2_pos, c='green', label='Classe 1 (Reale)', marker='x')\n",
        "plt.scatter(x1_neg, x2_neg, c='blue', label='Classe 0 (Reale)', marker='o')\n",
        "\n",
        "# Linea di decisione: w1*x1 + w2*x2 + b = 0 => x2 = -(w1*x1 + b)/w2\n",
        "x1_vals = [i for i in range(0, 11)]\n",
        "if weights[1] != 0:\n",
        "    x2_vals = [-(weights[0]*x + bias)/weights[1] for x in x1_vals]\n",
        "    plt.plot(x1_vals, x2_vals, '--', color='black', label='Confine decisionale')\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.title(\"Percettrone - Separazione tra classi\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il codice Python usato per l'implementazione del perceptrone e per il grafico dei risultati segue la seguente logica:\n",
        "\n",
        "1. **Generazione dati**\n",
        "Simuliamo 100 punti 2D. I punti per cui $x_1 + x_2 > 10$ sono etichettati come **classe 1**, altrimenti **classe 0**.\n",
        "\n",
        "2. **Implementazione del percettrone**\n",
        "- **`step_function(z)`**: restituisce 1 se la somma è maggiore o uguale a zero, altrimenti 0.\n",
        "- **`predict(x, weights, bias)`**: calcola il valore di $z$ e applica la funzione di attivazione.\n",
        "- **`train_perceptrone()`**: implementa l'algoritmo di apprendimento con aggiornamento dei pesi.\n",
        "\n",
        "3. **Addestramento**\n",
        "Il modello viene addestrato per 20 epoche (ripetizioni del dataset) su 80% dei dati.\n",
        "\n",
        "4. **Matrice di confusione**\n",
        "Calcolo dei 4 elementi della matrice di confusione:\n",
        "- **TP**: (True Positive = Vero Positivo) predetto 1 e vero 1\n",
        "- **TN**: (True Negative = Vero Negativo) predetto 0 e vero 0\n",
        "- **FP**: (False Positive = Falso Positivo) predetto 1 e vero 0 (falso allarme)\n",
        "- **FN**: (False Negative = Falso Negativo) predetto 0 e vero 1 (falso negativo)\n",
        "\n",
        "5. **Visualizzazione**\n",
        "Il grafico mostra:\n",
        "- I punti veri (blu per classe 0, verde per classe 1).\n",
        "- Il **confine decisionale** calcolato con la formula della retta.\n",
        "\n",
        "**Risultato atteso**\n",
        "\n",
        "Con dati così semplici e ben separabili, il percettrone dovrebbe ottenere una **accuratezza alta (quasi 100%)**.\n",
        "\n",
        "### Esperimento 2: il perceptrone bel caso di classi concentriche {#sec-lab-perceptrone-classi-concentriche}\n",
        "\n",
        "Il codice Python che segue implementa un semplice modello di classificatore a **perceptrone** usando la sola libreria random per la generazione di numeri casuali per simulare i dati e matplotlib per graficare i risultati.\n",
        "I dati simulati sono distribuiti su due corone circolari concentriche e quindi non linearmente separabili."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Generazione del dataset circolare\n",
        "# -------------------------------\n",
        "\n",
        "def genera_cerchi(n_samples):\n",
        "    X = []\n",
        "    y = []\n",
        "    for _ in range(n_samples):\n",
        "        r = random.uniform(0, 1)\n",
        "        angle = random.uniform(0, 2 * math.pi)\n",
        "        if r < 0.5:\n",
        "            radius = random.uniform(1, 2)\n",
        "            label = 0\n",
        "        else:\n",
        "            radius = random.uniform(3, 4)\n",
        "            label = 1\n",
        "        x1 = radius * math.cos(angle)\n",
        "        x2 = radius * math.sin(angle)\n",
        "        X.append([x1, x2])\n",
        "        y.append(label)\n",
        "    return X, y\n",
        "\n",
        "random.seed(42)\n",
        "X, y = genera_cerchi(200)\n",
        "\n",
        "# Suddividiamo in training e test set\n",
        "split_index = int(0.8 * len(X))\n",
        "X_train = X[:split_index]\n",
        "y_train = y[:split_index]\n",
        "X_test = X[split_index:]\n",
        "y_test = y[split_index:]\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Percettrone da zero\n",
        "# -------------------------------\n",
        "\n",
        "def step_function(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "\n",
        "def predict(x, weights, bias):\n",
        "    z = sum(w * xi for w, xi in zip(weights, x)) + bias\n",
        "    return step_function(z)\n",
        "\n",
        "def train_perceptrone(X, y, learning_rate=0.1, epochs=20):\n",
        "    n_features = len(X[0])\n",
        "    weights = [0.0 for _ in range(n_features)]\n",
        "    bias = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        for xi, yi in zip(X, y):\n",
        "            y_pred = predict(xi, weights, bias)\n",
        "            error = yi - y_pred\n",
        "            for i in range(n_features):\n",
        "                weights[i] += learning_rate * error * xi[i]\n",
        "            bias += learning_rate * error\n",
        "    return weights, bias\n",
        "\n",
        "# Addestramento\n",
        "weights, bias = train_perceptrone(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Valutazione\n",
        "# -------------------------------\n",
        "\n",
        "TP = FP = TN = FN = 0\n",
        "y_pred_test = []\n",
        "\n",
        "for x, label in zip(X_test, y_test):\n",
        "    y_hat = predict(x, weights, bias)\n",
        "    y_pred_test.append(y_hat)\n",
        "    if y_hat == 1 and label == 1:\n",
        "        TP += 1\n",
        "    elif y_hat == 1 and label == 0:\n",
        "        FP += 1\n",
        "    elif y_hat == 0 and label == 0:\n",
        "        TN += 1\n",
        "    elif y_hat == 0 and label == 1:\n",
        "        FN += 1\n",
        "\n",
        "print(\"Matrice di confusione:\")\n",
        "print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
        "accuracy = (TP + TN) / len(y_test)\n",
        "print(f\"Accuratezza: {accuracy:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Visualizzazione\n",
        "# -------------------------------\n",
        "\n",
        "# Colori reali\n",
        "x1_pos = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 1]\n",
        "x2_pos = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 1]\n",
        "x1_neg = [X_test[i][0] for i in range(len(y_test)) if y_test[i] == 0]\n",
        "x2_neg = [X_test[i][1] for i in range(len(y_test)) if y_test[i] == 0]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x1_pos, x2_pos, color='green', label='Classe 1 (Reale)', marker='x')\n",
        "plt.scatter(x1_neg, x2_neg, color='blue', label='Classe 0 (Reale)', marker='o')\n",
        "\n",
        "# Linea di decisione (valida solo per separazione lineare)\n",
        "x_vals = [i / 10.0 for i in range(-40, 41)]\n",
        "if weights[1] != 0:\n",
        "    y_vals = [-(weights[0]*x + bias)/weights[1] for x in x_vals]\n",
        "    plt.plot(x_vals, y_vals, '--', color='black', label='Confine decisionale')\n",
        "\n",
        "plt.title(\"Percettrone su dati non linearmente separabili\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'esito dell'esperimento mostra chiaramente ciò che già sapevamo bene:\n",
        "Il **percettrone può apprendere solo confini lineari**. \n",
        "In questo caso:\n",
        "\n",
        "- I dati sono disposti in **cerchi concentrici**, cioè non possono essere separati con una retta.\n",
        "- Il percettrone cerca una retta per dividere i dati… ma non riesce e commette molti errori.\n",
        "- L’**accuratezza è bassa** (minore del 50%).\n",
        "- Il grafico mostra che la **linea di decisione** non riesce a separare correttamente le due classi.\n",
        "\n",
        "In casi come questo servono modelli di reti neurali più avanzati come le **reti neurali multistrato (MLP)** ."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "C:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
