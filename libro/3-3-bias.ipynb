{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bias\n",
        "\n",
        "## Laboratorio in Python\n",
        "\n",
        "### Esperimento 1: Bias di Selezione\n",
        "\n",
        "Simuliamo un dataset dove la popolazione rappresentata è squilibrata tra due gruppi. Addestriamo un modello e analizziamo l'accuratezza per ciascun gruppo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "# Simulazione di un dataset con bias di selezione\n",
        "np.random.seed(42)\n",
        "n_samples = 500\n",
        "\n",
        "# Gruppo A (es. uomini)\n",
        "X_A = np.random.normal(loc=50, scale=10, size=(int(n_samples * 0.8), 1))  # più rappresentato\n",
        "y_A = (X_A.flatten() > 50).astype(int)  # outcome dipende dal valore\n",
        "\n",
        "# Gruppo B (es. donne), sottorappresentato\n",
        "X_B = np.random.normal(loc=50, scale=10, size=(int(n_samples * 0.2), 1))\n",
        "y_B = (X_B.flatten() > 50).astype(int)\n",
        "\n",
        "# Combinazione dei dati\n",
        "X = np.vstack((X_A, X_B))\n",
        "y = np.concatenate((y_A, y_B))\n",
        "groups = np.array(['A'] * len(X_A) + ['B'] * len(X_B))\n",
        "\n",
        "# Divisione del dataset\n",
        "X_train, X_test, y_train, y_test, groups_train, groups_test = train_test_split(X, y, groups, test_size=0.3, random_state=42)\n",
        "\n",
        "# Addestramento modello\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predizioni\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuratezza complessiva\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Accuratezza per gruppo\n",
        "acc_A = accuracy_score(y_test[groups_test == 'A'], y_pred[groups_test == 'A'])\n",
        "acc_B = accuracy_score(y_test[groups_test == 'B'], y_pred[groups_test == 'B'])\n",
        "\n",
        "# Matrice di confusione\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title(\"Matrice di Confusione - Bias di Selezione\")\n",
        "plt.show()\n",
        "\n",
        "# Visualizzazione delle accuratezze\n",
        "sns.barplot(x=['Totale', 'Gruppo A', 'Gruppo B'], y=[acc, acc_A, acc_B])\n",
        "plt.title('Accuratezza per Gruppo')\n",
        "plt.ylabel('Accuratezza')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "acc, acc_A, acc_B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I risultati dell'esperimento sul **bias di selezione** sono i seguenti:\n",
        "\n",
        "* **Accuratezza complessiva**: 99.3%\n",
        "* **Accuratezza sul Gruppo A** (maggiormente rappresentato): 100%\n",
        "* **Accuratezza sul Gruppo B** (sottorappresentato): 96.8%\n",
        "\n",
        "Questo esperimento evidenzia il pericolo del **bias di selezione**, un problema comune nei sistemi di classificazione. Anche se il modello ha un'elevata accuratezza complessiva, la sua performance sul gruppo sottorappresentato è significativamente inferiore. Questo dimostra come un modello possa essere ingiusto verso alcune categorie, anche se sembra essere accurato in generale.\n",
        "\n",
        "### Esperimento 2: Bias Sistemico\n",
        "\n",
        "L'obiettivo di questo esperimento è dimostrare l’effetto di un bias sistemico di genere in un modello di selezione del personale.\n",
        "A questo scopo simuliamo un processo di selezione del personale in cui, a parità di esperienza e età, **le donne vengono penalizzate** sistematicamente rispetto agli uomini. Usiamo un dataset artificiale in cui il genere influisce negativamente sulla probabilità di assunzione, creando così un **bias sistemico**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generazione dati simulati\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "esperienza = np.random.normal(5, 2, n)\n",
        "eta = np.random.normal(35, 5, n)\n",
        "genere = np.random.choice([0, 1], size=n)  # 0 = femmina, 1 = maschio\n",
        "\n",
        "# Bias sistemico: penalizzazione delle donne (genere=0)\n",
        "logits = 0.5 * esperienza + 0.1 * eta + 1.0 * genere - 7.5\n",
        "prob_assunzione = 1 / (1 + np.exp(-logits))\n",
        "assunto = np.random.binomial(1, prob_assunzione)\n",
        "\n",
        "# Dataset\n",
        "df = pd.DataFrame({\n",
        "    'esperienza': esperienza,\n",
        "    'eta': eta,\n",
        "    'genere': genere,\n",
        "    'assunto': assunto\n",
        "})\n",
        "\n",
        "# Split e normalizzazione\n",
        "X = df[['esperienza', 'eta', 'genere']]\n",
        "y = df['assunto']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Modello\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Classificazione report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Grafico: distribuzione delle probabilità predette per maschi e femmine\n",
        "prob_pred = model.predict_proba(X_test_scaled)[:, 1]\n",
        "X_test_with_probs = pd.DataFrame(X_test_scaled, columns=['esperienza', 'eta', 'genere'])\n",
        "X_test_with_probs['prob_assunto'] = prob_pred\n",
        "X_test_with_probs['genere'] = X_test['genere'].values\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "for g, label in zip([0, 1], ['Femmine', 'Maschi']):\n",
        "    subset = X_test_with_probs[X_test_with_probs['genere'] == g]\n",
        "    plt.hist(subset['prob_assunto'], bins=25, alpha=0.6, label=label, density=True)\n",
        "plt.xlabel('Probabilità Predetta di Assunzione')\n",
        "plt.ylabel('Densità')\n",
        "plt.title('Distribuzione della Probabilità di Assunzione per Genere')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Importazione delle librerie**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "```\n",
        "\n",
        "Queste librerie permettono di:\n",
        "\n",
        "* creare e gestire dati (`numpy`, `pandas`)\n",
        "* visualizzare grafici (`matplotlib`)\n",
        "* creare e valutare un modello di regressione logistica (`sklearn`)\n",
        "\n",
        "---\n",
        "\n",
        "2. **Generazione del dataset simulato**\n",
        "\n",
        "```python\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "genere = np.random.binomial(1, 0.5, n)  # 0=f, 1=m\n",
        "esperienza = np.random.normal(5 + genere*1.5, 1, n)  # maschi con +1.5 anni\n",
        "eta = np.random.normal(35, 5, n)\n",
        "```\n",
        "\n",
        "Qui generiamo 1000 candidati:\n",
        "\n",
        "* `genere`: 0 = femmina, 1 = maschio, distribuiti equamente.\n",
        "* `esperienza`: in media, i maschi hanno più esperienza (bias indotto).\n",
        "* `età`: distribuita normalmente.\n",
        "\n",
        "```python\n",
        "bias = -0.8 * (1 - genere)  # penalizzazione per le donne\n",
        "logits = 0.3*esperienza + 0.05*eta + bias\n",
        "prob = 1 / (1 + np.exp(-logits))\n",
        "assunto = np.random.binomial(1, prob)\n",
        "```\n",
        "\n",
        "* Calcoliamo la **probabilità di assunzione** come combinazione lineare delle variabili, con un **bias penalizzante per le donne**.\n",
        "* La variabile `assunto` simula se il candidato viene assunto.\n",
        "\n",
        "3. **Addestramento del modello**\n",
        "\n",
        "```python\n",
        "X = np.column_stack((esperienza, eta, genere))\n",
        "y = assunto\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "\n",
        "* Addestriamo un modello di **regressione logistica** per predire l’assunzione.\n",
        "* Usiamo il **genere** come input, quindi il modello può apprendere e replicare il bias.\n",
        "\n",
        "4. **Visualizzazione del bias**\n",
        "\n",
        "```python\n",
        "X_df = pd.DataFrame(X_test, columns=[\"esperienza\", \"eta\", \"genere\"])\n",
        "X_df[\"prob_pred\"] = model.predict_proba(X_test)[:,1]\n",
        "X_df[\"genere\"] = X_df[\"genere\"].astype(int)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for g in [0, 1]:\n",
        "    subset = X_df[X_df[\"genere\"] == g]\n",
        "    label = \"Femmine\" if g == 0 else \"Maschi\"\n",
        "    plt.hist(subset[\"prob_pred\"], bins=20, alpha=0.5, label=label, density=True)\n",
        "\n",
        "plt.title(\"Distribuzione delle probabilità predette di assunzione per genere\")\n",
        "plt.xlabel(\"Probabilità predetta di assunzione\")\n",
        "plt.ylabel(\"Densità\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "* **Istogramma** delle probabilità predette per ciascun genere.\n",
        "* Mostra chiaramente che i **maschi** hanno **più probabilità di essere assunti**, anche a parità di altre condizioni.\n",
        "\n",
        "Questo esperimento dimostra visivamente e quantitativamente:\n",
        "\n",
        "* l’effetto del **bias sistemico**,\n",
        "* come esso possa essere **appreso e amplificato** da un modello,\n",
        "* perché sia cruciale **rimuovere variabili sensibili** o applicare **strategie di mitigazione**.\n",
        "\n",
        "### Esperimento 2: Bias di razza nella valutazione del rischio di recidiva\n",
        "\n",
        "Obiettivo di questo esperimento è dimostrare come un modello predittivo possa riflettere o amplificare bias razziali analizzando la distribuzione delle probabilità predette per la recidiva in due gruppi demografici distinti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Simulazione dataset giustizia penale con possibile bias razziale\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "# Variabile sensibile: razza (0=gruppo A, 1=gruppo B)\n",
        "razza = np.random.binomial(1, 0.5, n)\n",
        "\n",
        "# Caratteristiche: numero precedenti penali, età\n",
        "precedenti = np.random.poisson(2 + razza * 0.5, n)  # il gruppo B ha in media più precedenti\n",
        "eta = np.random.normal(35, 5, n)\n",
        "\n",
        "# Probabilità \"vera\" di recidiva senza bias\n",
        "logits_veri = 0.8 * precedenti + 0.02 * eta\n",
        "prob_vera = 1 / (1 + np.exp(-logits_veri))\n",
        "recidiva_reale = np.random.binomial(1, prob_vera)\n",
        "\n",
        "# Sistema giudiziario introduce un bias implicito (più severo con gruppo B)\n",
        "bias = 0.7 * razza\n",
        "logits_predetti = logits_veri + bias\n",
        "prob_predetta = 1 / (1 + np.exp(-logits_predetti))\n",
        "recidiva_predetta = np.random.binomial(1, prob_predetta)\n",
        "\n",
        "# 2. Addestramento modello su dati \"biasati\"\n",
        "X = np.column_stack((precedenti, eta, razza))\n",
        "y = recidiva_predetta\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 3. Analisi dell'equità: confronto distribuzioni delle probabilità predette per gruppo\n",
        "X_test_df = pd.DataFrame(X_test, columns=[\"precedenti\", \"eta\", \"razza\"])\n",
        "X_test_df[\"prob_pred\"] = probs\n",
        "X_test_df[\"razza\"] = X_test_df[\"razza\"].astype(int)\n",
        "\n",
        "# 4. Grafico della distribuzione predetta per razza\n",
        "plt.figure(figsize=(8, 6))\n",
        "for r in [0, 1]:\n",
        "    subset = X_test_df[X_test_df[\"razza\"] == r]\n",
        "    label = \"Gruppo A\" if r == 0 else \"Gruppo B\"\n",
        "    plt.hist(subset[\"prob_pred\"], bins=20, alpha=0.6, label=label, density=True)\n",
        "\n",
        "plt.title(\"Distribuzione delle probabilità predette di recidiva per gruppo razziale\")\n",
        "plt.xlabel(\"Probabilità predetta di recidiva\")\n",
        "plt.ylabel(\"Densità\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5. Rapporto di classificazione\n",
        "report = classification_report(y_test, y_pred, target_names=[\"No recidiva\", \"Recidiva\"])\n",
        "report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il codice Python simula un dataset di giustizia penale con possibile bias razziale. Il modello predittivo apprende e amplifica questo bias, mostrando come la distribuzione delle probabilità predette sia diversa per i due gruppi.\n",
        "\n",
        "1. **Simulazione dei dati**\n",
        "\n",
        "Abbiamo simulato un dataset di **1.000 soggetti** nel contesto della giustizia penale, con le seguenti caratteristiche:\n",
        "\n",
        "* **Razza** (`0=Gruppo A`, `1=Gruppo B`)\n",
        "* **Numero di precedenti penali**\n",
        "* **Età**\n",
        "\n",
        "La **variabile sensibile** è la razza. Abbiamo introdotto un *bias implicito* che aumenta il rischio predetto di recidiva per il gruppo B, anche a parità di condizioni con il gruppo A.\n",
        "\n",
        "2. **Addestramento del modello**\n",
        "\n",
        "È stato addestrato un modello di **regressione logistica** sui dati biasati per simulare l’apprendimento in un ambiente non equo.\n",
        "\n",
        "3. **Analisi dell’equità**\n",
        "\n",
        "Abbiamo calcolato le **probabilità predette** di recidiva per ogni soggetto nel test set e confrontato graficamente le distribuzioni nei due gruppi razziali.\n",
        "\n",
        "4. **Risultati**\n",
        "\n",
        "Il grafico mostra chiaramente che il **gruppo B riceve sistematicamente predizioni di rischio più alte**, anche a parità di precedenti e di età. Questo è un segnale diretto di **bias sistemico** nel processo predittivo.\n",
        "\n",
        "5. **Valutazione delle prestazioni**\n",
        "\n",
        "Dal report di classificazione:\n",
        "\n",
        "* Il modello ha una **accuratezza del 91%**, ma è totalmente sbilanciato: **non predice mai la classe \"No recidiva\"** (precision = 0.00, recall = 0.00).\n",
        "* Questo è un esempio perfetto di come un modello possa sembrare “accurato” ma essere **profondamente ingiusto**.\n",
        "\n",
        "\n",
        "\n",
        "L'esperimento dimostra che:\n",
        "\n",
        "* Il bias può essere introdotto **nei dati**, non necessariamente nel modello.\n",
        "* È fondamentale **analizzare le predizioni per sottogruppi** (e.g., gruppi razziali, genere, età).\n",
        "* Anche modelli con alta accuratezza possono **comportarsi in modo discriminatorio**, e le metriche aggregate possono mascherare queste disuguaglianze."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "C:\\Users\\lcapitanio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
