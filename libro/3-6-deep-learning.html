<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>14&nbsp; Deep learning – Laboratorio di Intelligenza Artificiale</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./3-7-elaborazione-linguaggio-naturale.html" rel="next">
<link href="./3-5-perceptrone.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-254d8caa02a4f51d576d86802a86f2db.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-e5911a59318b73639a72866017db9c42.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-254d8caa02a4f51d576d86802a86f2db.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="epub.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./3-machine learning.html">Machine learning</a></li><li class="breadcrumb-item"><a href="./3-6-deep-learning.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Deep learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Laboratorio di Intelligenza Artificiale</a> 
        <div class="sidebar-tools-main tools-wide">
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Prefazione dell’autore{.unnumbered}</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0-introduzione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-Turing-vs-Searle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Turing vs Searle</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./2-algoritmi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Algoritmi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-1-inferenza-logica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Inferenza Logica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-2-inferenza-probabilistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Inferenza Probabilistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-3-inferenza-bayesiana.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inferenza Bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-4-algoritmi-di-ricerca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Algoritmi di Ricerca</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-5-algoritmi-equitativi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Algoritmi Equitativi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-6-algoritmi-predittivi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Algoritmi Predittivi</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./3-machine learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-1-apprendimento-supervisionato.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Apprendimento Supervisionato</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-2-apprendimento-non-supervisionato.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Apprendimento Non Supervisionato</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-3-bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Bias</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-4-regressione-lineare-e-logistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Regressione Lineare e Logistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-5-perceptrone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Percetptrone</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-6-deep-learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Deep learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-7-elaborazione-linguaggio-naturale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Elaborazione del Linguaggio Naturale</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bibliografia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Bibliografia</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">14.1</span> Introduzione</a></li>
  <li><a href="#reti-neurali-multistrato-mlp" id="toc-reti-neurali-multistrato-mlp" class="nav-link" data-scroll-target="#reti-neurali-multistrato-mlp"><span class="header-section-number">14.2</span> Reti Neurali Multistrato (MLP)</a>
  <ul class="collapse">
  <li><a href="#architettura-delle-mlp" id="toc-architettura-delle-mlp" class="nav-link" data-scroll-target="#architettura-delle-mlp"><span class="header-section-number">14.2.1</span> Architettura delle MLP</a></li>
  <li><a href="#funzioni-di-attivazione" id="toc-funzioni-di-attivazione" class="nav-link" data-scroll-target="#funzioni-di-attivazione"><span class="header-section-number">14.2.2</span> Funzioni di Attivazione</a></li>
  <li><a href="#funzioni-di-attivazione-degli-strati-di-uscita" id="toc-funzioni-di-attivazione-degli-strati-di-uscita" class="nav-link" data-scroll-target="#funzioni-di-attivazione-degli-strati-di-uscita"><span class="header-section-number">14.2.3</span> Funzioni di Attivazione degli Strati di Uscita</a></li>
  <li><a href="#funzioni-di-errore" id="toc-funzioni-di-errore" class="nav-link" data-scroll-target="#funzioni-di-errore"><span class="header-section-number">14.2.4</span> Funzioni di Errore</a></li>
  </ul></li>
  <li><a href="#algoritmo-di-backpropagation" id="toc-algoritmo-di-backpropagation" class="nav-link" data-scroll-target="#algoritmo-di-backpropagation"><span class="header-section-number">14.3</span> Algoritmo di Backpropagation</a>
  <ul class="collapse">
  <li><a href="#epoche-e-apprendimento-iterativo" id="toc-epoche-e-apprendimento-iterativo" class="nav-link" data-scroll-target="#epoche-e-apprendimento-iterativo"><span class="header-section-number">14.3.1</span> Epoche e apprendimento iterativo</a></li>
  <li><a href="#batch-di-dati-di-addestramento" id="toc-batch-di-dati-di-addestramento" class="nav-link" data-scroll-target="#batch-di-dati-di-addestramento"><span class="header-section-number">14.3.2</span> Batch di dati di addestramento</a></li>
  </ul></li>
  <li><a href="#architetture-di-reti-neurali-profonde" id="toc-architetture-di-reti-neurali-profonde" class="nav-link" data-scroll-target="#architetture-di-reti-neurali-profonde"><span class="header-section-number">14.4</span> Architetture di Reti Neurali Profonde</a>
  <ul class="collapse">
  <li><a href="#reti-neurali-convoluzionali-cnn" id="toc-reti-neurali-convoluzionali-cnn" class="nav-link" data-scroll-target="#reti-neurali-convoluzionali-cnn"><span class="header-section-number">14.4.1</span> Reti Neurali Convoluzionali (CNN)</a></li>
  <li><a href="#reti-neurali-ricorrenti-rnn" id="toc-reti-neurali-ricorrenti-rnn" class="nav-link" data-scroll-target="#reti-neurali-ricorrenti-rnn"><span class="header-section-number">14.4.2</span> Reti Neurali Ricorrenti (RNN)</a></li>
  <li><a href="#reti-generative-adversariali-gan" id="toc-reti-generative-adversariali-gan" class="nav-link" data-scroll-target="#reti-generative-adversariali-gan"><span class="header-section-number">14.4.3</span> Reti Generative Adversariali (GAN)</a></li>
  </ul></li>
  <li><a href="#tecniche-di-addestramento-per-reti-profonde" id="toc-tecniche-di-addestramento-per-reti-profonde" class="nav-link" data-scroll-target="#tecniche-di-addestramento-per-reti-profonde"><span class="header-section-number">14.5</span> Tecniche di Addestramento per Reti Profonde</a></li>
  <li><a href="#tecniche-di-ottimizzazione-dei-parametri-delle-reti-profonde" id="toc-tecniche-di-ottimizzazione-dei-parametri-delle-reti-profonde" class="nav-link" data-scroll-target="#tecniche-di-ottimizzazione-dei-parametri-delle-reti-profonde"><span class="header-section-number">14.6</span> Tecniche di Ottimizzazione dei Parametri delle Reti Profonde</a></li>
  <li><a href="#uso-di-modelli-pre-addestrati" id="toc-uso-di-modelli-pre-addestrati" class="nav-link" data-scroll-target="#uso-di-modelli-pre-addestrati"><span class="header-section-number">14.7</span> Uso di modelli pre-addestrati</a></li>
  <li><a href="#applicazioni-e-sfide" id="toc-applicazioni-e-sfide" class="nav-link" data-scroll-target="#applicazioni-e-sfide"><span class="header-section-number">14.8</span> Applicazioni e Sfide</a></li>
  <li><a href="#laboratorio-python" id="toc-laboratorio-python" class="nav-link" data-scroll-target="#laboratorio-python"><span class="header-section-number">14.9</span> Laboratorio Python</a>
  <ul class="collapse">
  <li><a href="#esperimento-1-rappresentazione-grafiche-di-reti-neurali-multistrato" id="toc-esperimento-1-rappresentazione-grafiche-di-reti-neurali-multistrato" class="nav-link" data-scroll-target="#esperimento-1-rappresentazione-grafiche-di-reti-neurali-multistrato"><span class="header-section-number">14.9.1</span> Esperimento 1: Rappresentazione grafiche di reti neurali multistrato</a></li>
  <li><a href="#sec-lab-rete-multistrato-classi-concentriche" id="toc-sec-lab-rete-multistrato-classi-concentriche" class="nav-link" data-scroll-target="#sec-lab-rete-multistrato-classi-concentriche"><span class="header-section-number">14.9.2</span> Esperimento 2: Rete MLP applicata al caso di classi concentriche</a></li>
  <li><a href="#esperimento-3-rete-mlp-per-la-predizione-dellesito-di-un-caso-giudiziario" id="toc-esperimento-3-rete-mlp-per-la-predizione-dellesito-di-un-caso-giudiziario" class="nav-link" data-scroll-target="#esperimento-3-rete-mlp-per-la-predizione-dellesito-di-un-caso-giudiziario"><span class="header-section-number">14.9.3</span> Esperimento 3: Rete MLP per la predizione dell’esito di un caso giudiziario</a></li>
  </ul></li>
  <li><a href="#esercizi" id="toc-esercizi" class="nav-link" data-scroll-target="#esercizi"><span class="header-section-number">14.10</span> Esercizi</a>
  <ul class="collapse">
  <li><a href="#esercizio-1-funzioni-di-attivazione-non-lineari" id="toc-esercizio-1-funzioni-di-attivazione-non-lineari" class="nav-link" data-scroll-target="#esercizio-1-funzioni-di-attivazione-non-lineari"><span class="header-section-number">14.10.1</span> Esercizio 1: Funzioni di attivazione non lineari</a></li>
  <li><a href="#esercizio-2-confronto-tra-architetture-neurali" id="toc-esercizio-2-confronto-tra-architetture-neurali" class="nav-link" data-scroll-target="#esercizio-2-confronto-tra-architetture-neurali"><span class="header-section-number">14.10.2</span> Esercizio 2: Confronto tra architetture neurali</a></li>
  <li><a href="#esercizio-3-vantaggi-dei-modelli-pre-addestrati" id="toc-esercizio-3-vantaggi-dei-modelli-pre-addestrati" class="nav-link" data-scroll-target="#esercizio-3-vantaggi-dei-modelli-pre-addestrati"><span class="header-section-number">14.10.3</span> Esercizio 3: Vantaggi dei modelli pre-addestrati</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./3-machine learning.html">Machine learning</a></li><li class="breadcrumb-item"><a href="./3-6-deep-learning.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Deep learning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Deep learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduzione" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="introduzione"><span class="header-section-number">14.1</span> Introduzione</h2>
<p>Il deep learning è una sottocategoria avanzata del machine learning che sfrutta reti neurali profonde per affrontare problemi complessi, caratterizzati da grandi quantità di dati e dalla necessità di apprendere rappresentazioni astratte e stratificate delle informazioni<span class="citation" data-cites="goodfellow2016deep">(<a href="#ref-goodfellow2016deep" role="doc-biblioref">Goodfellow, Bengio, and Courville 2016</a>)</span>. Il viaggio nel deep learning inizia spesso con le Reti Neurali Multistrato (MLP), che rappresentano il primo passo verso la comprensione delle reti neurali profonde.</p>
</section>
<section id="reti-neurali-multistrato-mlp" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="reti-neurali-multistrato-mlp"><span class="header-section-number">14.2</span> Reti Neurali Multistrato (MLP)</h2>
<p>Le Reti Neurali Multistrato (MLP = Multi Layer Perceptron) sono una forma di rete neurale feedforward, composte da uno strato di input, uno o più strati nascosti e uno strato di output. Le MLP sono in grado di apprendere rappresentazioni non lineari dei dati grazie all’uso di funzioni di attivazione non lineari nei neuroni dei loro strati nascosti. Sebbene siano efficaci per molti compiti, le MLP tradizionali hanno una capacità limitata di affrontare problemi particolarmente complessi, poiché sono generalmente composte da pochi strati nascosti. L’addestramento delle MLP avviene attraverso l’algoritmo di backpropagation, che calcola e minimizza l’errore del modello aggiornando i pesi dei collegamenti tra i neuroni<span class="citation" data-cites="haykin2009neural">(<a href="#ref-haykin2009neural" role="doc-biblioref">Haykin 2009</a>)</span>. Questa tecnica è fondamentale non solo per le MLP, ma anche per le reti neurali più complesse utilizzate nel deep learning.</p>
<section id="architettura-delle-mlp" class="level3" data-number="14.2.1">
<h3 data-number="14.2.1" class="anchored" data-anchor-id="architettura-delle-mlp"><span class="header-section-number">14.2.1</span> Architettura delle MLP</h3>
<p>Un MLP può essere configurato in diverse architetture a seconda del problema da risolvere. La configurazione più comune è quella con un singolo strato di input, uno o più strati nascosti e uno strato di output. Ogni neurone in uno strato è collegato a tutti i neuroni dello strato successivo, rendendo la rete completamente connessa.</p>
<ul>
<li><p><strong>Reti con un solo strato nascosto</strong>: Questo è il tipo più semplice di MLP, in cui un singolo strato nascosto è sufficiente per risolvere problemi relativamente semplici o linearmente separabili con una funzione di attivazione non lineare.</p></li>
<li><p><strong>Reti con più strati nascosti</strong>: Quando i dati presentano una complessità maggiore, un MLP con più strati nascosti può catturare pattern più complessi. Ogni strato aggiuntivo consente alla rete di apprendere rappresentazioni intermedie che possono essere utilizzate per ottenere una predizione finale più accurata.</p></li>
<li><p><strong>Deep MLP</strong>: Quando il numero di strati nascosti aumenta significativamente, la rete viene considerata “profonda” (deep). Questi modelli, sebbene potenti, richiedono una maggiore attenzione durante l’addestramento per evitare problemi come l’overfitting o la vanishing gradient problem.</p></li>
</ul>
</section>
<section id="funzioni-di-attivazione" class="level3" data-number="14.2.2">
<h3 data-number="14.2.2" class="anchored" data-anchor-id="funzioni-di-attivazione"><span class="header-section-number">14.2.2</span> Funzioni di Attivazione</h3>
<p>Le funzioni di attivazione sono cruciali per introdurre la non linearità nelle reti neurali, permettendo al modello multistrato di apprendere pattern complessi. Come visto in <a href="3-5-perceptrone.html#sec-lab-perceptrone-classi-concentriche" class="quarto-xref"><span>Section 13.6.2</span></a> un singolo perceptrone non riesce a classificare dati che non sono lineramente separabili. In questi casi occorre usare una rete multistrato con funzioni di attivazione non lineari nei neuroni artificiali degli strati intermedi. La non linearità è fondamentale: se si usassero solo funzioni di attivazione lineari, l’intera rete si comporterebbe come un singolo strato lineare. In altre parole, l’uscita sarebbe ancora una combinazione lineare degli ingressi, rendendo la rete incapace di apprendere relazioni complesse e limitandola a definire solo classificatori lineari (anche se in modo più articolato). Al contrario, la combinazione di funzioni non lineari dà la possibilità di approssimare funzioni complesse e definire curve di separazione tra classi (o superfici in più dimensioni) arbitrariamente elaborate. Si veda <a href="#sec-lab-rete-multistrato-classi-concentriche" class="quarto-xref"><span>Section 14.9.2</span></a> per una soluzione al problema di classificare dati distribuiti in classi concentriche con reti multistrato. Le funzioni di attivazione più comuni negli strati nascosti includono:</p>
<ul>
<li><p><strong>Sigmoide</strong>: Questa funzione mappa qualsiasi valore reale in un intervallo compreso tra 0 e 1, ed è definita come:</p>
<p><span class="math display">\[\text{sigmoide}(z) = \frac{1}{1 + e^{-z}}\]</span> La funzione sigmoide è utile quando si ha bisogno di un output probabilistico, ma può soffrire del problema della vanishing gradient, che rende difficile l’addestramento di reti profonde.</p></li>
<li><p><strong>ReLU (Rectified Linear Unit)</strong>: Una delle funzioni di attivazione più popolari, definita come:</p>
<p><span class="math display">\[
\text{ReLU}(z) = \max(0, z)
\]</span></p>
<p>ReLU è ampiamente utilizzata perché risolve in parte il problema della vanishing gradient, accelerando l’addestramento delle reti profonde. Tuttavia, può soffrire del problema della “morte dei neuroni”, dove i neuroni possono rimanere bloccati su zero.</p></li>
<li><p><strong>Tanh</strong>: Un’alternativa alla funzione sigmoide, mappa i valori in un intervallo tra -1 e 1, ed è definita come:</p>
<p><span class="math display">\[
\text{tanh}(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
\]</span></p>
<p>Tanh è spesso preferita alla sigmoide per la sua capacità di centrare i dati attorno a zero, migliorando la convergenza del modello.</p></li>
</ul>
</section>
<section id="funzioni-di-attivazione-degli-strati-di-uscita" class="level3" data-number="14.2.3">
<h3 data-number="14.2.3" class="anchored" data-anchor-id="funzioni-di-attivazione-degli-strati-di-uscita"><span class="header-section-number">14.2.3</span> Funzioni di Attivazione degli Strati di Uscita</h3>
<p>La scelta della funzione di attivazione nello strato di uscita dipende dal tipo di problema che il modello deve risolvere:</p>
<ul>
<li><p><strong>Classificazione binaria</strong>: Si utilizza comunemente la funzione sigmoide nello strato di uscita per ottenere una probabilità che l’output appartenga a una delle due classi.</p></li>
<li><p><strong>Classificazione multiclasse</strong>: La funzione softmax è preferita, poiché mappa i valori di output in un intervallo compreso tra 0 e 1 e la loro somma è 1, fornendo quindi una distribuzione di probabilità tra le diverse classi:</p>
<p><span class="math display">\[
\text{softmax}(z_j) = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}}
\]</span> Dove <span class="math inline">\(z_j\)</span> è l’output per la j-esima classe.</p></li>
<li><p><strong>Regressione</strong>: Per problemi di regressione, in genere non si applica alcuna funzione di attivazione nell’ultimo strato (o si utilizza l’identità) per mantenere l’output come un valore reale continuo.</p></li>
</ul>
</section>
<section id="funzioni-di-errore" class="level3" data-number="14.2.4">
<h3 data-number="14.2.4" class="anchored" data-anchor-id="funzioni-di-errore"><span class="header-section-number">14.2.4</span> Funzioni di Errore</h3>
<p>Le funzioni di errore (o funzioni di perdita) misurano la discrepanza tra l’output predetto dal modello e il valore reale, guidando così il processo di apprendimento:</p>
<ul>
<li><p><strong>Errore Quadratico Medio (MSE)</strong>: Utilizzato per problemi di regressione, è definito come:</p>
<p><span class="math display">\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
\]</span></p>
<p>Dove <span class="math inline">\(y_i\)</span> è il valore reale e <span class="math inline">\(\hat{y}_i\)</span> è il valore predetto.</p></li>
<li><p><strong>Cross-Entropy Loss</strong>: Utilizzata per la classificazione, particolarmente con softmax o sigmoide, misura la distanza tra le distribuzioni di probabilità:</p>
<p><span class="math display">\[
\text{Cross-Entropy} = -\sum_{i=1}^n y_i \log(\hat{y}_i)
\]</span></p></li>
</ul>
</section>
</section>
<section id="algoritmo-di-backpropagation" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="algoritmo-di-backpropagation"><span class="header-section-number">14.3</span> Algoritmo di Backpropagation</h2>
<p>Il <strong>backpropagation</strong> è l’algoritmo chiave che permette l’addestramento delle reti neurali multistrato<span class="citation" data-cites="rumelhart1986learning">(<a href="#ref-rumelhart1986learning" role="doc-biblioref">Rumelhart, Hinton, and Williams 1986</a>)</span>. Funziona in due fasi principali:</p>
<ol type="1">
<li><strong>Feedforward</strong>: I dati vengono propagati in avanti attraverso la rete fino a generare un output.</li>
<li><strong>Calcolo della perdita e propagazione all’indietro</strong>: L’errore viene calcolato confrontando l’output predetto con il valore reale. Questo errore viene poi propagato all’indietro attraverso la rete, calcolando il gradiente della funzione di perdita rispetto ai pesi della rete. I pesi vengono aggiornati utilizzando l’ottimizzazione tramite <strong>discesa del gradiente</strong>, minimizzando così la funzione di perdita.</li>
</ol>
<p>Il processo è iterativo e viene ripetuto molte volte fino a quando il modello non raggiunge un buon livello di accuratezza.</p>
<section id="epoche-e-apprendimento-iterativo" class="level3" data-number="14.3.1">
<h3 data-number="14.3.1" class="anchored" data-anchor-id="epoche-e-apprendimento-iterativo"><span class="header-section-number">14.3.1</span> Epoche e apprendimento iterativo</h3>
<p>Un’<strong>epoca</strong> (epoch) rappresenta un ciclo completo attraverso l’intero dataset di addestramento. Durante un’epoca, tutti gli esempi presenti nel dataset vengono utilizzati per aggiornare i pesi del modello. Tuttavia, per migliorare l’efficienza e la stabilità dell’apprendimento, il dataset viene tipicamente suddiviso in <strong>batch</strong>.</p>
</section>
<section id="batch-di-dati-di-addestramento" class="level3" data-number="14.3.2">
<h3 data-number="14.3.2" class="anchored" data-anchor-id="batch-di-dati-di-addestramento"><span class="header-section-number">14.3.2</span> Batch di dati di addestramento</h3>
<p>Un <strong>batch</strong> è un sottoinsieme del dataset utilizzato per aggiornare i pesi una volta. Questo approccio prende il nome di <strong>addestramento mini-batch</strong>. Esistono tre strategie principali:</p>
<ul>
<li><strong>Batch learning</strong>: tutto il dataset viene usato in un solo passo per ogni aggiornamento dei pesi. È computazionalmente intenso.</li>
<li><strong>Stochastic Gradient Descent (SGD)</strong>: ogni esempio di addestramento aggiorna i pesi immediatamente. È rumoroso ma può favorire la convergenza a un minimo globale.</li>
<li><strong>Mini-batch Gradient Descent</strong>: è il metodo più usato. I dati sono suddivisi in piccoli gruppi (batch), e ciascun batch viene utilizzato per calcolare un aggiornamento dei pesi. Questo equilibrio consente stabilità ed efficienza.</li>
</ul>
<p>Ad esempio, se abbiamo 10.000 esempi e un batch size di 100, avremo 100 batch per ogni epoca. Durante ogni epoca, il modello vedrà l’intero dataset, ma aggiornando i pesi 100 volte invece di una sola.</p>
<p>Organizzare l’apprendimento su più epoche permette alla rete di apprendere progressivamente dai dati. Durante l’addestramento, è comune monitorare l’errore sul <strong>set di validazione</strong> per evitare l’<strong>overfitting</strong> e applicare tecniche come l’<strong>early stopping</strong>, che interrompe l’addestramento se le prestazioni peggiorano su tale set.</p>
<p>In sintesi, l’algoritmo di backpropagation con l’organizzazione in epoche e batch costituisce il cuore del processo di apprendimento nelle reti neurali profonde, permettendo l’ottimizzazione dei pesi in modo efficiente e scalabile.</p>
</section>
</section>
<section id="architetture-di-reti-neurali-profonde" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="architetture-di-reti-neurali-profonde"><span class="header-section-number">14.4</span> Architetture di Reti Neurali Profonde</h2>
<p>Le reti neurali profonde rappresentano una specializzazione e un’estensione delle MLP. Queste reti, spesso costituite da decine o centinaia di strati nascosti, sono in grado di apprendere rappresentazioni molto più complesse e astratte rispetto alle MLP tradizionali. Ogni strato di una rete profonda elabora i dati in modo più dettagliato, consentendo al modello di catturare caratteristiche gerarchiche dei dati, come pattern semplici nei primi strati e strutture più complesse nei successivi.</p>
<section id="reti-neurali-convoluzionali-cnn" class="level3" data-number="14.4.1">
<h3 data-number="14.4.1" class="anchored" data-anchor-id="reti-neurali-convoluzionali-cnn"><span class="header-section-number">14.4.1</span> Reti Neurali Convoluzionali (CNN)</h3>
<p>Le reti neurali convoluzionali (CNN) sono una classe specializzata di reti neurali artificiali, particolarmente efficaci nell’elaborazione di dati strutturati a griglia, come le immagini <span class="citation" data-cites="lecun2015deep">(<a href="#ref-lecun2015deep" role="doc-biblioref">LeCun, Bengio, and Hinton 2015</a>)</span>. Il termine “convoluzionale” è fondamentale per comprendere il loro funzionamento unico.</p>
<p><strong>Cos’è la Convoluzione?</strong> La convoluzione è un’operazione matematica che sta alla base di queste reti. In termini semplici, consiste nell’applicare un filtro (o kernel) a una porzione dell’input, facendolo “scorrere” su tutta l’immagine. Questo processo può essere immaginato come una lente che si muove sull’immagine, focalizzandosi su piccole aree alla volta.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Immagine Input] --&gt; B[Applicazione Filtro]
    B --&gt; C[Feature Map]
    B --&gt; D[Scorrimento]
    D --&gt; |Ripeti| B
    C --&gt; E[Attivazione]
    E --&gt; F[Pooling]
    F --&gt; G[Prossimo Strato]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<ol type="1">
<li><strong>Filtri e Feature Maps</strong>:
<ul>
<li>I filtri sono matrici di pesi che vengono applicati all’input.</li>
<li>Ogni filtro è progettato per rilevare specifiche caratteristiche (come bordi, curve, o texture).</li>
<li>Il risultato dell’applicazione di un filtro è chiamato “feature map”.</li>
</ul></li>
<li><strong>Processo di Scorrimento</strong>:
<ul>
<li>Il filtro si muove sistematicamente attraverso l’immagine, pixel per pixel.</li>
<li>Ad ogni posizione, esegue una moltiplicazione elemento per elemento e una somma.</li>
<li>Questo crea una nuova rappresentazione dell’immagine che evidenzia certe caratteristiche.</li>
</ul></li>
<li><strong>Vantaggi della Convoluzione</strong>:
<ul>
<li><strong>Invarianza spaziale</strong>: La stessa caratteristica può essere rilevata ovunque nell’immagine.</li>
<li><strong>Parametri condivisi</strong>: I pesi del filtro sono riutilizzati, riducendo il numero totale di parametri.</li>
<li><strong>Gerarchia di features</strong>: Strati più profondi combinano features semplici in rappresentazioni più complesse.</li>
</ul></li>
</ol>
<p>Le CNN impilano multiple operazioni di convoluzione, alternate con funzioni di attivazione non lineari (come ReLU) e strati di pooling. Questa architettura permette alla rete di costruire una comprensione gerarchica dell’input, partendo da caratteristiche semplici negli strati iniziali (come bordi e texture) fino a concetti più astratti negli strati più profondi (come forme complesse e oggetti interi). Grazie a questa struttura “convoluzionale”, le CNN sono eccezionalmente efficaci in compiti come il riconoscimento di immagini, l’individuazione di oggetti, e la segmentazione semantica, superando spesso le capacità umane in questi domini.</p>
</section>
<section id="reti-neurali-ricorrenti-rnn" class="level3" data-number="14.4.2">
<h3 data-number="14.4.2" class="anchored" data-anchor-id="reti-neurali-ricorrenti-rnn"><span class="header-section-number">14.4.2</span> Reti Neurali Ricorrenti (RNN)</h3>
<p>Le RNN sono un’estensione delle MLP per dati sequenziali, come testi o segnali audio. Grazie alle connessioni ricorrenti, le RNN possono mantenere una memoria delle informazioni precedenti nella sequenza, rendendole ideali per compiti che richiedono la modellazione del contesto temporale. Tuttavia, le RNN tradizionali soffrono del problema del vanishing gradient, che può ostacolare l’apprendimento di dipendenze a lungo termine nelle sequenze. Per superare questa limitazione, sono state sviluppate varianti come le LSTM (Long Short-Term Memory) e le GRU (Gated Recurrent Unit), che migliorano la capacità della rete di apprendere e mantenere informazioni su lunghe sequenze temporali<span class="citation" data-cites="karpathy2015rnn">(<a href="#ref-karpathy2015rnn" role="doc-biblioref">Karpathy 2015</a>)</span>.</p>
</section>
<section id="reti-generative-adversariali-gan" class="level3" data-number="14.4.3">
<h3 data-number="14.4.3" class="anchored" data-anchor-id="reti-generative-adversariali-gan"><span class="header-section-number">14.4.3</span> Reti Generative Adversariali (GAN)</h3>
<p>Le GAN rappresentano un’architettura avanzata che contrappone due reti neurali, una generativa e una discriminativa, in un meccanismo competitivo (o framework competitivo)<span class="citation" data-cites="goodfellow2014generative">(<a href="#ref-goodfellow2014generative" role="doc-biblioref">Goodfellow et al. 2014</a>)</span>. Queste reti sono in grado di generare nuovi dati simili a quelli reali, estendendo le capacità delle MLP in modi creativi e innovativi. La rete generativa tenta di produrre dati falsi che siano indistinguibili dai dati reali, mentre la rete discriminativa cerca di distinguere tra dati reali e falsi. Questo approccio ha portato a notevoli innovazioni nella generazione di immagini realistiche, video, musica e persino testo, aprendo nuove possibilità nel campo della creatività artificiale e della simulazione.</p>
</section>
</section>
<section id="tecniche-di-addestramento-per-reti-profonde" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="tecniche-di-addestramento-per-reti-profonde"><span class="header-section-number">14.5</span> Tecniche di Addestramento per Reti Profonde</h2>
<p>L’addestramento delle reti profonde è più complesso rispetto a quello delle MLP a causa della maggiore profondità e del numero di parametri coinvolti. Il processo di addestramento utilizza algoritmi di ottimizzazione come la discesa del gradiente, ma con alcune sfide specifiche:</p>
<ul>
<li><p><strong>Problema del Vanishing Gradient</strong>: Nelle reti molto profonde, i gradienti calcolati durante la backpropagation possono diventare molto piccoli, impedendo l’aggiornamento efficace dei pesi nei primi strati della rete. Questo problema è particolarmente critico nelle RNN, dove la propagazione dei gradienti attraverso molteplici passi temporali può portare alla perdita di informazioni utili. Per mitigare questo problema, si utilizzano funzioni di attivazione come ReLU, che mantengono gradienti più ampi, e tecniche come il batch normalization, che stabilizza e accelera il processo di addestramento.</p></li>
<li><p><strong>Batch Normalization</strong>: Questa tecnica normalizza gli input a ciascuno strato per avere una media zero e una varianza unitaria, riducendo così il rischio di gradienti esplosivi o vanishing e migliorando la stabilità dell’addestramento. Il batch normalization è ampiamente utilizzato nelle reti profonde, poiché permette un addestramento più efficiente e riduce la sensibilità agli iperparametri, facilitando l’uso di learning rate più elevati.</p></li>
<li><p><strong>Dropout</strong>: Per prevenire l’overfitting, una delle tecniche più comuni è il dropout, che consiste nel disattivare casualmente alcuni neuroni durante l’addestramento, impedendo alla rete di dipendere troppo da specifiche connessioni. Questo forza la rete a generalizzare meglio, migliorando le sue prestazioni su dati mai visti. Durante la fase di inferenza, tutti i neuroni vengono utilizzati, ma i pesi sono scalati per mantenere la coerenza delle attivazioni.</p></li>
</ul>
</section>
<section id="tecniche-di-ottimizzazione-dei-parametri-delle-reti-profonde" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="tecniche-di-ottimizzazione-dei-parametri-delle-reti-profonde"><span class="header-section-number">14.6</span> Tecniche di Ottimizzazione dei Parametri delle Reti Profonde</h2>
<p>Oltre alle tecniche di addestramento, le reti profonde richiedono l’uso di tecniche avanzate di ottimizzazione per gestire la complessità e migliorare la convergenza:</p>
<ul>
<li><p><strong>Algoritmi di Ottimizzazione</strong>: Sebbene la discesa del gradiente stocastica (SGD) sia l’approccio di base, varianti più avanzate come Adam (Adaptive Moment Estimation) e RMSprop sono ampiamente utilizzate. Adam, in particolare, combina i vantaggi di AdaGrad (che adatta il learning rate per ogni parametro) e RMSprop (che mantiene un learning rate efficiente per ogni parametro), risultando in una convergenza più rapida e stabile anche in reti molto profonde.</p></li>
<li><p><strong>Learning Rate Scheduling</strong>: Il learning rate, ossia la velocità con cui vengono aggiornati i pesi, è un parametro critico che influisce sulla velocità e sull’efficacia dell’addestramento. Tecniche come il learning rate scheduling permettono di iniziare l’addestramento con un learning rate elevato, che viene ridotto man mano che il modello si avvicina a una soluzione ottimale. Questo aiuta a trovare il minimo globale della funzione di perdita più rapidamente.</p></li>
<li><p><strong>Early Stopping</strong>: Per evitare l’overfitting durante l’addestramento, l’early stopping monitora la performance del modello su un set di validazione e interrompe l’addestramento quando le prestazioni iniziano a peggiorare. Questo evita che la rete apprenda troppo i dettagli del set di addestramento, migliorando la generalizzazione.</p></li>
</ul>
</section>
<section id="uso-di-modelli-pre-addestrati" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="uso-di-modelli-pre-addestrati"><span class="header-section-number">14.7</span> Uso di modelli pre-addestrati</h2>
<p>L’addestramento delle reti neurali profonde richiede notevoli risorse computazionali e dataset di grandi dimensioni, rendendo i costi in termini di tempo e potenza di calcolo molto elevati. Per ridurre questi costi, l’uso di modelli pre-addestrati rappresenta una soluzione efficace, poiché consente di sfruttare reti già addestrate su ampi dataset e adattarle a specifici problemi con un processo noto come fine-tuning. Ciò permette di evitare il lungo e dispendioso processo di addestramento da zero, ottenendo comunque prestazioni eccellenti.</p>
<p>Le collezioni di modelli pre-addestrati disponibili su piattaforme come <a href="https://www.tensorflow.org/hub?hl=it">TensorFlow Hub</a>, <a href="https://pytorch.org/hub/">PyTorch Hub</a> e <a href="https://huggingface.co/models">Hugging Face Model Hub</a> offrono reti avanzate, già ottimizzate, come ResNet, EfficientNet per la visione e BERT, GPT per il linguaggio. Questi modelli, addestrati su dataset estesi, possono essere facilmente utilizzati per applicazioni specifiche con poche risorse computazionali aggiuntive, rendendo il processo più accessibile ed economico senza sacrificare la qualità delle prestazioni.</p>
</section>
<section id="applicazioni-e-sfide" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="applicazioni-e-sfide"><span class="header-section-number">14.8</span> Applicazioni e Sfide</h2>
<p>Le applicazioni del deep learning sono vaste e coprono molte aree, dalla visione artificiale all’elaborazione del linguaggio naturale. In ambito giuridico, le reti profonde possono essere utilizzate per l’analisi predittiva, la classificazione automatica di documenti legali e l’estrazione di informazioni da grandi volumi di testo. Tuttavia, l’implementazione del deep learning richiede una grande quantità di dati e risorse computazionali, oltre a una profonda comprensione delle reti neurali per evitare problemi di interpretabilità e bias. Nonostante queste sfide, il deep learning continua a spingere i confini dell’intelligenza artificiale, offrendo soluzioni avanzate a problemi complessi che erano precedentemente irrisolvibili.</p>
</section>
<section id="laboratorio-python" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="laboratorio-python"><span class="header-section-number">14.9</span> Laboratorio Python</h2>
<section id="esperimento-1-rappresentazione-grafiche-di-reti-neurali-multistrato" class="level3" data-number="14.9.1">
<h3 data-number="14.9.1" class="anchored" data-anchor-id="esperimento-1-rappresentazione-grafiche-di-reti-neurali-multistrato"><span class="header-section-number">14.9.1</span> Esperimento 1: Rappresentazione grafiche di reti neurali multistrato</h3>
<p>In questo esperimento vogliamo programmare una funzione in grado di realizzare una rappresentazione grafica di una rete neurale. A tale scopo adotteremo la libreria Python <strong>networkx</strong>. La funzione draw_mlp riceve in ingresso la descrizione della rete multistrato in termini di numero di neuroni di ingresso, numero di strati e numero di neuroni per ogni strato e numero di neuroni di uscita. Il risultato della funzione è il disegno del grafo della rete MLP.</p>
<div id="44872ad0" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Funzione per disegnare una rappresentazione grafica della rete MLP</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_mlp(hidden_layers, input_size, output_size):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> nx.DiGraph()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    layer_sizes <span class="op">=</span> [input_size] <span class="op">+</span> <span class="bu">list</span>(hidden_layers) <span class="op">+</span> [output_size]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Posizionamento dei nodi</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> {}</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    n_layers <span class="op">=</span> <span class="bu">len</span>(layer_sizes)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    v_spacing <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Creazione dei nodi</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, layer_size <span class="kw">in</span> <span class="bu">enumerate</span>(layer_sizes):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        layer_top <span class="op">=</span> v_spacing <span class="op">*</span> (layer_size <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(layer_size):</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            pos[<span class="ss">f'</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">'</span>] <span class="op">=</span> (i, layer_top <span class="op">-</span> v_spacing <span class="op">*</span> j)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>            G.add_node(<span class="ss">f'</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Creazione degli archi</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (layer_size_a, layer_size_b) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(layer_sizes[:<span class="op">-</span><span class="dv">1</span>], layer_sizes[<span class="dv">1</span>:])):</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(layer_size_a):</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(layer_size_b):</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                G.add_edge(<span class="ss">f'</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">'</span>, <span class="ss">f'</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Disegna il grafico</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    nx.draw(G, pos<span class="op">=</span>pos, with_labels<span class="op">=</span><span class="va">False</span>, arrows<span class="op">=</span><span class="va">False</span>, node_size<span class="op">=</span><span class="dv">300</span>, node_color<span class="op">=</span><span class="st">"lightblue"</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Etichette</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(input_size):</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        pos[<span class="ss">f'0-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>] <span class="op">=</span> (pos[<span class="ss">f'0-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">0</span>] <span class="op">-</span> <span class="fl">0.1</span>, pos[<span class="ss">f'0-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">1</span>])</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        plt.text(pos[<span class="ss">f'0-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">0</span>], pos[<span class="ss">f'0-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">1</span>], <span class="ss">f'Input </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>, horizontalalignment<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(output_size):</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        pos[<span class="ss">f'</span><span class="sc">{</span>n_layers<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>] <span class="op">=</span> (pos[<span class="ss">f'</span><span class="sc">{</span>n_layers<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">0</span>] <span class="op">+</span> <span class="fl">0.1</span>, pos[<span class="ss">f'</span><span class="sc">{</span>n_layers<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">1</span>])</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        plt.text(pos[<span class="ss">f'</span><span class="sc">{</span>n_layers<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">0</span>], pos[<span class="ss">f'</span><span class="sc">{</span>n_layers<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>][<span class="dv">1</span>], <span class="ss">f'Output </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>, horizontalalignment<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Rappresentazione Grafica della Rete MLP"</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Applichiamo la funzione draw_mlp() al caso di una rete con 4 ingressi 3 strati nascosti da 3, 9 e 3 neuroni rispettivamente e 1 neurone di uscita:</p>
<div id="14a13bcb" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri della rete MLP utilizzata nell'esempio</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>hidden_layers <span class="op">=</span> (<span class="dv">3</span>,<span class="dv">9</span>, <span class="dv">3</span>)  <span class="co"># Due strati nascosti con 10 e 5 neuroni rispettivamente</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> <span class="dv">4</span>  <span class="co"># Due caratteristiche in input</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>output_size <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Un neurone di output (classificazione binaria)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Disegnare la rappresentazione della rete MLP</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>draw_mlp(hidden_layers, input_size, output_size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3-6-deep-learning_files/figure-html/cell-3-output-1.png" width="1171" height="807" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-lab-rete-multistrato-classi-concentriche" class="level3" data-number="14.9.2">
<h3 data-number="14.9.2" class="anchored" data-anchor-id="sec-lab-rete-multistrato-classi-concentriche"><span class="header-section-number">14.9.2</span> Esperimento 2: Rete MLP applicata al caso di classi concentriche</h3>
<p>In questo esperimento vogliamo applicare una rete multistrato al problema della classificazione binaria nel caso di un dataset bidimensionale composto da due classi concentrichele La rete è composta da:</p>
<ul>
<li><strong>Strato di input</strong>: Due ingressi, ciascuno corrispondente a una delle caratteristiche del dataset (x1,x2).</li>
<li><strong>Strati nascosti</strong>: Due strati nascosti, il primo con 10 neuroni e il secondo con 5 neuroni, che permettono alla rete di apprendere rappresentazioni più complesse dei dati grazie alla funzione di attivazione non lineare “relu” adottata. Ogni neurone in un determinato strato è connesso a tutti i neuroni dello strato successivo, consentendo il flusso delle informazioni attraverso la rete durante l’addestramento e la predizione.</li>
<li><strong>Strato di output</strong>: Un singolo neurone di output, utilizzato per la classificazione binaria (classe 0, class 1).</li>
</ul>
<p>Usando la funzione introdotta nell’esempio 1 possiamo disegnare la rete MLP che vogliamo adottare per risolvere il problem di classificazione nel caso di classi concentriche.</p>
<div id="eede123c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri della rete MLP utilizzata nell'esempio</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>hidden_layers <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">5</span>)  <span class="co"># Due strati nascosti con 10 e 5 neuroni rispettivamente</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Due caratteristiche in input</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>output_size <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Un neurone di output (classificazione binaria)</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Disegnare la rappresentazione della rete MLP</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>draw_mlp(hidden_layers, input_size, output_size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3-6-deep-learning_files/figure-html/cell-4-output-1.png" width="1171" height="807" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="2243b345" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importa le librerie necessarie</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Generazione dei dati: due classi concentriche</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_concentric_circles(n_samples<span class="op">=</span><span class="dv">500</span>, noise<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    n_samples_per_class <span class="op">=</span> n_samples <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    angles <span class="op">=</span> np.random.rand(n_samples_per_class) <span class="op">*</span> <span class="dv">2</span> <span class="op">*</span> np.pi</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    inner_radius <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> noise <span class="op">*</span> np.random.randn(n_samples_per_class)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    outer_radius <span class="op">=</span> <span class="dv">3</span> <span class="op">+</span> noise <span class="op">*</span> np.random.randn(n_samples_per_class)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    inner_x <span class="op">=</span> np.stack([inner_radius <span class="op">*</span> np.cos(angles), inner_radius <span class="op">*</span> np.sin(angles)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    outer_x <span class="op">=</span> np.stack([outer_radius <span class="op">*</span> np.cos(angles), outer_radius <span class="op">*</span> np.sin(angles)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.concatenate([inner_x, outer_x], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.array([<span class="dv">0</span>] <span class="op">*</span> n_samples_per_class <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> n_samples_per_class)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> generate_concentric_circles()</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Visualizzazione dei dati</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Classe 0'</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Classe 1'</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Dati con Classi Concentriche'</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Divisione del dataset e normalizzazione</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Creazione e addestramento del modello MLP</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>), activation<span class="op">=</span><span class="st">'relu'</span>, max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>model.fit(X_train_scaled, y_train)</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Valutazione: matrice di confusione</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test_scaled)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Classe 0"</span>, <span class="st">"Classe 1"</span>])</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Matrice di Confusione"</span>)</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Grafico della superficie di decisione</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">.02</span>  <span class="co"># step size</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">.5</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">.5</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">.5</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">.5</span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max, h),</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>                     np.arange(y_min, y_max, h))</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.c_[xx.ravel(), yy.ravel()]</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>grid_scaled <span class="op">=</span> scaler.transform(grid)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> model.predict(grid_scaled)</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z, cmap<span class="op">=</span>plt.cm.Pastel2, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Classe 0'</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Classe 1'</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Superficie di Decisione del Modello MLP"</span>)</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3-6-deep-learning_files/figure-html/cell-5-output-1.png" width="495" height="505" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3-6-deep-learning_files/figure-html/cell-5-output-2.png" width="543" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3-6-deep-learning_files/figure-html/cell-5-output-3.png" width="643" height="505" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Il codice Python scritto per questo esperimento segue la seguente logica:</p>
<ul>
<li><p><strong>Generazione dei dati</strong>: Due insiemi di punti sono distribuiti in cerchi concentrici: il primo (classe 0) vicino all’origine, il secondo (classe 1) su un raggio maggiore. La forma dei dati rende il problema non linearmente separabile.</p></li>
<li><p><strong>Visualizzazione</strong>: Il primo grafico mostra chiaramente la distribuzione circolare dei due insiemi di punti.</p></li>
<li><p><strong>Preprocessing</strong>: I dati vengono suddivisi in un training e test set (70% - 30%) e normalizzati con StandardScaler.</p></li>
<li><p><strong>Modello MLP</strong>: È stata creata una rete con due strati nascosti (10 e 5 neuroni) e funzione di attivazione ReLU. La rete viene addestrata per classificare i dati.</p></li>
<li><p><strong>Valutazione</strong>: Viene calcolata e mostrata la matrice di confusione, che evidenzia l’accuratezza del modello nel distinguere le due classi.</p></li>
<li><p>S<strong>uperficie di decisione</strong>: Il terzo grafico mostra come la rete ha appreso a separare le due classi: la forma curva della regione di decisione indica che il modello ha effettivamente appreso la complessità dei dati, superando i limiti del percettrone semplice (che può solo separare linearmente).</p></li>
</ul>
</section>
<section id="esperimento-3-rete-mlp-per-la-predizione-dellesito-di-un-caso-giudiziario" class="level3" data-number="14.9.3">
<h3 data-number="14.9.3" class="anchored" data-anchor-id="esperimento-3-rete-mlp-per-la-predizione-dellesito-di-un-caso-giudiziario"><span class="header-section-number">14.9.3</span> Esperimento 3: Rete MLP per la predizione dell’esito di un caso giudiziario</h3>
<p>Applicazione di una rete neurale multistrato (MLP) per la predizione dell’esito di un caso giudiziario basandosi su tre caratteristiche: complessità del caso, esperienza dell’avvocato, e importanza mediatica. La rete è composta da:</p>
<ul>
<li><strong>Strato di input</strong>: Tre ingressi, ciascuno corrispondente a una delle caratteristiche del dataset (complessità del caso, esperienza dell’avvocato, importanza mediatica).</li>
<li><strong>Strati nascosti</strong>: Due strati nascosti, il primo con 10 neuroni e il secondo con 5 neuroni, che permettono alla rete di apprendere rappresentazioni più complesse dei dati.</li>
<li><strong>Strato di output</strong>: Un singolo neurone di output, utilizzato per la classificazione binaria (vittoria o sconfitta del caso).</li>
</ul>
<p>Usando la funzione introdotta nell’esempio 1 possiamo disegnare la rete MLP che vogliamo adottare per risolvere il problem di classificazione in studio. Si noti che è necessario eseguire il codice dell’esempio 1 per poter eseguire il seguente codice altrimenti Python segnalerà come errore il fatto di non conoscere la funzione draw_mlp().</p>
<div id="72544a17" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri della rete MLP utilizzata nell'esempio</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>hidden_layers <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">5</span>)  <span class="co"># Due strati nascosti con 10 e 5 neuroni rispettivamente</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> <span class="dv">3</span>  <span class="co"># Tre caratteristiche in input</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>output_size <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Un neurone di output (classificazione binaria)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Disegnare la rappresentazione della rete MLP</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>draw_mlp(hidden_layers, input_size, output_size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3-6-deep-learning_files/figure-html/cell-6-output-1.png" width="1171" height="807" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>L’implementazione in Python della rete MLP per il nostro problema di classificazione è la seguente:</p>
<div id="34cd6432" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay, classification_report</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler <span class="co"># Aggiunto import</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Simuliamo un dataset per predire se un caso giudiziario sarà vinto o perso basandosi su tre caratteristiche</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Ad esempio, complessità del caso, esperienza dell'avvocato, e importanza mediatica</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generare dati di esempio</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">200</span>, n_features<span class="op">=</span><span class="dv">3</span>, n_informative<span class="op">=</span><span class="dv">3</span>, n_redundant<span class="op">=</span><span class="dv">0</span>, n_clusters_per_class<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Dividere i dati in train e test</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; Aggiunta sezione per lo scaling</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalare i dati (buona pratica per MLP)</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co"># &lt;-- Fine sezione scaling</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Creare e addestrare un modello MLP usando i dati scalati</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>mlp_model <span class="op">=</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>), max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>mlp_model.fit(X_train_scaled, y_train) <span class="co"># Usa X_train_scaled</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Predire sul set di test scalato</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> mlp_model.predict(X_test_scaled) <span class="co"># Usa X_test_scaled</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrare la matrice di confusione usando i dati scalati</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(mlp_model, X_test_scaled, y_test, display_labels<span class="op">=</span>[<span class="st">"Perso"</span>, <span class="st">"Vinto"</span>], cmap<span class="op">=</span>plt.cm.Blues) <span class="co"># Usa X_test_scaled</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Matrice di Confusione'</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizzare il rapporto di classificazione</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> classification_report(y_test, y_pred, target_names<span class="op">=</span>[<span class="st">"Perso"</span>, <span class="st">"Vinto"</span>])</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(report)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="3-6-deep-learning_files/figure-html/cell-7-output-1.png" width="524" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

       Perso       0.97      1.00      0.99        35
       Vinto       1.00      0.96      0.98        25

    accuracy                           0.98        60
   macro avg       0.99      0.98      0.98        60
weighted avg       0.98      0.98      0.98        60
</code></pre>
</div>
</div>
<p><strong>Analisi dei Risultati</strong></p>
<ol type="1">
<li><p><strong>Matrice di Confusione</strong>: La matrice di confusione mostra le prestazioni del modello nella classificazione dei casi giudiziari come “Vinto” o “Perso”. Nel set di test, il modello ha classificato correttamente la maggior parte dei casi, con solo pochi errori. La matrice di confusione indica che il modello ha identificato con una buona precisione sia i casi vinti che quelli persi.</p></li>
<li><p><strong>Rapporto di Classificazione</strong>:</p>
<ul>
<li><strong>Precisione</strong>: La precisione per i casi persi è del 97%, mentre per i casi vinti è dell’100%. Questo significa che quando il modello prevede un caso come “Perso”, nel 97% dei casi ha ragione, mentre per i casi “Vinto”, la precisione è del 100%.</li>
<li><strong>Recall</strong>: La recall per i casi persi è del 100% e per i casi vinti è del 96%. Questo indica che il modello è riuscito a identificare correttamente la quasi totalità dei casi vinti e persi.</li>
<li><strong>F1-score</strong>: L’F1-score, che rappresenta un bilanciamento tra precisione e recall, è del 99% per i casi persi e del 98% per i casi vinti, riflettendo una ottima performance complessiva del modello.</li>
</ul></li>
</ol>
<p><strong>Osservazioni</strong>: - Il modello ha raggiunto un’accuratezza complessiva del 98%, che è un buon risultato considerando che i dati generati non sono perfettamente separabili. - È importante notare che il modello non ha raggiunto il valore di convergenza entro il numero massimo di iterazioni impostato (1000), come indicato dall’avviso di convergenza. Questo suggerisce che con ulteriori iterazioni o con l’ottimizzazione dei parametri del modello, le prestazioni potrebbero migliorare ulteriormente. - In sintesi, l’MLP si è dimostrato efficace nel classificare correttamente i casi giudiziari in base alle caratteristiche fornite, anche in presenza di dati non perfettamente distinti. - Questo esempio mostra il potenziale delle reti neurali multistrato per applicazioni giuridiche, come la predizione degli esiti legali, pur sottolineando l’importanza di una corretta configurazione e addestramento del modello per ottenere i migliori risultati possibili.</p>
</section>
</section>
<section id="esercizi" class="level2" data-number="14.10">
<h2 data-number="14.10" class="anchored" data-anchor-id="esercizi"><span class="header-section-number">14.10</span> Esercizi</h2>
<section id="esercizio-1-funzioni-di-attivazione-non-lineari" class="level3" data-number="14.10.1">
<h3 data-number="14.10.1" class="anchored" data-anchor-id="esercizio-1-funzioni-di-attivazione-non-lineari"><span class="header-section-number">14.10.1</span> Esercizio 1: Funzioni di attivazione non lineari</h3>
<p>Spiega il ruolo delle funzioni di attivazione non lineari nelle reti MLP: - Perché non è sufficiente usare solo funzioni lineari?<br>
- Cosa accadrebbe alla capacità della rete di apprendere pattern complessi?</p>
</section>
<section id="esercizio-2-confronto-tra-architetture-neurali" class="level3" data-number="14.10.2">
<h3 data-number="14.10.2" class="anchored" data-anchor-id="esercizio-2-confronto-tra-architetture-neurali"><span class="header-section-number">14.10.2</span> Esercizio 2: Confronto tra architetture neurali</h3>
<p>Metti a confronto CNN, RNN e GAN:</p>
<ul>
<li>Qual è il tipo di dati o problema che ciascuna architettura affronta meglio?<br>
</li>
<li>In quali contesti applicativi (es. immagine, testo, generazione di contenuti) useresti ognuna?</li>
</ul>
</section>
<section id="esercizio-3-vantaggi-dei-modelli-pre-addestrati" class="level3" data-number="14.10.3">
<h3 data-number="14.10.3" class="anchored" data-anchor-id="esercizio-3-vantaggi-dei-modelli-pre-addestrati"><span class="header-section-number">14.10.3</span> Esercizio 3: Vantaggi dei modelli pre-addestrati</h3>
<p>Spiega perché può essere utile utilizzare modelli pre-addestrati:</p>
<ul>
<li>Quali sono i principali benefici in termini di tempo, accuratezza e risorse computazionali?<br>
</li>
<li>In quali situazioni l’uso di un modello pre-addestrato è particolarmente indicato?</li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-goodfellow2016deep" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press. <a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a>.
</div>
<div id="ref-goodfellow2014generative" class="csl-entry" role="listitem">
Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. <span>“Generative Adversarial Nets.”</span> In <em>Advances in Neural Information Processing Systems</em>, 2672–80.
</div>
<div id="ref-haykin2009neural" class="csl-entry" role="listitem">
Haykin, Simon. 2009. <em>Neural Networks and Learning Machines</em>. 3rd ed. Pearson.
</div>
<div id="ref-karpathy2015rnn" class="csl-entry" role="listitem">
Karpathy, Andrej. 2015. <span>“The Unreasonable Effectiveness of Recurrent Neural Networks.”</span> <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="uri">https://karpathy.github.io/2015/05/21/rnn-effectiveness/</a>.
</div>
<div id="ref-lecun2015deep" class="csl-entry" role="listitem">
LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. <span>“Deep Learning.”</span> <em>Nature</em> 521 (7553): 436–44.
</div>
<div id="ref-rumelhart1986learning" class="csl-entry" role="listitem">
Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1986. <span>“Learning Representations by Back-Propagating Errors.”</span> <em>Nature</em> 323: 533–36.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "capitanio/laboratorio-ia";
    script.dataset.repoId = "";
    script.dataset.category = "General";
    script.dataset.categoryId = "";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./3-5-perceptrone.html" class="pagination-link" aria-label="Percetptrone">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Percetptrone</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./3-7-elaborazione-linguaggio-naturale.html" class="pagination-link" aria-label="Elaborazione del Linguaggio Naturale">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Elaborazione del Linguaggio Naturale</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Laboratorio di Intelligenza Artificiale (1e) scritto da Luciano Capitanio.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Draft - Licenza Apache ver. 2</p>
</div>
  </div>
</footer>




</body></html>